{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d9c86fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10ec80f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('emails.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68bd4835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Email No.</th>\n",
       "      <th>the</th>\n",
       "      <th>to</th>\n",
       "      <th>ect</th>\n",
       "      <th>and</th>\n",
       "      <th>for</th>\n",
       "      <th>of</th>\n",
       "      <th>a</th>\n",
       "      <th>you</th>\n",
       "      <th>hou</th>\n",
       "      <th>...</th>\n",
       "      <th>connevey</th>\n",
       "      <th>jay</th>\n",
       "      <th>valued</th>\n",
       "      <th>lay</th>\n",
       "      <th>infrastructure</th>\n",
       "      <th>military</th>\n",
       "      <th>allowing</th>\n",
       "      <th>ff</th>\n",
       "      <th>dry</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Email 1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Email 2</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Email 3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Email 4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Email 5</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 3002 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Email No.  the  to  ect  and  for  of    a  you  hou  ...  connevey  jay  \\\n",
       "0   Email 1    0   0    1    0    0   0    2    0    0  ...         0    0   \n",
       "1   Email 2    8  13   24    6    6   2  102    1   27  ...         0    0   \n",
       "2   Email 3    0   0    1    0    0   0    8    0    0  ...         0    0   \n",
       "3   Email 4    0   5   22    0    5   1   51    2   10  ...         0    0   \n",
       "4   Email 5    7   6   17    1    5   2   57    0    9  ...         0    0   \n",
       "\n",
       "   valued  lay  infrastructure  military  allowing  ff  dry  Prediction  \n",
       "0       0    0               0         0         0   0    0           0  \n",
       "1       0    0               0         0         0   1    0           0  \n",
       "2       0    0               0         0         0   0    0           0  \n",
       "3       0    0               0         0         0   0    0           0  \n",
       "4       0    0               0         0         0   1    0           0  \n",
       "\n",
       "[5 rows x 3002 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e74578c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Email No.'].is_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b592947",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Email No.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b6b71ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction\n",
       "0    3672\n",
       "1    1500\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Prediction'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "bd5ba87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, StratifiedShuffleSplit\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "8bc4a74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c711070",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df75a0b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "8039e5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_acc_df(classifies, sp_ls, pcs, n_components, rs_ls):\n",
    "    \n",
    "    n_results_acc = {}\n",
    "    n_results_rep = {}\n",
    "\n",
    "    for cl_name, cl_func in classifies.items():\n",
    "        for p in pcs:\n",
    "            for sp in sp_ls:\n",
    "                for n in n_components:\n",
    "                    for rs in rs_ls:\n",
    "                        acc, rep = sc_pca_class_test(X, y, StandardScaler(), p, n, 0.2, cl_func, sp, rs) \n",
    "                        key_name = cl_name + '_' + sp + '_' + str(p) + '_' + str(n) + '_' + str(rs)\n",
    "                        n_results_acc[key_name] = acc\n",
    "                        n_results_rep[key_name] = rep\n",
    "                        \n",
    "    acc = pd.DataFrame.from_dict(n_results_acc, orient='index')\n",
    "    acc.reset_index(inplace=True)\n",
    "    acc.rename(columns={'index': 'model', 0 : 'accuracy'}, inplace=True)\n",
    "\n",
    "    split_columns = acc['model'].str.split('_', expand=True)\n",
    "\n",
    "    split_columns.columns = ['model_name', 'split_method', 'pca', 'n_components', 'random_state']\n",
    "\n",
    "    acc2 = acc.join(split_columns)\n",
    "    acc2.drop(columns=['model'], inplace=True) \n",
    "    \n",
    "\n",
    "    \n",
    "    return acc2.sort_values(by='accuracy', ascending=False), rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "b038ae29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.983784</td>\n",
       "      <td>0.982456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.959044</td>\n",
       "      <td>0.952542</td>\n",
       "      <td>0.955782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   precision    recall  f1-score\n",
       "0   0.981132  0.983784  0.982456\n",
       "1   0.959044  0.952542  0.955782"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_dc = {}\n",
    "\n",
    "for k in n_results_rep.keys():\n",
    "    n_results_rep[k].loc[['0','1'], ['precision', 'recall', 'f1-score']]\n",
    "    \n",
    "    \n",
    "    ['accuracy', 'weighted avg'], ['precision', 'recall', 'f1-score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a075154a",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = pd.DataFrame.from_dict(n_results_rep, orient='index')\n",
    "acc.reset_index(inplace=True)\n",
    "acc.rename(columns={'index': 'model', 0 : 'accuracy'}, inplace=True)\n",
    "\n",
    "split_columns = acc['model'].str.split('_', expand=True)\n",
    "\n",
    "split_columns.columns = ['model_name', 'split_method', 'pca', 'n_components', 'random_state']\n",
    "\n",
    "acc2 = acc.join(split_columns)\n",
    "acc2.drop(columns=['model'], inplace=True) \n",
    "\n",
    "\n",
    "\n",
    "return acc2.sort_values(by='accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "7cb1288f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(n_results_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656e8e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_results_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "432aed5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "\n",
    "for model,df in n_results_rep.items():\n",
    "    row = df.loc[['weighted avg'], ['precision', 'recall', 'f1-score']].T.to_dict()\n",
    "    row = row['weighted avg']\n",
    "    row['model'] = model\n",
    "    rows.append(row)\n",
    "\n",
    "result_df = pd.DataFrame(rows)\n",
    "\n",
    "result_df = result_df[['model', 'precision', 'recall', 'f1-score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "376f735d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "\n",
    "for model,df in pca_results_rep.items():\n",
    "    row = df.loc[['weighted avg'], ['precision', 'recall', 'f1-score']].T.to_dict()\n",
    "    row = row['weighted avg']\n",
    "    row['model'] = model\n",
    "    rows.append(row)\n",
    "\n",
    "p_result_df = pd.DataFrame(rows)\n",
    "\n",
    "#p_result_df = p_result_df[['model', 'precision', 'recall', 'f1-score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "7a367f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "864"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(p_result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "0561e3c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.975776</td>\n",
       "      <td>0.975845</td>\n",
       "      <td>0.975783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score\n",
       "weighted avg   0.975776  0.975845  0.975783"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_results_rep['RandomForest200_StandardScaler_tt_2'].loc[['weighted avg'], ['precision', 'recall', 'f1-score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "95533db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = create_acc_df({key:value for (key,value) in classifiers.items() if key in ['RandomForest200']}, ['tt'], ['pca'], [25,50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "8a6349ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>model_name</th>\n",
       "      <th>split_method</th>\n",
       "      <th>pca</th>\n",
       "      <th>n_components</th>\n",
       "      <th>random_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.972947</td>\n",
       "      <td>RandomForest200</td>\n",
       "      <td>tt</td>\n",
       "      <td>pca</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.971014</td>\n",
       "      <td>RandomForest200</td>\n",
       "      <td>tt</td>\n",
       "      <td>pca</td>\n",
       "      <td>50</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.969082</td>\n",
       "      <td>RandomForest200</td>\n",
       "      <td>tt</td>\n",
       "      <td>pca</td>\n",
       "      <td>50</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.968116</td>\n",
       "      <td>RandomForest200</td>\n",
       "      <td>tt</td>\n",
       "      <td>pca</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.968116</td>\n",
       "      <td>RandomForest200</td>\n",
       "      <td>tt</td>\n",
       "      <td>pca</td>\n",
       "      <td>25</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.967150</td>\n",
       "      <td>RandomForest200</td>\n",
       "      <td>tt</td>\n",
       "      <td>pca</td>\n",
       "      <td>50</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy       model_name split_method  pca n_components random_state\n",
       "1  0.972947  RandomForest200           tt  pca           25            9\n",
       "3  0.971014  RandomForest200           tt  pca           50           25\n",
       "4  0.969082  RandomForest200           tt  pca           50            9\n",
       "0  0.968116  RandomForest200           tt  pca           25           25\n",
       "2  0.968116  RandomForest200           tt  pca           25          210\n",
       "5  0.967150  RandomForest200           tt  pca           50          210"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f10cfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4326caff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "bc895d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_classifiers = {key:value for (key,value) in classifiers.items() if key in ['RandomForest200', 'RandomForest100','LGBM']}\n",
    "sp_ls_2 = ['tt', 'sss']\n",
    "pcs = ['pca','svd', 'None']\n",
    "n_components = [100, 75, 125]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "ddc7b938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.983784</td>\n",
       "      <td>0.982456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.959044</td>\n",
       "      <td>0.952542</td>\n",
       "      <td>0.955782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   precision    recall  f1-score\n",
       "0   0.981132  0.983784  0.982456\n",
       "1   0.959044  0.952542  0.955782"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56924443",
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in [0,1]:\n",
    "    df.loc[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "4275bac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1205, number of negative: 2932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021694 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23809\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2610\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.291274 -> initscore=-0.889205\n",
      "[LightGBM] [Info] Start training from score -0.889205\n",
      "[LightGBM] [Info] Number of positive: 1213, number of negative: 2924\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020869 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23679\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2585\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.293208 -> initscore=-0.879856\n",
      "[LightGBM] [Info] Start training from score -0.879856\n",
      "[LightGBM] [Info] Number of positive: 1203, number of negative: 2934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021413 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23660\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2580\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290790 -> initscore=-0.891548\n",
      "[LightGBM] [Info] Start training from score -0.891548\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023117 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23415\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2564\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021393 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23523\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2564\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021393 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23380\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2577\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n"
     ]
    }
   ],
   "source": [
    "n_results_acc = {}\n",
    "n_results_rep = {}\n",
    "\n",
    "for cl_name, cl_func in top_classifiers.items():\n",
    "    for p in pcs:\n",
    "        for sp in sp_ls_2:\n",
    "            for n in n_components:\n",
    "                for rs in [25, 9, 210]:\n",
    "                    acc, rep = sc_pca_class_test(X, y, StandardScaler(), p, n, 0.2, cl_func, sp, rs) \n",
    "                    key_name = cl_name + '_' + sp + '_' + str(p) + '_' + str(n_components) + '_' + str(rs)\n",
    "                    n_results_acc[key_name] = acc\n",
    "                    n_results_rep[key_name] = rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "60109a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = pd.DataFrame.from_dict(n_results_acc, orient='index')\n",
    "acc.reset_index(inplace=True)\n",
    "acc.rename(columns={'index': 'model', 0 : 'accuracy'}, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f729e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(p_result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "44d39258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.950304</td>\n",
       "      <td>0.949758</td>\n",
       "      <td>0.948884</td>\n",
       "      <td>LogisticRegression_StandardScaler_tt_25_25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.947511</td>\n",
       "      <td>0.947826</td>\n",
       "      <td>0.947459</td>\n",
       "      <td>LogisticRegression_StandardScaler_tt_25_105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.930364</td>\n",
       "      <td>0.930435</td>\n",
       "      <td>0.929140</td>\n",
       "      <td>LogisticRegression_StandardScaler_tt_25_94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.964107</td>\n",
       "      <td>0.964251</td>\n",
       "      <td>0.964126</td>\n",
       "      <td>LogisticRegression_StandardScaler_tt_50_25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.963568</td>\n",
       "      <td>0.963285</td>\n",
       "      <td>0.963389</td>\n",
       "      <td>LogisticRegression_StandardScaler_tt_50_105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>0.956357</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.956413</td>\n",
       "      <td>ADABoost_200_MinMaxScaler_sss_75_105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>0.948063</td>\n",
       "      <td>0.947826</td>\n",
       "      <td>0.947928</td>\n",
       "      <td>ADABoost_200_MinMaxScaler_sss_75_94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>0.952535</td>\n",
       "      <td>0.952657</td>\n",
       "      <td>0.952586</td>\n",
       "      <td>ADABoost_200_MinMaxScaler_sss_100_25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>0.954415</td>\n",
       "      <td>0.954589</td>\n",
       "      <td>0.954476</td>\n",
       "      <td>ADABoost_200_MinMaxScaler_sss_100_105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>0.944875</td>\n",
       "      <td>0.944928</td>\n",
       "      <td>0.944900</td>\n",
       "      <td>ADABoost_200_MinMaxScaler_sss_100_94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>864 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     precision    recall  f1-score  \\\n",
       "0     0.950304  0.949758  0.948884   \n",
       "1     0.947511  0.947826  0.947459   \n",
       "2     0.930364  0.930435  0.929140   \n",
       "3     0.964107  0.964251  0.964126   \n",
       "4     0.963568  0.963285  0.963389   \n",
       "..         ...       ...       ...   \n",
       "859   0.956357  0.956522  0.956413   \n",
       "860   0.948063  0.947826  0.947928   \n",
       "861   0.952535  0.952657  0.952586   \n",
       "862   0.954415  0.954589  0.954476   \n",
       "863   0.944875  0.944928  0.944900   \n",
       "\n",
       "                                           model  \n",
       "0     LogisticRegression_StandardScaler_tt_25_25  \n",
       "1    LogisticRegression_StandardScaler_tt_25_105  \n",
       "2     LogisticRegression_StandardScaler_tt_25_94  \n",
       "3     LogisticRegression_StandardScaler_tt_50_25  \n",
       "4    LogisticRegression_StandardScaler_tt_50_105  \n",
       "..                                           ...  \n",
       "859         ADABoost_200_MinMaxScaler_sss_75_105  \n",
       "860          ADABoost_200_MinMaxScaler_sss_75_94  \n",
       "861         ADABoost_200_MinMaxScaler_sss_100_25  \n",
       "862        ADABoost_200_MinMaxScaler_sss_100_105  \n",
       "863         ADABoost_200_MinMaxScaler_sss_100_94  \n",
       "\n",
       "[864 rows x 4 columns]"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "0e072f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_res_5 = p_result_df[p_result_df.underscore_count == 5]\n",
    "p_res_4 = p_result_df[p_result_df.underscore_count == 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "2bfeefd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mitch\\AppData\\Local\\Temp\\ipykernel_25184\\3063789221.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  p_res_5['model'] = p_res_5['model'].apply(lambda x: x.replace('_', '', 1))\n"
     ]
    }
   ],
   "source": [
    "p_res_5['model'] = p_res_5['model'].apply(lambda x: x.replace('_', '', 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "d8b76ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_res_5['underscore_count'] = p_res_5['model'].str.count('_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "a52c6606",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp['underscore_count'] = pp['model'].str.count('_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "7723a9f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "underscore_count\n",
       "4    864\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp.underscore_count.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "ee6c9422",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = pd.concat([p_res_4, p_res_5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "53ba2e58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>model</th>\n",
       "      <th>underscore_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.950304</td>\n",
       "      <td>0.949758</td>\n",
       "      <td>0.948884</td>\n",
       "      <td>LogisticRegression_StandardScaler_tt_25_25</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.947511</td>\n",
       "      <td>0.947826</td>\n",
       "      <td>0.947459</td>\n",
       "      <td>LogisticRegression_StandardScaler_tt_25_105</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.930364</td>\n",
       "      <td>0.930435</td>\n",
       "      <td>0.929140</td>\n",
       "      <td>LogisticRegression_StandardScaler_tt_25_94</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.964107</td>\n",
       "      <td>0.964251</td>\n",
       "      <td>0.964126</td>\n",
       "      <td>LogisticRegression_StandardScaler_tt_50_25</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.963568</td>\n",
       "      <td>0.963285</td>\n",
       "      <td>0.963389</td>\n",
       "      <td>LogisticRegression_StandardScaler_tt_50_105</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>0.956357</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.956413</td>\n",
       "      <td>ADABoost200_MinMaxScaler_sss_75_105</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>0.948063</td>\n",
       "      <td>0.947826</td>\n",
       "      <td>0.947928</td>\n",
       "      <td>ADABoost200_MinMaxScaler_sss_75_94</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>0.952535</td>\n",
       "      <td>0.952657</td>\n",
       "      <td>0.952586</td>\n",
       "      <td>ADABoost200_MinMaxScaler_sss_100_25</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>0.954415</td>\n",
       "      <td>0.954589</td>\n",
       "      <td>0.954476</td>\n",
       "      <td>ADABoost200_MinMaxScaler_sss_100_105</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>0.944875</td>\n",
       "      <td>0.944928</td>\n",
       "      <td>0.944900</td>\n",
       "      <td>ADABoost200_MinMaxScaler_sss_100_94</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>864 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     precision    recall  f1-score  \\\n",
       "0     0.950304  0.949758  0.948884   \n",
       "1     0.947511  0.947826  0.947459   \n",
       "2     0.930364  0.930435  0.929140   \n",
       "3     0.964107  0.964251  0.964126   \n",
       "4     0.963568  0.963285  0.963389   \n",
       "..         ...       ...       ...   \n",
       "859   0.956357  0.956522  0.956413   \n",
       "860   0.948063  0.947826  0.947928   \n",
       "861   0.952535  0.952657  0.952586   \n",
       "862   0.954415  0.954589  0.954476   \n",
       "863   0.944875  0.944928  0.944900   \n",
       "\n",
       "                                           model  underscore_count  \n",
       "0     LogisticRegression_StandardScaler_tt_25_25                 4  \n",
       "1    LogisticRegression_StandardScaler_tt_25_105                 4  \n",
       "2     LogisticRegression_StandardScaler_tt_25_94                 4  \n",
       "3     LogisticRegression_StandardScaler_tt_50_25                 4  \n",
       "4    LogisticRegression_StandardScaler_tt_50_105                 4  \n",
       "..                                           ...               ...  \n",
       "859          ADABoost200_MinMaxScaler_sss_75_105                 4  \n",
       "860           ADABoost200_MinMaxScaler_sss_75_94                 4  \n",
       "861          ADABoost200_MinMaxScaler_sss_100_25                 4  \n",
       "862         ADABoost200_MinMaxScaler_sss_100_105                 4  \n",
       "863          ADABoost200_MinMaxScaler_sss_100_94                 4  \n",
       "\n",
       "[864 rows x 5 columns]"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "630abe81",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp2 = dfc(pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "7d652837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>model_name</th>\n",
       "      <th>scaler</th>\n",
       "      <th>split_method</th>\n",
       "      <th>random_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.950304</td>\n",
       "      <td>0.949758</td>\n",
       "      <td>0.948884</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>tt</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.947511</td>\n",
       "      <td>0.947826</td>\n",
       "      <td>0.947459</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>tt</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.930364</td>\n",
       "      <td>0.930435</td>\n",
       "      <td>0.929140</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>tt</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.964107</td>\n",
       "      <td>0.964251</td>\n",
       "      <td>0.964126</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>tt</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.963568</td>\n",
       "      <td>0.963285</td>\n",
       "      <td>0.963389</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>tt</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>0.956357</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.956413</td>\n",
       "      <td>ADABoost200</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>sss</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>0.948063</td>\n",
       "      <td>0.947826</td>\n",
       "      <td>0.947928</td>\n",
       "      <td>ADABoost200</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>sss</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>0.952535</td>\n",
       "      <td>0.952657</td>\n",
       "      <td>0.952586</td>\n",
       "      <td>ADABoost200</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>sss</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>0.954415</td>\n",
       "      <td>0.954589</td>\n",
       "      <td>0.954476</td>\n",
       "      <td>ADABoost200</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>sss</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>0.944875</td>\n",
       "      <td>0.944928</td>\n",
       "      <td>0.944900</td>\n",
       "      <td>ADABoost200</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>sss</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>864 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     precision    recall  f1-score          model_name          scaler  \\\n",
       "0     0.950304  0.949758  0.948884  LogisticRegression  StandardScaler   \n",
       "1     0.947511  0.947826  0.947459  LogisticRegression  StandardScaler   \n",
       "2     0.930364  0.930435  0.929140  LogisticRegression  StandardScaler   \n",
       "3     0.964107  0.964251  0.964126  LogisticRegression  StandardScaler   \n",
       "4     0.963568  0.963285  0.963389  LogisticRegression  StandardScaler   \n",
       "..         ...       ...       ...                 ...             ...   \n",
       "859   0.956357  0.956522  0.956413         ADABoost200    MinMaxScaler   \n",
       "860   0.948063  0.947826  0.947928         ADABoost200    MinMaxScaler   \n",
       "861   0.952535  0.952657  0.952586         ADABoost200    MinMaxScaler   \n",
       "862   0.954415  0.954589  0.954476         ADABoost200    MinMaxScaler   \n",
       "863   0.944875  0.944928  0.944900         ADABoost200    MinMaxScaler   \n",
       "\n",
       "    split_method random_state  \n",
       "0             tt           25  \n",
       "1             tt          105  \n",
       "2             tt           94  \n",
       "3             tt           25  \n",
       "4             tt          105  \n",
       "..           ...          ...  \n",
       "859          sss          105  \n",
       "860          sss           94  \n",
       "861          sss           25  \n",
       "862          sss          105  \n",
       "863          sss           94  \n",
       "\n",
       "[864 rows x 7 columns]"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp2.drop(columns=['n_components', 'underscore_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "a84e7e92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['LogisticRegression', 'SVMLinear', 'SVMSigmoid', 'LGBM', 'GrdBst',\n",
       "       'RandomForest100', 'RandomForest200', 'KNN5n', 'KNN15n', 'KNN25n',\n",
       "       'ADABoost100', 'ADABoost200'], dtype=object)"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp2.model_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "5ce8db32",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_pp2 = pp2[['model_name','scaler','precision','recall','f1-score']].groupby(['model_name', 'scaler']).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "8ca8d1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_pp2['combination'] = mean_pp2['model_name'] + '_' + mean_pp2['scaler']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "11e83697",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "817aa80f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Plot lines for precision, recall, and f1-score\n",
    "for metric in ['precision', 'recall', 'f1-score']:\n",
    "    ax.plot(mean_pp2['combination'], mean_pp2[metric], marker='o', label=metric)\n",
    "\n",
    "# Add labels and title\n",
    "ax.set_xlabel('Model and Scaler Combination')\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('Precision, Recall, and F1-Score by Model and Scaler Combination')\n",
    "ax.legend(title='Metrics', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Rotate x-axis labels for better readability\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1ddcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size = 0.1, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5431505d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8709b989",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7e5bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Unique model and scaler combinations\n",
    "combinations = mean_df.groupby(['model_name', 'scaler'])\n",
    "\n",
    "# Plot lines for each combination\n",
    "for (model_name, scaler), group in combinations:\n",
    "    ax.plot(group['scaler'], group['precision'], marker='o', label=f'{model_name} - Precision')\n",
    "    ax.plot(group['scaler'], group['recall'], marker='o', label=f'{model_name} - Recall')\n",
    "    ax.plot(group['scaler'], group['f1-score'], marker='o', label=f'{model_name} - F1-Score')\n",
    "\n",
    "# Add labels and title\n",
    "ax.set_xlabel('Scaler')\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('Precision, Recall, and F1-Score by Model and Scaler')\n",
    "ax.legend(title='Legend', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25208a03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "504e2623",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfc(df):\n",
    "    \n",
    "    split_columns = df['model'].str.split('_', expand=True)\n",
    "\n",
    "    split_columns.columns = ['model_name', 'scaler', 'split_method', 'n_components', 'random_state']\n",
    "\n",
    "    df2 = df.join(split_columns)\n",
    "\n",
    "    # Optionally, drop the original 'model' column\n",
    "    df2.drop(columns=['model'], inplace=True)\n",
    "    \n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "f4ec9da6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 6 elements, new values have 4 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[263], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m split_columns \u001b[38;5;241m=\u001b[39m p_result_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m, expand\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 3\u001b[0m split_columns\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_name\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscaler\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msplit_method\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom_state\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      5\u001b[0m p_res_df \u001b[38;5;241m=\u001b[39m p_result_df\u001b[38;5;241m.\u001b[39mjoin(split_columns)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Optionally, drop the original 'model' column\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:6218\u001b[0m, in \u001b[0;36mNDFrame.__setattr__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m   6216\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   6217\u001b[0m     \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name)\n\u001b[1;32m-> 6218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, value)\n\u001b[0;32m   6219\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[0;32m   6220\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32mproperties.pyx:69\u001b[0m, in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:767\u001b[0m, in \u001b[0;36mNDFrame._set_axis\u001b[1;34m(self, axis, labels)\u001b[0m\n\u001b[0;32m    762\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    763\u001b[0m \u001b[38;5;124;03mThis is called from the cython code when we set the `index` attribute\u001b[39;00m\n\u001b[0;32m    764\u001b[0m \u001b[38;5;124;03mdirectly, e.g. `series.index = [1, 2, 3]`.\u001b[39;00m\n\u001b[0;32m    765\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    766\u001b[0m labels \u001b[38;5;241m=\u001b[39m ensure_index(labels)\n\u001b[1;32m--> 767\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mset_axis(axis, labels)\n\u001b[0;32m    768\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:227\u001b[0m, in \u001b[0;36mBaseBlockManager.set_axis\u001b[1;34m(self, axis, new_labels)\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_axis\u001b[39m(\u001b[38;5;28mself\u001b[39m, axis: AxisInt, new_labels: Index) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    226\u001b[0m     \u001b[38;5;66;03m# Caller is responsible for ensuring we have an Index object.\u001b[39;00m\n\u001b[1;32m--> 227\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_set_axis(axis, new_labels)\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis] \u001b[38;5;241m=\u001b[39m new_labels\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\base.py:85\u001b[0m, in \u001b[0;36mDataManager._validate_set_axis\u001b[1;34m(self, axis, new_labels)\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m new_len \u001b[38;5;241m!=\u001b[39m old_len:\n\u001b[1;32m---> 85\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     86\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength mismatch: Expected axis has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mold_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements, new \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     87\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     88\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Length mismatch: Expected axis has 6 elements, new values have 4 elements"
     ]
    }
   ],
   "source": [
    "split_columns = p_result_df['model'].str.split('_', expand=True)\n",
    "\n",
    "split_columns.columns = ['model_name', 'scaler', 'split_method', 'random_state']\n",
    "\n",
    "p_res_df = p_result_df.join(split_columns)\n",
    "\n",
    "# Optionally, drop the original 'model' column\n",
    "p_res_df.drop(columns=['model'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "83701d76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>model_name</th>\n",
       "      <th>scaler</th>\n",
       "      <th>split_method</th>\n",
       "      <th>random_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.981643</td>\n",
       "      <td>RandomForest200</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>tt</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.980676</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>tt</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.979710</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>sss</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.976812</td>\n",
       "      <td>RandomForest100</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>sss</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.976812</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>sss</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.975845</td>\n",
       "      <td>RandomForest200</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>tt</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.975845</td>\n",
       "      <td>RandomForest200</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>sss</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.975845</td>\n",
       "      <td>RandomForest100</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>tt</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.974879</td>\n",
       "      <td>RandomForest100</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>tt</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.974879</td>\n",
       "      <td>RandomForest200</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>sss</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.974879</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>tt</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.972947</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>sss</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.972947</td>\n",
       "      <td>RandomForest200</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>tt</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.971981</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>tt</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.971014</td>\n",
       "      <td>RandomForest100</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>sss</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.971014</td>\n",
       "      <td>RandomForest100</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>tt</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.970048</td>\n",
       "      <td>RandomForest200</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>sss</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.969082</td>\n",
       "      <td>RandomForest100</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>sss</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.955556</td>\n",
       "      <td>SVMLinear</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>sss</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.951691</td>\n",
       "      <td>SVMLinear</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>tt</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.944928</td>\n",
       "      <td>SVMLinear</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>tt</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.944928</td>\n",
       "      <td>SVMLinear</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>sss</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.941063</td>\n",
       "      <td>SVMLinear</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>sss</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.937198</td>\n",
       "      <td>SVMLinear</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>tt</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    accuracy       model_name          scaler split_method random_state\n",
       "8   0.981643  RandomForest200  StandardScaler           tt          410\n",
       "19  0.980676             LGBM  StandardScaler           tt           52\n",
       "22  0.979710             LGBM  StandardScaler          sss           52\n",
       "3   0.976812  RandomForest100  StandardScaler          sss            2\n",
       "21  0.976812             LGBM  StandardScaler          sss            2\n",
       "6   0.975845  RandomForest200  StandardScaler           tt            2\n",
       "9   0.975845  RandomForest200  StandardScaler          sss            2\n",
       "1   0.975845  RandomForest100  StandardScaler           tt           52\n",
       "0   0.974879  RandomForest100  StandardScaler           tt            2\n",
       "11  0.974879  RandomForest200  StandardScaler          sss          410\n",
       "20  0.974879             LGBM  StandardScaler           tt          410\n",
       "23  0.972947             LGBM  StandardScaler          sss          410\n",
       "7   0.972947  RandomForest200  StandardScaler           tt           52\n",
       "18  0.971981             LGBM  StandardScaler           tt            2\n",
       "4   0.971014  RandomForest100  StandardScaler          sss           52\n",
       "2   0.971014  RandomForest100  StandardScaler           tt          410\n",
       "10  0.970048  RandomForest200  StandardScaler          sss           52\n",
       "5   0.969082  RandomForest100  StandardScaler          sss          410\n",
       "15  0.955556        SVMLinear  StandardScaler          sss            2\n",
       "13  0.951691        SVMLinear  StandardScaler           tt           52\n",
       "14  0.944928        SVMLinear  StandardScaler           tt          410\n",
       "17  0.944928        SVMLinear  StandardScaler          sss          410\n",
       "16  0.941063        SVMLinear  StandardScaler          sss           52\n",
       "12  0.937198        SVMLinear  StandardScaler           tt            2"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc2.sort_values(by='accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "6bdf7b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lda'"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'lda_svd'[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "f36edc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "5f5e2fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "k1, k2 = sc_pca_class_test(X, y, StandardScaler(), 'svd', 25, 0.2, RandomForestClassifier(n_estimators=175), 'tt', 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "80e2fc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c953370d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sc_pca_class_test(X, y, scaler, reduce, components, ts, classifier, split_method, rs):\n",
    "\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "        \n",
    "    r_params = {'n_components': components, 'random_state': rs}\n",
    "    \n",
    "    r_dc = {'pca': PCA(**r_params),\n",
    "            'svd' : TruncatedSVD(**r_params),\n",
    "            'tsne': TSNE(**r_params),\n",
    "            'lda_svd' : LDA(solver= 'svd'),\n",
    "            'lda_eigen' : LDA(solver='eigen'),\n",
    "            'lda_lsqr' : LDA(solver='lsqr')}\n",
    "    \n",
    "    if reduce in r_dc.keys():\n",
    "        if reduce[:3].lower() == 'lda':\n",
    "            X_reduced = r_dc[reduce].fit_transform(X_scaled, y)\n",
    "        else:\n",
    "            X_reduced = r_dc[reduce].fit_transform(X_scaled)\n",
    "    else: \n",
    "        X_reduced = X_scaled.copy()   \n",
    "        \n",
    "    n_splits=int((1/ts))\n",
    "    \n",
    "    split_dc = {\n",
    "           'skf' : StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=rs),\n",
    "            'sss' : StratifiedShuffleSplit(n_splits=n_splits, test_size=ts, random_state=rs),    \n",
    "            'kf': KFold(n_splits=n_splits, shuffle=True, random_state=rs)\n",
    "    }\n",
    "    \n",
    "\n",
    "    if split_method == 'tt':\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_reduced, y, test_size=ts, random_state=rs)\n",
    "        \n",
    "    elif split_method in split_dc.keys():\n",
    "        \n",
    "        for train_index, test_index in split_dc[split_method].split(X_reduced, y):\n",
    "            X_train, X_test = X_reduced[train_index], X_reduced[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "    else:\n",
    "        print(split_method + ' not allowed')\n",
    "        return 'FAILURE'\n",
    "    \n",
    "    classifier.fit(X_train, y_train)    \n",
    "    \n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report_dc = classification_report(y_test, y_pred, output_dict=True)\n",
    "    report_df = pd.DataFrame(report_dc).transpose()\n",
    "    \n",
    "    return accuracy, report_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "31c4c061",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "n_components cannot be larger than min(n_features, n_classes - 1).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[324], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m bac, brep \u001b[38;5;241m=\u001b[39m sc_pca_class_test(X, y, StandardScaler(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlda_svd\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m0.2\u001b[39m, RandomForestClassifier(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m42\u001b[39m)\n",
      "Cell \u001b[1;32mIn[319], line 14\u001b[0m, in \u001b[0;36msc_pca_class_test\u001b[1;34m(X, y, scaler, reduce, components, ts, classifier, split_method, rs)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reduce \u001b[38;5;129;01min\u001b[39;00m r_dc\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m reduce[:\u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlda\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m---> 14\u001b[0m         X_reduced \u001b[38;5;241m=\u001b[39m r_dc[reduce]\u001b[38;5;241m.\u001b[39mfit_transform(X_scaled, y)\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     16\u001b[0m         X_reduced \u001b[38;5;241m=\u001b[39m r_dc[reduce]\u001b[38;5;241m.\u001b[39mfit_transform(X_scaled)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:870\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    867\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m--> 870\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:582\u001b[0m, in \u001b[0;36mLinearDiscriminantAnalysis.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    580\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    581\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components \u001b[38;5;241m>\u001b[39m max_components:\n\u001b[1;32m--> 582\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    583\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_components cannot be larger than min(n_features, n_classes - 1).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    584\u001b[0m         )\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_components \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components\n\u001b[0;32m    587\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msolver \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msvd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;31mValueError\u001b[0m: n_components cannot be larger than min(n_features, n_classes - 1)."
     ]
    }
   ],
   "source": [
    "bac, brep = sc_pca_class_test(X, y, StandardScaler(), 'lda_svd', 5, 0.2, RandomForestClassifier(), 'tt', 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d242b75a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1db3a20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf089ef2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0bed21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "a67ae29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Fetch data (we use newsgroups data for demonstration; replace with actual email spam dataset)\n",
    "newsgroups = fetch_20newsgroups(subset='all', categories=['alt.atheism', 'soc.religion.christian'])\n",
    "X = newsgroups.data\n",
    "y = newsgroups.target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "c9a29071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1796\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1796"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(str(len(X)))\n",
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "839d0c33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "be1e4c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text data to TF-IDF features\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X_tfidf = vectorizer.fit_transform(X)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "5974666c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD Solver\n",
      "Accuracy: 0.8831168831168831\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.83      0.86       235\n",
      "           1       0.88      0.92      0.90       304\n",
      "\n",
      "    accuracy                           0.88       539\n",
      "   macro avg       0.88      0.88      0.88       539\n",
      "weighted avg       0.88      0.88      0.88       539\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create LDA model using SVD solver\n",
    "lda_svd = LinearDiscriminantAnalysis(solver='svd')\n",
    "lda_svd.fit(X_train.toarray(), y_train)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "y_pred_svd = lda_svd.predict(X_test.toarray())\n",
    "print(\"SVD Solver\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_svd))\n",
    "print(classification_report(y_test, y_pred_svd))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "8befcd7c",
   "metadata": {},
   "outputs": [
    {
     "ename": "LinAlgError",
     "evalue": "The leading minor of order 12 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[336], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Create LDA model using Eigen solver\u001b[39;00m\n\u001b[0;32m      2\u001b[0m lda_eigen \u001b[38;5;241m=\u001b[39m LinearDiscriminantAnalysis(solver\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meigen\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m lda_eigen\u001b[38;5;241m.\u001b[39mfit(X_train\u001b[38;5;241m.\u001b[39mtoarray(), y_train)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Make predictions and evaluate\u001b[39;00m\n\u001b[0;32m      6\u001b[0m y_pred_eigen \u001b[38;5;241m=\u001b[39m lda_eigen\u001b[38;5;241m.\u001b[39mpredict(X_test\u001b[38;5;241m.\u001b[39mtoarray())\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:605\u001b[0m, in \u001b[0;36mLinearDiscriminantAnalysis.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    598\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_solve_lsqr(\n\u001b[0;32m    599\u001b[0m         X,\n\u001b[0;32m    600\u001b[0m         y,\n\u001b[0;32m    601\u001b[0m         shrinkage\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshrinkage,\n\u001b[0;32m    602\u001b[0m         covariance_estimator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcovariance_estimator,\n\u001b[0;32m    603\u001b[0m     )\n\u001b[0;32m    604\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msolver \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meigen\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 605\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_solve_eigen(\n\u001b[0;32m    606\u001b[0m         X,\n\u001b[0;32m    607\u001b[0m         y,\n\u001b[0;32m    608\u001b[0m         shrinkage\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshrinkage,\n\u001b[0;32m    609\u001b[0m         covariance_estimator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcovariance_estimator,\n\u001b[0;32m    610\u001b[0m     )\n\u001b[0;32m    611\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    612\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    613\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munknown solver \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m (valid solvers are \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msvd\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    614\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlsqr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meigen\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msolver)\n\u001b[0;32m    615\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:445\u001b[0m, in \u001b[0;36mLinearDiscriminantAnalysis._solve_eigen\u001b[1;34m(self, X, y, shrinkage, covariance_estimator)\u001b[0m\n\u001b[0;32m    442\u001b[0m St \u001b[38;5;241m=\u001b[39m _cov(X, shrinkage, covariance_estimator)  \u001b[38;5;66;03m# total scatter\u001b[39;00m\n\u001b[0;32m    443\u001b[0m Sb \u001b[38;5;241m=\u001b[39m St \u001b[38;5;241m-\u001b[39m Sw  \u001b[38;5;66;03m# between scatter\u001b[39;00m\n\u001b[1;32m--> 445\u001b[0m evals, evecs \u001b[38;5;241m=\u001b[39m linalg\u001b[38;5;241m.\u001b[39meigh(Sb, Sw)\n\u001b[0;32m    446\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexplained_variance_ratio_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msort(evals \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39msum(evals))[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\n\u001b[0;32m    447\u001b[0m     : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_components\n\u001b[0;32m    448\u001b[0m ]\n\u001b[0;32m    449\u001b[0m evecs \u001b[38;5;241m=\u001b[39m evecs[:, np\u001b[38;5;241m.\u001b[39margsort(evals)[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]]  \u001b[38;5;66;03m# sort eigenvectors\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\scipy\\linalg\\_decomp.py:594\u001b[0m, in \u001b[0;36meigh\u001b[1;34m(a, b, lower, eigvals_only, overwrite_a, overwrite_b, turbo, eigvals, type, check_finite, subset_by_index, subset_by_value, driver)\u001b[0m\n\u001b[0;32m    591\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIllegal value in argument \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m of internal \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    592\u001b[0m                       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;241m-\u001b[39minfo, drv\u001b[38;5;241m.\u001b[39mtypecode \u001b[38;5;241m+\u001b[39m pfx \u001b[38;5;241m+\u001b[39m driver))\n\u001b[0;32m    593\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m info \u001b[38;5;241m>\u001b[39m n:\n\u001b[1;32m--> 594\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe leading minor of order \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m of B is not \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    595\u001b[0m                       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpositive definite. The factorization of B \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    596\u001b[0m                       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcould not be completed and no eigenvalues \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    597\u001b[0m                       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mor eigenvectors were computed.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(info\u001b[38;5;241m-\u001b[39mn))\n\u001b[0;32m    598\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    599\u001b[0m     drv_err \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mev\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe algorithm failed to converge; \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    600\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moff-diagonal elements of an intermediate \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    601\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtridiagonal form did not converge to zero.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    606\u001b[0m                \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevr\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInternal Error.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    607\u001b[0m                }\n",
      "\u001b[1;31mLinAlgError\u001b[0m: The leading minor of order 12 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed."
     ]
    }
   ],
   "source": [
    "# Create LDA model using Eigen solver\n",
    "lda_eigen = LinearDiscriminantAnalysis(solver='eigen')\n",
    "lda_eigen.fit(X_train.toarray(), y_train)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "y_pred_eigen = lda_eigen.predict(X_test.toarray())\n",
    "print(\"Eigen Solver\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_eigen))\n",
    "print(classification_report(y_test, y_pred_eigen))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "3e3402de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSQR Solver\n",
      "Accuracy: 0.5139146567717996\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.49      0.47       235\n",
      "           1       0.57      0.53      0.55       304\n",
      "\n",
      "    accuracy                           0.51       539\n",
      "   macro avg       0.51      0.51      0.51       539\n",
      "weighted avg       0.52      0.51      0.52       539\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create LDA model using LSQR solver\n",
    "lda_lsqr = LinearDiscriminantAnalysis(solver='lsqr')\n",
    "lda_lsqr.fit(X_train.toarray(), y_train)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "y_pred_lsqr = lda_lsqr.predict(X_test.toarray())\n",
    "print(\"LSQR Solver\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_lsqr))\n",
    "print(classification_report(y_test, y_pred_lsqr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ed733b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3a6d0aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale\n",
      "pca\n"
     ]
    }
   ],
   "source": [
    "c1, c2 = sc_pca_class_test(X, y, mm_sc, 50, 0.2, LogisticRegression(), 'skf', 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "210b609c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.962060</td>\n",
       "      <td>0.967302</td>\n",
       "      <td>0.964674</td>\n",
       "      <td>734.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.918919</td>\n",
       "      <td>0.906667</td>\n",
       "      <td>0.912752</td>\n",
       "      <td>300.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.949710</td>\n",
       "      <td>0.949710</td>\n",
       "      <td>0.949710</td>\n",
       "      <td>0.94971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.940489</td>\n",
       "      <td>0.936985</td>\n",
       "      <td>0.938713</td>\n",
       "      <td>1034.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.949543</td>\n",
       "      <td>0.949710</td>\n",
       "      <td>0.949609</td>\n",
       "      <td>1034.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "0              0.962060  0.967302  0.964674   734.00000\n",
       "1              0.918919  0.906667  0.912752   300.00000\n",
       "accuracy       0.949710  0.949710  0.949710     0.94971\n",
       "macro avg      0.940489  0.936985  0.938713  1034.00000\n",
       "weighted avg   0.949543  0.949710  0.949609  1034.00000"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4f9c3b65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9497098646034816"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e2913611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(int((1/0.2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32e28876",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Prediction']\n",
    "X = df.drop(columns=['Prediction'])\n",
    "\n",
    "\n",
    "mm_sc = MinMaxScaler()\n",
    "sc_sc = StandardScaler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84a1cccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data\n",
    "X_scaled = mm_sc.fit_transform(X)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=25)\n",
    "X_pca = pca.fit_transform(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e1906706",
   "metadata": {},
   "outputs": [],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d037a2ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "17d30c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, test_index in sss.split(X_pca, y):\n",
    "    X_train, X_test = X_pca[train_index], X_pca[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "40e5e95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eeaf6e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "05bb9e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fbf0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "        sss = StratifiedShuffleSplit(n_splits=int((1/ts)), test_size=ts, random_state=rs)\n",
    "        \n",
    "        for train_index, test_index in sss.split(X_pca, y):\n",
    "            X_train, X_test = X_pca[train_index], X_pca[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceaaf0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_test, rep_test = sc_pca_class_test(X, y, mm_sc, 0.2, 25, LogisticRegression(), 'sss', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205cccba",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c05b0395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1199, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001616 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6375\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289824 -> initscore=-0.896241\n",
      "[LightGBM] [Info] Start training from score -0.896241\n",
      "[LightGBM] [Info] Number of positive: 1196, number of negative: 2941\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000485 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6375\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289098 -> initscore=-0.899767\n",
      "[LightGBM] [Info] Start training from score -0.899767\n",
      "[LightGBM] [Info] Number of positive: 1199, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000827 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6375\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289824 -> initscore=-0.896241\n",
      "[LightGBM] [Info] Start training from score -0.896241\n",
      "[LightGBM] [Info] Number of positive: 1199, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001194 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12750\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 50\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289824 -> initscore=-0.896241\n",
      "[LightGBM] [Info] Start training from score -0.896241\n",
      "[LightGBM] [Info] Number of positive: 1196, number of negative: 2941\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001149 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12750\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 50\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289098 -> initscore=-0.899767\n",
      "[LightGBM] [Info] Start training from score -0.899767\n",
      "[LightGBM] [Info] Number of positive: 1199, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001148 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12750\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 50\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289824 -> initscore=-0.896241\n",
      "[LightGBM] [Info] Start training from score -0.896241\n",
      "[LightGBM] [Info] Number of positive: 1199, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001715 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19125\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289824 -> initscore=-0.896241\n",
      "[LightGBM] [Info] Start training from score -0.896241\n",
      "[LightGBM] [Info] Number of positive: 1196, number of negative: 2941\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001738 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19125\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289098 -> initscore=-0.899767\n",
      "[LightGBM] [Info] Start training from score -0.899767\n",
      "[LightGBM] [Info] Number of positive: 1199, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001707 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19125\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289824 -> initscore=-0.896241\n",
      "[LightGBM] [Info] Start training from score -0.896241\n",
      "[LightGBM] [Info] Number of positive: 1199, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002161 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 25500\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289824 -> initscore=-0.896241\n",
      "[LightGBM] [Info] Start training from score -0.896241\n",
      "[LightGBM] [Info] Number of positive: 1196, number of negative: 2941\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002634 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 25500\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289098 -> initscore=-0.899767\n",
      "[LightGBM] [Info] Start training from score -0.899767\n",
      "[LightGBM] [Info] Number of positive: 1199, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002466 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 25500\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289824 -> initscore=-0.896241\n",
      "[LightGBM] [Info] Start training from score -0.896241\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000991 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6375\n",
      "[LightGBM] [Info] Number of data points in the train set: 4138, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289995 -> initscore=-0.895408\n",
      "[LightGBM] [Info] Start training from score -0.895408\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000480 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6375\n",
      "[LightGBM] [Info] Number of data points in the train set: 4138, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289995 -> initscore=-0.895408\n",
      "[LightGBM] [Info] Start training from score -0.895408\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000492 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6375\n",
      "[LightGBM] [Info] Number of data points in the train set: 4138, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289995 -> initscore=-0.895408\n",
      "[LightGBM] [Info] Start training from score -0.895408\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001138 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12750\n",
      "[LightGBM] [Info] Number of data points in the train set: 4138, number of used features: 50\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289995 -> initscore=-0.895408\n",
      "[LightGBM] [Info] Start training from score -0.895408\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001223 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12750\n",
      "[LightGBM] [Info] Number of data points in the train set: 4138, number of used features: 50\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289995 -> initscore=-0.895408\n",
      "[LightGBM] [Info] Start training from score -0.895408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001198 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12750\n",
      "[LightGBM] [Info] Number of data points in the train set: 4138, number of used features: 50\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289995 -> initscore=-0.895408\n",
      "[LightGBM] [Info] Start training from score -0.895408\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001637 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19125\n",
      "[LightGBM] [Info] Number of data points in the train set: 4138, number of used features: 75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289995 -> initscore=-0.895408\n",
      "[LightGBM] [Info] Start training from score -0.895408\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001653 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19125\n",
      "[LightGBM] [Info] Number of data points in the train set: 4138, number of used features: 75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289995 -> initscore=-0.895408\n",
      "[LightGBM] [Info] Start training from score -0.895408\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001663 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19125\n",
      "[LightGBM] [Info] Number of data points in the train set: 4138, number of used features: 75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289995 -> initscore=-0.895408\n",
      "[LightGBM] [Info] Start training from score -0.895408\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002125 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 25500\n",
      "[LightGBM] [Info] Number of data points in the train set: 4138, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289995 -> initscore=-0.895408\n",
      "[LightGBM] [Info] Start training from score -0.895408\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002145 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 25500\n",
      "[LightGBM] [Info] Number of data points in the train set: 4138, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289995 -> initscore=-0.895408\n",
      "[LightGBM] [Info] Start training from score -0.895408\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002232 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 25500\n",
      "[LightGBM] [Info] Number of data points in the train set: 4138, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289995 -> initscore=-0.895408\n",
      "[LightGBM] [Info] Start training from score -0.895408\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000614 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6375\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000748 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6375\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000491 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6375\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001427 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12750\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 50\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001494 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12750\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 50\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001306 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12750\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 50\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001730 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19125\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001698 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19125\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001811 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19125\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002057 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 25500\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002278 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 25500\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002247 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 25500\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1199, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000941 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6375\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289824 -> initscore=-0.896241\n",
      "[LightGBM] [Info] Start training from score -0.896241\n",
      "[LightGBM] [Info] Number of positive: 1196, number of negative: 2941\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000518 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6375\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289098 -> initscore=-0.899767\n",
      "[LightGBM] [Info] Start training from score -0.899767\n",
      "[LightGBM] [Info] Number of positive: 1199, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000547 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6375\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289824 -> initscore=-0.896241\n",
      "[LightGBM] [Info] Start training from score -0.896241\n",
      "[LightGBM] [Info] Number of positive: 1199, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001252 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12750\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 50\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289824 -> initscore=-0.896241\n",
      "[LightGBM] [Info] Start training from score -0.896241\n",
      "[LightGBM] [Info] Number of positive: 1196, number of negative: 2941\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001240 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12750\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 50\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289098 -> initscore=-0.899767\n",
      "[LightGBM] [Info] Start training from score -0.899767\n",
      "[LightGBM] [Info] Number of positive: 1199, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001246 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12750\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 50\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289824 -> initscore=-0.896241\n",
      "[LightGBM] [Info] Start training from score -0.896241\n",
      "[LightGBM] [Info] Number of positive: 1199, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001775 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19125\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289824 -> initscore=-0.896241\n",
      "[LightGBM] [Info] Start training from score -0.896241\n",
      "[LightGBM] [Info] Number of positive: 1196, number of negative: 2941\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002181 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19125\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289098 -> initscore=-0.899767\n",
      "[LightGBM] [Info] Start training from score -0.899767\n",
      "[LightGBM] [Info] Number of positive: 1199, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002092 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19125\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289824 -> initscore=-0.896241\n",
      "[LightGBM] [Info] Start training from score -0.896241\n",
      "[LightGBM] [Info] Number of positive: 1199, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002605 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 25500\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289824 -> initscore=-0.896241\n",
      "[LightGBM] [Info] Start training from score -0.896241\n",
      "[LightGBM] [Info] Number of positive: 1196, number of negative: 2941\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002373 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 25500\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289098 -> initscore=-0.899767\n",
      "[LightGBM] [Info] Start training from score -0.899767\n",
      "[LightGBM] [Info] Number of positive: 1199, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002265 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 25500\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289824 -> initscore=-0.896241\n",
      "[LightGBM] [Info] Start training from score -0.896241\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000691 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6375\n",
      "[LightGBM] [Info] Number of data points in the train set: 4138, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289995 -> initscore=-0.895408\n",
      "[LightGBM] [Info] Start training from score -0.895408\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000971 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6375\n",
      "[LightGBM] [Info] Number of data points in the train set: 4138, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289995 -> initscore=-0.895408\n",
      "[LightGBM] [Info] Start training from score -0.895408\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000460 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6375\n",
      "[LightGBM] [Info] Number of data points in the train set: 4138, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289995 -> initscore=-0.895408\n",
      "[LightGBM] [Info] Start training from score -0.895408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001261 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12750\n",
      "[LightGBM] [Info] Number of data points in the train set: 4138, number of used features: 50\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289995 -> initscore=-0.895408\n",
      "[LightGBM] [Info] Start training from score -0.895408\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001276 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12750\n",
      "[LightGBM] [Info] Number of data points in the train set: 4138, number of used features: 50\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289995 -> initscore=-0.895408\n",
      "[LightGBM] [Info] Start training from score -0.895408\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001196 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12750\n",
      "[LightGBM] [Info] Number of data points in the train set: 4138, number of used features: 50\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289995 -> initscore=-0.895408\n",
      "[LightGBM] [Info] Start training from score -0.895408\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001946 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19125\n",
      "[LightGBM] [Info] Number of data points in the train set: 4138, number of used features: 75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289995 -> initscore=-0.895408\n",
      "[LightGBM] [Info] Start training from score -0.895408\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001602 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19125\n",
      "[LightGBM] [Info] Number of data points in the train set: 4138, number of used features: 75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289995 -> initscore=-0.895408\n",
      "[LightGBM] [Info] Start training from score -0.895408\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001720 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19125\n",
      "[LightGBM] [Info] Number of data points in the train set: 4138, number of used features: 75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289995 -> initscore=-0.895408\n",
      "[LightGBM] [Info] Start training from score -0.895408\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002290 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 25500\n",
      "[LightGBM] [Info] Number of data points in the train set: 4138, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289995 -> initscore=-0.895408\n",
      "[LightGBM] [Info] Start training from score -0.895408\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002288 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 25500\n",
      "[LightGBM] [Info] Number of data points in the train set: 4138, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289995 -> initscore=-0.895408\n",
      "[LightGBM] [Info] Start training from score -0.895408\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002274 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 25500\n",
      "[LightGBM] [Info] Number of data points in the train set: 4138, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289995 -> initscore=-0.895408\n",
      "[LightGBM] [Info] Start training from score -0.895408\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000847 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6375\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000632 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6375\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000520 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6375\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001234 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12750\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 50\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001274 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12750\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 50\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001316 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12750\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 50\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001820 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19125\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001936 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19125\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002006 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19125\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002262 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 25500\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002417 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 25500\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002277 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 25500\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "sc_dc = {'StandardScaler' : StandardScaler(), 'MinMaxScaler' : MinMaxScaler()}\n",
    "\n",
    "sp_ls = ['tt', 'skf', 'sss']\n",
    "\n",
    "pca_comp = [25, 50, 75, 100]\n",
    "\n",
    "SV_lin = SVC(kernel='linear')\n",
    "SV_log = SVC(kernel='sigmoid')\n",
    "\n",
    "classifiers = {\n",
    "    'LogisticRegression': LogisticRegression(max_iter=500),\n",
    "    'RandomForest100': RandomForestClassifier(n_estimators=100),\n",
    "    'RandomForest200': RandomForestClassifier(n_estimators=200),\n",
    "    'SVMLinear': SV_lin,\n",
    "    'SVMSigmoid': SV_log,\n",
    "    'KNN5n' : KNeighborsClassifier(n_neighbors=5),\n",
    "    'KNN15n' : KNeighborsClassifier(n_neighbors=15),\n",
    "    'KNN25n' : KNeighborsClassifier(n_neighbors=25),    \n",
    "    'LGBM' : lgb.LGBMClassifier(),\n",
    "    'GrdBst': GradientBoostingClassifier(),\n",
    "    'ADABoost100': AdaBoostClassifier(n_estimators=100),\n",
    "    'ADABoost200': AdaBoostClassifier(n_estimators=200),    \n",
    "}\n",
    "\n",
    "pca_results_acc = {}\n",
    "pca_results_rep = {}\n",
    "\n",
    "for cl_name, cl_func in classifiers.items():\n",
    "    for sc_name, sc_func in sc_dc.items():\n",
    "        for sp in sp_ls:\n",
    "            for n_comp in pca_comp:\n",
    "                for rs in [25, 105, 94]:\n",
    "                    acc, rep = sc_pca_class_test(X, y, sc_func, n_comp, 0.2, cl_func, sp, rs) \n",
    "                    key_name = cl_name + '_' + sc_name + '_' + sp + '_' + str(n_comp) + '_' + str(rs)\n",
    "                    pca_results_acc[key_name] = acc\n",
    "                    pca_results_rep[key_name] = rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "098d2045",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_classifiers = {key:value for (key,value) in classifiers.items() if key in ['RandomForest200', 'RandomForest100','LGBM','GrdBost','AdaBoost200','SVMLinear']}\n",
    "sp_ls_2 = ['tt', 'sss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e42a3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "0c9653fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1205, number of negative: 2932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021694 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23809\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2610\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.291274 -> initscore=-0.889205\n",
      "[LightGBM] [Info] Start training from score -0.889205\n",
      "[LightGBM] [Info] Number of positive: 1213, number of negative: 2924\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020869 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23679\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2585\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.293208 -> initscore=-0.879856\n",
      "[LightGBM] [Info] Start training from score -0.879856\n",
      "[LightGBM] [Info] Number of positive: 1203, number of negative: 2934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021413 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23660\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2580\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290790 -> initscore=-0.891548\n",
      "[LightGBM] [Info] Start training from score -0.891548\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023117 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23415\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2564\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021393 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23523\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2564\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021393 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23380\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2577\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n"
     ]
    }
   ],
   "source": [
    "n_results_acc = {}\n",
    "n_results_rep = {}\n",
    "\n",
    "for cl_name, cl_func in top_classifiers.items():\n",
    "    for sp in sp_ls_2:\n",
    "        for rs in [2, 52, 410]:\n",
    "            acc, rep = sc_pca_class_test(X, y, StandardScaler(), False, 0.2, cl_func, sp, rs) \n",
    "            key_name = cl_name + '_' + 'StandardScaler' + '_' + sp + '_' + str(rs)\n",
    "            n_results_acc[key_name] = acc\n",
    "            n_results_rep[key_name] = rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "0026af08",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = pd.DataFrame.from_dict(n_results_acc, orient='index')\n",
    "acc.reset_index(inplace=True)\n",
    "acc.rename(columns={'index': 'model', 0 : 'accuracy'}, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "e81b8c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_columns = acc['model'].str.split('_', expand=True)\n",
    "\n",
    "split_columns.columns = ['model_name', 'scaler', 'split_method', 'random_state']\n",
    "\n",
    "acc2 = acc.join(split_columns)\n",
    "\n",
    "# Optionally, drop the original 'model' column\n",
    "acc2.drop(columns=['model'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "6411b525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>model_name</th>\n",
       "      <th>scaler</th>\n",
       "      <th>split_method</th>\n",
       "      <th>random_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.981643</td>\n",
       "      <td>RandomForest200</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>tt</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.980676</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>tt</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.979710</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>sss</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.976812</td>\n",
       "      <td>RandomForest100</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>sss</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.976812</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>sss</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.975845</td>\n",
       "      <td>RandomForest200</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>tt</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.975845</td>\n",
       "      <td>RandomForest200</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>sss</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.975845</td>\n",
       "      <td>RandomForest100</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>tt</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.974879</td>\n",
       "      <td>RandomForest100</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>tt</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.974879</td>\n",
       "      <td>RandomForest200</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>sss</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.974879</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>tt</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.972947</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>sss</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.972947</td>\n",
       "      <td>RandomForest200</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>tt</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.971981</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>tt</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.971014</td>\n",
       "      <td>RandomForest100</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>sss</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.971014</td>\n",
       "      <td>RandomForest100</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>tt</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.970048</td>\n",
       "      <td>RandomForest200</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>sss</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.969082</td>\n",
       "      <td>RandomForest100</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>sss</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.955556</td>\n",
       "      <td>SVMLinear</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>sss</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.951691</td>\n",
       "      <td>SVMLinear</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>tt</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.944928</td>\n",
       "      <td>SVMLinear</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>tt</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.944928</td>\n",
       "      <td>SVMLinear</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>sss</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.941063</td>\n",
       "      <td>SVMLinear</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>sss</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.937198</td>\n",
       "      <td>SVMLinear</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>tt</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    accuracy       model_name          scaler split_method random_state\n",
       "8   0.981643  RandomForest200  StandardScaler           tt          410\n",
       "19  0.980676             LGBM  StandardScaler           tt           52\n",
       "22  0.979710             LGBM  StandardScaler          sss           52\n",
       "3   0.976812  RandomForest100  StandardScaler          sss            2\n",
       "21  0.976812             LGBM  StandardScaler          sss            2\n",
       "6   0.975845  RandomForest200  StandardScaler           tt            2\n",
       "9   0.975845  RandomForest200  StandardScaler          sss            2\n",
       "1   0.975845  RandomForest100  StandardScaler           tt           52\n",
       "0   0.974879  RandomForest100  StandardScaler           tt            2\n",
       "11  0.974879  RandomForest200  StandardScaler          sss          410\n",
       "20  0.974879             LGBM  StandardScaler           tt          410\n",
       "23  0.972947             LGBM  StandardScaler          sss          410\n",
       "7   0.972947  RandomForest200  StandardScaler           tt           52\n",
       "18  0.971981             LGBM  StandardScaler           tt            2\n",
       "4   0.971014  RandomForest100  StandardScaler          sss           52\n",
       "2   0.971014  RandomForest100  StandardScaler           tt          410\n",
       "10  0.970048  RandomForest200  StandardScaler          sss           52\n",
       "5   0.969082  RandomForest100  StandardScaler          sss          410\n",
       "15  0.955556        SVMLinear  StandardScaler          sss            2\n",
       "13  0.951691        SVMLinear  StandardScaler           tt           52\n",
       "14  0.944928        SVMLinear  StandardScaler           tt          410\n",
       "17  0.944928        SVMLinear  StandardScaler          sss          410\n",
       "16  0.941063        SVMLinear  StandardScaler          sss           52\n",
       "12  0.937198        SVMLinear  StandardScaler           tt            2"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc2.sort_values(by='accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8e1efd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e83fff5",
   "metadata": {},
   "outputs": [],
   "source": [
    ", StandardScaler(), tt or sss, pca=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bb7b64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d1100e8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LogisticRegression_StandardScaler_tt_25_25': 0.9497584541062802,\n",
       " 'LogisticRegression_StandardScaler_tt_25_105': 0.9478260869565217,\n",
       " 'LogisticRegression_StandardScaler_tt_25_94': 0.9304347826086956,\n",
       " 'LogisticRegression_StandardScaler_tt_50_25': 0.9642512077294686,\n",
       " 'LogisticRegression_StandardScaler_tt_50_105': 0.9632850241545894,\n",
       " 'LogisticRegression_StandardScaler_tt_50_94': 0.9603864734299516,\n",
       " 'LogisticRegression_StandardScaler_tt_75_25': 0.9632850241545894,\n",
       " 'LogisticRegression_StandardScaler_tt_75_105': 0.9671497584541063,\n",
       " 'LogisticRegression_StandardScaler_tt_75_94': 0.9584541062801932,\n",
       " 'LogisticRegression_StandardScaler_tt_100_25': 0.9594202898550724,\n",
       " 'LogisticRegression_StandardScaler_tt_100_105': 0.9719806763285024,\n",
       " 'LogisticRegression_StandardScaler_tt_100_94': 0.9632850241545894,\n",
       " 'LogisticRegression_StandardScaler_skf_25_25': 0.9429400386847195,\n",
       " 'LogisticRegression_StandardScaler_skf_25_105': 0.9487427466150871,\n",
       " 'LogisticRegression_StandardScaler_skf_25_94': 0.9458413926499033,\n",
       " 'LogisticRegression_StandardScaler_skf_50_25': 0.9477756286266924,\n",
       " 'LogisticRegression_StandardScaler_skf_50_105': 0.9555125725338491,\n",
       " 'LogisticRegression_StandardScaler_skf_50_94': 0.9555125725338491,\n",
       " 'LogisticRegression_StandardScaler_skf_75_25': 0.9564796905222437,\n",
       " 'LogisticRegression_StandardScaler_skf_75_105': 0.9545454545454546,\n",
       " 'LogisticRegression_StandardScaler_skf_75_94': 0.9535783365570599,\n",
       " 'LogisticRegression_StandardScaler_skf_100_25': 0.9545454545454546,\n",
       " 'LogisticRegression_StandardScaler_skf_100_105': 0.9622823984526112,\n",
       " 'LogisticRegression_StandardScaler_skf_100_94': 0.9564796905222437,\n",
       " 'LogisticRegression_StandardScaler_sss_25_25': 0.9429951690821256,\n",
       " 'LogisticRegression_StandardScaler_sss_25_105': 0.9323671497584541,\n",
       " 'LogisticRegression_StandardScaler_sss_25_94': 0.9420289855072463,\n",
       " 'LogisticRegression_StandardScaler_sss_50_25': 0.9603864734299516,\n",
       " 'LogisticRegression_StandardScaler_sss_50_105': 0.9652173913043478,\n",
       " 'LogisticRegression_StandardScaler_sss_50_94': 0.9594202898550724,\n",
       " 'LogisticRegression_StandardScaler_sss_75_25': 0.9710144927536232,\n",
       " 'LogisticRegression_StandardScaler_sss_75_105': 0.9632850241545894,\n",
       " 'LogisticRegression_StandardScaler_sss_75_94': 0.9603864734299516,\n",
       " 'LogisticRegression_StandardScaler_sss_100_25': 0.970048309178744,\n",
       " 'LogisticRegression_StandardScaler_sss_100_105': 0.9594202898550724,\n",
       " 'LogisticRegression_StandardScaler_sss_100_94': 0.9545893719806763,\n",
       " 'LogisticRegression_MinMaxScaler_tt_25_25': 0.9400966183574879,\n",
       " 'LogisticRegression_MinMaxScaler_tt_25_105': 0.9429951690821256,\n",
       " 'LogisticRegression_MinMaxScaler_tt_25_94': 0.9314009661835749,\n",
       " 'LogisticRegression_MinMaxScaler_tt_50_25': 0.9536231884057971,\n",
       " 'LogisticRegression_MinMaxScaler_tt_50_105': 0.9555555555555556,\n",
       " 'LogisticRegression_MinMaxScaler_tt_50_94': 0.9439613526570049,\n",
       " 'LogisticRegression_MinMaxScaler_tt_75_25': 0.9516908212560387,\n",
       " 'LogisticRegression_MinMaxScaler_tt_75_105': 0.9507246376811594,\n",
       " 'LogisticRegression_MinMaxScaler_tt_75_94': 0.9478260869565217,\n",
       " 'LogisticRegression_MinMaxScaler_tt_100_25': 0.9468599033816425,\n",
       " 'LogisticRegression_MinMaxScaler_tt_100_105': 0.9642512077294686,\n",
       " 'LogisticRegression_MinMaxScaler_tt_100_94': 0.9497584541062802,\n",
       " 'LogisticRegression_MinMaxScaler_skf_25_25': 0.9410058027079303,\n",
       " 'LogisticRegression_MinMaxScaler_skf_25_105': 0.9313346228239845,\n",
       " 'LogisticRegression_MinMaxScaler_skf_25_94': 0.9332688588007737,\n",
       " 'LogisticRegression_MinMaxScaler_skf_50_25': 0.9535783365570599,\n",
       " 'LogisticRegression_MinMaxScaler_skf_50_105': 0.9487427466150871,\n",
       " 'LogisticRegression_MinMaxScaler_skf_50_94': 0.9439071566731141,\n",
       " 'LogisticRegression_MinMaxScaler_skf_75_25': 0.9593810444874274,\n",
       " 'LogisticRegression_MinMaxScaler_skf_75_105': 0.9468085106382979,\n",
       " 'LogisticRegression_MinMaxScaler_skf_75_94': 0.9448742746615088,\n",
       " 'LogisticRegression_MinMaxScaler_skf_100_25': 0.960348162475822,\n",
       " 'LogisticRegression_MinMaxScaler_skf_100_105': 0.9497098646034816,\n",
       " 'LogisticRegression_MinMaxScaler_skf_100_94': 0.9468085106382979,\n",
       " 'LogisticRegression_MinMaxScaler_sss_25_25': 0.9285024154589372,\n",
       " 'LogisticRegression_MinMaxScaler_sss_25_105': 0.9420289855072463,\n",
       " 'LogisticRegression_MinMaxScaler_sss_25_94': 0.9323671497584541,\n",
       " 'LogisticRegression_MinMaxScaler_sss_50_25': 0.9478260869565217,\n",
       " 'LogisticRegression_MinMaxScaler_sss_50_105': 0.9545893719806763,\n",
       " 'LogisticRegression_MinMaxScaler_sss_50_94': 0.9478260869565217,\n",
       " 'LogisticRegression_MinMaxScaler_sss_75_25': 0.9507246376811594,\n",
       " 'LogisticRegression_MinMaxScaler_sss_75_105': 0.9497584541062802,\n",
       " 'LogisticRegression_MinMaxScaler_sss_75_94': 0.9507246376811594,\n",
       " 'LogisticRegression_MinMaxScaler_sss_100_25': 0.9497584541062802,\n",
       " 'LogisticRegression_MinMaxScaler_sss_100_105': 0.9594202898550724,\n",
       " 'LogisticRegression_MinMaxScaler_sss_100_94': 0.9536231884057971,\n",
       " 'RandomForest_100_StandardScaler_tt_25_25': 0.9681159420289855,\n",
       " 'RandomForest_100_StandardScaler_tt_25_105': 0.970048309178744,\n",
       " 'RandomForest_100_StandardScaler_tt_25_94': 0.9642512077294686,\n",
       " 'RandomForest_100_StandardScaler_tt_50_25': 0.9690821256038648,\n",
       " 'RandomForest_100_StandardScaler_tt_50_105': 0.970048309178744,\n",
       " 'RandomForest_100_StandardScaler_tt_50_94': 0.9671497584541063,\n",
       " 'RandomForest_100_StandardScaler_tt_75_25': 0.9739130434782609,\n",
       " 'RandomForest_100_StandardScaler_tt_75_105': 0.9690821256038648,\n",
       " 'RandomForest_100_StandardScaler_tt_75_94': 0.9710144927536232,\n",
       " 'RandomForest_100_StandardScaler_tt_100_25': 0.9690821256038648,\n",
       " 'RandomForest_100_StandardScaler_tt_100_105': 0.9710144927536232,\n",
       " 'RandomForest_100_StandardScaler_tt_100_94': 0.9690821256038648,\n",
       " 'RandomForest_100_StandardScaler_skf_25_25': 0.9680851063829787,\n",
       " 'RandomForest_100_StandardScaler_skf_25_105': 0.9593810444874274,\n",
       " 'RandomForest_100_StandardScaler_skf_25_94': 0.9574468085106383,\n",
       " 'RandomForest_100_StandardScaler_skf_50_25': 0.9690522243713733,\n",
       " 'RandomForest_100_StandardScaler_skf_50_105': 0.9642166344294004,\n",
       " 'RandomForest_100_StandardScaler_skf_50_94': 0.965183752417795,\n",
       " 'RandomForest_100_StandardScaler_skf_75_25': 0.9680851063829787,\n",
       " 'RandomForest_100_StandardScaler_skf_75_105': 0.9690522243713733,\n",
       " 'RandomForest_100_StandardScaler_skf_75_94': 0.9671179883945842,\n",
       " 'RandomForest_100_StandardScaler_skf_100_25': 0.9700193423597679,\n",
       " 'RandomForest_100_StandardScaler_skf_100_105': 0.9671179883945842,\n",
       " 'RandomForest_100_StandardScaler_skf_100_94': 0.9661508704061895,\n",
       " 'RandomForest_100_StandardScaler_sss_25_25': 0.9681159420289855,\n",
       " 'RandomForest_100_StandardScaler_sss_25_105': 0.9671497584541063,\n",
       " 'RandomForest_100_StandardScaler_sss_25_94': 0.9584541062801932,\n",
       " 'RandomForest_100_StandardScaler_sss_50_25': 0.970048309178744,\n",
       " 'RandomForest_100_StandardScaler_sss_50_105': 0.970048309178744,\n",
       " 'RandomForest_100_StandardScaler_sss_50_94': 0.9632850241545894,\n",
       " 'RandomForest_100_StandardScaler_sss_75_25': 0.9719806763285024,\n",
       " 'RandomForest_100_StandardScaler_sss_75_105': 0.978743961352657,\n",
       " 'RandomForest_100_StandardScaler_sss_75_94': 0.9603864734299516,\n",
       " 'RandomForest_100_StandardScaler_sss_100_25': 0.9690821256038648,\n",
       " 'RandomForest_100_StandardScaler_sss_100_105': 0.9729468599033816,\n",
       " 'RandomForest_100_StandardScaler_sss_100_94': 0.9642512077294686,\n",
       " 'RandomForest_100_MinMaxScaler_tt_25_25': 0.9681159420289855,\n",
       " 'RandomForest_100_MinMaxScaler_tt_25_105': 0.970048309178744,\n",
       " 'RandomForest_100_MinMaxScaler_tt_25_94': 0.9652173913043478,\n",
       " 'RandomForest_100_MinMaxScaler_tt_50_25': 0.9632850241545894,\n",
       " 'RandomForest_100_MinMaxScaler_tt_50_105': 0.9719806763285024,\n",
       " 'RandomForest_100_MinMaxScaler_tt_50_94': 0.9671497584541063,\n",
       " 'RandomForest_100_MinMaxScaler_tt_75_25': 0.9632850241545894,\n",
       " 'RandomForest_100_MinMaxScaler_tt_75_105': 0.9729468599033816,\n",
       " 'RandomForest_100_MinMaxScaler_tt_75_94': 0.9652173913043478,\n",
       " 'RandomForest_100_MinMaxScaler_tt_100_25': 0.9632850241545894,\n",
       " 'RandomForest_100_MinMaxScaler_tt_100_105': 0.9768115942028985,\n",
       " 'RandomForest_100_MinMaxScaler_tt_100_94': 0.9690821256038648,\n",
       " 'RandomForest_100_MinMaxScaler_skf_25_25': 0.9700193423597679,\n",
       " 'RandomForest_100_MinMaxScaler_skf_25_105': 0.9700193423597679,\n",
       " 'RandomForest_100_MinMaxScaler_skf_25_94': 0.9526112185686654,\n",
       " 'RandomForest_100_MinMaxScaler_skf_50_25': 0.9671179883945842,\n",
       " 'RandomForest_100_MinMaxScaler_skf_50_105': 0.965183752417795,\n",
       " 'RandomForest_100_MinMaxScaler_skf_50_94': 0.9535783365570599,\n",
       " 'RandomForest_100_MinMaxScaler_skf_75_25': 0.9622823984526112,\n",
       " 'RandomForest_100_MinMaxScaler_skf_75_105': 0.960348162475822,\n",
       " 'RandomForest_100_MinMaxScaler_skf_75_94': 0.9564796905222437,\n",
       " 'RandomForest_100_MinMaxScaler_skf_100_25': 0.965183752417795,\n",
       " 'RandomForest_100_MinMaxScaler_skf_100_105': 0.9622823984526112,\n",
       " 'RandomForest_100_MinMaxScaler_skf_100_94': 0.9477756286266924,\n",
       " 'RandomForest_100_MinMaxScaler_sss_25_25': 0.9652173913043478,\n",
       " 'RandomForest_100_MinMaxScaler_sss_25_105': 0.9710144927536232,\n",
       " 'RandomForest_100_MinMaxScaler_sss_25_94': 0.9671497584541063,\n",
       " 'RandomForest_100_MinMaxScaler_sss_50_25': 0.9671497584541063,\n",
       " 'RandomForest_100_MinMaxScaler_sss_50_105': 0.9623188405797102,\n",
       " 'RandomForest_100_MinMaxScaler_sss_50_94': 0.9671497584541063,\n",
       " 'RandomForest_100_MinMaxScaler_sss_75_25': 0.966183574879227,\n",
       " 'RandomForest_100_MinMaxScaler_sss_75_105': 0.966183574879227,\n",
       " 'RandomForest_100_MinMaxScaler_sss_75_94': 0.9642512077294686,\n",
       " 'RandomForest_100_MinMaxScaler_sss_100_25': 0.966183574879227,\n",
       " 'RandomForest_100_MinMaxScaler_sss_100_105': 0.9681159420289855,\n",
       " 'RandomForest_100_MinMaxScaler_sss_100_94': 0.9632850241545894,\n",
       " 'RandomForest_200_StandardScaler_tt_25_25': 0.9671497584541063,\n",
       " 'RandomForest_200_StandardScaler_tt_25_105': 0.9652173913043478,\n",
       " 'RandomForest_200_StandardScaler_tt_25_94': 0.9690821256038648,\n",
       " 'RandomForest_200_StandardScaler_tt_50_25': 0.9739130434782609,\n",
       " 'RandomForest_200_StandardScaler_tt_50_105': 0.9690821256038648,\n",
       " 'RandomForest_200_StandardScaler_tt_50_94': 0.9671497584541063,\n",
       " 'RandomForest_200_StandardScaler_tt_75_25': 0.9758454106280193,\n",
       " 'RandomForest_200_StandardScaler_tt_75_105': 0.9671497584541063,\n",
       " 'RandomForest_200_StandardScaler_tt_75_94': 0.9710144927536232,\n",
       " 'RandomForest_200_StandardScaler_tt_100_25': 0.9710144927536232,\n",
       " 'RandomForest_200_StandardScaler_tt_100_105': 0.9690821256038648,\n",
       " 'RandomForest_200_StandardScaler_tt_100_94': 0.966183574879227,\n",
       " 'RandomForest_200_StandardScaler_skf_25_25': 0.9671179883945842,\n",
       " 'RandomForest_200_StandardScaler_skf_25_105': 0.9613152804642167,\n",
       " 'RandomForest_200_StandardScaler_skf_25_94': 0.9545454545454546,\n",
       " 'RandomForest_200_StandardScaler_skf_50_25': 0.9680851063829787,\n",
       " 'RandomForest_200_StandardScaler_skf_50_105': 0.9661508704061895,\n",
       " 'RandomForest_200_StandardScaler_skf_50_94': 0.965183752417795,\n",
       " 'RandomForest_200_StandardScaler_skf_75_25': 0.9700193423597679,\n",
       " 'RandomForest_200_StandardScaler_skf_75_105': 0.9661508704061895,\n",
       " 'RandomForest_200_StandardScaler_skf_75_94': 0.9632495164410058,\n",
       " 'RandomForest_200_StandardScaler_skf_100_25': 0.9709864603481625,\n",
       " 'RandomForest_200_StandardScaler_skf_100_105': 0.9700193423597679,\n",
       " 'RandomForest_200_StandardScaler_skf_100_94': 0.9642166344294004,\n",
       " 'RandomForest_200_StandardScaler_sss_25_25': 0.966183574879227,\n",
       " 'RandomForest_200_StandardScaler_sss_25_105': 0.9681159420289855,\n",
       " 'RandomForest_200_StandardScaler_sss_25_94': 0.9584541062801932,\n",
       " 'RandomForest_200_StandardScaler_sss_50_25': 0.9671497584541063,\n",
       " 'RandomForest_200_StandardScaler_sss_50_105': 0.9719806763285024,\n",
       " 'RandomForest_200_StandardScaler_sss_50_94': 0.9603864734299516,\n",
       " 'RandomForest_200_StandardScaler_sss_75_25': 0.9710144927536232,\n",
       " 'RandomForest_200_StandardScaler_sss_75_105': 0.9710144927536232,\n",
       " 'RandomForest_200_StandardScaler_sss_75_94': 0.961352657004831,\n",
       " 'RandomForest_200_StandardScaler_sss_100_25': 0.9710144927536232,\n",
       " 'RandomForest_200_StandardScaler_sss_100_105': 0.970048309178744,\n",
       " 'RandomForest_200_StandardScaler_sss_100_94': 0.9623188405797102,\n",
       " 'RandomForest_200_MinMaxScaler_tt_25_25': 0.9690821256038648,\n",
       " 'RandomForest_200_MinMaxScaler_tt_25_105': 0.9671497584541063,\n",
       " 'RandomForest_200_MinMaxScaler_tt_25_94': 0.970048309178744,\n",
       " 'RandomForest_200_MinMaxScaler_tt_50_25': 0.9690821256038648,\n",
       " 'RandomForest_200_MinMaxScaler_tt_50_105': 0.9719806763285024,\n",
       " 'RandomForest_200_MinMaxScaler_tt_50_94': 0.9681159420289855,\n",
       " 'RandomForest_200_MinMaxScaler_tt_75_25': 0.9632850241545894,\n",
       " 'RandomForest_200_MinMaxScaler_tt_75_105': 0.9777777777777777,\n",
       " 'RandomForest_200_MinMaxScaler_tt_75_94': 0.9632850241545894,\n",
       " 'RandomForest_200_MinMaxScaler_tt_100_25': 0.9681159420289855,\n",
       " 'RandomForest_200_MinMaxScaler_tt_100_105': 0.978743961352657,\n",
       " 'RandomForest_200_MinMaxScaler_tt_100_94': 0.9642512077294686,\n",
       " 'RandomForest_200_MinMaxScaler_skf_25_25': 0.9690522243713733,\n",
       " 'RandomForest_200_MinMaxScaler_skf_25_105': 0.965183752417795,\n",
       " 'RandomForest_200_MinMaxScaler_skf_25_94': 0.9516441005802708,\n",
       " 'RandomForest_200_MinMaxScaler_skf_50_25': 0.9680851063829787,\n",
       " 'RandomForest_200_MinMaxScaler_skf_50_105': 0.9671179883945842,\n",
       " 'RandomForest_200_MinMaxScaler_skf_50_94': 0.9535783365570599,\n",
       " 'RandomForest_200_MinMaxScaler_skf_75_25': 0.9680851063829787,\n",
       " 'RandomForest_200_MinMaxScaler_skf_75_105': 0.960348162475822,\n",
       " 'RandomForest_200_MinMaxScaler_skf_75_94': 0.9545454545454546,\n",
       " 'RandomForest_200_MinMaxScaler_skf_100_25': 0.9671179883945842,\n",
       " 'RandomForest_200_MinMaxScaler_skf_100_105': 0.9555125725338491,\n",
       " 'RandomForest_200_MinMaxScaler_skf_100_94': 0.9555125725338491,\n",
       " 'RandomForest_200_MinMaxScaler_sss_25_25': 0.970048309178744,\n",
       " 'RandomForest_200_MinMaxScaler_sss_25_105': 0.9681159420289855,\n",
       " 'RandomForest_200_MinMaxScaler_sss_25_94': 0.9642512077294686,\n",
       " 'RandomForest_200_MinMaxScaler_sss_50_25': 0.9710144927536232,\n",
       " 'RandomForest_200_MinMaxScaler_sss_50_105': 0.9719806763285024,\n",
       " 'RandomForest_200_MinMaxScaler_sss_50_94': 0.9642512077294686,\n",
       " 'RandomForest_200_MinMaxScaler_sss_75_25': 0.9710144927536232,\n",
       " 'RandomForest_200_MinMaxScaler_sss_75_105': 0.9671497584541063,\n",
       " 'RandomForest_200_MinMaxScaler_sss_75_94': 0.966183574879227,\n",
       " 'RandomForest_200_MinMaxScaler_sss_100_25': 0.9690821256038648,\n",
       " 'RandomForest_200_MinMaxScaler_sss_100_105': 0.9710144927536232,\n",
       " 'RandomForest_200_MinMaxScaler_sss_100_94': 0.9671497584541063,\n",
       " 'SVMLinear_StandardScaler_tt_25_25': 0.9487922705314009,\n",
       " 'SVMLinear_StandardScaler_tt_25_105': 0.9487922705314009,\n",
       " 'SVMLinear_StandardScaler_tt_25_94': 0.9449275362318841,\n",
       " 'SVMLinear_StandardScaler_tt_50_25': 0.9594202898550724,\n",
       " 'SVMLinear_StandardScaler_tt_50_105': 0.970048309178744,\n",
       " 'SVMLinear_StandardScaler_tt_50_94': 0.9603864734299516,\n",
       " 'SVMLinear_StandardScaler_tt_75_25': 0.9652173913043478,\n",
       " 'SVMLinear_StandardScaler_tt_75_105': 0.9690821256038648,\n",
       " 'SVMLinear_StandardScaler_tt_75_94': 0.961352657004831,\n",
       " 'SVMLinear_StandardScaler_tt_100_25': 0.957487922705314,\n",
       " 'SVMLinear_StandardScaler_tt_100_105': 0.9681159420289855,\n",
       " 'SVMLinear_StandardScaler_tt_100_94': 0.9584541062801932,\n",
       " 'SVMLinear_StandardScaler_skf_25_25': 0.9506769825918762,\n",
       " 'SVMLinear_StandardScaler_skf_25_105': 0.937137330754352,\n",
       " 'SVMLinear_StandardScaler_skf_25_94': 0.937137330754352,\n",
       " 'SVMLinear_StandardScaler_skf_50_25': 0.9526112185686654,\n",
       " 'SVMLinear_StandardScaler_skf_50_105': 0.9506769825918762,\n",
       " 'SVMLinear_StandardScaler_skf_50_94': 0.9526112185686654,\n",
       " 'SVMLinear_StandardScaler_skf_75_25': 0.9613152804642167,\n",
       " 'SVMLinear_StandardScaler_skf_75_105': 0.9584139264990329,\n",
       " 'SVMLinear_StandardScaler_skf_75_94': 0.9506769825918762,\n",
       " 'SVMLinear_StandardScaler_skf_100_25': 0.9526112185686654,\n",
       " 'SVMLinear_StandardScaler_skf_100_105': 0.9613152804642167,\n",
       " 'SVMLinear_StandardScaler_skf_100_94': 0.9584139264990329,\n",
       " 'SVMLinear_StandardScaler_sss_25_25': 0.9449275362318841,\n",
       " 'SVMLinear_StandardScaler_sss_25_105': 0.9429951690821256,\n",
       " 'SVMLinear_StandardScaler_sss_25_94': 0.9487922705314009,\n",
       " 'SVMLinear_StandardScaler_sss_50_25': 0.961352657004831,\n",
       " 'SVMLinear_StandardScaler_sss_50_105': 0.961352657004831,\n",
       " 'SVMLinear_StandardScaler_sss_50_94': 0.9555555555555556,\n",
       " 'SVMLinear_StandardScaler_sss_75_25': 0.9652173913043478,\n",
       " 'SVMLinear_StandardScaler_sss_75_105': 0.9603864734299516,\n",
       " 'SVMLinear_StandardScaler_sss_75_94': 0.9555555555555556,\n",
       " 'SVMLinear_StandardScaler_sss_100_25': 0.9671497584541063,\n",
       " 'SVMLinear_StandardScaler_sss_100_105': 0.966183574879227,\n",
       " 'SVMLinear_StandardScaler_sss_100_94': 0.957487922705314,\n",
       " 'SVMLinear_MinMaxScaler_tt_25_25': 0.9478260869565217,\n",
       " 'SVMLinear_MinMaxScaler_tt_25_105': 0.9545893719806763,\n",
       " 'SVMLinear_MinMaxScaler_tt_25_94': 0.9449275362318841,\n",
       " 'SVMLinear_MinMaxScaler_tt_50_25': 0.9555555555555556,\n",
       " 'SVMLinear_MinMaxScaler_tt_50_105': 0.9565217391304348,\n",
       " 'SVMLinear_MinMaxScaler_tt_50_94': 0.9497584541062802,\n",
       " 'SVMLinear_MinMaxScaler_tt_75_25': 0.9555555555555556,\n",
       " 'SVMLinear_MinMaxScaler_tt_75_105': 0.957487922705314,\n",
       " 'SVMLinear_MinMaxScaler_tt_75_94': 0.9439613526570049,\n",
       " 'SVMLinear_MinMaxScaler_tt_100_25': 0.961352657004831,\n",
       " 'SVMLinear_MinMaxScaler_tt_100_105': 0.9652173913043478,\n",
       " 'SVMLinear_MinMaxScaler_tt_100_94': 0.9545893719806763,\n",
       " 'SVMLinear_MinMaxScaler_skf_25_25': 0.9477756286266924,\n",
       " 'SVMLinear_MinMaxScaler_skf_25_105': 0.9458413926499033,\n",
       " 'SVMLinear_MinMaxScaler_skf_25_94': 0.9352030947775629,\n",
       " 'SVMLinear_MinMaxScaler_skf_50_25': 0.9584139264990329,\n",
       " 'SVMLinear_MinMaxScaler_skf_50_105': 0.9555125725338491,\n",
       " 'SVMLinear_MinMaxScaler_skf_50_94': 0.9487427466150871,\n",
       " 'SVMLinear_MinMaxScaler_skf_75_25': 0.9574468085106383,\n",
       " 'SVMLinear_MinMaxScaler_skf_75_105': 0.9593810444874274,\n",
       " 'SVMLinear_MinMaxScaler_skf_75_94': 0.9390715667311412,\n",
       " 'SVMLinear_MinMaxScaler_skf_100_25': 0.9613152804642167,\n",
       " 'SVMLinear_MinMaxScaler_skf_100_105': 0.9516441005802708,\n",
       " 'SVMLinear_MinMaxScaler_skf_100_94': 0.9429400386847195,\n",
       " 'SVMLinear_MinMaxScaler_sss_25_25': 0.957487922705314,\n",
       " 'SVMLinear_MinMaxScaler_sss_25_105': 0.9458937198067633,\n",
       " 'SVMLinear_MinMaxScaler_sss_25_94': 0.9439613526570049,\n",
       " 'SVMLinear_MinMaxScaler_sss_50_25': 0.9632850241545894,\n",
       " 'SVMLinear_MinMaxScaler_sss_50_105': 0.9468599033816425,\n",
       " 'SVMLinear_MinMaxScaler_sss_50_94': 0.9507246376811594,\n",
       " 'SVMLinear_MinMaxScaler_sss_75_25': 0.9623188405797102,\n",
       " 'SVMLinear_MinMaxScaler_sss_75_105': 0.9487922705314009,\n",
       " 'SVMLinear_MinMaxScaler_sss_75_94': 0.9449275362318841,\n",
       " 'SVMLinear_MinMaxScaler_sss_100_25': 0.9710144927536232,\n",
       " 'SVMLinear_MinMaxScaler_sss_100_105': 0.9565217391304348,\n",
       " 'SVMLinear_MinMaxScaler_sss_100_94': 0.9526570048309179,\n",
       " 'SVMSigmoid_StandardScaler_tt_25_25': 0.8840579710144928,\n",
       " 'SVMSigmoid_StandardScaler_tt_25_105': 0.8183574879227054,\n",
       " 'SVMSigmoid_StandardScaler_tt_25_94': 0.8164251207729468,\n",
       " 'SVMSigmoid_StandardScaler_tt_50_25': 0.8966183574879227,\n",
       " 'SVMSigmoid_StandardScaler_tt_50_105': 0.8309178743961353,\n",
       " 'SVMSigmoid_StandardScaler_tt_50_94': 0.8309178743961353,\n",
       " 'SVMSigmoid_StandardScaler_tt_75_25': 0.855072463768116,\n",
       " 'SVMSigmoid_StandardScaler_tt_75_105': 0.8367149758454107,\n",
       " 'SVMSigmoid_StandardScaler_tt_75_94': 0.842512077294686,\n",
       " 'SVMSigmoid_StandardScaler_tt_100_25': 0.9053140096618357,\n",
       " 'SVMSigmoid_StandardScaler_tt_100_105': 0.8483091787439614,\n",
       " 'SVMSigmoid_StandardScaler_tt_100_94': 0.855072463768116,\n",
       " 'SVMSigmoid_StandardScaler_skf_25_25': 0.8404255319148937,\n",
       " 'SVMSigmoid_StandardScaler_skf_25_105': 0.8462282398452611,\n",
       " 'SVMSigmoid_StandardScaler_skf_25_94': 0.8201160541586073,\n",
       " 'SVMSigmoid_StandardScaler_skf_50_25': 0.8462282398452611,\n",
       " 'SVMSigmoid_StandardScaler_skf_50_105': 0.8539651837524178,\n",
       " 'SVMSigmoid_StandardScaler_skf_50_94': 0.8278529980657641,\n",
       " 'SVMSigmoid_StandardScaler_skf_75_25': 0.8568665377176016,\n",
       " 'SVMSigmoid_StandardScaler_skf_75_105': 0.851063829787234,\n",
       " 'SVMSigmoid_StandardScaler_skf_75_94': 0.8500967117988395,\n",
       " 'SVMSigmoid_StandardScaler_skf_100_25': 0.8588007736943907,\n",
       " 'SVMSigmoid_StandardScaler_skf_100_105': 0.8568665377176016,\n",
       " 'SVMSigmoid_StandardScaler_skf_100_94': 0.8529980657640233,\n",
       " 'SVMSigmoid_StandardScaler_sss_25_25': 0.8241545893719807,\n",
       " 'SVMSigmoid_StandardScaler_sss_25_105': 0.8135265700483092,\n",
       " 'SVMSigmoid_StandardScaler_sss_25_94': 0.8280193236714976,\n",
       " 'SVMSigmoid_StandardScaler_sss_50_25': 0.8309178743961353,\n",
       " 'SVMSigmoid_StandardScaler_sss_50_105': 0.8164251207729468,\n",
       " 'SVMSigmoid_StandardScaler_sss_50_94': 0.8338164251207729,\n",
       " 'SVMSigmoid_StandardScaler_sss_75_25': 0.8347826086956521,\n",
       " 'SVMSigmoid_StandardScaler_sss_75_105': 0.8376811594202899,\n",
       " 'SVMSigmoid_StandardScaler_sss_75_94': 0.8434782608695652,\n",
       " 'SVMSigmoid_StandardScaler_sss_100_25': 0.8483091787439614,\n",
       " 'SVMSigmoid_StandardScaler_sss_100_105': 0.842512077294686,\n",
       " 'SVMSigmoid_StandardScaler_sss_100_94': 0.8502415458937198,\n",
       " 'SVMSigmoid_MinMaxScaler_tt_25_25': 0.8560386473429952,\n",
       " 'SVMSigmoid_MinMaxScaler_tt_25_105': 0.8028985507246377,\n",
       " 'SVMSigmoid_MinMaxScaler_tt_25_94': 0.8231884057971014,\n",
       " 'SVMSigmoid_MinMaxScaler_tt_50_25': 0.8347826086956521,\n",
       " 'SVMSigmoid_MinMaxScaler_tt_50_105': 0.8144927536231884,\n",
       " 'SVMSigmoid_MinMaxScaler_tt_50_94': 0.8289855072463768,\n",
       " 'SVMSigmoid_MinMaxScaler_tt_75_25': 0.8357487922705314,\n",
       " 'SVMSigmoid_MinMaxScaler_tt_75_105': 0.8222222222222222,\n",
       " 'SVMSigmoid_MinMaxScaler_tt_75_94': 0.881159420289855,\n",
       " 'SVMSigmoid_MinMaxScaler_tt_100_25': 0.8347826086956521,\n",
       " 'SVMSigmoid_MinMaxScaler_tt_100_105': 0.8241545893719807,\n",
       " 'SVMSigmoid_MinMaxScaler_tt_100_94': 0.8879227053140096,\n",
       " 'SVMSigmoid_MinMaxScaler_skf_25_25': 0.8239845261121856,\n",
       " 'SVMSigmoid_MinMaxScaler_skf_25_105': 0.8317214700193424,\n",
       " 'SVMSigmoid_MinMaxScaler_skf_25_94': 0.8133462282398453,\n",
       " 'SVMSigmoid_MinMaxScaler_skf_50_25': 0.8230174081237911,\n",
       " 'SVMSigmoid_MinMaxScaler_skf_50_105': 0.8346228239845261,\n",
       " 'SVMSigmoid_MinMaxScaler_skf_50_94': 0.8220502901353965,\n",
       " 'SVMSigmoid_MinMaxScaler_skf_75_25': 0.8268858800773694,\n",
       " 'SVMSigmoid_MinMaxScaler_skf_75_105': 0.8365570599613152,\n",
       " 'SVMSigmoid_MinMaxScaler_skf_75_94': 0.8239845261121856,\n",
       " 'SVMSigmoid_MinMaxScaler_skf_100_25': 0.8413926499032882,\n",
       " 'SVMSigmoid_MinMaxScaler_skf_100_105': 0.8404255319148937,\n",
       " 'SVMSigmoid_MinMaxScaler_skf_100_94': 0.8307543520309478,\n",
       " 'SVMSigmoid_MinMaxScaler_sss_25_25': 0.8676328502415459,\n",
       " 'SVMSigmoid_MinMaxScaler_sss_25_105': 0.8135265700483092,\n",
       " 'SVMSigmoid_MinMaxScaler_sss_25_94': 0.8115942028985508,\n",
       " 'SVMSigmoid_MinMaxScaler_sss_50_25': 0.8289855072463768,\n",
       " 'SVMSigmoid_MinMaxScaler_sss_50_105': 0.8270531400966183,\n",
       " 'SVMSigmoid_MinMaxScaler_sss_50_94': 0.8270531400966183,\n",
       " 'SVMSigmoid_MinMaxScaler_sss_75_25': 0.8724637681159421,\n",
       " 'SVMSigmoid_MinMaxScaler_sss_75_105': 0.8772946859903382,\n",
       " 'SVMSigmoid_MinMaxScaler_sss_75_94': 0.851207729468599,\n",
       " 'SVMSigmoid_MinMaxScaler_sss_100_25': 0.8338164251207729,\n",
       " 'SVMSigmoid_MinMaxScaler_sss_100_105': 0.8309178743961353,\n",
       " 'SVMSigmoid_MinMaxScaler_sss_100_94': 0.8318840579710145,\n",
       " 'KNN_5n_StandardScaler_tt_25_25': 0.9642512077294686,\n",
       " 'KNN_5n_StandardScaler_tt_25_105': 0.9555555555555556,\n",
       " 'KNN_5n_StandardScaler_tt_25_94': 0.9565217391304348,\n",
       " 'KNN_5n_StandardScaler_tt_50_25': 0.9565217391304348,\n",
       " 'KNN_5n_StandardScaler_tt_50_105': 0.957487922705314,\n",
       " 'KNN_5n_StandardScaler_tt_50_94': 0.9516908212560387,\n",
       " 'KNN_5n_StandardScaler_tt_75_25': 0.9594202898550724,\n",
       " 'KNN_5n_StandardScaler_tt_75_105': 0.9603864734299516,\n",
       " 'KNN_5n_StandardScaler_tt_75_94': 0.9516908212560387,\n",
       " 'KNN_5n_StandardScaler_tt_100_25': 0.9516908212560387,\n",
       " 'KNN_5n_StandardScaler_tt_100_105': 0.9603864734299516,\n",
       " 'KNN_5n_StandardScaler_tt_100_94': 0.9507246376811594,\n",
       " 'KNN_5n_StandardScaler_skf_25_25': 0.9564796905222437,\n",
       " 'KNN_5n_StandardScaler_skf_25_105': 0.965183752417795,\n",
       " 'KNN_5n_StandardScaler_skf_25_94': 0.9535783365570599,\n",
       " 'KNN_5n_StandardScaler_skf_50_25': 0.9564796905222437,\n",
       " 'KNN_5n_StandardScaler_skf_50_105': 0.9613152804642167,\n",
       " 'KNN_5n_StandardScaler_skf_50_94': 0.9468085106382979,\n",
       " 'KNN_5n_StandardScaler_skf_75_25': 0.9555125725338491,\n",
       " 'KNN_5n_StandardScaler_skf_75_105': 0.9564796905222437,\n",
       " 'KNN_5n_StandardScaler_skf_75_94': 0.9468085106382979,\n",
       " 'KNN_5n_StandardScaler_skf_100_25': 0.9439071566731141,\n",
       " 'KNN_5n_StandardScaler_skf_100_105': 0.9564796905222437,\n",
       " 'KNN_5n_StandardScaler_skf_100_94': 0.9410058027079303,\n",
       " 'KNN_5n_StandardScaler_sss_25_25': 0.9545893719806763,\n",
       " 'KNN_5n_StandardScaler_sss_25_105': 0.9603864734299516,\n",
       " 'KNN_5n_StandardScaler_sss_25_94': 0.9507246376811594,\n",
       " 'KNN_5n_StandardScaler_sss_50_25': 0.9545893719806763,\n",
       " 'KNN_5n_StandardScaler_sss_50_105': 0.9681159420289855,\n",
       " 'KNN_5n_StandardScaler_sss_50_94': 0.9497584541062802,\n",
       " 'KNN_5n_StandardScaler_sss_75_25': 0.9565217391304348,\n",
       " 'KNN_5n_StandardScaler_sss_75_105': 0.9681159420289855,\n",
       " 'KNN_5n_StandardScaler_sss_75_94': 0.9545893719806763,\n",
       " 'KNN_5n_StandardScaler_sss_100_25': 0.966183574879227,\n",
       " 'KNN_5n_StandardScaler_sss_100_105': 0.9594202898550724,\n",
       " 'KNN_5n_StandardScaler_sss_100_94': 0.9526570048309179,\n",
       " 'KNN_5n_MinMaxScaler_tt_25_25': 0.957487922705314,\n",
       " 'KNN_5n_MinMaxScaler_tt_25_105': 0.9584541062801932,\n",
       " 'KNN_5n_MinMaxScaler_tt_25_94': 0.957487922705314,\n",
       " 'KNN_5n_MinMaxScaler_tt_50_25': 0.957487922705314,\n",
       " 'KNN_5n_MinMaxScaler_tt_50_105': 0.957487922705314,\n",
       " 'KNN_5n_MinMaxScaler_tt_50_94': 0.9478260869565217,\n",
       " 'KNN_5n_MinMaxScaler_tt_75_25': 0.9478260869565217,\n",
       " 'KNN_5n_MinMaxScaler_tt_75_105': 0.9565217391304348,\n",
       " 'KNN_5n_MinMaxScaler_tt_75_94': 0.9439613526570049,\n",
       " 'KNN_5n_MinMaxScaler_tt_100_25': 0.9526570048309179,\n",
       " 'KNN_5n_MinMaxScaler_tt_100_105': 0.9458937198067633,\n",
       " 'KNN_5n_MinMaxScaler_tt_100_94': 0.9400966183574879,\n",
       " 'KNN_5n_MinMaxScaler_skf_25_25': 0.9574468085106383,\n",
       " 'KNN_5n_MinMaxScaler_skf_25_105': 0.9593810444874274,\n",
       " 'KNN_5n_MinMaxScaler_skf_25_94': 0.9448742746615088,\n",
       " 'KNN_5n_MinMaxScaler_skf_50_25': 0.9458413926499033,\n",
       " 'KNN_5n_MinMaxScaler_skf_50_105': 0.9526112185686654,\n",
       " 'KNN_5n_MinMaxScaler_skf_50_94': 0.9400386847195358,\n",
       " 'KNN_5n_MinMaxScaler_skf_75_25': 0.9400386847195358,\n",
       " 'KNN_5n_MinMaxScaler_skf_75_105': 0.9506769825918762,\n",
       " 'KNN_5n_MinMaxScaler_skf_75_94': 0.9323017408123792,\n",
       " 'KNN_5n_MinMaxScaler_skf_100_25': 0.9352030947775629,\n",
       " 'KNN_5n_MinMaxScaler_skf_100_105': 0.9410058027079303,\n",
       " 'KNN_5n_MinMaxScaler_skf_100_94': 0.9264990328820116,\n",
       " 'KNN_5n_MinMaxScaler_sss_25_25': 0.9671497584541063,\n",
       " 'KNN_5n_MinMaxScaler_sss_25_105': 0.9526570048309179,\n",
       " 'KNN_5n_MinMaxScaler_sss_25_94': 0.9536231884057971,\n",
       " 'KNN_5n_MinMaxScaler_sss_50_25': 0.9555555555555556,\n",
       " 'KNN_5n_MinMaxScaler_sss_50_105': 0.9478260869565217,\n",
       " 'KNN_5n_MinMaxScaler_sss_50_94': 0.9487922705314009,\n",
       " 'KNN_5n_MinMaxScaler_sss_75_25': 0.9555555555555556,\n",
       " 'KNN_5n_MinMaxScaler_sss_75_105': 0.9449275362318841,\n",
       " 'KNN_5n_MinMaxScaler_sss_75_94': 0.9420289855072463,\n",
       " 'KNN_5n_MinMaxScaler_sss_100_25': 0.9555555555555556,\n",
       " 'KNN_5n_MinMaxScaler_sss_100_105': 0.9352657004830918,\n",
       " 'KNN_5n_MinMaxScaler_sss_100_94': 0.9333333333333333,\n",
       " 'KNN_15n_StandardScaler_tt_25_25': 0.9545893719806763,\n",
       " 'KNN_15n_StandardScaler_tt_25_105': 0.9516908212560387,\n",
       " 'KNN_15n_StandardScaler_tt_25_94': 0.9526570048309179,\n",
       " 'KNN_15n_StandardScaler_tt_50_25': 0.9565217391304348,\n",
       " 'KNN_15n_StandardScaler_tt_50_105': 0.9449275362318841,\n",
       " 'KNN_15n_StandardScaler_tt_50_94': 0.9536231884057971,\n",
       " 'KNN_15n_StandardScaler_tt_75_25': 0.9526570048309179,\n",
       " 'KNN_15n_StandardScaler_tt_75_105': 0.9497584541062802,\n",
       " 'KNN_15n_StandardScaler_tt_75_94': 0.9449275362318841,\n",
       " 'KNN_15n_StandardScaler_tt_100_25': 0.9478260869565217,\n",
       " 'KNN_15n_StandardScaler_tt_100_105': 0.9420289855072463,\n",
       " 'KNN_15n_StandardScaler_tt_100_94': 0.9391304347826087,\n",
       " 'KNN_15n_StandardScaler_skf_25_25': 0.9555125725338491,\n",
       " 'KNN_15n_StandardScaler_skf_25_105': 0.9593810444874274,\n",
       " 'KNN_15n_StandardScaler_skf_25_94': 0.9448742746615088,\n",
       " 'KNN_15n_StandardScaler_skf_50_25': 0.9535783365570599,\n",
       " 'KNN_15n_StandardScaler_skf_50_105': 0.9516441005802708,\n",
       " 'KNN_15n_StandardScaler_skf_50_94': 0.9429400386847195,\n",
       " 'KNN_15n_StandardScaler_skf_75_25': 0.9448742746615088,\n",
       " 'KNN_15n_StandardScaler_skf_75_105': 0.9506769825918762,\n",
       " 'KNN_15n_StandardScaler_skf_75_94': 0.9342359767891683,\n",
       " 'KNN_15n_StandardScaler_skf_100_25': 0.9468085106382979,\n",
       " 'KNN_15n_StandardScaler_skf_100_105': 0.9439071566731141,\n",
       " 'KNN_15n_StandardScaler_skf_100_94': 0.9274661508704062,\n",
       " 'KNN_15n_StandardScaler_sss_25_25': 0.9623188405797102,\n",
       " 'KNN_15n_StandardScaler_sss_25_105': 0.9623188405797102,\n",
       " 'KNN_15n_StandardScaler_sss_25_94': 0.9584541062801932,\n",
       " 'KNN_15n_StandardScaler_sss_50_25': 0.9565217391304348,\n",
       " 'KNN_15n_StandardScaler_sss_50_105': 0.961352657004831,\n",
       " 'KNN_15n_StandardScaler_sss_50_94': 0.9516908212560387,\n",
       " 'KNN_15n_StandardScaler_sss_75_25': 0.9507246376811594,\n",
       " 'KNN_15n_StandardScaler_sss_75_105': 0.9526570048309179,\n",
       " 'KNN_15n_StandardScaler_sss_75_94': 0.9391304347826087,\n",
       " 'KNN_15n_StandardScaler_sss_100_25': 0.9449275362318841,\n",
       " 'KNN_15n_StandardScaler_sss_100_105': 0.9507246376811594,\n",
       " 'KNN_15n_StandardScaler_sss_100_94': 0.9420289855072463,\n",
       " 'KNN_15n_MinMaxScaler_tt_25_25': 0.9536231884057971,\n",
       " 'KNN_15n_MinMaxScaler_tt_25_105': 0.957487922705314,\n",
       " 'KNN_15n_MinMaxScaler_tt_25_94': 0.9497584541062802,\n",
       " 'KNN_15n_MinMaxScaler_tt_50_25': 0.9487922705314009,\n",
       " 'KNN_15n_MinMaxScaler_tt_50_105': 0.9458937198067633,\n",
       " 'KNN_15n_MinMaxScaler_tt_50_94': 0.9420289855072463,\n",
       " 'KNN_15n_MinMaxScaler_tt_75_25': 0.9381642512077295,\n",
       " 'KNN_15n_MinMaxScaler_tt_75_105': 0.9371980676328503,\n",
       " 'KNN_15n_MinMaxScaler_tt_75_94': 0.9323671497584541,\n",
       " 'KNN_15n_MinMaxScaler_tt_100_25': 0.9342995169082126,\n",
       " 'KNN_15n_MinMaxScaler_tt_100_105': 0.936231884057971,\n",
       " 'KNN_15n_MinMaxScaler_tt_100_94': 0.9304347826086956,\n",
       " 'KNN_15n_MinMaxScaler_skf_25_25': 0.9545454545454546,\n",
       " 'KNN_15n_MinMaxScaler_skf_25_105': 0.9613152804642167,\n",
       " 'KNN_15n_MinMaxScaler_skf_25_94': 0.9400386847195358,\n",
       " 'KNN_15n_MinMaxScaler_skf_50_25': 0.937137330754352,\n",
       " 'KNN_15n_MinMaxScaler_skf_50_105': 0.9545454545454546,\n",
       " 'KNN_15n_MinMaxScaler_skf_50_94': 0.9332688588007737,\n",
       " 'KNN_15n_MinMaxScaler_skf_75_25': 0.9332688588007737,\n",
       " 'KNN_15n_MinMaxScaler_skf_75_105': 0.937137330754352,\n",
       " 'KNN_15n_MinMaxScaler_skf_75_94': 0.9245647969052224,\n",
       " 'KNN_15n_MinMaxScaler_skf_100_25': 0.925531914893617,\n",
       " 'KNN_15n_MinMaxScaler_skf_100_105': 0.9294003868471954,\n",
       " 'KNN_15n_MinMaxScaler_skf_100_94': 0.9158607350096711,\n",
       " 'KNN_15n_MinMaxScaler_sss_25_25': 0.9594202898550724,\n",
       " 'KNN_15n_MinMaxScaler_sss_25_105': 0.9468599033816425,\n",
       " 'KNN_15n_MinMaxScaler_sss_25_94': 0.9478260869565217,\n",
       " 'KNN_15n_MinMaxScaler_sss_50_25': 0.9458937198067633,\n",
       " 'KNN_15n_MinMaxScaler_sss_50_105': 0.9391304347826087,\n",
       " 'KNN_15n_MinMaxScaler_sss_50_94': 0.9391304347826087,\n",
       " 'KNN_15n_MinMaxScaler_sss_75_25': 0.9391304347826087,\n",
       " 'KNN_15n_MinMaxScaler_sss_75_105': 0.927536231884058,\n",
       " 'KNN_15n_MinMaxScaler_sss_75_94': 0.9246376811594202,\n",
       " 'KNN_15n_MinMaxScaler_sss_100_25': 0.9410628019323671,\n",
       " 'KNN_15n_MinMaxScaler_sss_100_105': 0.9265700483091788,\n",
       " 'KNN_15n_MinMaxScaler_sss_100_94': 0.9207729468599034,\n",
       " 'KNN_25n_StandardScaler_tt_25_25': 0.9584541062801932,\n",
       " 'KNN_25n_StandardScaler_tt_25_105': 0.9497584541062802,\n",
       " 'KNN_25n_StandardScaler_tt_25_94': 0.9555555555555556,\n",
       " 'KNN_25n_StandardScaler_tt_50_25': 0.9478260869565217,\n",
       " 'KNN_25n_StandardScaler_tt_50_105': 0.9507246376811594,\n",
       " 'KNN_25n_StandardScaler_tt_50_94': 0.9487922705314009,\n",
       " 'KNN_25n_StandardScaler_tt_75_25': 0.9400966183574879,\n",
       " 'KNN_25n_StandardScaler_tt_75_105': 0.9449275362318841,\n",
       " 'KNN_25n_StandardScaler_tt_75_94': 0.936231884057971,\n",
       " 'KNN_25n_StandardScaler_tt_100_25': 0.9420289855072463,\n",
       " 'KNN_25n_StandardScaler_tt_100_105': 0.9333333333333333,\n",
       " 'KNN_25n_StandardScaler_tt_100_94': 0.927536231884058,\n",
       " 'KNN_25n_StandardScaler_skf_25_25': 0.9506769825918762,\n",
       " 'KNN_25n_StandardScaler_skf_25_105': 0.9613152804642167,\n",
       " 'KNN_25n_StandardScaler_skf_25_94': 0.9410058027079303,\n",
       " 'KNN_25n_StandardScaler_skf_50_25': 0.941972920696325,\n",
       " 'KNN_25n_StandardScaler_skf_50_105': 0.9516441005802708,\n",
       " 'KNN_25n_StandardScaler_skf_50_94': 0.9274661508704062,\n",
       " 'KNN_25n_StandardScaler_skf_75_25': 0.937137330754352,\n",
       " 'KNN_25n_StandardScaler_skf_75_105': 0.9390715667311412,\n",
       " 'KNN_25n_StandardScaler_skf_75_94': 0.925531914893617,\n",
       " 'KNN_25n_StandardScaler_skf_100_25': 0.9323017408123792,\n",
       " 'KNN_25n_StandardScaler_skf_100_105': 0.9342359767891683,\n",
       " 'KNN_25n_StandardScaler_skf_100_94': 0.9197292069632496,\n",
       " 'KNN_25n_StandardScaler_sss_25_25': 0.961352657004831,\n",
       " 'KNN_25n_StandardScaler_sss_25_105': 0.9584541062801932,\n",
       " 'KNN_25n_StandardScaler_sss_25_94': 0.9478260869565217,\n",
       " 'KNN_25n_StandardScaler_sss_50_25': 0.9478260869565217,\n",
       " 'KNN_25n_StandardScaler_sss_50_105': 0.9516908212560387,\n",
       " 'KNN_25n_StandardScaler_sss_50_94': 0.9429951690821256,\n",
       " 'KNN_25n_StandardScaler_sss_75_25': 0.9410628019323671,\n",
       " 'KNN_25n_StandardScaler_sss_75_105': 0.9468599033816425,\n",
       " 'KNN_25n_StandardScaler_sss_75_94': 0.9371980676328503,\n",
       " 'KNN_25n_StandardScaler_sss_100_25': 0.9381642512077295,\n",
       " 'KNN_25n_StandardScaler_sss_100_105': 0.936231884057971,\n",
       " 'KNN_25n_StandardScaler_sss_100_94': 0.9314009661835749,\n",
       " 'KNN_25n_MinMaxScaler_tt_25_25': 0.9468599033816425,\n",
       " 'KNN_25n_MinMaxScaler_tt_25_105': 0.9507246376811594,\n",
       " 'KNN_25n_MinMaxScaler_tt_25_94': 0.9439613526570049,\n",
       " 'KNN_25n_MinMaxScaler_tt_50_25': 0.9458937198067633,\n",
       " 'KNN_25n_MinMaxScaler_tt_50_105': 0.9468599033816425,\n",
       " 'KNN_25n_MinMaxScaler_tt_50_94': 0.9333333333333333,\n",
       " 'KNN_25n_MinMaxScaler_tt_75_25': 0.936231884057971,\n",
       " 'KNN_25n_MinMaxScaler_tt_75_105': 0.9285024154589372,\n",
       " 'KNN_25n_MinMaxScaler_tt_75_94': 0.927536231884058,\n",
       " 'KNN_25n_MinMaxScaler_tt_100_25': 0.927536231884058,\n",
       " 'KNN_25n_MinMaxScaler_tt_100_105': 0.927536231884058,\n",
       " 'KNN_25n_MinMaxScaler_tt_100_94': 0.9198067632850242,\n",
       " 'KNN_25n_MinMaxScaler_skf_25_25': 0.9458413926499033,\n",
       " 'KNN_25n_MinMaxScaler_skf_25_105': 0.9555125725338491,\n",
       " 'KNN_25n_MinMaxScaler_skf_25_94': 0.9332688588007737,\n",
       " 'KNN_25n_MinMaxScaler_skf_50_25': 0.937137330754352,\n",
       " 'KNN_25n_MinMaxScaler_skf_50_105': 0.9381044487427466,\n",
       " 'KNN_25n_MinMaxScaler_skf_50_94': 0.9235976789168279,\n",
       " 'KNN_25n_MinMaxScaler_skf_75_25': 0.9264990328820116,\n",
       " 'KNN_25n_MinMaxScaler_skf_75_105': 0.9284332688588007,\n",
       " 'KNN_25n_MinMaxScaler_skf_75_94': 0.9158607350096711,\n",
       " 'KNN_25n_MinMaxScaler_skf_100_25': 0.9284332688588007,\n",
       " 'KNN_25n_MinMaxScaler_skf_100_105': 0.925531914893617,\n",
       " 'KNN_25n_MinMaxScaler_skf_100_94': 0.9100580270793037,\n",
       " 'KNN_25n_MinMaxScaler_sss_25_25': 0.9565217391304348,\n",
       " 'KNN_25n_MinMaxScaler_sss_25_105': 0.9420289855072463,\n",
       " 'KNN_25n_MinMaxScaler_sss_25_94': 0.9410628019323671,\n",
       " 'KNN_25n_MinMaxScaler_sss_50_25': 0.9429951690821256,\n",
       " 'KNN_25n_MinMaxScaler_sss_50_105': 0.9294685990338164,\n",
       " 'KNN_25n_MinMaxScaler_sss_50_94': 0.9304347826086956,\n",
       " 'KNN_25n_MinMaxScaler_sss_75_25': 0.9333333333333333,\n",
       " 'KNN_25n_MinMaxScaler_sss_75_105': 0.9314009661835749,\n",
       " 'KNN_25n_MinMaxScaler_sss_75_94': 0.9246376811594202,\n",
       " 'KNN_25n_MinMaxScaler_sss_100_25': 0.9381642512077295,\n",
       " 'KNN_25n_MinMaxScaler_sss_100_105': 0.9198067632850242,\n",
       " 'KNN_25n_MinMaxScaler_sss_100_94': 0.9140096618357488,\n",
       " 'LGBM_StandardScaler_tt_25_25': 0.9671497584541063,\n",
       " 'LGBM_StandardScaler_tt_25_105': 0.966183574879227,\n",
       " 'LGBM_StandardScaler_tt_25_94': 0.9632850241545894,\n",
       " 'LGBM_StandardScaler_tt_50_25': 0.966183574879227,\n",
       " 'LGBM_StandardScaler_tt_50_105': 0.9690821256038648,\n",
       " 'LGBM_StandardScaler_tt_50_94': 0.961352657004831,\n",
       " 'LGBM_StandardScaler_tt_75_25': 0.966183574879227,\n",
       " 'LGBM_StandardScaler_tt_75_105': 0.9690821256038648,\n",
       " 'LGBM_StandardScaler_tt_75_94': 0.9603864734299516,\n",
       " 'LGBM_StandardScaler_tt_100_25': 0.9690821256038648,\n",
       " 'LGBM_StandardScaler_tt_100_105': 0.9690821256038648,\n",
       " 'LGBM_StandardScaler_tt_100_94': 0.9642512077294686,\n",
       " 'LGBM_StandardScaler_skf_25_25': 0.9709864603481625,\n",
       " 'LGBM_StandardScaler_skf_25_105': 0.9593810444874274,\n",
       " 'LGBM_StandardScaler_skf_25_94': 0.9593810444874274,\n",
       " 'LGBM_StandardScaler_skf_50_25': 0.9709864603481625,\n",
       " 'LGBM_StandardScaler_skf_50_105': 0.9622823984526112,\n",
       " 'LGBM_StandardScaler_skf_50_94': 0.9642166344294004,\n",
       " 'LGBM_StandardScaler_skf_75_25': 0.9709864603481625,\n",
       " 'LGBM_StandardScaler_skf_75_105': 0.9642166344294004,\n",
       " 'LGBM_StandardScaler_skf_75_94': 0.9593810444874274,\n",
       " 'LGBM_StandardScaler_skf_100_25': 0.9690522243713733,\n",
       " 'LGBM_StandardScaler_skf_100_105': 0.965183752417795,\n",
       " 'LGBM_StandardScaler_skf_100_94': 0.965183752417795,\n",
       " 'LGBM_StandardScaler_sss_25_25': 0.970048309178744,\n",
       " 'LGBM_StandardScaler_sss_25_105': 0.9671497584541063,\n",
       " 'LGBM_StandardScaler_sss_25_94': 0.9584541062801932,\n",
       " 'LGBM_StandardScaler_sss_50_25': 0.9748792270531401,\n",
       " 'LGBM_StandardScaler_sss_50_105': 0.9681159420289855,\n",
       " 'LGBM_StandardScaler_sss_50_94': 0.9584541062801932,\n",
       " 'LGBM_StandardScaler_sss_75_25': 0.9710144927536232,\n",
       " 'LGBM_StandardScaler_sss_75_105': 0.966183574879227,\n",
       " 'LGBM_StandardScaler_sss_75_94': 0.9671497584541063,\n",
       " 'LGBM_StandardScaler_sss_100_25': 0.9690821256038648,\n",
       " 'LGBM_StandardScaler_sss_100_105': 0.9642512077294686,\n",
       " 'LGBM_StandardScaler_sss_100_94': 0.9681159420289855,\n",
       " 'LGBM_MinMaxScaler_tt_25_25': 0.9652173913043478,\n",
       " 'LGBM_MinMaxScaler_tt_25_105': 0.9603864734299516,\n",
       " 'LGBM_MinMaxScaler_tt_25_94': 0.9594202898550724,\n",
       " 'LGBM_MinMaxScaler_tt_50_25': 0.9719806763285024,\n",
       " 'LGBM_MinMaxScaler_tt_50_105': 0.9719806763285024,\n",
       " 'LGBM_MinMaxScaler_tt_50_94': 0.966183574879227,\n",
       " 'LGBM_MinMaxScaler_tt_75_25': 0.970048309178744,\n",
       " 'LGBM_MinMaxScaler_tt_75_105': 0.966183574879227,\n",
       " 'LGBM_MinMaxScaler_tt_75_94': 0.9632850241545894,\n",
       " 'LGBM_MinMaxScaler_tt_100_25': 0.9758454106280193,\n",
       " 'LGBM_MinMaxScaler_tt_100_105': 0.970048309178744,\n",
       " 'LGBM_MinMaxScaler_tt_100_94': 0.9642512077294686,\n",
       " 'LGBM_MinMaxScaler_skf_25_25': 0.9661508704061895,\n",
       " 'LGBM_MinMaxScaler_skf_25_105': 0.965183752417795,\n",
       " 'LGBM_MinMaxScaler_skf_25_94': 0.9535783365570599,\n",
       " 'LGBM_MinMaxScaler_skf_50_25': 0.9671179883945842,\n",
       " 'LGBM_MinMaxScaler_skf_50_105': 0.965183752417795,\n",
       " 'LGBM_MinMaxScaler_skf_50_94': 0.9526112185686654,\n",
       " 'LGBM_MinMaxScaler_skf_75_25': 0.9680851063829787,\n",
       " 'LGBM_MinMaxScaler_skf_75_105': 0.9671179883945842,\n",
       " 'LGBM_MinMaxScaler_skf_75_94': 0.9545454545454546,\n",
       " 'LGBM_MinMaxScaler_skf_100_25': 0.971953578336557,\n",
       " 'LGBM_MinMaxScaler_skf_100_105': 0.9661508704061895,\n",
       " 'LGBM_MinMaxScaler_skf_100_94': 0.9526112185686654,\n",
       " 'LGBM_MinMaxScaler_sss_25_25': 0.9758454106280193,\n",
       " 'LGBM_MinMaxScaler_sss_25_105': 0.966183574879227,\n",
       " 'LGBM_MinMaxScaler_sss_25_94': 0.9719806763285024,\n",
       " 'LGBM_MinMaxScaler_sss_50_25': 0.9739130434782609,\n",
       " 'LGBM_MinMaxScaler_sss_50_105': 0.9623188405797102,\n",
       " 'LGBM_MinMaxScaler_sss_50_94': 0.970048309178744,\n",
       " 'LGBM_MinMaxScaler_sss_75_25': 0.9719806763285024,\n",
       " 'LGBM_MinMaxScaler_sss_75_105': 0.9719806763285024,\n",
       " 'LGBM_MinMaxScaler_sss_75_94': 0.966183574879227,\n",
       " 'LGBM_MinMaxScaler_sss_100_25': 0.9739130434782609,\n",
       " 'LGBM_MinMaxScaler_sss_100_105': 0.9681159420289855,\n",
       " 'LGBM_MinMaxScaler_sss_100_94': 0.9710144927536232,\n",
       " 'GrdBst_StandardScaler_tt_25_25': 0.9603864734299516,\n",
       " 'GrdBst_StandardScaler_tt_25_105': 0.961352657004831,\n",
       " 'GrdBst_StandardScaler_tt_25_94': 0.9632850241545894,\n",
       " 'GrdBst_StandardScaler_tt_50_25': 0.9681159420289855,\n",
       " 'GrdBst_StandardScaler_tt_50_105': 0.966183574879227,\n",
       " 'GrdBst_StandardScaler_tt_50_94': 0.966183574879227,\n",
       " 'GrdBst_StandardScaler_tt_75_25': 0.9729468599033816,\n",
       " 'GrdBst_StandardScaler_tt_75_105': 0.9652173913043478,\n",
       " 'GrdBst_StandardScaler_tt_75_94': 0.9642512077294686,\n",
       " 'GrdBst_StandardScaler_tt_100_25': 0.9719806763285024,\n",
       " 'GrdBst_StandardScaler_tt_100_105': 0.966183574879227,\n",
       " 'GrdBst_StandardScaler_tt_100_94': 0.9632850241545894,\n",
       " 'GrdBst_StandardScaler_skf_25_25': 0.9584139264990329,\n",
       " 'GrdBst_StandardScaler_skf_25_105': 0.9574468085106383,\n",
       " 'GrdBst_StandardScaler_skf_25_94': 0.9593810444874274,\n",
       " 'GrdBst_StandardScaler_skf_50_25': 0.9642166344294004,\n",
       " 'GrdBst_StandardScaler_skf_50_105': 0.9584139264990329,\n",
       " 'GrdBst_StandardScaler_skf_50_94': 0.9642166344294004,\n",
       " 'GrdBst_StandardScaler_skf_75_25': 0.9642166344294004,\n",
       " 'GrdBst_StandardScaler_skf_75_105': 0.9632495164410058,\n",
       " 'GrdBst_StandardScaler_skf_75_94': 0.960348162475822,\n",
       " 'GrdBst_StandardScaler_skf_100_25': 0.9671179883945842,\n",
       " 'GrdBst_StandardScaler_skf_100_105': 0.965183752417795,\n",
       " 'GrdBst_StandardScaler_skf_100_94': 0.9613152804642167,\n",
       " 'GrdBst_StandardScaler_sss_25_25': 0.961352657004831,\n",
       " 'GrdBst_StandardScaler_sss_25_105': 0.966183574879227,\n",
       " 'GrdBst_StandardScaler_sss_25_94': 0.9565217391304348,\n",
       " 'GrdBst_StandardScaler_sss_50_25': 0.9623188405797102,\n",
       " 'GrdBst_StandardScaler_sss_50_105': 0.9690821256038648,\n",
       " 'GrdBst_StandardScaler_sss_50_94': 0.9603864734299516,\n",
       " 'GrdBst_StandardScaler_sss_75_25': 0.966183574879227,\n",
       " 'GrdBst_StandardScaler_sss_75_105': 0.9671497584541063,\n",
       " 'GrdBst_StandardScaler_sss_75_94': 0.961352657004831,\n",
       " 'GrdBst_StandardScaler_sss_100_25': 0.9642512077294686,\n",
       " 'GrdBst_StandardScaler_sss_100_105': 0.966183574879227,\n",
       " 'GrdBst_StandardScaler_sss_100_94': 0.9623188405797102,\n",
       " 'GrdBst_MinMaxScaler_tt_25_25': 0.9603864734299516,\n",
       " 'GrdBst_MinMaxScaler_tt_25_105': 0.9603864734299516,\n",
       " 'GrdBst_MinMaxScaler_tt_25_94': 0.9594202898550724,\n",
       " 'GrdBst_MinMaxScaler_tt_50_25': 0.9642512077294686,\n",
       " 'GrdBst_MinMaxScaler_tt_50_105': 0.9642512077294686,\n",
       " 'GrdBst_MinMaxScaler_tt_50_94': 0.9603864734299516,\n",
       " 'GrdBst_MinMaxScaler_tt_75_25': 0.9623188405797102,\n",
       " 'GrdBst_MinMaxScaler_tt_75_105': 0.966183574879227,\n",
       " 'GrdBst_MinMaxScaler_tt_75_94': 0.9584541062801932,\n",
       " 'GrdBst_MinMaxScaler_tt_100_25': 0.9603864734299516,\n",
       " 'GrdBst_MinMaxScaler_tt_100_105': 0.9690821256038648,\n",
       " 'GrdBst_MinMaxScaler_tt_100_94': 0.9623188405797102,\n",
       " 'GrdBst_MinMaxScaler_skf_25_25': 0.9584139264990329,\n",
       " 'GrdBst_MinMaxScaler_skf_25_105': 0.9622823984526112,\n",
       " 'GrdBst_MinMaxScaler_skf_25_94': 0.941972920696325,\n",
       " 'GrdBst_MinMaxScaler_skf_50_25': 0.960348162475822,\n",
       " 'GrdBst_MinMaxScaler_skf_50_105': 0.9671179883945842,\n",
       " 'GrdBst_MinMaxScaler_skf_50_94': 0.9497098646034816,\n",
       " 'GrdBst_MinMaxScaler_skf_75_25': 0.9661508704061895,\n",
       " 'GrdBst_MinMaxScaler_skf_75_105': 0.965183752417795,\n",
       " 'GrdBst_MinMaxScaler_skf_75_94': 0.9458413926499033,\n",
       " 'GrdBst_MinMaxScaler_skf_100_25': 0.9661508704061895,\n",
       " 'GrdBst_MinMaxScaler_skf_100_105': 0.9593810444874274,\n",
       " 'GrdBst_MinMaxScaler_skf_100_94': 0.9487427466150871,\n",
       " 'GrdBst_MinMaxScaler_sss_25_25': 0.9642512077294686,\n",
       " 'GrdBst_MinMaxScaler_sss_25_105': 0.9565217391304348,\n",
       " 'GrdBst_MinMaxScaler_sss_25_94': 0.9603864734299516,\n",
       " 'GrdBst_MinMaxScaler_sss_50_25': 0.9681159420289855,\n",
       " 'GrdBst_MinMaxScaler_sss_50_105': 0.961352657004831,\n",
       " 'GrdBst_MinMaxScaler_sss_50_94': 0.9584541062801932,\n",
       " 'GrdBst_MinMaxScaler_sss_75_25': 0.966183574879227,\n",
       " 'GrdBst_MinMaxScaler_sss_75_105': 0.9632850241545894,\n",
       " 'GrdBst_MinMaxScaler_sss_75_94': 0.961352657004831,\n",
       " 'GrdBst_MinMaxScaler_sss_100_25': 0.9671497584541063,\n",
       " 'GrdBst_MinMaxScaler_sss_100_105': 0.9652173913043478,\n",
       " 'GrdBst_MinMaxScaler_sss_100_94': 0.9584541062801932,\n",
       " 'ADABoost_100_StandardScaler_tt_25_25': 0.957487922705314,\n",
       " 'ADABoost_100_StandardScaler_tt_25_105': 0.9603864734299516,\n",
       " 'ADABoost_100_StandardScaler_tt_25_94': 0.9526570048309179,\n",
       " 'ADABoost_100_StandardScaler_tt_50_25': 0.9594202898550724,\n",
       " 'ADABoost_100_StandardScaler_tt_50_105': 0.9642512077294686,\n",
       " 'ADABoost_100_StandardScaler_tt_50_94': 0.961352657004831,\n",
       " 'ADABoost_100_StandardScaler_tt_75_25': 0.9623188405797102,\n",
       " 'ADABoost_100_StandardScaler_tt_75_105': 0.9642512077294686,\n",
       " 'ADABoost_100_StandardScaler_tt_75_94': 0.9642512077294686,\n",
       " 'ADABoost_100_StandardScaler_tt_100_25': 0.9642512077294686,\n",
       " 'ADABoost_100_StandardScaler_tt_100_105': 0.9642512077294686,\n",
       " 'ADABoost_100_StandardScaler_tt_100_94': 0.961352657004831,\n",
       " 'ADABoost_100_StandardScaler_skf_25_25': 0.9545454545454546,\n",
       " 'ADABoost_100_StandardScaler_skf_25_105': 0.9487427466150871,\n",
       " 'ADABoost_100_StandardScaler_skf_25_94': 0.9439071566731141,\n",
       " 'ADABoost_100_StandardScaler_skf_50_25': 0.9555125725338491,\n",
       " 'ADABoost_100_StandardScaler_skf_50_105': 0.9632495164410058,\n",
       " 'ADABoost_100_StandardScaler_skf_50_94': 0.9535783365570599,\n",
       " 'ADABoost_100_StandardScaler_skf_75_25': 0.9613152804642167,\n",
       " 'ADABoost_100_StandardScaler_skf_75_105': 0.960348162475822,\n",
       " 'ADABoost_100_StandardScaler_skf_75_94': 0.960348162475822,\n",
       " 'ADABoost_100_StandardScaler_skf_100_25': 0.9642166344294004,\n",
       " 'ADABoost_100_StandardScaler_skf_100_105': 0.9661508704061895,\n",
       " 'ADABoost_100_StandardScaler_skf_100_94': 0.9506769825918762,\n",
       " 'ADABoost_100_StandardScaler_sss_25_25': 0.9603864734299516,\n",
       " 'ADABoost_100_StandardScaler_sss_25_105': 0.9594202898550724,\n",
       " 'ADABoost_100_StandardScaler_sss_25_94': 0.9507246376811594,\n",
       " 'ADABoost_100_StandardScaler_sss_50_25': 0.9584541062801932,\n",
       " 'ADABoost_100_StandardScaler_sss_50_105': 0.9632850241545894,\n",
       " 'ADABoost_100_StandardScaler_sss_50_94': 0.9565217391304348,\n",
       " 'ADABoost_100_StandardScaler_sss_75_25': 0.9594202898550724,\n",
       " 'ADABoost_100_StandardScaler_sss_75_105': 0.9594202898550724,\n",
       " 'ADABoost_100_StandardScaler_sss_75_94': 0.9555555555555556,\n",
       " 'ADABoost_100_StandardScaler_sss_100_25': 0.9623188405797102,\n",
       " 'ADABoost_100_StandardScaler_sss_100_105': 0.9594202898550724,\n",
       " 'ADABoost_100_StandardScaler_sss_100_94': 0.9555555555555556,\n",
       " 'ADABoost_100_MinMaxScaler_tt_25_25': 0.9391304347826087,\n",
       " 'ADABoost_100_MinMaxScaler_tt_25_105': 0.9565217391304348,\n",
       " 'ADABoost_100_MinMaxScaler_tt_25_94': 0.9439613526570049,\n",
       " 'ADABoost_100_MinMaxScaler_tt_50_25': 0.9565217391304348,\n",
       " 'ADABoost_100_MinMaxScaler_tt_50_105': 0.9623188405797102,\n",
       " 'ADABoost_100_MinMaxScaler_tt_50_94': 0.9400966183574879,\n",
       " 'ADABoost_100_MinMaxScaler_tt_75_25': 0.9536231884057971,\n",
       " 'ADABoost_100_MinMaxScaler_tt_75_105': 0.9594202898550724,\n",
       " 'ADABoost_100_MinMaxScaler_tt_75_94': 0.9487922705314009,\n",
       " 'ADABoost_100_MinMaxScaler_tt_100_25': 0.9507246376811594,\n",
       " 'ADABoost_100_MinMaxScaler_tt_100_105': 0.961352657004831,\n",
       " 'ADABoost_100_MinMaxScaler_tt_100_94': 0.9516908212560387,\n",
       " 'ADABoost_100_MinMaxScaler_skf_25_25': 0.9468085106382979,\n",
       " 'ADABoost_100_MinMaxScaler_skf_25_105': 0.9506769825918762,\n",
       " 'ADABoost_100_MinMaxScaler_skf_25_94': 0.9429400386847195,\n",
       " 'ADABoost_100_MinMaxScaler_skf_50_25': 0.9526112185686654,\n",
       " 'ADABoost_100_MinMaxScaler_skf_50_105': 0.9526112185686654,\n",
       " 'ADABoost_100_MinMaxScaler_skf_50_94': 0.9342359767891683,\n",
       " 'ADABoost_100_MinMaxScaler_skf_75_25': 0.9497098646034816,\n",
       " 'ADABoost_100_MinMaxScaler_skf_75_105': 0.9506769825918762,\n",
       " 'ADABoost_100_MinMaxScaler_skf_75_94': 0.9381044487427466,\n",
       " 'ADABoost_100_MinMaxScaler_skf_100_25': 0.965183752417795,\n",
       " 'ADABoost_100_MinMaxScaler_skf_100_105': 0.9584139264990329,\n",
       " 'ADABoost_100_MinMaxScaler_skf_100_94': 0.9410058027079303,\n",
       " 'ADABoost_100_MinMaxScaler_sss_25_25': 0.9487922705314009,\n",
       " 'ADABoost_100_MinMaxScaler_sss_25_105': 0.9449275362318841,\n",
       " 'ADABoost_100_MinMaxScaler_sss_25_94': 0.9478260869565217,\n",
       " 'ADABoost_100_MinMaxScaler_sss_50_25': 0.9487922705314009,\n",
       " 'ADABoost_100_MinMaxScaler_sss_50_105': 0.9497584541062802,\n",
       " 'ADABoost_100_MinMaxScaler_sss_50_94': 0.9468599033816425,\n",
       " 'ADABoost_100_MinMaxScaler_sss_75_25': 0.9507246376811594,\n",
       " 'ADABoost_100_MinMaxScaler_sss_75_105': 0.9507246376811594,\n",
       " 'ADABoost_100_MinMaxScaler_sss_75_94': 0.9497584541062802,\n",
       " 'ADABoost_100_MinMaxScaler_sss_100_25': 0.9545893719806763,\n",
       " 'ADABoost_100_MinMaxScaler_sss_100_105': 0.9545893719806763,\n",
       " 'ADABoost_100_MinMaxScaler_sss_100_94': 0.9468599033816425,\n",
       " 'ADABoost_200_StandardScaler_tt_25_25': 0.9652173913043478,\n",
       " 'ADABoost_200_StandardScaler_tt_25_105': 0.9526570048309179,\n",
       " 'ADABoost_200_StandardScaler_tt_25_94': 0.9497584541062802,\n",
       " 'ADABoost_200_StandardScaler_tt_50_25': 0.9652173913043478,\n",
       " 'ADABoost_200_StandardScaler_tt_50_105': 0.9594202898550724,\n",
       " 'ADABoost_200_StandardScaler_tt_50_94': 0.961352657004831,\n",
       " 'ADABoost_200_StandardScaler_tt_75_25': 0.9632850241545894,\n",
       " 'ADABoost_200_StandardScaler_tt_75_105': 0.970048309178744,\n",
       " 'ADABoost_200_StandardScaler_tt_75_94': 0.9603864734299516,\n",
       " 'ADABoost_200_StandardScaler_tt_100_25': 0.9584541062801932,\n",
       " 'ADABoost_200_StandardScaler_tt_100_105': 0.9642512077294686,\n",
       " 'ADABoost_200_StandardScaler_tt_100_94': 0.9584541062801932,\n",
       " 'ADABoost_200_StandardScaler_skf_25_25': 0.9564796905222437,\n",
       " 'ADABoost_200_StandardScaler_skf_25_105': 0.960348162475822,\n",
       " 'ADABoost_200_StandardScaler_skf_25_94': 0.9506769825918762,\n",
       " 'ADABoost_200_StandardScaler_skf_50_25': 0.9564796905222437,\n",
       " 'ADABoost_200_StandardScaler_skf_50_105': 0.960348162475822,\n",
       " 'ADABoost_200_StandardScaler_skf_50_94': 0.9535783365570599,\n",
       " 'ADABoost_200_StandardScaler_skf_75_25': 0.9584139264990329,\n",
       " 'ADABoost_200_StandardScaler_skf_75_105': 0.971953578336557,\n",
       " 'ADABoost_200_StandardScaler_skf_75_94': 0.9632495164410058,\n",
       " 'ADABoost_200_StandardScaler_skf_100_25': 0.9642166344294004,\n",
       " 'ADABoost_200_StandardScaler_skf_100_105': 0.9661508704061895,\n",
       " 'ADABoost_200_StandardScaler_skf_100_94': 0.9574468085106383,\n",
       " 'ADABoost_200_StandardScaler_sss_25_25': 0.961352657004831,\n",
       " 'ADABoost_200_StandardScaler_sss_25_105': 0.961352657004831,\n",
       " 'ADABoost_200_StandardScaler_sss_25_94': 0.9526570048309179,\n",
       " 'ADABoost_200_StandardScaler_sss_50_25': 0.9652173913043478,\n",
       " 'ADABoost_200_StandardScaler_sss_50_105': 0.9642512077294686,\n",
       " 'ADABoost_200_StandardScaler_sss_50_94': 0.9536231884057971,\n",
       " 'ADABoost_200_StandardScaler_sss_75_25': 0.9671497584541063,\n",
       " 'ADABoost_200_StandardScaler_sss_75_105': 0.9594202898550724,\n",
       " 'ADABoost_200_StandardScaler_sss_75_94': 0.9632850241545894,\n",
       " 'ADABoost_200_StandardScaler_sss_100_25': 0.966183574879227,\n",
       " 'ADABoost_200_StandardScaler_sss_100_105': 0.9681159420289855,\n",
       " 'ADABoost_200_StandardScaler_sss_100_94': 0.9594202898550724,\n",
       " 'ADABoost_200_MinMaxScaler_tt_25_25': 0.9449275362318841,\n",
       " 'ADABoost_200_MinMaxScaler_tt_25_105': 0.9555555555555556,\n",
       " 'ADABoost_200_MinMaxScaler_tt_25_94': 0.9478260869565217,\n",
       " 'ADABoost_200_MinMaxScaler_tt_50_25': 0.9623188405797102,\n",
       " 'ADABoost_200_MinMaxScaler_tt_50_105': 0.9623188405797102,\n",
       " 'ADABoost_200_MinMaxScaler_tt_50_94': 0.9458937198067633,\n",
       " 'ADABoost_200_MinMaxScaler_tt_75_25': 0.9584541062801932,\n",
       " 'ADABoost_200_MinMaxScaler_tt_75_105': 0.9603864734299516,\n",
       " 'ADABoost_200_MinMaxScaler_tt_75_94': 0.9536231884057971,\n",
       " 'ADABoost_200_MinMaxScaler_tt_100_25': 0.9565217391304348,\n",
       " 'ADABoost_200_MinMaxScaler_tt_100_105': 0.9681159420289855,\n",
       " 'ADABoost_200_MinMaxScaler_tt_100_94': 0.961352657004831,\n",
       " 'ADABoost_200_MinMaxScaler_skf_25_25': 0.9564796905222437,\n",
       " 'ADABoost_200_MinMaxScaler_skf_25_105': 0.9516441005802708,\n",
       " 'ADABoost_200_MinMaxScaler_skf_25_94': 0.9429400386847195,\n",
       " 'ADABoost_200_MinMaxScaler_skf_50_25': 0.9574468085106383,\n",
       " 'ADABoost_200_MinMaxScaler_skf_50_105': 0.960348162475822,\n",
       " 'ADABoost_200_MinMaxScaler_skf_50_94': 0.9439071566731141,\n",
       " 'ADABoost_200_MinMaxScaler_skf_75_25': 0.9535783365570599,\n",
       " 'ADABoost_200_MinMaxScaler_skf_75_105': 0.9497098646034816,\n",
       " 'ADABoost_200_MinMaxScaler_skf_75_94': 0.941972920696325,\n",
       " 'ADABoost_200_MinMaxScaler_skf_100_25': 0.9574468085106383,\n",
       " 'ADABoost_200_MinMaxScaler_skf_100_105': 0.960348162475822,\n",
       " 'ADABoost_200_MinMaxScaler_skf_100_94': 0.9535783365570599,\n",
       " 'ADABoost_200_MinMaxScaler_sss_25_25': 0.9497584541062802,\n",
       " 'ADABoost_200_MinMaxScaler_sss_25_105': 0.9545893719806763,\n",
       " 'ADABoost_200_MinMaxScaler_sss_25_94': 0.9497584541062802,\n",
       " 'ADABoost_200_MinMaxScaler_sss_50_25': 0.9555555555555556,\n",
       " 'ADABoost_200_MinMaxScaler_sss_50_105': 0.9497584541062802,\n",
       " 'ADABoost_200_MinMaxScaler_sss_50_94': 0.9468599033816425,\n",
       " 'ADABoost_200_MinMaxScaler_sss_75_25': 0.9526570048309179,\n",
       " 'ADABoost_200_MinMaxScaler_sss_75_105': 0.9565217391304348,\n",
       " 'ADABoost_200_MinMaxScaler_sss_75_94': 0.9478260869565217,\n",
       " 'ADABoost_200_MinMaxScaler_sss_100_25': 0.9526570048309179,\n",
       " 'ADABoost_200_MinMaxScaler_sss_100_105': 0.9545893719806763,\n",
       " 'ADABoost_200_MinMaxScaler_sss_100_94': 0.9449275362318841}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_results_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2fd1d8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_df = pd.DataFrame.from_dict(pca_results_acc, orient='index')\n",
    "acc_df.reset_index(inplace=True)\n",
    "acc_df.rename(columns={'index': 'model', 0 : 'accuracy'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "40c9496c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>underscore_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>RandomForest_200_MinMaxScaler_tt_100_105</td>\n",
       "      <td>0.978744</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>RandomForest_100_StandardScaler_sss_75_105</td>\n",
       "      <td>0.978744</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>RandomForest_200_MinMaxScaler_tt_75_105</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>RandomForest_100_MinMaxScaler_tt_100_105</td>\n",
       "      <td>0.976812</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>LGBM_MinMaxScaler_tt_100_25</td>\n",
       "      <td>0.975845</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>SVMSigmoid_StandardScaler_sss_25_105</td>\n",
       "      <td>0.813527</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>SVMSigmoid_MinMaxScaler_sss_25_105</td>\n",
       "      <td>0.813527</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>SVMSigmoid_MinMaxScaler_skf_25_94</td>\n",
       "      <td>0.813346</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>SVMSigmoid_MinMaxScaler_sss_25_94</td>\n",
       "      <td>0.811594</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>SVMSigmoid_MinMaxScaler_tt_25_105</td>\n",
       "      <td>0.802899</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>864 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          model  accuracy  underscore_count\n",
       "190    RandomForest_200_MinMaxScaler_tt_100_105  0.978744                 5\n",
       "103  RandomForest_100_StandardScaler_sss_75_105  0.978744                 5\n",
       "187     RandomForest_200_MinMaxScaler_tt_75_105  0.977778                 5\n",
       "118    RandomForest_100_MinMaxScaler_tt_100_105  0.976812                 5\n",
       "621                 LGBM_MinMaxScaler_tt_100_25  0.975845                 4\n",
       "..                                          ...       ...               ...\n",
       "313        SVMSigmoid_StandardScaler_sss_25_105  0.813527                 4\n",
       "349          SVMSigmoid_MinMaxScaler_sss_25_105  0.813527                 4\n",
       "338           SVMSigmoid_MinMaxScaler_skf_25_94  0.813346                 4\n",
       "350           SVMSigmoid_MinMaxScaler_sss_25_94  0.811594                 4\n",
       "325           SVMSigmoid_MinMaxScaler_tt_25_105  0.802899                 4\n",
       "\n",
       "[864 rows x 3 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_df.sort_values(by='accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e616fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_df.model.str.contains()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "cc1edca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of underscores in the 'model' column\n",
    "p_result_df['underscore_count'] = p_result_df['model'].str.count('_')\n",
    "\n",
    "# Find rows with exactly six underscores (i.e., seven parts)\n",
    "#acc_df = acc_df[acc_df['underscore_count'] == 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "2be40146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "underscore_count\n",
       "5    504\n",
       "4    360\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_result_df.underscore_count.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b0049c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_5df = acc_df[acc_df['underscore_count'] == 5]\n",
    "acc_5df_2 = acc_5df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f9000bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_5df_2['model'] = acc_5df_2['model'].str.replace('_', '',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9fa424d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>underscore_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>RandomForest100_StandardScaler_tt_25_25</td>\n",
       "      <td>0.968116</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>RandomForest100_StandardScaler_tt_25_105</td>\n",
       "      <td>0.970048</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>RandomForest100_StandardScaler_tt_25_94</td>\n",
       "      <td>0.964251</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>RandomForest100_StandardScaler_tt_50_25</td>\n",
       "      <td>0.969082</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>RandomForest100_StandardScaler_tt_50_105</td>\n",
       "      <td>0.970048</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>ADABoost200_MinMaxScaler_sss_75_105</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>ADABoost200_MinMaxScaler_sss_75_94</td>\n",
       "      <td>0.947826</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>ADABoost200_MinMaxScaler_sss_100_25</td>\n",
       "      <td>0.952657</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>ADABoost200_MinMaxScaler_sss_100_105</td>\n",
       "      <td>0.954589</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>ADABoost200_MinMaxScaler_sss_100_94</td>\n",
       "      <td>0.944928</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>504 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        model  accuracy  underscore_count\n",
       "72    RandomForest100_StandardScaler_tt_25_25  0.968116                 5\n",
       "73   RandomForest100_StandardScaler_tt_25_105  0.970048                 5\n",
       "74    RandomForest100_StandardScaler_tt_25_94  0.964251                 5\n",
       "75    RandomForest100_StandardScaler_tt_50_25  0.969082                 5\n",
       "76   RandomForest100_StandardScaler_tt_50_105  0.970048                 5\n",
       "..                                        ...       ...               ...\n",
       "859       ADABoost200_MinMaxScaler_sss_75_105  0.956522                 5\n",
       "860        ADABoost200_MinMaxScaler_sss_75_94  0.947826                 5\n",
       "861       ADABoost200_MinMaxScaler_sss_100_25  0.952657                 5\n",
       "862      ADABoost200_MinMaxScaler_sss_100_105  0.954589                 5\n",
       "863       ADABoost200_MinMaxScaler_sss_100_94  0.944928                 5\n",
       "\n",
       "[504 rows x 3 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_5df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "fc0bb5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_5df_2['model'] = acc_5df_2['model'].apply(lambda x: x.replace('_', '', 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6d128bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_first_underscore(s):\n",
    "    # Find the position of the first underscore\n",
    "    pos = s.find('_')\n",
    "    # If an underscore is found, replace it with an empty string\n",
    "    if pos != -1:\n",
    "        return s[:pos] + s[pos + 1:]\n",
    "    return s\n",
    "\n",
    "# Apply the function to the 'model' column\n",
    "acc_5df_2['model'] = acc_5df_2['model'].apply(remove_first_underscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91370c56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5bcbc966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72      RandomForest100StandardScalertt_25_25\n",
       "73     RandomForest100StandardScalertt_25_105\n",
       "74      RandomForest100StandardScalertt_25_94\n",
       "75      RandomForest100StandardScalertt_50_25\n",
       "76     RandomForest100StandardScalertt_50_105\n",
       "                        ...                  \n",
       "859         ADABoost200MinMaxScalersss_75_105\n",
       "860          ADABoost200MinMaxScalersss_75_94\n",
       "861         ADABoost200MinMaxScalersss_100_25\n",
       "862        ADABoost200MinMaxScalersss_100_105\n",
       "863         ADABoost200MinMaxScalersss_100_94\n",
       "Name: model, Length: 504, dtype: object"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_5df_2.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e75ab313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "underscore_count\n",
       "4    504\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_5df_2['underscore_count'] = acc_5df_2['model'].str.count('_')\n",
    "acc_5df_2.underscore_count.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f811b0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_df2 = pd.concat([acc_df[acc_df['underscore_count'] == 4],acc_5df_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf821d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647b86e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "04150fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_models = acc_df[acc_df.accuracy > 0.97]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "af8345e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression_StandardScaler_tt_100_105</td>\n",
       "      <td>0.971981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>LogisticRegression_StandardScaler_sss_75_25</td>\n",
       "      <td>0.971014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>LogisticRegression_StandardScaler_sss_100_25</td>\n",
       "      <td>0.970048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>RandomForest_100_StandardScaler_tt_25_105</td>\n",
       "      <td>0.970048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>RandomForest_100_StandardScaler_tt_50_105</td>\n",
       "      <td>0.970048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>LGBM_MinMaxScaler_sss_100_94</td>\n",
       "      <td>0.971014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>GrdBst_StandardScaler_tt_75_25</td>\n",
       "      <td>0.972947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>GrdBst_StandardScaler_tt_100_25</td>\n",
       "      <td>0.971981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>ADABoost_200_StandardScaler_tt_75_105</td>\n",
       "      <td>0.970048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>ADABoost_200_StandardScaler_skf_75_105</td>\n",
       "      <td>0.971954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            model  accuracy\n",
       "10   LogisticRegression_StandardScaler_tt_100_105  0.971981\n",
       "30    LogisticRegression_StandardScaler_sss_75_25  0.971014\n",
       "33   LogisticRegression_StandardScaler_sss_100_25  0.970048\n",
       "73      RandomForest_100_StandardScaler_tt_25_105  0.970048\n",
       "76      RandomForest_100_StandardScaler_tt_50_105  0.970048\n",
       "..                                            ...       ...\n",
       "647                  LGBM_MinMaxScaler_sss_100_94  0.971014\n",
       "654                GrdBst_StandardScaler_tt_75_25  0.972947\n",
       "657               GrdBst_StandardScaler_tt_100_25  0.971981\n",
       "799         ADABoost_200_StandardScaler_tt_75_105  0.970048\n",
       "811        ADABoost_200_StandardScaler_skf_75_105  0.971954\n",
       "\n",
       "[68 rows x 2 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e356ad48",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_columns = acc_df2['model'].str.split('_', expand=True)\n",
    "\n",
    "# Rename the new columns\n",
    "split_columns.columns = ['model_name', 'scaler', 'split_method', 'pca_components', 'random_state']\n",
    "\n",
    "# Join the new columns back to the original DataFrame\n",
    "acc_df3 = acc_df2.join(split_columns)\n",
    "\n",
    "# Optionally, drop the original 'model' column\n",
    "acc_df3.drop(columns=['model', 'underscore_count'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "f3ed80d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>model_name</th>\n",
       "      <th>scaler</th>\n",
       "      <th>split_method</th>\n",
       "      <th>pca_components</th>\n",
       "      <th>random_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>0.978744</td>\n",
       "      <td>RandomForest200</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>tt</td>\n",
       "      <td>100</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.978744</td>\n",
       "      <td>RandomForest100</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>sss</td>\n",
       "      <td>75</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>0.977778</td>\n",
       "      <td>RandomForest200</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>tt</td>\n",
       "      <td>75</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0.976812</td>\n",
       "      <td>RandomForest100</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>tt</td>\n",
       "      <td>100</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>0.975845</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>sss</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>0.813527</td>\n",
       "      <td>SVMSigmoid</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>sss</td>\n",
       "      <td>25</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>0.813527</td>\n",
       "      <td>SVMSigmoid</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>sss</td>\n",
       "      <td>25</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>0.813346</td>\n",
       "      <td>SVMSigmoid</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>skf</td>\n",
       "      <td>25</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>0.811594</td>\n",
       "      <td>SVMSigmoid</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>sss</td>\n",
       "      <td>25</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>0.802899</td>\n",
       "      <td>SVMSigmoid</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>tt</td>\n",
       "      <td>25</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>864 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     accuracy       model_name          scaler split_method pca_components  \\\n",
       "190  0.978744  RandomForest200    MinMaxScaler           tt            100   \n",
       "103  0.978744  RandomForest100  StandardScaler          sss             75   \n",
       "187  0.977778  RandomForest200    MinMaxScaler           tt             75   \n",
       "118  0.976812  RandomForest100    MinMaxScaler           tt            100   \n",
       "636  0.975845             LGBM    MinMaxScaler          sss             25   \n",
       "..        ...              ...             ...          ...            ...   \n",
       "349  0.813527       SVMSigmoid    MinMaxScaler          sss             25   \n",
       "313  0.813527       SVMSigmoid  StandardScaler          sss             25   \n",
       "338  0.813346       SVMSigmoid    MinMaxScaler          skf             25   \n",
       "350  0.811594       SVMSigmoid    MinMaxScaler          sss             25   \n",
       "325  0.802899       SVMSigmoid    MinMaxScaler           tt             25   \n",
       "\n",
       "    random_state  \n",
       "190          105  \n",
       "103          105  \n",
       "187          105  \n",
       "118          105  \n",
       "636           25  \n",
       "..           ...  \n",
       "349          105  \n",
       "313          105  \n",
       "338           94  \n",
       "350           94  \n",
       "325          105  \n",
       "\n",
       "[864 rows x 6 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_df3.sort_values(by='accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "55d5873c",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_df3 = acc_df3.sort_values(by='accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "693d0195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_models = acc_df3[acc_df3.accuracy > 0.97]\n",
    "len(top_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "00f3cf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_mods = acc_df3[acc_df3.model_name.isin(['RandomForest200', 'RandomForest100','LGBM','GrdBost','AdaBoost200','SVMLinear'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aff7e6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "68972a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest200: 0.9667\n",
      "RandomForest100: 0.9664\n",
      "LGBM: 0.9663\n",
      "SVMLinear: 0.9544\n",
      "\n",
      "\n",
      "MinMaxScaler: 0.9627\n",
      "StandardScaler: 0.9643\n",
      "\n",
      "\n",
      "tt: 0.9653\n",
      "sss: 0.9647\n",
      "skf: 0.9605\n",
      "\n",
      "\n",
      "100: 0.9652\n",
      "75: 0.9642\n",
      "25: 0.9604\n",
      "50: 0.9641\n"
     ]
    }
   ],
   "source": [
    "for mod in top_mods.model_name.unique():\n",
    "    print(mod + ': ' + str(round(top_mods[top_mods.model_name == mod]['accuracy'].mean(), 4)))\n",
    "\n",
    "print('\\n')\n",
    "for mod in top_mods.scaler.unique():\n",
    "    print(mod + ': ' + str(round(top_mods[top_mods.scaler == mod]['accuracy'].mean(), 4)))   \n",
    "    \n",
    "print('\\n')\n",
    "for mod in top_mods.split_method.unique():\n",
    "    print(mod + ': ' + str(round(top_mods[top_mods.split_method == mod]['accuracy'].mean(), 4))) \n",
    "    \n",
    "print('\\n')\n",
    "for mod in top_mods.pca_components.unique():\n",
    "    print(mod + ': ' + str(round(top_mods[top_mods.pca_components == mod]['accuracy'].mean(), 4)))     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c860c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "'tt', "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228d63a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "63722642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest200: 0.972\n",
      "RandomForest100: 0.9718\n",
      "LGBM: 0.9721\n",
      "GrdBst: 0.9725\n",
      "LogisticRegression: 0.971\n",
      "ADABoost200: 0.971\n",
      "SVMLinear: 0.9705\n",
      "\n",
      "\n",
      "MinMaxScaler: 0.9723\n",
      "StandardScaler: 0.9715\n",
      "\n",
      "\n",
      "tt: 0.9724\n",
      "sss: 0.9718\n",
      "skf: 0.9707\n",
      "\n",
      "\n",
      "100: 0.9721\n",
      "75: 0.9723\n",
      "25: 0.9709\n",
      "50: 0.9717\n"
     ]
    }
   ],
   "source": [
    "for mod in top_models.model_name.unique():\n",
    "    print(mod + ': ' + str(round(top_models[top_models.model_name == mod]['accuracy'].mean(), 4)))\n",
    "\n",
    "print('\\n')\n",
    "for mod in top_models.scaler.unique():\n",
    "    print(mod + ': ' + str(round(top_models[top_models.scaler == mod]['accuracy'].mean(), 4)))   \n",
    "    \n",
    "print('\\n')\n",
    "for mod in top_models.split_method.unique():\n",
    "    print(mod + ': ' + str(round(top_models[top_models.split_method == mod]['accuracy'].mean(), 4))) \n",
    "    \n",
    "print('\\n')\n",
    "for mod in top_models.pca_components.unique():\n",
    "    print(mod + ': ' + str(round(top_models[top_models.pca_components == mod]['accuracy'].mean(), 4)))     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9815b96d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f3bbad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303d7e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1, c2 = sc_pca_class_test(X, y, mm_sc, 50, 0.2, LogisticRegression(), 'skf', 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e9a05307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Random Forest\n",
      "SVM Linear\n",
      "SVM Sigmoid\n",
      "KNN\n",
      "LGBM\n",
      "GrdBst\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "results_acc = {}\n",
    "results_rep = {}\n",
    "\n",
    "for classifier, func in classifiers.items():\n",
    "    for sc_name, sc_func in sc_dc.items(): \n",
    "        results[classifier] = \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5039e203",
   "metadata": {},
   "outputs": [],
   "source": [
    "SV_log = SVC(kernel='sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7ec63409",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6a720e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_acc, svm_class = sc_pca_class(X, y, mm_sc, 50, 0.2, SV_log, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "da7672b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8521739130434782"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0f76a418",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_acc_50, log_class = sc_pca_class(X, y, mm_sc, 50, 0.2, LogisticRegression(), 12)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "33f0fdcd",
   "metadata": {},
   "source": [
    "rf_acc, rf_class = sc_pca_class(X, y, mm_sc, 50, 0.2, LogisticRegression(), 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a08128d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sc_pca_class(X, y, scaler, n_comp, ts, classifier, split_method)\n",
    "\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    if split_method == 'train_test':\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n",
    "        \n",
    "        # Train and evaluate the classifier\n",
    "        classifier.fit(X_train, y_train)\n",
    "        y_pred = classifier.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        report = classification_report(y_test, y_pred)\n",
    "        \n",
    "    elif split_method == 'stratified_kfold':\n",
    "        # Split data using StratifiedKFold\n",
    "        n_splits = kwargs.get('n_splits', 5)  # Default to 5 splits\n",
    "        skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "        \n",
    "        accuracies = []\n",
    "        reports = []\n",
    "\n",
    "        for train_index, test_index in skf.split(X_pca, y):\n",
    "            X_train, X_test = X_pca[train_index], X_pca[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            \n",
    "            classifier.fit(X_train, y_train)\n",
    "            y_pred = classifier.predict(X_test)\n",
    "            accuracies.append(accuracy_score(y_test, y_pred))\n",
    "            reports.append(classification_report(y_test, y_pred, output_dict=True))\n",
    "        \n",
    "        accuracy = np.mean(accuracies)\n",
    "        report = reports  # List of classification reports for each fold\n",
    "        \n",
    "    elif split_method == 'stratified_shuffle_split':\n",
    "        # Split data using StratifiedShuffleSplit\n",
    "        test_size = kwargs.get('test_size', 0.2)  # Default test size\n",
    "        sss = StratifiedShuffleSplit(n_splits=1, test_size=test_size, random_state=42)\n",
    "        \n",
    "        for train_index, test_index in sss.split(X_pca, y):\n",
    "            X_train, X_test = X_pca[train_index], X_pca[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            \n",
    "            classifier.fit(X_train, y_train)\n",
    "            y_pred = classifier.predict(X_test)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            report = classification_report(y_test, y_pred)\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(\"Unsupported split_method. Choose from 'train_test', 'stratified_kfold', or 'stratified_shuffle_split'.\")\n",
    "    \n",
    "    classifier.fit(X_train, y_train)    \n",
    "    \n",
    "    y_pred = classifier.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    return accuracy, classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "494a2d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sc_pca_class(X, y, scaler, components, ts, classifier, split_method):\n",
    "\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    pca = PCA(n_components=components)\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=ts, random_state=42)\n",
    "\n",
    "    classifier.fit(X_train, y_train)    \n",
    "    \n",
    "    y_pred = classifier.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    return accuracy, classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1825538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9729468599033816\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       739\n",
      "           1       0.95      0.96      0.95       296\n",
      "\n",
      "    accuracy                           0.97      1035\n",
      "   macro avg       0.97      0.97      0.97      1035\n",
      "weighted avg       0.97      0.97      0.97      1035\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# pca = 25\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "22c31c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9429951690821256\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       739\n",
      "           1       0.89      0.91      0.90       296\n",
      "\n",
      "    accuracy                           0.94      1035\n",
      "   macro avg       0.93      0.93      0.93      1035\n",
      "weighted avg       0.94      0.94      0.94      1035\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# pca = 5\n",
    "\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "18991f1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier()"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "LGBMClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "11f6615c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1199, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000323 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3825\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289824 -> initscore=-0.896241\n",
      "[LightGBM] [Info] Start training from score -0.896241\n",
      "[LightGBM] [Info] Number of positive: 1187, number of negative: 2950\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000314 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3825\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.286923 -> initscore=-0.910376\n",
      "[LightGBM] [Info] Start training from score -0.910376\n",
      "[LightGBM] [Info] Number of positive: 1207, number of negative: 2930\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000820 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3825\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.291757 -> initscore=-0.886864\n",
      "[LightGBM] [Info] Start training from score -0.886864\n",
      "[LightGBM] [Info] Number of positive: 1199, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000555 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6375\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289824 -> initscore=-0.896241\n",
      "[LightGBM] [Info] Start training from score -0.896241\n",
      "[LightGBM] [Info] Number of positive: 1187, number of negative: 2950\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000543 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6375\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.286923 -> initscore=-0.910376\n",
      "[LightGBM] [Info] Start training from score -0.910376\n",
      "[LightGBM] [Info] Number of positive: 1207, number of negative: 2930\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000515 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6375\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.291757 -> initscore=-0.886864\n",
      "[LightGBM] [Info] Start training from score -0.886864\n",
      "[LightGBM] [Info] Number of positive: 1199, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001003 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289824 -> initscore=-0.896241\n",
      "[LightGBM] [Info] Start training from score -0.896241\n",
      "[LightGBM] [Info] Number of positive: 1187, number of negative: 2950\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001087 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.286923 -> initscore=-0.910376\n",
      "[LightGBM] [Info] Start training from score -0.910376\n",
      "[LightGBM] [Info] Number of positive: 1207, number of negative: 2930\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001142 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.291757 -> initscore=-0.886864\n",
      "[LightGBM] [Info] Start training from score -0.886864\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000411 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3825\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000307 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3825\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000324 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3825\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000483 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6375\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000526 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6375\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000515 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6375\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000919 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001406 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000860 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1199, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000257 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3825\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289824 -> initscore=-0.896241\n",
      "[LightGBM] [Info] Start training from score -0.896241\n",
      "[LightGBM] [Info] Number of positive: 1187, number of negative: 2950\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000307 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3825\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.286923 -> initscore=-0.910376\n",
      "[LightGBM] [Info] Start training from score -0.910376\n",
      "[LightGBM] [Info] Number of positive: 1207, number of negative: 2930\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000247 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3825\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.291757 -> initscore=-0.886864\n",
      "[LightGBM] [Info] Start training from score -0.886864\n",
      "[LightGBM] [Info] Number of positive: 1199, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000423 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6375\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289824 -> initscore=-0.896241\n",
      "[LightGBM] [Info] Start training from score -0.896241\n",
      "[LightGBM] [Info] Number of positive: 1187, number of negative: 2950\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000494 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6375\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.286923 -> initscore=-0.910376\n",
      "[LightGBM] [Info] Start training from score -0.910376\n",
      "[LightGBM] [Info] Number of positive: 1207, number of negative: 2930\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000447 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6375\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.291757 -> initscore=-0.886864\n",
      "[LightGBM] [Info] Start training from score -0.886864\n",
      "[LightGBM] [Info] Number of positive: 1199, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000885 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289824 -> initscore=-0.896241\n",
      "[LightGBM] [Info] Start training from score -0.896241\n",
      "[LightGBM] [Info] Number of positive: 1187, number of negative: 2950\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000907 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.286923 -> initscore=-0.910376\n",
      "[LightGBM] [Info] Start training from score -0.910376\n",
      "[LightGBM] [Info] Number of positive: 1207, number of negative: 2930\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000912 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.291757 -> initscore=-0.886864\n",
      "[LightGBM] [Info] Start training from score -0.886864\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000292 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3825\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000258 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3825\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000304 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3825\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000480 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6375\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000639 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6375\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000470 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6375\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000877 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000930 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000875 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1199, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025931 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23603\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2571\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289824 -> initscore=-0.896241\n",
      "[LightGBM] [Info] Start training from score -0.896241\n",
      "[LightGBM] [Info] Number of positive: 1187, number of negative: 2950\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024239 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23788\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2584\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.286923 -> initscore=-0.910376\n",
      "[LightGBM] [Info] Start training from score -0.910376\n",
      "[LightGBM] [Info] Number of positive: 1207, number of negative: 2930\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022966 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23741\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2593\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.291757 -> initscore=-0.886864\n",
      "[LightGBM] [Info] Start training from score -0.886864\n",
      "[LightGBM] [Info] Number of positive: 1199, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023080 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23603\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2571\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289824 -> initscore=-0.896241\n",
      "[LightGBM] [Info] Start training from score -0.896241\n",
      "[LightGBM] [Info] Number of positive: 1187, number of negative: 2950\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023931 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23788\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2584\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.286923 -> initscore=-0.910376\n",
      "[LightGBM] [Info] Start training from score -0.910376\n",
      "[LightGBM] [Info] Number of positive: 1207, number of negative: 2930\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024137 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23741\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2593\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.291757 -> initscore=-0.886864\n",
      "[LightGBM] [Info] Start training from score -0.886864\n",
      "[LightGBM] [Info] Number of positive: 1199, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031546 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23603\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2571\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289824 -> initscore=-0.896241\n",
      "[LightGBM] [Info] Start training from score -0.896241\n",
      "[LightGBM] [Info] Number of positive: 1187, number of negative: 2950\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028483 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23788\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2584\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.286923 -> initscore=-0.910376\n",
      "[LightGBM] [Info] Start training from score -0.910376\n",
      "[LightGBM] [Info] Number of positive: 1207, number of negative: 2930\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026439 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23741\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2593\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.291757 -> initscore=-0.886864\n",
      "[LightGBM] [Info] Start training from score -0.886864\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023537 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23574\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2584\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029453 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23603\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2577\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026920 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23723\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2593\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023695 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23574\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2584\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022972 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23603\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2577\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025289 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23723\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2593\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027409 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23574\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2584\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031232 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23603\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2577\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031493 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23723\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2593\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>model_name</th>\n",
       "      <th>split_method</th>\n",
       "      <th>pca</th>\n",
       "      <th>n_components</th>\n",
       "      <th>random_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.983575</td>\n",
       "      <td>RandomForest100</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>15</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0.983575</td>\n",
       "      <td>RandomForest200</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>35</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>0.982609</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>0.982609</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>0.982609</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>35</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.940097</td>\n",
       "      <td>RandomForest100</td>\n",
       "      <td>sss</td>\n",
       "      <td>svd</td>\n",
       "      <td>15</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>0.940097</td>\n",
       "      <td>RandomForest200</td>\n",
       "      <td>sss</td>\n",
       "      <td>pca</td>\n",
       "      <td>15</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.939130</td>\n",
       "      <td>RandomForest150</td>\n",
       "      <td>sss</td>\n",
       "      <td>pca</td>\n",
       "      <td>15</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0.939130</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>sss</td>\n",
       "      <td>svd</td>\n",
       "      <td>15</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.936232</td>\n",
       "      <td>RandomForest100</td>\n",
       "      <td>sss</td>\n",
       "      <td>pca</td>\n",
       "      <td>15</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>216 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     accuracy       model_name split_method   pca n_components random_state\n",
       "36   0.983575  RandomForest100           tt  None           15           25\n",
       "150  0.983575  RandomForest200           tt  None           35           25\n",
       "202  0.982609             LGBM           tt  None           25            9\n",
       "201  0.982609             LGBM           tt  None           25           25\n",
       "206  0.982609             LGBM           tt  None           35          210\n",
       "..        ...              ...          ...   ...          ...          ...\n",
       "29   0.940097  RandomForest100          sss   svd           15          210\n",
       "119  0.940097  RandomForest200          sss   pca           15          210\n",
       "65   0.939130  RandomForest150          sss   pca           15          210\n",
       "191  0.939130             LGBM          sss   svd           15          210\n",
       "11   0.936232  RandomForest100          sss   pca           15          210\n",
       "\n",
       "[216 rows x 6 columns]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = {'RandomForest100': RandomForestClassifier(n_estimators=100),\n",
    "'RandomForest150': RandomForestClassifier(n_estimators=150),         \n",
    " 'RandomForest200': RandomForestClassifier(n_estimators=200),\n",
    " 'LGBM': LGBMClassifier()}\n",
    "\n",
    "test_df_1 = create_acc_df(classes, ['tt', 'sss'], ['pca', 'svd', 'None'], [15, 25, 35])\n",
    "test_df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "76b7391a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None: 0.9750939345142243\n",
      "pca: 0.9630703166935051\n",
      "svd: 0.9629495437466452\n",
      "\n",
      "\n",
      "RandomForest100: 0.9661120057255322\n",
      "RandomForest200: 0.9673286813383434\n",
      "LGBM: 0.968795848989086\n",
      "RandomForest150: 0.9659151905528719\n"
     ]
    }
   ],
   "source": [
    "for c in test_df_1.pca.unique():\n",
    "    print(str(c) + ': ' + str(test_df_1[test_df_1.pca == c]['accuracy'].mean()))\n",
    "\n",
    "print('\\n')\n",
    "    \n",
    "for c in test_df_1.model_name.unique():\n",
    "    print(str(c) + ': ' + str(test_df_1[test_df_1.model_name == c]['accuracy'].mean()))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "57fe390e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1199, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019966 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23327\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2558\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289824 -> initscore=-0.896241\n",
      "[LightGBM] [Info] Start training from score -0.896241\n",
      "[LightGBM] [Info] Number of positive: 1185, number of negative: 2952\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019430 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23207\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2540\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.286439 -> initscore=-0.912740\n",
      "[LightGBM] [Info] Start training from score -0.912740\n",
      "[LightGBM] [Info] Number of positive: 1179, number of negative: 2958\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019835 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23602\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2568\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284989 -> initscore=-0.919847\n",
      "[LightGBM] [Info] Start training from score -0.919847\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>model_name</th>\n",
       "      <th>split_method</th>\n",
       "      <th>pca</th>\n",
       "      <th>n_components</th>\n",
       "      <th>random_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.982609</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.979710</td>\n",
       "      <td>RandomForest300</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.979710</td>\n",
       "      <td>RandomForest300</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.978744</td>\n",
       "      <td>RandomForest200</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.977778</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.976812</td>\n",
       "      <td>RandomForest200</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.976812</td>\n",
       "      <td>RandomForest300</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.975845</td>\n",
       "      <td>RandomForest250</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.974879</td>\n",
       "      <td>RandomForest250</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.974879</td>\n",
       "      <td>RandomForest250</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.973913</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.971981</td>\n",
       "      <td>RandomForest200</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    accuracy       model_name split_method   pca n_components random_state\n",
       "11  0.982609             LGBM           tt  None            0           35\n",
       "6   0.979710  RandomForest300           tt  None            0           94\n",
       "8   0.979710  RandomForest300           tt  None            0           35\n",
       "0   0.978744  RandomForest200           tt  None            0           94\n",
       "9   0.977778             LGBM           tt  None            0           94\n",
       "2   0.976812  RandomForest200           tt  None            0           35\n",
       "7   0.976812  RandomForest300           tt  None            0           73\n",
       "3   0.975845  RandomForest250           tt  None            0           94\n",
       "4   0.974879  RandomForest250           tt  None            0           73\n",
       "5   0.974879  RandomForest250           tt  None            0           35\n",
       "10  0.973913             LGBM           tt  None            0           73\n",
       "1   0.971981  RandomForest200           tt  None            0           73"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes_2 = {'RandomForest200': RandomForestClassifier(n_estimators=200),\n",
    "'RandomForest250': RandomForestClassifier(n_estimators=250),         \n",
    " 'RandomForest300': RandomForestClassifier(n_estimators=300),\n",
    " 'LGBM': LGBMClassifier()}\n",
    "\n",
    "test_df_2 = create_acc_df(classes_2, ['tt'], [None], [0], [94, 73, 35])\n",
    "test_df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "f3715871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM: 0.9780998389694041\n",
      "RandomForest300: 0.9787439613526571\n",
      "RandomForest200: 0.9758454106280192\n",
      "RandomForest250: 0.9752012882447666\n"
     ]
    }
   ],
   "source": [
    "for c in test_df_2.model_name.unique():\n",
    "    print(str(c) + ': ' + str(test_df_2[test_df_2.model_name == c]['accuracy'].mean()))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "7348e4fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1190, number of negative: 2947\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020166 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23419\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2559\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.287648 -> initscore=-0.906834\n",
      "[LightGBM] [Info] Start training from score -0.906834\n",
      "[LightGBM] [Info] Number of positive: 1201, number of negative: 2936\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023706 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23742\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2584\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290307 -> initscore=-0.893894\n",
      "[LightGBM] [Info] Start training from score -0.893894\n",
      "[LightGBM] [Info] Number of positive: 1218, number of negative: 2919\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022749 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23550\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2572\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.294416 -> initscore=-0.874031\n",
      "[LightGBM] [Info] Start training from score -0.874031\n",
      "[LightGBM] [Info] Number of positive: 1214, number of negative: 2923\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022779 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23472\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2564\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.293449 -> initscore=-0.878690\n",
      "[LightGBM] [Info] Start training from score -0.878690\n",
      "[LightGBM] [Info] Number of positive: 1205, number of negative: 2932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024742 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23809\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2610\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.291274 -> initscore=-0.889205\n",
      "[LightGBM] [Info] Start training from score -0.889205\n",
      "[LightGBM] [Info] Number of positive: 1203, number of negative: 2934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023602 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23436\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2569\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290790 -> initscore=-0.891548\n",
      "[LightGBM] [Info] Start training from score -0.891548\n",
      "[LightGBM] [Info] Number of positive: 1201, number of negative: 2936\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021951 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23911\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2602\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290307 -> initscore=-0.893894\n",
      "[LightGBM] [Info] Start training from score -0.893894\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>model_name</th>\n",
       "      <th>split_method</th>\n",
       "      <th>pca</th>\n",
       "      <th>n_components</th>\n",
       "      <th>random_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.984541</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.984541</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.984541</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.983575</td>\n",
       "      <td>RandomForest350</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.983575</td>\n",
       "      <td>RandomForest300</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.982609</td>\n",
       "      <td>RandomForest350</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.982609</td>\n",
       "      <td>RandomForest400</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.981643</td>\n",
       "      <td>RandomForest350</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.981643</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.981643</td>\n",
       "      <td>RandomForest300</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.980676</td>\n",
       "      <td>RandomForest400</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.978744</td>\n",
       "      <td>RandomForest400</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.978744</td>\n",
       "      <td>RandomForest300</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.978744</td>\n",
       "      <td>RandomForest350</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.978744</td>\n",
       "      <td>RandomForest300</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.976812</td>\n",
       "      <td>RandomForest350</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.976812</td>\n",
       "      <td>RandomForest300</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.976812</td>\n",
       "      <td>RandomForest400</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.974879</td>\n",
       "      <td>RandomForest400</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.971981</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.971981</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.969082</td>\n",
       "      <td>RandomForest400</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.967150</td>\n",
       "      <td>RandomForest300</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.967150</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.966184</td>\n",
       "      <td>RandomForest400</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.965217</td>\n",
       "      <td>RandomForest350</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.964251</td>\n",
       "      <td>RandomForest300</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.963285</td>\n",
       "      <td>RandomForest350</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    accuracy       model_name split_method   pca n_components random_state\n",
       "27  0.984541             LGBM           tt  None            0           21\n",
       "22  0.984541             LGBM           tt  None            0          290\n",
       "21  0.984541             LGBM           tt  None            0          194\n",
       "8   0.983575  RandomForest350           tt  None            0          290\n",
       "1   0.983575  RandomForest300           tt  None            0          290\n",
       "7   0.982609  RandomForest350           tt  None            0          194\n",
       "15  0.982609  RandomForest400           tt  None            0          290\n",
       "13  0.981643  RandomForest350           tt  None            0           21\n",
       "23  0.981643             LGBM           tt  None            0           20\n",
       "6   0.981643  RandomForest300           tt  None            0           21\n",
       "20  0.980676  RandomForest400           tt  None            0           21\n",
       "18  0.978744  RandomForest400           tt  None            0            2\n",
       "0   0.978744  RandomForest300           tt  None            0          194\n",
       "11  0.978744  RandomForest350           tt  None            0            2\n",
       "2   0.978744  RandomForest300           tt  None            0           20\n",
       "9   0.976812  RandomForest350           tt  None            0           20\n",
       "4   0.976812  RandomForest300           tt  None            0            2\n",
       "14  0.976812  RandomForest400           tt  None            0          194\n",
       "16  0.974879  RandomForest400           tt  None            0           20\n",
       "25  0.971981             LGBM           tt  None            0            2\n",
       "26  0.971981             LGBM           tt  None            0           53\n",
       "17  0.969082  RandomForest400           tt  None            0          100\n",
       "3   0.967150  RandomForest300           tt  None            0          100\n",
       "24  0.967150             LGBM           tt  None            0          100\n",
       "19  0.966184  RandomForest400           tt  None            0           53\n",
       "10  0.965217  RandomForest350           tt  None            0          100\n",
       "5   0.964251  RandomForest300           tt  None            0           53\n",
       "12  0.963285  RandomForest350           tt  None            0           53"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes_3 = {'RandomForest300': RandomForestClassifier(n_estimators=300),\n",
    "'RandomForest350': RandomForestClassifier(n_estimators=350),         \n",
    " 'RandomForest400': RandomForestClassifier(n_estimators=400),\n",
    " 'LGBM': LGBMClassifier()}\n",
    "\n",
    "test_df_3 = create_acc_df(classes_3, ['tt'], [None], [0], [194, 290, 20, 100, 2, 53, 21])\n",
    "test_df_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "ac8efe7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "def lgbm_rand_seach(X, y, params):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    lgbm = lgb.LGBMClassifier()\n",
    "    \n",
    "    param_dist = params\n",
    "    \n",
    "    random_search = RandomizedSearchCV(\n",
    "    estimator=lgbm,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=10,\n",
    "    scoring='accuracy',\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # Fit RandomizedSearchCV\n",
    "    random_search.fit(X_train, y_train)\n",
    "\n",
    "    # Best parameters and score\n",
    "    print(\"Best parameters found: \", random_search.best_params_)\n",
    "    print(\"Best score: \", random_search.best_score_)\n",
    "\n",
    "    # Predict and evaluate on the test set\n",
    "    best_model = random_search.best_estimator_\n",
    "    test_score = best_model.score(X_test, y_test)\n",
    "    print(\"Test set score: \", test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "e97a0406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[LightGBM] [Info] Number of positive: 1204, number of negative: 2933\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043176 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21031\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2582\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.291032 -> initscore=-0.890376\n",
      "[LightGBM] [Info] Start training from score -0.890376\n",
      "Best parameters found:  {'num_leaves': 70, 'n_estimators': 60, 'min_child_samples': 20, 'max_depth': 20, 'learning_rate': 0.2}\n",
      "Best score:  0.9758299306614328\n",
      "Test set score:  0.978743961352657\n"
     ]
    }
   ],
   "source": [
    "'''    param_dist = {\n",
    "        'num_leaves': [31, 50, 70],\n",
    "        'max_depth': [-1, 10, 20, 30],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'n_estimators': [20, 40, 60, 100],\n",
    "        'min_child_samples': [5, 10, 20]\n",
    "    }    \n",
    "'''\n",
    "lgbm_rand_seach(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "fe45f6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_1 = {\n",
    "    'num_leaves': [50, 70, 90],\n",
    "    'max_depth': [15, 20, 25, 35],\n",
    "    'learning_rate': [0.225, 0.15, 0.175],\n",
    "    'n_estimators': [80, 60, 100, 120],\n",
    "    'min_child_samples': [10, 20, 30, 25]\n",
    "}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "dee18d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[LightGBM] [Info] Number of positive: 1204, number of negative: 2933\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.037450 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21031\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2582\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.291032 -> initscore=-0.890376\n",
      "[LightGBM] [Info] Start training from score -0.890376\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Best parameters found:  {'num_leaves': 70, 'n_estimators': 120, 'min_child_samples': 20, 'max_depth': 25, 'learning_rate': 0.225}\n",
      "Best score:  0.9767946538621057\n",
      "Test set score:  0.978743961352657\n"
     ]
    }
   ],
   "source": [
    "lgbm_rand_seach(X,y,param_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "12cd3123",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_2 = {\n",
    "    'num_leaves': [110, 70, 90],\n",
    "    'max_depth': [30, 22, 25, 35],\n",
    "    'learning_rate': [0.225, 0.25, 0.2],\n",
    "    'n_estimators': [80, 150, 110, 120],\n",
    "    'min_child_samples': [35, 20, 30, 25]\n",
    "}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "617e3f96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[LightGBM] [Info] Number of positive: 1204, number of negative: 2933\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.048650 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21031\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2582\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.291032 -> initscore=-0.890376\n",
      "[LightGBM] [Info] Start training from score -0.890376\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Best parameters found:  {'num_leaves': 70, 'n_estimators': 120, 'min_child_samples': 20, 'max_depth': 25, 'learning_rate': 0.225}\n",
      "Best score:  0.9767946538621057\n",
      "Test set score:  0.978743961352657\n"
     ]
    }
   ],
   "source": [
    "lgbm_rand_seach(X,y,param_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "47147585",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_3 = {\n",
    "    'num_leaves': [80, 70, 90],\n",
    "    'max_depth': [22, 25, 28],\n",
    "    'learning_rate': [0.225, 0.25, 0.2],\n",
    "    'n_estimators': [100, 130, 110, 120],\n",
    "    'min_child_samples': [15, 20, 25]\n",
    "}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "95be892b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[LightGBM] [Info] Number of positive: 1204, number of negative: 2933\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030461 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21820\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2808\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.291032 -> initscore=-0.890376\n",
      "[LightGBM] [Info] Start training from score -0.890376\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Best parameters found:  {'num_leaves': 80, 'n_estimators': 130, 'min_child_samples': 15, 'max_depth': 22, 'learning_rate': 0.2}\n",
      "Best score:  0.976553400043227\n",
      "Test set score:  0.9826086956521739\n"
     ]
    }
   ],
   "source": [
    "lgbm_rand_seach(X,y,param_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f3fdb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "1888bda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_4 = {\n",
    "    'num_leaves': [80, 85, 90],\n",
    "    'max_depth': [22, 25, 20],\n",
    "    'learning_rate': [0.21, 0.19, 0.2],\n",
    "    'n_estimators': [135, 130, 125],\n",
    "    'min_child_samples': [15, 18, 12]\n",
    "}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "8b4ed2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[LightGBM] [Info] Number of positive: 1204, number of negative: 2933\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024100 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21356\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2679\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.291032 -> initscore=-0.890376\n",
      "[LightGBM] [Info] Start training from score -0.890376\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Best parameters found:  {'num_leaves': 80, 'n_estimators': 125, 'min_child_samples': 18, 'max_depth': 20, 'learning_rate': 0.19}\n",
      "Best score:  0.977036783905508\n",
      "Test set score:  0.9826086956521739\n"
     ]
    }
   ],
   "source": [
    "lgbm_rand_seach(X,y,param_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "11ef3999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM: 0.9780538302277434\n",
      "RandomForest350: 0.975983436853002\n",
      "RandomForest300: 0.9758454106280192\n",
      "RandomForest400: 0.9755693581780537\n"
     ]
    }
   ],
   "source": [
    "for c in test_df_3.model_name.unique():\n",
    "    print(str(c) + ': ' + str(test_df_3[test_df_3.model_name == c]['accuracy'].mean()))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167adc3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
