{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6ab13a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "425553f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('emails.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "19624831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Email No.</th>\n",
       "      <th>the</th>\n",
       "      <th>to</th>\n",
       "      <th>ect</th>\n",
       "      <th>and</th>\n",
       "      <th>for</th>\n",
       "      <th>of</th>\n",
       "      <th>a</th>\n",
       "      <th>you</th>\n",
       "      <th>hou</th>\n",
       "      <th>...</th>\n",
       "      <th>connevey</th>\n",
       "      <th>jay</th>\n",
       "      <th>valued</th>\n",
       "      <th>lay</th>\n",
       "      <th>infrastructure</th>\n",
       "      <th>military</th>\n",
       "      <th>allowing</th>\n",
       "      <th>ff</th>\n",
       "      <th>dry</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Email 1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Email 2</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Email 3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Email 4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Email 5</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 3002 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Email No.  the  to  ect  and  for  of    a  you  hou  ...  connevey  jay  \\\n",
       "0   Email 1    0   0    1    0    0   0    2    0    0  ...         0    0   \n",
       "1   Email 2    8  13   24    6    6   2  102    1   27  ...         0    0   \n",
       "2   Email 3    0   0    1    0    0   0    8    0    0  ...         0    0   \n",
       "3   Email 4    0   5   22    0    5   1   51    2   10  ...         0    0   \n",
       "4   Email 5    7   6   17    1    5   2   57    0    9  ...         0    0   \n",
       "\n",
       "   valued  lay  infrastructure  military  allowing  ff  dry  Prediction  \n",
       "0       0    0               0         0         0   0    0           0  \n",
       "1       0    0               0         0         0   1    0           0  \n",
       "2       0    0               0         0         0   0    0           0  \n",
       "3       0    0               0         0         0   0    0           0  \n",
       "4       0    0               0         0         0   1    0           0  \n",
       "\n",
       "[5 rows x 3002 columns]"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "4edce7ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Email No.'].is_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "30265aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Email No.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "ea92de5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction\n",
       "0    3672\n",
       "1    1500\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Prediction'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "3c6d50c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, StratifiedShuffleSplit\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "85607e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "97572046",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Prediction'])\n",
    "y = df['Prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "e289a3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "215e2033",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers['CatBoost'] = CatBoostClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "fdb42134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LogisticRegression': LogisticRegression(max_iter=500),\n",
       " 'RandomForest100': RandomForestClassifier(),\n",
       " 'RandomForest200': RandomForestClassifier(n_estimators=200),\n",
       " 'SVMLinear': SVC(kernel='linear'),\n",
       " 'SVMSigmoid': SVC(kernel='sigmoid'),\n",
       " 'KNN5n': KNeighborsClassifier(),\n",
       " 'KNN15n': KNeighborsClassifier(n_neighbors=15),\n",
       " 'KNN25n': KNeighborsClassifier(n_neighbors=25),\n",
       " 'LGBM': LGBMClassifier(),\n",
       " 'GrdBst': GradientBoostingClassifier(),\n",
       " 'ADABoost100': AdaBoostClassifier(n_estimators=100),\n",
       " 'ADABoost200': AdaBoostClassifier(n_estimators=200),\n",
       " 'CatBoost': <catboost.core.CatBoostClassifier at 0x27e37972050>}"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "7f548063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LogisticRegression': LogisticRegression(max_iter=500),\n",
       " 'RandomForest100': RandomForestClassifier(),\n",
       " 'RandomForest200': RandomForestClassifier(n_estimators=200),\n",
       " 'SVMLinear': SVC(kernel='linear'),\n",
       " 'SVMSigmoid': SVC(kernel='sigmoid'),\n",
       " 'LGBM': LGBMClassifier(),\n",
       " 'GrdBst': GradientBoostingClassifier(),\n",
       " 'ADABoost100': AdaBoostClassifier(n_estimators=100),\n",
       " 'ADABoost200': AdaBoostClassifier(n_estimators=200),\n",
       " 'CatBoost': <catboost.core.CatBoostClassifier at 0x27e37972050>}"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k:v for (k,v) in classifiers.items() if ('KNN' not in k)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "d0e0522f",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_classes = {'LogisticRegression': LogisticRegression(max_iter=500),\n",
    " 'RandomForest100': RandomForestClassifier(),\n",
    " 'RandomForest200': RandomForestClassifier(n_estimators=200),\n",
    " 'SVMLinear': SVC(kernel='linear'),\n",
    " 'SVMSigmoid': SVC(kernel='sigmoid'),\n",
    " 'LGBM': LGBMClassifier(),\n",
    " 'GrdBst': GradientBoostingClassifier(),\n",
    " 'ADABoost100': AdaBoostClassifier(n_estimators=100),\n",
    " 'ADABoost200': AdaBoostClassifier(n_estimators=200),\n",
    " 'CatBoost':CatBoostClassifier()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "129289ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{4: {'sadf': ' asdfs', 'asdfds': 'asdfds'}, 10: None, 104: None}"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "5f36cb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores1[4].update({'asdfds':'asdfds'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "0452e76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores1[4] = {'sadf' :' asdfs'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "1565a42f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1205, number of negative: 2932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020946 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20962\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2574\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.291274 -> initscore=-0.889205\n",
      "[LightGBM] [Info] Start training from score -0.889205\n",
      "[LightGBM] [Info] Number of positive: 1205, number of negative: 2932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020950 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20962\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2574\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.291274 -> initscore=-0.889205\n",
      "[LightGBM] [Info] Start training from score -0.889205\n",
      "[LightGBM] [Info] Number of positive: 1205, number of negative: 2932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020887 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20962\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2574\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.291274 -> initscore=-0.889205\n",
      "[LightGBM] [Info] Start training from score -0.889205\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021984 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20819\n",
      "[LightGBM] [Info] Number of data points in the train set: 4138, number of used features: 2561\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289995 -> initscore=-0.895408\n",
      "[LightGBM] [Info] Start training from score -0.895408\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020511 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20819\n",
      "[LightGBM] [Info] Number of data points in the train set: 4138, number of used features: 2561\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289995 -> initscore=-0.895408\n",
      "[LightGBM] [Info] Start training from score -0.895408\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021206 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20819\n",
      "[LightGBM] [Info] Number of data points in the train set: 4138, number of used features: 2561\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289995 -> initscore=-0.895408\n",
      "[LightGBM] [Info] Start training from score -0.895408\n",
      "Learning rate set to 0.018891\n",
      "0:\tlearn: 0.6681439\ttotal: 23.1ms\tremaining: 23s\n",
      "1:\tlearn: 0.6461748\ttotal: 43.8ms\tremaining: 21.9s\n",
      "2:\tlearn: 0.6238874\ttotal: 67ms\tremaining: 22.3s\n",
      "3:\tlearn: 0.6033953\ttotal: 90.6ms\tremaining: 22.5s\n",
      "4:\tlearn: 0.5841681\ttotal: 108ms\tremaining: 21.5s\n",
      "5:\tlearn: 0.5640228\ttotal: 125ms\tremaining: 20.7s\n",
      "6:\tlearn: 0.5469258\ttotal: 141ms\tremaining: 20.1s\n",
      "7:\tlearn: 0.5297632\ttotal: 160ms\tremaining: 19.8s\n",
      "8:\tlearn: 0.5147994\ttotal: 180ms\tremaining: 19.8s\n",
      "9:\tlearn: 0.5096489\ttotal: 200ms\tremaining: 19.8s\n",
      "10:\tlearn: 0.4950606\ttotal: 218ms\tremaining: 19.6s\n",
      "11:\tlearn: 0.4811226\ttotal: 239ms\tremaining: 19.6s\n",
      "12:\tlearn: 0.4686314\ttotal: 259ms\tremaining: 19.7s\n",
      "13:\tlearn: 0.4581063\ttotal: 279ms\tremaining: 19.7s\n",
      "14:\tlearn: 0.4485066\ttotal: 300ms\tremaining: 19.7s\n",
      "15:\tlearn: 0.4386207\ttotal: 317ms\tremaining: 19.5s\n",
      "16:\tlearn: 0.4316234\ttotal: 335ms\tremaining: 19.3s\n",
      "17:\tlearn: 0.4216568\ttotal: 355ms\tremaining: 19.4s\n",
      "18:\tlearn: 0.4140483\ttotal: 376ms\tremaining: 19.4s\n",
      "19:\tlearn: 0.4096710\ttotal: 396ms\tremaining: 19.4s\n",
      "20:\tlearn: 0.4032663\ttotal: 417ms\tremaining: 19.4s\n",
      "21:\tlearn: 0.3943720\ttotal: 437ms\tremaining: 19.4s\n",
      "22:\tlearn: 0.3884446\ttotal: 458ms\tremaining: 19.4s\n",
      "23:\tlearn: 0.3842495\ttotal: 478ms\tremaining: 19.5s\n",
      "24:\tlearn: 0.3779136\ttotal: 499ms\tremaining: 19.5s\n",
      "25:\tlearn: 0.3753541\ttotal: 519ms\tremaining: 19.4s\n",
      "26:\tlearn: 0.3682865\ttotal: 535ms\tremaining: 19.3s\n",
      "27:\tlearn: 0.3642515\ttotal: 552ms\tremaining: 19.2s\n",
      "28:\tlearn: 0.3588011\ttotal: 569ms\tremaining: 19s\n",
      "29:\tlearn: 0.3537777\ttotal: 586ms\tremaining: 18.9s\n",
      "30:\tlearn: 0.3487666\ttotal: 604ms\tremaining: 18.9s\n",
      "31:\tlearn: 0.3432139\ttotal: 625ms\tremaining: 18.9s\n",
      "32:\tlearn: 0.3386846\ttotal: 645ms\tremaining: 18.9s\n",
      "33:\tlearn: 0.3361314\ttotal: 666ms\tremaining: 18.9s\n",
      "34:\tlearn: 0.3336702\ttotal: 686ms\tremaining: 18.9s\n",
      "35:\tlearn: 0.3311908\ttotal: 706ms\tremaining: 18.9s\n",
      "36:\tlearn: 0.3263064\ttotal: 726ms\tremaining: 18.9s\n",
      "37:\tlearn: 0.3228299\ttotal: 747ms\tremaining: 18.9s\n",
      "38:\tlearn: 0.3198409\ttotal: 767ms\tremaining: 18.9s\n",
      "39:\tlearn: 0.3169026\ttotal: 788ms\tremaining: 18.9s\n",
      "40:\tlearn: 0.3126075\ttotal: 809ms\tremaining: 18.9s\n",
      "41:\tlearn: 0.3089347\ttotal: 830ms\tremaining: 18.9s\n",
      "42:\tlearn: 0.3063923\ttotal: 850ms\tremaining: 18.9s\n",
      "43:\tlearn: 0.3025664\ttotal: 871ms\tremaining: 18.9s\n",
      "44:\tlearn: 0.2991137\ttotal: 892ms\tremaining: 18.9s\n",
      "45:\tlearn: 0.2956983\ttotal: 912ms\tremaining: 18.9s\n",
      "46:\tlearn: 0.2910637\ttotal: 934ms\tremaining: 18.9s\n",
      "47:\tlearn: 0.2890708\ttotal: 954ms\tremaining: 18.9s\n",
      "48:\tlearn: 0.2857813\ttotal: 974ms\tremaining: 18.9s\n",
      "49:\tlearn: 0.2837762\ttotal: 995ms\tremaining: 18.9s\n",
      "50:\tlearn: 0.2811453\ttotal: 1.02s\tremaining: 18.9s\n",
      "51:\tlearn: 0.2790087\ttotal: 1.04s\tremaining: 18.9s\n",
      "52:\tlearn: 0.2773931\ttotal: 1.05s\tremaining: 18.8s\n",
      "53:\tlearn: 0.2746970\ttotal: 1.07s\tremaining: 18.8s\n",
      "54:\tlearn: 0.2728736\ttotal: 1.09s\tremaining: 18.7s\n",
      "55:\tlearn: 0.2711010\ttotal: 1.11s\tremaining: 18.6s\n",
      "56:\tlearn: 0.2692992\ttotal: 1.13s\tremaining: 18.6s\n",
      "57:\tlearn: 0.2665114\ttotal: 1.15s\tremaining: 18.6s\n",
      "58:\tlearn: 0.2634683\ttotal: 1.16s\tremaining: 18.5s\n",
      "59:\tlearn: 0.2605295\ttotal: 1.18s\tremaining: 18.5s\n",
      "60:\tlearn: 0.2588443\ttotal: 1.2s\tremaining: 18.4s\n",
      "61:\tlearn: 0.2573441\ttotal: 1.21s\tremaining: 18.4s\n",
      "62:\tlearn: 0.2561580\ttotal: 1.23s\tremaining: 18.3s\n",
      "63:\tlearn: 0.2546168\ttotal: 1.25s\tremaining: 18.3s\n",
      "64:\tlearn: 0.2528659\ttotal: 1.27s\tremaining: 18.2s\n",
      "65:\tlearn: 0.2510845\ttotal: 1.28s\tremaining: 18.2s\n",
      "66:\tlearn: 0.2498444\ttotal: 1.3s\tremaining: 18.1s\n",
      "67:\tlearn: 0.2475093\ttotal: 1.32s\tremaining: 18.1s\n",
      "68:\tlearn: 0.2447730\ttotal: 1.34s\tremaining: 18.1s\n",
      "69:\tlearn: 0.2432478\ttotal: 1.36s\tremaining: 18.1s\n",
      "70:\tlearn: 0.2419763\ttotal: 1.38s\tremaining: 18s\n",
      "71:\tlearn: 0.2403220\ttotal: 1.4s\tremaining: 18s\n",
      "72:\tlearn: 0.2389013\ttotal: 1.42s\tremaining: 18s\n",
      "73:\tlearn: 0.2377620\ttotal: 1.43s\tremaining: 17.9s\n",
      "74:\tlearn: 0.2358445\ttotal: 1.45s\tremaining: 17.9s\n",
      "75:\tlearn: 0.2349577\ttotal: 1.47s\tremaining: 17.8s\n",
      "76:\tlearn: 0.2336385\ttotal: 1.48s\tremaining: 17.8s\n",
      "77:\tlearn: 0.2324597\ttotal: 1.5s\tremaining: 17.7s\n",
      "78:\tlearn: 0.2308080\ttotal: 1.52s\tremaining: 17.7s\n",
      "79:\tlearn: 0.2298321\ttotal: 1.54s\tremaining: 17.7s\n",
      "80:\tlearn: 0.2289291\ttotal: 1.56s\tremaining: 17.7s\n",
      "81:\tlearn: 0.2275312\ttotal: 1.58s\tremaining: 17.7s\n",
      "82:\tlearn: 0.2260562\ttotal: 1.6s\tremaining: 17.7s\n",
      "83:\tlearn: 0.2251278\ttotal: 1.62s\tremaining: 17.7s\n",
      "84:\tlearn: 0.2235371\ttotal: 1.64s\tremaining: 17.7s\n",
      "85:\tlearn: 0.2224943\ttotal: 1.66s\tremaining: 17.7s\n",
      "86:\tlearn: 0.2209768\ttotal: 1.68s\tremaining: 17.7s\n",
      "87:\tlearn: 0.2198947\ttotal: 1.7s\tremaining: 17.6s\n",
      "88:\tlearn: 0.2180929\ttotal: 1.72s\tremaining: 17.6s\n",
      "89:\tlearn: 0.2172916\ttotal: 1.74s\tremaining: 17.6s\n",
      "90:\tlearn: 0.2161540\ttotal: 1.76s\tremaining: 17.6s\n",
      "91:\tlearn: 0.2149261\ttotal: 1.78s\tremaining: 17.6s\n",
      "92:\tlearn: 0.2139299\ttotal: 1.8s\tremaining: 17.6s\n",
      "93:\tlearn: 0.2132066\ttotal: 1.82s\tremaining: 17.5s\n",
      "94:\tlearn: 0.2113835\ttotal: 1.84s\tremaining: 17.5s\n",
      "95:\tlearn: 0.2094823\ttotal: 1.85s\tremaining: 17.4s\n",
      "96:\tlearn: 0.2085537\ttotal: 1.87s\tremaining: 17.4s\n",
      "97:\tlearn: 0.2075749\ttotal: 1.89s\tremaining: 17.4s\n",
      "98:\tlearn: 0.2064943\ttotal: 1.91s\tremaining: 17.4s\n",
      "99:\tlearn: 0.2050813\ttotal: 1.93s\tremaining: 17.3s\n",
      "100:\tlearn: 0.2041914\ttotal: 1.94s\tremaining: 17.3s\n",
      "101:\tlearn: 0.2027286\ttotal: 1.96s\tremaining: 17.3s\n",
      "102:\tlearn: 0.2018776\ttotal: 1.98s\tremaining: 17.3s\n",
      "103:\tlearn: 0.2011117\ttotal: 2s\tremaining: 17.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104:\tlearn: 0.2000259\ttotal: 2.02s\tremaining: 17.2s\n",
      "105:\tlearn: 0.1987728\ttotal: 2.04s\tremaining: 17.2s\n",
      "106:\tlearn: 0.1975260\ttotal: 2.06s\tremaining: 17.2s\n",
      "107:\tlearn: 0.1966483\ttotal: 2.08s\tremaining: 17.2s\n",
      "108:\tlearn: 0.1958083\ttotal: 2.11s\tremaining: 17.2s\n",
      "109:\tlearn: 0.1946165\ttotal: 2.13s\tremaining: 17.3s\n",
      "110:\tlearn: 0.1935834\ttotal: 2.15s\tremaining: 17.2s\n",
      "111:\tlearn: 0.1927435\ttotal: 2.17s\tremaining: 17.2s\n",
      "112:\tlearn: 0.1918948\ttotal: 2.19s\tremaining: 17.2s\n",
      "113:\tlearn: 0.1911779\ttotal: 2.21s\tremaining: 17.2s\n",
      "114:\tlearn: 0.1906800\ttotal: 2.23s\tremaining: 17.2s\n",
      "115:\tlearn: 0.1899747\ttotal: 2.25s\tremaining: 17.2s\n",
      "116:\tlearn: 0.1889044\ttotal: 2.27s\tremaining: 17.2s\n",
      "117:\tlearn: 0.1875421\ttotal: 2.29s\tremaining: 17.1s\n",
      "118:\tlearn: 0.1864495\ttotal: 2.31s\tremaining: 17.1s\n",
      "119:\tlearn: 0.1857880\ttotal: 2.33s\tremaining: 17.1s\n",
      "120:\tlearn: 0.1849473\ttotal: 2.35s\tremaining: 17.1s\n",
      "121:\tlearn: 0.1839368\ttotal: 2.37s\tremaining: 17.1s\n",
      "122:\tlearn: 0.1831855\ttotal: 2.39s\tremaining: 17s\n",
      "123:\tlearn: 0.1822958\ttotal: 2.41s\tremaining: 17s\n",
      "124:\tlearn: 0.1817974\ttotal: 2.43s\tremaining: 17s\n",
      "125:\tlearn: 0.1810043\ttotal: 2.45s\tremaining: 17s\n",
      "126:\tlearn: 0.1802968\ttotal: 2.47s\tremaining: 17s\n",
      "127:\tlearn: 0.1798239\ttotal: 2.48s\tremaining: 16.9s\n",
      "128:\tlearn: 0.1791141\ttotal: 2.5s\tremaining: 16.9s\n",
      "129:\tlearn: 0.1781145\ttotal: 2.52s\tremaining: 16.9s\n",
      "130:\tlearn: 0.1773516\ttotal: 2.54s\tremaining: 16.9s\n",
      "131:\tlearn: 0.1768512\ttotal: 2.56s\tremaining: 16.8s\n",
      "132:\tlearn: 0.1760643\ttotal: 2.58s\tremaining: 16.8s\n",
      "133:\tlearn: 0.1757198\ttotal: 2.59s\tremaining: 16.8s\n",
      "134:\tlearn: 0.1748846\ttotal: 2.61s\tremaining: 16.7s\n",
      "135:\tlearn: 0.1743383\ttotal: 2.63s\tremaining: 16.7s\n",
      "136:\tlearn: 0.1738075\ttotal: 2.64s\tremaining: 16.6s\n",
      "137:\tlearn: 0.1734024\ttotal: 2.66s\tremaining: 16.6s\n",
      "138:\tlearn: 0.1726237\ttotal: 2.68s\tremaining: 16.6s\n",
      "139:\tlearn: 0.1720563\ttotal: 2.69s\tremaining: 16.5s\n",
      "140:\tlearn: 0.1715292\ttotal: 2.71s\tremaining: 16.5s\n",
      "141:\tlearn: 0.1707801\ttotal: 2.73s\tremaining: 16.5s\n",
      "142:\tlearn: 0.1698639\ttotal: 2.74s\tremaining: 16.4s\n",
      "143:\tlearn: 0.1692931\ttotal: 2.76s\tremaining: 16.4s\n",
      "144:\tlearn: 0.1684411\ttotal: 2.78s\tremaining: 16.4s\n",
      "145:\tlearn: 0.1677698\ttotal: 2.79s\tremaining: 16.3s\n",
      "146:\tlearn: 0.1669906\ttotal: 2.81s\tremaining: 16.3s\n",
      "147:\tlearn: 0.1665253\ttotal: 2.83s\tremaining: 16.3s\n",
      "148:\tlearn: 0.1660796\ttotal: 2.85s\tremaining: 16.3s\n",
      "149:\tlearn: 0.1654150\ttotal: 2.86s\tremaining: 16.2s\n",
      "150:\tlearn: 0.1649072\ttotal: 2.88s\tremaining: 16.2s\n",
      "151:\tlearn: 0.1645038\ttotal: 2.9s\tremaining: 16.2s\n",
      "152:\tlearn: 0.1636525\ttotal: 2.92s\tremaining: 16.1s\n",
      "153:\tlearn: 0.1629076\ttotal: 2.94s\tremaining: 16.1s\n",
      "154:\tlearn: 0.1620450\ttotal: 2.96s\tremaining: 16.1s\n",
      "155:\tlearn: 0.1613772\ttotal: 2.98s\tremaining: 16.1s\n",
      "156:\tlearn: 0.1608984\ttotal: 3s\tremaining: 16.1s\n",
      "157:\tlearn: 0.1602161\ttotal: 3.02s\tremaining: 16.1s\n",
      "158:\tlearn: 0.1593561\ttotal: 3.04s\tremaining: 16.1s\n",
      "159:\tlearn: 0.1587949\ttotal: 3.06s\tremaining: 16.1s\n",
      "160:\tlearn: 0.1583393\ttotal: 3.08s\tremaining: 16s\n",
      "161:\tlearn: 0.1576487\ttotal: 3.09s\tremaining: 16s\n",
      "162:\tlearn: 0.1571209\ttotal: 3.11s\tremaining: 16s\n",
      "163:\tlearn: 0.1566335\ttotal: 3.13s\tremaining: 16s\n",
      "164:\tlearn: 0.1560852\ttotal: 3.15s\tremaining: 16s\n",
      "165:\tlearn: 0.1557095\ttotal: 3.17s\tremaining: 15.9s\n",
      "166:\tlearn: 0.1550493\ttotal: 3.19s\tremaining: 15.9s\n",
      "167:\tlearn: 0.1546046\ttotal: 3.22s\tremaining: 15.9s\n",
      "168:\tlearn: 0.1541857\ttotal: 3.23s\tremaining: 15.9s\n",
      "169:\tlearn: 0.1539360\ttotal: 3.25s\tremaining: 15.9s\n",
      "170:\tlearn: 0.1535027\ttotal: 3.27s\tremaining: 15.9s\n",
      "171:\tlearn: 0.1529073\ttotal: 3.29s\tremaining: 15.9s\n",
      "172:\tlearn: 0.1523771\ttotal: 3.31s\tremaining: 15.8s\n",
      "173:\tlearn: 0.1519130\ttotal: 3.33s\tremaining: 15.8s\n",
      "174:\tlearn: 0.1513949\ttotal: 3.35s\tremaining: 15.8s\n",
      "175:\tlearn: 0.1511429\ttotal: 3.37s\tremaining: 15.8s\n",
      "176:\tlearn: 0.1507131\ttotal: 3.39s\tremaining: 15.8s\n",
      "177:\tlearn: 0.1504351\ttotal: 3.41s\tremaining: 15.8s\n",
      "178:\tlearn: 0.1501274\ttotal: 3.43s\tremaining: 15.8s\n",
      "179:\tlearn: 0.1495563\ttotal: 3.45s\tremaining: 15.7s\n",
      "180:\tlearn: 0.1489555\ttotal: 3.47s\tremaining: 15.7s\n",
      "181:\tlearn: 0.1485510\ttotal: 3.49s\tremaining: 15.7s\n",
      "182:\tlearn: 0.1482320\ttotal: 3.5s\tremaining: 15.6s\n",
      "183:\tlearn: 0.1479297\ttotal: 3.52s\tremaining: 15.6s\n",
      "184:\tlearn: 0.1472747\ttotal: 3.54s\tremaining: 15.6s\n",
      "185:\tlearn: 0.1469389\ttotal: 3.56s\tremaining: 15.6s\n",
      "186:\tlearn: 0.1466877\ttotal: 3.58s\tremaining: 15.6s\n",
      "187:\tlearn: 0.1463507\ttotal: 3.6s\tremaining: 15.5s\n",
      "188:\tlearn: 0.1460992\ttotal: 3.62s\tremaining: 15.5s\n",
      "189:\tlearn: 0.1458741\ttotal: 3.64s\tremaining: 15.5s\n",
      "190:\tlearn: 0.1454504\ttotal: 3.65s\tremaining: 15.5s\n",
      "191:\tlearn: 0.1447931\ttotal: 3.67s\tremaining: 15.5s\n",
      "192:\tlearn: 0.1443616\ttotal: 3.69s\tremaining: 15.4s\n",
      "193:\tlearn: 0.1439308\ttotal: 3.71s\tremaining: 15.4s\n",
      "194:\tlearn: 0.1436315\ttotal: 3.73s\tremaining: 15.4s\n",
      "195:\tlearn: 0.1429029\ttotal: 3.74s\tremaining: 15.4s\n",
      "196:\tlearn: 0.1423645\ttotal: 3.77s\tremaining: 15.3s\n",
      "197:\tlearn: 0.1420276\ttotal: 3.78s\tremaining: 15.3s\n",
      "198:\tlearn: 0.1415333\ttotal: 3.8s\tremaining: 15.3s\n",
      "199:\tlearn: 0.1410650\ttotal: 3.82s\tremaining: 15.3s\n",
      "200:\tlearn: 0.1407712\ttotal: 3.84s\tremaining: 15.3s\n",
      "201:\tlearn: 0.1402397\ttotal: 3.86s\tremaining: 15.3s\n",
      "202:\tlearn: 0.1397292\ttotal: 3.88s\tremaining: 15.2s\n",
      "203:\tlearn: 0.1392334\ttotal: 3.9s\tremaining: 15.2s\n",
      "204:\tlearn: 0.1388392\ttotal: 3.92s\tremaining: 15.2s\n",
      "205:\tlearn: 0.1384475\ttotal: 3.94s\tremaining: 15.2s\n",
      "206:\tlearn: 0.1381349\ttotal: 3.96s\tremaining: 15.2s\n",
      "207:\tlearn: 0.1377807\ttotal: 3.98s\tremaining: 15.2s\n",
      "208:\tlearn: 0.1372365\ttotal: 4s\tremaining: 15.2s\n",
      "209:\tlearn: 0.1367757\ttotal: 4.03s\tremaining: 15.1s\n",
      "210:\tlearn: 0.1364171\ttotal: 4.05s\tremaining: 15.1s\n",
      "211:\tlearn: 0.1359191\ttotal: 4.08s\tremaining: 15.2s\n",
      "212:\tlearn: 0.1353717\ttotal: 4.1s\tremaining: 15.2s\n",
      "213:\tlearn: 0.1350974\ttotal: 4.12s\tremaining: 15.1s\n",
      "214:\tlearn: 0.1348960\ttotal: 4.14s\tremaining: 15.1s\n",
      "215:\tlearn: 0.1344837\ttotal: 4.16s\tremaining: 15.1s\n",
      "216:\tlearn: 0.1341420\ttotal: 4.18s\tremaining: 15.1s\n",
      "217:\tlearn: 0.1335818\ttotal: 4.2s\tremaining: 15.1s\n",
      "218:\tlearn: 0.1331594\ttotal: 4.22s\tremaining: 15s\n",
      "219:\tlearn: 0.1328424\ttotal: 4.24s\tremaining: 15s\n",
      "220:\tlearn: 0.1326259\ttotal: 4.25s\tremaining: 15s\n",
      "221:\tlearn: 0.1323234\ttotal: 4.27s\tremaining: 15s\n",
      "222:\tlearn: 0.1318664\ttotal: 4.29s\tremaining: 15s\n",
      "223:\tlearn: 0.1314900\ttotal: 4.31s\tremaining: 14.9s\n",
      "224:\tlearn: 0.1311187\ttotal: 4.33s\tremaining: 14.9s\n",
      "225:\tlearn: 0.1308582\ttotal: 4.35s\tremaining: 14.9s\n",
      "226:\tlearn: 0.1305542\ttotal: 4.37s\tremaining: 14.9s\n",
      "227:\tlearn: 0.1300047\ttotal: 4.39s\tremaining: 14.9s\n",
      "228:\tlearn: 0.1296433\ttotal: 4.41s\tremaining: 14.9s\n",
      "229:\tlearn: 0.1294340\ttotal: 4.43s\tremaining: 14.8s\n",
      "230:\tlearn: 0.1290971\ttotal: 4.45s\tremaining: 14.8s\n",
      "231:\tlearn: 0.1287616\ttotal: 4.47s\tremaining: 14.8s\n",
      "232:\tlearn: 0.1283170\ttotal: 4.5s\tremaining: 14.8s\n",
      "233:\tlearn: 0.1278785\ttotal: 4.51s\tremaining: 14.8s\n",
      "234:\tlearn: 0.1276181\ttotal: 4.53s\tremaining: 14.7s\n",
      "235:\tlearn: 0.1271686\ttotal: 4.55s\tremaining: 14.7s\n",
      "236:\tlearn: 0.1267459\ttotal: 4.57s\tremaining: 14.7s\n",
      "237:\tlearn: 0.1264633\ttotal: 4.59s\tremaining: 14.7s\n",
      "238:\tlearn: 0.1261555\ttotal: 4.61s\tremaining: 14.7s\n",
      "239:\tlearn: 0.1258731\ttotal: 4.63s\tremaining: 14.7s\n",
      "240:\tlearn: 0.1255517\ttotal: 4.65s\tremaining: 14.7s\n",
      "241:\tlearn: 0.1251707\ttotal: 4.67s\tremaining: 14.6s\n",
      "242:\tlearn: 0.1246942\ttotal: 4.69s\tremaining: 14.6s\n",
      "243:\tlearn: 0.1243642\ttotal: 4.71s\tremaining: 14.6s\n",
      "244:\tlearn: 0.1241139\ttotal: 4.73s\tremaining: 14.6s\n",
      "245:\tlearn: 0.1238028\ttotal: 4.75s\tremaining: 14.6s\n",
      "246:\tlearn: 0.1234849\ttotal: 4.77s\tremaining: 14.6s\n",
      "247:\tlearn: 0.1230728\ttotal: 4.79s\tremaining: 14.5s\n",
      "248:\tlearn: 0.1224707\ttotal: 4.81s\tremaining: 14.5s\n",
      "249:\tlearn: 0.1221409\ttotal: 4.83s\tremaining: 14.5s\n",
      "250:\tlearn: 0.1218613\ttotal: 4.85s\tremaining: 14.5s\n",
      "251:\tlearn: 0.1216654\ttotal: 4.87s\tremaining: 14.5s\n",
      "252:\tlearn: 0.1214198\ttotal: 4.89s\tremaining: 14.4s\n",
      "253:\tlearn: 0.1211699\ttotal: 4.91s\tremaining: 14.4s\n",
      "254:\tlearn: 0.1207715\ttotal: 4.93s\tremaining: 14.4s\n",
      "255:\tlearn: 0.1205547\ttotal: 4.94s\tremaining: 14.4s\n",
      "256:\tlearn: 0.1203899\ttotal: 4.96s\tremaining: 14.3s\n",
      "257:\tlearn: 0.1201484\ttotal: 4.98s\tremaining: 14.3s\n",
      "258:\tlearn: 0.1199786\ttotal: 5s\tremaining: 14.3s\n",
      "259:\tlearn: 0.1196666\ttotal: 5.02s\tremaining: 14.3s\n",
      "260:\tlearn: 0.1193370\ttotal: 5.04s\tremaining: 14.3s\n",
      "261:\tlearn: 0.1190373\ttotal: 5.06s\tremaining: 14.3s\n",
      "262:\tlearn: 0.1188392\ttotal: 5.08s\tremaining: 14.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263:\tlearn: 0.1186296\ttotal: 5.1s\tremaining: 14.2s\n",
      "264:\tlearn: 0.1184034\ttotal: 5.12s\tremaining: 14.2s\n",
      "265:\tlearn: 0.1182065\ttotal: 5.13s\tremaining: 14.2s\n",
      "266:\tlearn: 0.1178639\ttotal: 5.15s\tremaining: 14.1s\n",
      "267:\tlearn: 0.1175677\ttotal: 5.17s\tremaining: 14.1s\n",
      "268:\tlearn: 0.1173010\ttotal: 5.18s\tremaining: 14.1s\n",
      "269:\tlearn: 0.1168190\ttotal: 5.2s\tremaining: 14.1s\n",
      "270:\tlearn: 0.1165461\ttotal: 5.22s\tremaining: 14s\n",
      "271:\tlearn: 0.1162121\ttotal: 5.23s\tremaining: 14s\n",
      "272:\tlearn: 0.1158209\ttotal: 5.25s\tremaining: 14s\n",
      "273:\tlearn: 0.1155125\ttotal: 5.27s\tremaining: 14s\n",
      "274:\tlearn: 0.1153243\ttotal: 5.29s\tremaining: 13.9s\n",
      "275:\tlearn: 0.1150139\ttotal: 5.3s\tremaining: 13.9s\n",
      "276:\tlearn: 0.1147180\ttotal: 5.32s\tremaining: 13.9s\n",
      "277:\tlearn: 0.1144997\ttotal: 5.34s\tremaining: 13.9s\n",
      "278:\tlearn: 0.1142992\ttotal: 5.35s\tremaining: 13.8s\n",
      "279:\tlearn: 0.1139347\ttotal: 5.37s\tremaining: 13.8s\n",
      "280:\tlearn: 0.1137008\ttotal: 5.39s\tremaining: 13.8s\n",
      "281:\tlearn: 0.1134676\ttotal: 5.4s\tremaining: 13.8s\n",
      "282:\tlearn: 0.1132952\ttotal: 5.42s\tremaining: 13.7s\n",
      "283:\tlearn: 0.1131044\ttotal: 5.44s\tremaining: 13.7s\n",
      "284:\tlearn: 0.1126446\ttotal: 5.45s\tremaining: 13.7s\n",
      "285:\tlearn: 0.1124137\ttotal: 5.47s\tremaining: 13.7s\n",
      "286:\tlearn: 0.1122081\ttotal: 5.49s\tremaining: 13.6s\n",
      "287:\tlearn: 0.1120500\ttotal: 5.51s\tremaining: 13.6s\n",
      "288:\tlearn: 0.1118502\ttotal: 5.53s\tremaining: 13.6s\n",
      "289:\tlearn: 0.1115060\ttotal: 5.55s\tremaining: 13.6s\n",
      "290:\tlearn: 0.1111791\ttotal: 5.57s\tremaining: 13.6s\n",
      "291:\tlearn: 0.1108305\ttotal: 5.59s\tremaining: 13.6s\n",
      "292:\tlearn: 0.1106413\ttotal: 5.61s\tremaining: 13.5s\n",
      "293:\tlearn: 0.1102785\ttotal: 5.63s\tremaining: 13.5s\n",
      "294:\tlearn: 0.1100362\ttotal: 5.65s\tremaining: 13.5s\n",
      "295:\tlearn: 0.1098391\ttotal: 5.67s\tremaining: 13.5s\n",
      "296:\tlearn: 0.1094790\ttotal: 5.69s\tremaining: 13.5s\n",
      "297:\tlearn: 0.1092975\ttotal: 5.71s\tremaining: 13.4s\n",
      "298:\tlearn: 0.1091230\ttotal: 5.73s\tremaining: 13.4s\n",
      "299:\tlearn: 0.1088765\ttotal: 5.75s\tremaining: 13.4s\n",
      "300:\tlearn: 0.1086989\ttotal: 5.77s\tremaining: 13.4s\n",
      "301:\tlearn: 0.1084212\ttotal: 5.79s\tremaining: 13.4s\n",
      "302:\tlearn: 0.1082221\ttotal: 5.81s\tremaining: 13.4s\n",
      "303:\tlearn: 0.1079987\ttotal: 5.83s\tremaining: 13.3s\n",
      "304:\tlearn: 0.1078172\ttotal: 5.85s\tremaining: 13.3s\n",
      "305:\tlearn: 0.1076509\ttotal: 5.87s\tremaining: 13.3s\n",
      "306:\tlearn: 0.1075072\ttotal: 5.88s\tremaining: 13.3s\n",
      "307:\tlearn: 0.1073303\ttotal: 5.9s\tremaining: 13.3s\n",
      "308:\tlearn: 0.1071612\ttotal: 5.92s\tremaining: 13.2s\n",
      "309:\tlearn: 0.1069989\ttotal: 5.94s\tremaining: 13.2s\n",
      "310:\tlearn: 0.1067629\ttotal: 5.95s\tremaining: 13.2s\n",
      "311:\tlearn: 0.1065858\ttotal: 5.97s\tremaining: 13.2s\n",
      "312:\tlearn: 0.1063543\ttotal: 5.99s\tremaining: 13.2s\n",
      "313:\tlearn: 0.1061299\ttotal: 6.01s\tremaining: 13.1s\n",
      "314:\tlearn: 0.1058993\ttotal: 6.03s\tremaining: 13.1s\n",
      "315:\tlearn: 0.1057109\ttotal: 6.04s\tremaining: 13.1s\n",
      "316:\tlearn: 0.1054681\ttotal: 6.06s\tremaining: 13.1s\n",
      "317:\tlearn: 0.1052600\ttotal: 6.08s\tremaining: 13s\n",
      "318:\tlearn: 0.1050545\ttotal: 6.11s\tremaining: 13s\n",
      "319:\tlearn: 0.1047956\ttotal: 6.12s\tremaining: 13s\n",
      "320:\tlearn: 0.1046339\ttotal: 6.14s\tremaining: 13s\n",
      "321:\tlearn: 0.1044144\ttotal: 6.16s\tremaining: 13s\n",
      "322:\tlearn: 0.1041809\ttotal: 6.18s\tremaining: 13s\n",
      "323:\tlearn: 0.1039447\ttotal: 6.2s\tremaining: 12.9s\n",
      "324:\tlearn: 0.1038257\ttotal: 6.22s\tremaining: 12.9s\n",
      "325:\tlearn: 0.1035811\ttotal: 6.25s\tremaining: 12.9s\n",
      "326:\tlearn: 0.1033354\ttotal: 6.27s\tremaining: 12.9s\n",
      "327:\tlearn: 0.1031379\ttotal: 6.29s\tremaining: 12.9s\n",
      "328:\tlearn: 0.1028767\ttotal: 6.31s\tremaining: 12.9s\n",
      "329:\tlearn: 0.1026144\ttotal: 6.33s\tremaining: 12.9s\n",
      "330:\tlearn: 0.1024712\ttotal: 6.35s\tremaining: 12.8s\n",
      "331:\tlearn: 0.1022727\ttotal: 6.37s\tremaining: 12.8s\n",
      "332:\tlearn: 0.1021483\ttotal: 6.39s\tremaining: 12.8s\n",
      "333:\tlearn: 0.1018867\ttotal: 6.41s\tremaining: 12.8s\n",
      "334:\tlearn: 0.1017626\ttotal: 6.43s\tremaining: 12.8s\n",
      "335:\tlearn: 0.1016222\ttotal: 6.44s\tremaining: 12.7s\n",
      "336:\tlearn: 0.1014123\ttotal: 6.46s\tremaining: 12.7s\n",
      "337:\tlearn: 0.1011615\ttotal: 6.48s\tremaining: 12.7s\n",
      "338:\tlearn: 0.1009451\ttotal: 6.5s\tremaining: 12.7s\n",
      "339:\tlearn: 0.1006693\ttotal: 6.52s\tremaining: 12.7s\n",
      "340:\tlearn: 0.1004891\ttotal: 6.54s\tremaining: 12.6s\n",
      "341:\tlearn: 0.1003364\ttotal: 6.56s\tremaining: 12.6s\n",
      "342:\tlearn: 0.1001672\ttotal: 6.58s\tremaining: 12.6s\n",
      "343:\tlearn: 0.0999746\ttotal: 6.6s\tremaining: 12.6s\n",
      "344:\tlearn: 0.0997543\ttotal: 6.62s\tremaining: 12.6s\n",
      "345:\tlearn: 0.0995931\ttotal: 6.64s\tremaining: 12.6s\n",
      "346:\tlearn: 0.0994455\ttotal: 6.66s\tremaining: 12.5s\n",
      "347:\tlearn: 0.0992589\ttotal: 6.68s\tremaining: 12.5s\n",
      "348:\tlearn: 0.0991022\ttotal: 6.7s\tremaining: 12.5s\n",
      "349:\tlearn: 0.0988597\ttotal: 6.71s\tremaining: 12.5s\n",
      "350:\tlearn: 0.0986994\ttotal: 6.73s\tremaining: 12.4s\n",
      "351:\tlearn: 0.0984739\ttotal: 6.75s\tremaining: 12.4s\n",
      "352:\tlearn: 0.0983661\ttotal: 6.77s\tremaining: 12.4s\n",
      "353:\tlearn: 0.0981536\ttotal: 6.79s\tremaining: 12.4s\n",
      "354:\tlearn: 0.0980232\ttotal: 6.8s\tremaining: 12.4s\n",
      "355:\tlearn: 0.0977011\ttotal: 6.82s\tremaining: 12.3s\n",
      "356:\tlearn: 0.0974633\ttotal: 6.84s\tremaining: 12.3s\n",
      "357:\tlearn: 0.0973300\ttotal: 6.86s\tremaining: 12.3s\n",
      "358:\tlearn: 0.0971002\ttotal: 6.88s\tremaining: 12.3s\n",
      "359:\tlearn: 0.0968977\ttotal: 6.91s\tremaining: 12.3s\n",
      "360:\tlearn: 0.0966941\ttotal: 6.93s\tremaining: 12.3s\n",
      "361:\tlearn: 0.0964667\ttotal: 6.95s\tremaining: 12.2s\n",
      "362:\tlearn: 0.0961948\ttotal: 6.97s\tremaining: 12.2s\n",
      "363:\tlearn: 0.0960654\ttotal: 6.99s\tremaining: 12.2s\n",
      "364:\tlearn: 0.0958070\ttotal: 7.01s\tremaining: 12.2s\n",
      "365:\tlearn: 0.0956727\ttotal: 7.03s\tremaining: 12.2s\n",
      "366:\tlearn: 0.0955205\ttotal: 7.05s\tremaining: 12.2s\n",
      "367:\tlearn: 0.0954351\ttotal: 7.07s\tremaining: 12.1s\n",
      "368:\tlearn: 0.0952789\ttotal: 7.09s\tremaining: 12.1s\n",
      "369:\tlearn: 0.0951170\ttotal: 7.11s\tremaining: 12.1s\n",
      "370:\tlearn: 0.0948310\ttotal: 7.13s\tremaining: 12.1s\n",
      "371:\tlearn: 0.0947341\ttotal: 7.15s\tremaining: 12.1s\n",
      "372:\tlearn: 0.0946096\ttotal: 7.17s\tremaining: 12s\n",
      "373:\tlearn: 0.0944379\ttotal: 7.19s\tremaining: 12s\n",
      "374:\tlearn: 0.0942831\ttotal: 7.21s\tremaining: 12s\n",
      "375:\tlearn: 0.0940538\ttotal: 7.22s\tremaining: 12s\n",
      "376:\tlearn: 0.0939454\ttotal: 7.24s\tremaining: 12s\n",
      "377:\tlearn: 0.0938307\ttotal: 7.26s\tremaining: 11.9s\n",
      "378:\tlearn: 0.0936934\ttotal: 7.28s\tremaining: 11.9s\n",
      "379:\tlearn: 0.0935213\ttotal: 7.29s\tremaining: 11.9s\n",
      "380:\tlearn: 0.0933476\ttotal: 7.31s\tremaining: 11.9s\n",
      "381:\tlearn: 0.0932609\ttotal: 7.33s\tremaining: 11.9s\n",
      "382:\tlearn: 0.0930959\ttotal: 7.35s\tremaining: 11.8s\n",
      "383:\tlearn: 0.0929366\ttotal: 7.36s\tremaining: 11.8s\n",
      "384:\tlearn: 0.0928183\ttotal: 7.38s\tremaining: 11.8s\n",
      "385:\tlearn: 0.0926238\ttotal: 7.4s\tremaining: 11.8s\n",
      "386:\tlearn: 0.0924609\ttotal: 7.42s\tremaining: 11.7s\n",
      "387:\tlearn: 0.0923034\ttotal: 7.43s\tremaining: 11.7s\n",
      "388:\tlearn: 0.0921338\ttotal: 7.45s\tremaining: 11.7s\n",
      "389:\tlearn: 0.0920066\ttotal: 7.47s\tremaining: 11.7s\n",
      "390:\tlearn: 0.0917539\ttotal: 7.48s\tremaining: 11.7s\n",
      "391:\tlearn: 0.0915938\ttotal: 7.5s\tremaining: 11.6s\n",
      "392:\tlearn: 0.0914745\ttotal: 7.52s\tremaining: 11.6s\n",
      "393:\tlearn: 0.0913020\ttotal: 7.54s\tremaining: 11.6s\n",
      "394:\tlearn: 0.0911237\ttotal: 7.55s\tremaining: 11.6s\n",
      "395:\tlearn: 0.0909768\ttotal: 7.57s\tremaining: 11.6s\n",
      "396:\tlearn: 0.0907758\ttotal: 7.59s\tremaining: 11.5s\n",
      "397:\tlearn: 0.0906522\ttotal: 7.61s\tremaining: 11.5s\n",
      "398:\tlearn: 0.0904428\ttotal: 7.62s\tremaining: 11.5s\n",
      "399:\tlearn: 0.0902518\ttotal: 7.64s\tremaining: 11.5s\n",
      "400:\tlearn: 0.0900428\ttotal: 7.66s\tremaining: 11.4s\n",
      "401:\tlearn: 0.0897669\ttotal: 7.67s\tremaining: 11.4s\n",
      "402:\tlearn: 0.0895654\ttotal: 7.69s\tremaining: 11.4s\n",
      "403:\tlearn: 0.0893949\ttotal: 7.71s\tremaining: 11.4s\n",
      "404:\tlearn: 0.0892959\ttotal: 7.73s\tremaining: 11.4s\n",
      "405:\tlearn: 0.0891338\ttotal: 7.74s\tremaining: 11.3s\n",
      "406:\tlearn: 0.0888797\ttotal: 7.76s\tremaining: 11.3s\n",
      "407:\tlearn: 0.0886864\ttotal: 7.78s\tremaining: 11.3s\n",
      "408:\tlearn: 0.0884150\ttotal: 7.8s\tremaining: 11.3s\n",
      "409:\tlearn: 0.0882233\ttotal: 7.82s\tremaining: 11.3s\n",
      "410:\tlearn: 0.0880503\ttotal: 7.84s\tremaining: 11.2s\n",
      "411:\tlearn: 0.0878694\ttotal: 7.86s\tremaining: 11.2s\n",
      "412:\tlearn: 0.0874929\ttotal: 7.88s\tremaining: 11.2s\n",
      "413:\tlearn: 0.0873346\ttotal: 7.9s\tremaining: 11.2s\n",
      "414:\tlearn: 0.0871731\ttotal: 7.92s\tremaining: 11.2s\n",
      "415:\tlearn: 0.0869043\ttotal: 7.94s\tremaining: 11.1s\n",
      "416:\tlearn: 0.0867651\ttotal: 7.96s\tremaining: 11.1s\n",
      "417:\tlearn: 0.0865821\ttotal: 7.98s\tremaining: 11.1s\n",
      "418:\tlearn: 0.0864514\ttotal: 7.99s\tremaining: 11.1s\n",
      "419:\tlearn: 0.0862329\ttotal: 8.01s\tremaining: 11.1s\n",
      "420:\tlearn: 0.0861061\ttotal: 8.03s\tremaining: 11s\n",
      "421:\tlearn: 0.0860625\ttotal: 8.04s\tremaining: 11s\n",
      "422:\tlearn: 0.0858721\ttotal: 8.06s\tremaining: 11s\n",
      "423:\tlearn: 0.0857414\ttotal: 8.08s\tremaining: 11s\n",
      "424:\tlearn: 0.0855727\ttotal: 8.1s\tremaining: 11s\n",
      "425:\tlearn: 0.0854502\ttotal: 8.11s\tremaining: 10.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426:\tlearn: 0.0852805\ttotal: 8.13s\tremaining: 10.9s\n",
      "427:\tlearn: 0.0851301\ttotal: 8.15s\tremaining: 10.9s\n",
      "428:\tlearn: 0.0850325\ttotal: 8.17s\tremaining: 10.9s\n",
      "429:\tlearn: 0.0848097\ttotal: 8.19s\tremaining: 10.9s\n",
      "430:\tlearn: 0.0846658\ttotal: 8.21s\tremaining: 10.8s\n",
      "431:\tlearn: 0.0844906\ttotal: 8.23s\tremaining: 10.8s\n",
      "432:\tlearn: 0.0844668\ttotal: 8.25s\tremaining: 10.8s\n",
      "433:\tlearn: 0.0843561\ttotal: 8.27s\tremaining: 10.8s\n",
      "434:\tlearn: 0.0842131\ttotal: 8.29s\tremaining: 10.8s\n",
      "435:\tlearn: 0.0840860\ttotal: 8.31s\tremaining: 10.8s\n",
      "436:\tlearn: 0.0839132\ttotal: 8.33s\tremaining: 10.7s\n",
      "437:\tlearn: 0.0838969\ttotal: 8.35s\tremaining: 10.7s\n",
      "438:\tlearn: 0.0837872\ttotal: 8.37s\tremaining: 10.7s\n",
      "439:\tlearn: 0.0836704\ttotal: 8.38s\tremaining: 10.7s\n",
      "440:\tlearn: 0.0835248\ttotal: 8.4s\tremaining: 10.6s\n",
      "441:\tlearn: 0.0832594\ttotal: 8.41s\tremaining: 10.6s\n",
      "442:\tlearn: 0.0831336\ttotal: 8.43s\tremaining: 10.6s\n",
      "443:\tlearn: 0.0829215\ttotal: 8.45s\tremaining: 10.6s\n",
      "444:\tlearn: 0.0827303\ttotal: 8.47s\tremaining: 10.6s\n",
      "445:\tlearn: 0.0826344\ttotal: 8.49s\tremaining: 10.5s\n",
      "446:\tlearn: 0.0826237\ttotal: 8.51s\tremaining: 10.5s\n",
      "447:\tlearn: 0.0824751\ttotal: 8.53s\tremaining: 10.5s\n",
      "448:\tlearn: 0.0823440\ttotal: 8.55s\tremaining: 10.5s\n",
      "449:\tlearn: 0.0821505\ttotal: 8.57s\tremaining: 10.5s\n",
      "450:\tlearn: 0.0820258\ttotal: 8.59s\tremaining: 10.5s\n",
      "451:\tlearn: 0.0819184\ttotal: 8.61s\tremaining: 10.4s\n",
      "452:\tlearn: 0.0817142\ttotal: 8.63s\tremaining: 10.4s\n",
      "453:\tlearn: 0.0815252\ttotal: 8.65s\tremaining: 10.4s\n",
      "454:\tlearn: 0.0813953\ttotal: 8.67s\tremaining: 10.4s\n",
      "455:\tlearn: 0.0811758\ttotal: 8.69s\tremaining: 10.4s\n",
      "456:\tlearn: 0.0809848\ttotal: 8.71s\tremaining: 10.4s\n",
      "457:\tlearn: 0.0808420\ttotal: 8.74s\tremaining: 10.3s\n",
      "458:\tlearn: 0.0806671\ttotal: 8.76s\tremaining: 10.3s\n",
      "459:\tlearn: 0.0804955\ttotal: 8.78s\tremaining: 10.3s\n",
      "460:\tlearn: 0.0802454\ttotal: 8.8s\tremaining: 10.3s\n",
      "461:\tlearn: 0.0801907\ttotal: 8.81s\tremaining: 10.3s\n",
      "462:\tlearn: 0.0799469\ttotal: 8.83s\tremaining: 10.2s\n",
      "463:\tlearn: 0.0798957\ttotal: 8.85s\tremaining: 10.2s\n",
      "464:\tlearn: 0.0797171\ttotal: 8.87s\tremaining: 10.2s\n",
      "465:\tlearn: 0.0795955\ttotal: 8.89s\tremaining: 10.2s\n",
      "466:\tlearn: 0.0794748\ttotal: 8.91s\tremaining: 10.2s\n",
      "467:\tlearn: 0.0792999\ttotal: 8.93s\tremaining: 10.2s\n",
      "468:\tlearn: 0.0792115\ttotal: 8.95s\tremaining: 10.1s\n",
      "469:\tlearn: 0.0790871\ttotal: 8.96s\tremaining: 10.1s\n",
      "470:\tlearn: 0.0790724\ttotal: 8.98s\tremaining: 10.1s\n",
      "471:\tlearn: 0.0789079\ttotal: 9s\tremaining: 10.1s\n",
      "472:\tlearn: 0.0787789\ttotal: 9.01s\tremaining: 10s\n",
      "473:\tlearn: 0.0786165\ttotal: 9.03s\tremaining: 10s\n",
      "474:\tlearn: 0.0784392\ttotal: 9.05s\tremaining: 10s\n",
      "475:\tlearn: 0.0783874\ttotal: 9.06s\tremaining: 9.98s\n",
      "476:\tlearn: 0.0782426\ttotal: 9.08s\tremaining: 9.96s\n",
      "477:\tlearn: 0.0781248\ttotal: 9.1s\tremaining: 9.93s\n",
      "478:\tlearn: 0.0779737\ttotal: 9.11s\tremaining: 9.91s\n",
      "479:\tlearn: 0.0777279\ttotal: 9.13s\tremaining: 9.89s\n",
      "480:\tlearn: 0.0775390\ttotal: 9.15s\tremaining: 9.87s\n",
      "481:\tlearn: 0.0774186\ttotal: 9.17s\tremaining: 9.86s\n",
      "482:\tlearn: 0.0772815\ttotal: 9.19s\tremaining: 9.84s\n",
      "483:\tlearn: 0.0772520\ttotal: 9.21s\tremaining: 9.82s\n",
      "484:\tlearn: 0.0772240\ttotal: 9.23s\tremaining: 9.8s\n",
      "485:\tlearn: 0.0770823\ttotal: 9.25s\tremaining: 9.78s\n",
      "486:\tlearn: 0.0769586\ttotal: 9.27s\tremaining: 9.77s\n",
      "487:\tlearn: 0.0769041\ttotal: 9.29s\tremaining: 9.75s\n",
      "488:\tlearn: 0.0767690\ttotal: 9.31s\tremaining: 9.73s\n",
      "489:\tlearn: 0.0767500\ttotal: 9.33s\tremaining: 9.71s\n",
      "490:\tlearn: 0.0765193\ttotal: 9.35s\tremaining: 9.7s\n",
      "491:\tlearn: 0.0764890\ttotal: 9.37s\tremaining: 9.68s\n",
      "492:\tlearn: 0.0763307\ttotal: 9.39s\tremaining: 9.66s\n",
      "493:\tlearn: 0.0761873\ttotal: 9.41s\tremaining: 9.64s\n",
      "494:\tlearn: 0.0760296\ttotal: 9.43s\tremaining: 9.62s\n",
      "495:\tlearn: 0.0759085\ttotal: 9.45s\tremaining: 9.6s\n",
      "496:\tlearn: 0.0757345\ttotal: 9.46s\tremaining: 9.58s\n",
      "497:\tlearn: 0.0756439\ttotal: 9.48s\tremaining: 9.55s\n",
      "498:\tlearn: 0.0754874\ttotal: 9.5s\tremaining: 9.53s\n",
      "499:\tlearn: 0.0753417\ttotal: 9.51s\tremaining: 9.51s\n",
      "500:\tlearn: 0.0751664\ttotal: 9.53s\tremaining: 9.49s\n",
      "501:\tlearn: 0.0750674\ttotal: 9.55s\tremaining: 9.47s\n",
      "502:\tlearn: 0.0748558\ttotal: 9.56s\tremaining: 9.45s\n",
      "503:\tlearn: 0.0747498\ttotal: 9.58s\tremaining: 9.43s\n",
      "504:\tlearn: 0.0747066\ttotal: 9.6s\tremaining: 9.41s\n",
      "505:\tlearn: 0.0745788\ttotal: 9.62s\tremaining: 9.39s\n",
      "506:\tlearn: 0.0743844\ttotal: 9.63s\tremaining: 9.37s\n",
      "507:\tlearn: 0.0742853\ttotal: 9.65s\tremaining: 9.35s\n",
      "508:\tlearn: 0.0740691\ttotal: 9.67s\tremaining: 9.32s\n",
      "509:\tlearn: 0.0738960\ttotal: 9.68s\tremaining: 9.3s\n",
      "510:\tlearn: 0.0737558\ttotal: 9.7s\tremaining: 9.28s\n",
      "511:\tlearn: 0.0735079\ttotal: 9.72s\tremaining: 9.26s\n",
      "512:\tlearn: 0.0732541\ttotal: 9.74s\tremaining: 9.25s\n",
      "513:\tlearn: 0.0729936\ttotal: 9.76s\tremaining: 9.23s\n",
      "514:\tlearn: 0.0726958\ttotal: 9.78s\tremaining: 9.21s\n",
      "515:\tlearn: 0.0724276\ttotal: 9.79s\tremaining: 9.18s\n",
      "516:\tlearn: 0.0723309\ttotal: 9.81s\tremaining: 9.16s\n",
      "517:\tlearn: 0.0722776\ttotal: 9.82s\tremaining: 9.14s\n",
      "518:\tlearn: 0.0722482\ttotal: 9.84s\tremaining: 9.12s\n",
      "519:\tlearn: 0.0720791\ttotal: 9.86s\tremaining: 9.11s\n",
      "520:\tlearn: 0.0720585\ttotal: 9.88s\tremaining: 9.09s\n",
      "521:\tlearn: 0.0720483\ttotal: 9.9s\tremaining: 9.07s\n",
      "522:\tlearn: 0.0719418\ttotal: 9.93s\tremaining: 9.06s\n",
      "523:\tlearn: 0.0718112\ttotal: 9.97s\tremaining: 9.05s\n",
      "524:\tlearn: 0.0716725\ttotal: 9.99s\tremaining: 9.04s\n",
      "525:\tlearn: 0.0716602\ttotal: 10s\tremaining: 9.02s\n",
      "526:\tlearn: 0.0714746\ttotal: 10s\tremaining: 9s\n",
      "527:\tlearn: 0.0714646\ttotal: 10s\tremaining: 8.98s\n",
      "528:\tlearn: 0.0713267\ttotal: 10.1s\tremaining: 8.96s\n",
      "529:\tlearn: 0.0711679\ttotal: 10.1s\tremaining: 8.95s\n",
      "530:\tlearn: 0.0710668\ttotal: 10.1s\tremaining: 8.93s\n",
      "531:\tlearn: 0.0708725\ttotal: 10.1s\tremaining: 8.91s\n",
      "532:\tlearn: 0.0708617\ttotal: 10.1s\tremaining: 8.89s\n",
      "533:\tlearn: 0.0708515\ttotal: 10.2s\tremaining: 8.87s\n",
      "534:\tlearn: 0.0707915\ttotal: 10.2s\tremaining: 8.85s\n",
      "535:\tlearn: 0.0706252\ttotal: 10.2s\tremaining: 8.84s\n",
      "536:\tlearn: 0.0705628\ttotal: 10.2s\tremaining: 8.82s\n",
      "537:\tlearn: 0.0703820\ttotal: 10.3s\tremaining: 8.8s\n",
      "538:\tlearn: 0.0703728\ttotal: 10.3s\tremaining: 8.78s\n",
      "539:\tlearn: 0.0701691\ttotal: 10.3s\tremaining: 8.76s\n",
      "540:\tlearn: 0.0701592\ttotal: 10.3s\tremaining: 8.74s\n",
      "541:\tlearn: 0.0699856\ttotal: 10.3s\tremaining: 8.72s\n",
      "542:\tlearn: 0.0698324\ttotal: 10.3s\tremaining: 8.71s\n",
      "543:\tlearn: 0.0698235\ttotal: 10.4s\tremaining: 8.69s\n",
      "544:\tlearn: 0.0697181\ttotal: 10.4s\tremaining: 8.66s\n",
      "545:\tlearn: 0.0696385\ttotal: 10.4s\tremaining: 8.64s\n",
      "546:\tlearn: 0.0694485\ttotal: 10.4s\tremaining: 8.62s\n",
      "547:\tlearn: 0.0693087\ttotal: 10.4s\tremaining: 8.6s\n",
      "548:\tlearn: 0.0691941\ttotal: 10.5s\tremaining: 8.59s\n",
      "549:\tlearn: 0.0690003\ttotal: 10.5s\tremaining: 8.57s\n",
      "550:\tlearn: 0.0688327\ttotal: 10.5s\tremaining: 8.55s\n",
      "551:\tlearn: 0.0687177\ttotal: 10.5s\tremaining: 8.53s\n",
      "552:\tlearn: 0.0687087\ttotal: 10.5s\tremaining: 8.51s\n",
      "553:\tlearn: 0.0687003\ttotal: 10.6s\tremaining: 8.49s\n",
      "554:\tlearn: 0.0684675\ttotal: 10.6s\tremaining: 8.48s\n",
      "555:\tlearn: 0.0683692\ttotal: 10.6s\tremaining: 8.46s\n",
      "556:\tlearn: 0.0682497\ttotal: 10.6s\tremaining: 8.44s\n",
      "557:\tlearn: 0.0680944\ttotal: 10.6s\tremaining: 8.42s\n",
      "558:\tlearn: 0.0678951\ttotal: 10.6s\tremaining: 8.4s\n",
      "559:\tlearn: 0.0677451\ttotal: 10.7s\tremaining: 8.38s\n",
      "560:\tlearn: 0.0677076\ttotal: 10.7s\tremaining: 8.36s\n",
      "561:\tlearn: 0.0674675\ttotal: 10.7s\tremaining: 8.34s\n",
      "562:\tlearn: 0.0674585\ttotal: 10.7s\tremaining: 8.32s\n",
      "563:\tlearn: 0.0673000\ttotal: 10.7s\tremaining: 8.3s\n",
      "564:\tlearn: 0.0672912\ttotal: 10.8s\tremaining: 8.28s\n",
      "565:\tlearn: 0.0671298\ttotal: 10.8s\tremaining: 8.26s\n",
      "566:\tlearn: 0.0670239\ttotal: 10.8s\tremaining: 8.24s\n",
      "567:\tlearn: 0.0669829\ttotal: 10.8s\tremaining: 8.22s\n",
      "568:\tlearn: 0.0667632\ttotal: 10.8s\tremaining: 8.2s\n",
      "569:\tlearn: 0.0666104\ttotal: 10.8s\tremaining: 8.18s\n",
      "570:\tlearn: 0.0664445\ttotal: 10.9s\tremaining: 8.16s\n",
      "571:\tlearn: 0.0663646\ttotal: 10.9s\tremaining: 8.14s\n",
      "572:\tlearn: 0.0662694\ttotal: 10.9s\tremaining: 8.12s\n",
      "573:\tlearn: 0.0661603\ttotal: 10.9s\tremaining: 8.1s\n",
      "574:\tlearn: 0.0660140\ttotal: 10.9s\tremaining: 8.08s\n",
      "575:\tlearn: 0.0659964\ttotal: 10.9s\tremaining: 8.06s\n",
      "576:\tlearn: 0.0658902\ttotal: 11s\tremaining: 8.04s\n",
      "577:\tlearn: 0.0658715\ttotal: 11s\tremaining: 8.02s\n",
      "578:\tlearn: 0.0658002\ttotal: 11s\tremaining: 8s\n",
      "579:\tlearn: 0.0656916\ttotal: 11s\tremaining: 7.98s\n",
      "580:\tlearn: 0.0655582\ttotal: 11s\tremaining: 7.96s\n",
      "581:\tlearn: 0.0654372\ttotal: 11.1s\tremaining: 7.94s\n",
      "582:\tlearn: 0.0653298\ttotal: 11.1s\tremaining: 7.92s\n",
      "583:\tlearn: 0.0651301\ttotal: 11.1s\tremaining: 7.9s\n",
      "584:\tlearn: 0.0651215\ttotal: 11.1s\tremaining: 7.88s\n",
      "585:\tlearn: 0.0649446\ttotal: 11.1s\tremaining: 7.86s\n",
      "586:\tlearn: 0.0648803\ttotal: 11.1s\tremaining: 7.84s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "587:\tlearn: 0.0647899\ttotal: 11.2s\tremaining: 7.83s\n",
      "588:\tlearn: 0.0646712\ttotal: 11.2s\tremaining: 7.81s\n",
      "589:\tlearn: 0.0645092\ttotal: 11.2s\tremaining: 7.79s\n",
      "590:\tlearn: 0.0644371\ttotal: 11.2s\tremaining: 7.77s\n",
      "591:\tlearn: 0.0644288\ttotal: 11.2s\tremaining: 7.75s\n",
      "592:\tlearn: 0.0642962\ttotal: 11.3s\tremaining: 7.73s\n",
      "593:\tlearn: 0.0641738\ttotal: 11.3s\tremaining: 7.72s\n",
      "594:\tlearn: 0.0640710\ttotal: 11.3s\tremaining: 7.7s\n",
      "595:\tlearn: 0.0638893\ttotal: 11.3s\tremaining: 7.68s\n",
      "596:\tlearn: 0.0638233\ttotal: 11.3s\tremaining: 7.66s\n",
      "597:\tlearn: 0.0637571\ttotal: 11.4s\tremaining: 7.64s\n",
      "598:\tlearn: 0.0637433\ttotal: 11.4s\tremaining: 7.63s\n",
      "599:\tlearn: 0.0637355\ttotal: 11.4s\tremaining: 7.61s\n",
      "600:\tlearn: 0.0635896\ttotal: 11.4s\tremaining: 7.59s\n",
      "601:\tlearn: 0.0634761\ttotal: 11.4s\tremaining: 7.57s\n",
      "602:\tlearn: 0.0634265\ttotal: 11.5s\tremaining: 7.55s\n",
      "603:\tlearn: 0.0633384\ttotal: 11.5s\tremaining: 7.53s\n",
      "604:\tlearn: 0.0631963\ttotal: 11.5s\tremaining: 7.51s\n",
      "605:\tlearn: 0.0630351\ttotal: 11.5s\tremaining: 7.49s\n",
      "606:\tlearn: 0.0628713\ttotal: 11.5s\tremaining: 7.48s\n",
      "607:\tlearn: 0.0628600\ttotal: 11.6s\tremaining: 7.46s\n",
      "608:\tlearn: 0.0626966\ttotal: 11.6s\tremaining: 7.44s\n",
      "609:\tlearn: 0.0625789\ttotal: 11.6s\tremaining: 7.42s\n",
      "610:\tlearn: 0.0624737\ttotal: 11.6s\tremaining: 7.4s\n",
      "611:\tlearn: 0.0623420\ttotal: 11.6s\tremaining: 7.38s\n",
      "612:\tlearn: 0.0621767\ttotal: 11.7s\tremaining: 7.37s\n",
      "613:\tlearn: 0.0620456\ttotal: 11.7s\tremaining: 7.35s\n",
      "614:\tlearn: 0.0619502\ttotal: 11.7s\tremaining: 7.33s\n",
      "615:\tlearn: 0.0619203\ttotal: 11.7s\tremaining: 7.31s\n",
      "616:\tlearn: 0.0619127\ttotal: 11.7s\tremaining: 7.29s\n",
      "617:\tlearn: 0.0619053\ttotal: 11.8s\tremaining: 7.27s\n",
      "618:\tlearn: 0.0618907\ttotal: 11.8s\tremaining: 7.25s\n",
      "619:\tlearn: 0.0617464\ttotal: 11.8s\tremaining: 7.24s\n",
      "620:\tlearn: 0.0617265\ttotal: 11.8s\tremaining: 7.21s\n",
      "621:\tlearn: 0.0616180\ttotal: 11.8s\tremaining: 7.2s\n",
      "622:\tlearn: 0.0615011\ttotal: 11.9s\tremaining: 7.18s\n",
      "623:\tlearn: 0.0614377\ttotal: 11.9s\tremaining: 7.16s\n",
      "624:\tlearn: 0.0613183\ttotal: 11.9s\tremaining: 7.14s\n",
      "625:\tlearn: 0.0612077\ttotal: 11.9s\tremaining: 7.12s\n",
      "626:\tlearn: 0.0610621\ttotal: 11.9s\tremaining: 7.1s\n",
      "627:\tlearn: 0.0610451\ttotal: 12s\tremaining: 7.08s\n",
      "628:\tlearn: 0.0610307\ttotal: 12s\tremaining: 7.07s\n",
      "629:\tlearn: 0.0608787\ttotal: 12s\tremaining: 7.05s\n",
      "630:\tlearn: 0.0607324\ttotal: 12s\tremaining: 7.03s\n",
      "631:\tlearn: 0.0606865\ttotal: 12s\tremaining: 7.01s\n",
      "632:\tlearn: 0.0605981\ttotal: 12.1s\tremaining: 6.99s\n",
      "633:\tlearn: 0.0605583\ttotal: 12.1s\tremaining: 6.98s\n",
      "634:\tlearn: 0.0604660\ttotal: 12.1s\tremaining: 6.96s\n",
      "635:\tlearn: 0.0603753\ttotal: 12.1s\tremaining: 6.94s\n",
      "636:\tlearn: 0.0602554\ttotal: 12.1s\tremaining: 6.92s\n",
      "637:\tlearn: 0.0601590\ttotal: 12.2s\tremaining: 6.91s\n",
      "638:\tlearn: 0.0600727\ttotal: 12.2s\tremaining: 6.89s\n",
      "639:\tlearn: 0.0599685\ttotal: 12.2s\tremaining: 6.87s\n",
      "640:\tlearn: 0.0598489\ttotal: 12.2s\tremaining: 6.85s\n",
      "641:\tlearn: 0.0597427\ttotal: 12.3s\tremaining: 6.84s\n",
      "642:\tlearn: 0.0596491\ttotal: 12.3s\tremaining: 6.82s\n",
      "643:\tlearn: 0.0595011\ttotal: 12.3s\tremaining: 6.8s\n",
      "644:\tlearn: 0.0594746\ttotal: 12.3s\tremaining: 6.78s\n",
      "645:\tlearn: 0.0593614\ttotal: 12.3s\tremaining: 6.76s\n",
      "646:\tlearn: 0.0592714\ttotal: 12.4s\tremaining: 6.74s\n",
      "647:\tlearn: 0.0591681\ttotal: 12.4s\tremaining: 6.73s\n",
      "648:\tlearn: 0.0591260\ttotal: 12.4s\tremaining: 6.71s\n",
      "649:\tlearn: 0.0590282\ttotal: 12.4s\tremaining: 6.69s\n",
      "650:\tlearn: 0.0588833\ttotal: 12.4s\tremaining: 6.67s\n",
      "651:\tlearn: 0.0588112\ttotal: 12.5s\tremaining: 6.65s\n",
      "652:\tlearn: 0.0586953\ttotal: 12.5s\tremaining: 6.63s\n",
      "653:\tlearn: 0.0586012\ttotal: 12.5s\tremaining: 6.62s\n",
      "654:\tlearn: 0.0585146\ttotal: 12.5s\tremaining: 6.6s\n",
      "655:\tlearn: 0.0584995\ttotal: 12.5s\tremaining: 6.58s\n",
      "656:\tlearn: 0.0583853\ttotal: 12.6s\tremaining: 6.56s\n",
      "657:\tlearn: 0.0582737\ttotal: 12.6s\tremaining: 6.54s\n",
      "658:\tlearn: 0.0582598\ttotal: 12.6s\tremaining: 6.52s\n",
      "659:\tlearn: 0.0581435\ttotal: 12.6s\tremaining: 6.5s\n",
      "660:\tlearn: 0.0581369\ttotal: 12.6s\tremaining: 6.49s\n",
      "661:\tlearn: 0.0580505\ttotal: 12.7s\tremaining: 6.47s\n",
      "662:\tlearn: 0.0579524\ttotal: 12.7s\tremaining: 6.45s\n",
      "663:\tlearn: 0.0578923\ttotal: 12.7s\tremaining: 6.43s\n",
      "664:\tlearn: 0.0577365\ttotal: 12.7s\tremaining: 6.41s\n",
      "665:\tlearn: 0.0577301\ttotal: 12.8s\tremaining: 6.39s\n",
      "666:\tlearn: 0.0577239\ttotal: 12.8s\tremaining: 6.38s\n",
      "667:\tlearn: 0.0576218\ttotal: 12.8s\tremaining: 6.36s\n",
      "668:\tlearn: 0.0574612\ttotal: 12.8s\tremaining: 6.34s\n",
      "669:\tlearn: 0.0573682\ttotal: 12.8s\tremaining: 6.32s\n",
      "670:\tlearn: 0.0572414\ttotal: 12.9s\tremaining: 6.3s\n",
      "671:\tlearn: 0.0572156\ttotal: 12.9s\tremaining: 6.29s\n",
      "672:\tlearn: 0.0571495\ttotal: 12.9s\tremaining: 6.27s\n",
      "673:\tlearn: 0.0570751\ttotal: 12.9s\tremaining: 6.25s\n",
      "674:\tlearn: 0.0569318\ttotal: 12.9s\tremaining: 6.23s\n",
      "675:\tlearn: 0.0568538\ttotal: 13s\tremaining: 6.21s\n",
      "676:\tlearn: 0.0567515\ttotal: 13s\tremaining: 6.19s\n",
      "677:\tlearn: 0.0566799\ttotal: 13s\tremaining: 6.17s\n",
      "678:\tlearn: 0.0566690\ttotal: 13s\tremaining: 6.15s\n",
      "679:\tlearn: 0.0565734\ttotal: 13s\tremaining: 6.13s\n",
      "680:\tlearn: 0.0564786\ttotal: 13.1s\tremaining: 6.12s\n",
      "681:\tlearn: 0.0564154\ttotal: 13.1s\tremaining: 6.1s\n",
      "682:\tlearn: 0.0563090\ttotal: 13.1s\tremaining: 6.08s\n",
      "683:\tlearn: 0.0562444\ttotal: 13.1s\tremaining: 6.06s\n",
      "684:\tlearn: 0.0561775\ttotal: 13.1s\tremaining: 6.04s\n",
      "685:\tlearn: 0.0560780\ttotal: 13.2s\tremaining: 6.03s\n",
      "686:\tlearn: 0.0560580\ttotal: 13.2s\tremaining: 6.01s\n",
      "687:\tlearn: 0.0559999\ttotal: 13.2s\tremaining: 5.99s\n",
      "688:\tlearn: 0.0559270\ttotal: 13.2s\tremaining: 5.97s\n",
      "689:\tlearn: 0.0559188\ttotal: 13.2s\tremaining: 5.95s\n",
      "690:\tlearn: 0.0558154\ttotal: 13.3s\tremaining: 5.94s\n",
      "691:\tlearn: 0.0557392\ttotal: 13.3s\tremaining: 5.92s\n",
      "692:\tlearn: 0.0556499\ttotal: 13.3s\tremaining: 5.9s\n",
      "693:\tlearn: 0.0555502\ttotal: 13.3s\tremaining: 5.88s\n",
      "694:\tlearn: 0.0554400\ttotal: 13.4s\tremaining: 5.86s\n",
      "695:\tlearn: 0.0554321\ttotal: 13.4s\tremaining: 5.85s\n",
      "696:\tlearn: 0.0553921\ttotal: 13.4s\tremaining: 5.83s\n",
      "697:\tlearn: 0.0552876\ttotal: 13.4s\tremaining: 5.81s\n",
      "698:\tlearn: 0.0551960\ttotal: 13.4s\tremaining: 5.79s\n",
      "699:\tlearn: 0.0551691\ttotal: 13.5s\tremaining: 5.77s\n",
      "700:\tlearn: 0.0550445\ttotal: 13.5s\tremaining: 5.75s\n",
      "701:\tlearn: 0.0549346\ttotal: 13.5s\tremaining: 5.73s\n",
      "702:\tlearn: 0.0548132\ttotal: 13.5s\tremaining: 5.71s\n",
      "703:\tlearn: 0.0547273\ttotal: 13.5s\tremaining: 5.7s\n",
      "704:\tlearn: 0.0546179\ttotal: 13.6s\tremaining: 5.68s\n",
      "705:\tlearn: 0.0545666\ttotal: 13.6s\tremaining: 5.66s\n",
      "706:\tlearn: 0.0544480\ttotal: 13.6s\tremaining: 5.64s\n",
      "707:\tlearn: 0.0543583\ttotal: 13.6s\tremaining: 5.62s\n",
      "708:\tlearn: 0.0543510\ttotal: 13.7s\tremaining: 5.6s\n",
      "709:\tlearn: 0.0542805\ttotal: 13.7s\tremaining: 5.58s\n",
      "710:\tlearn: 0.0541968\ttotal: 13.7s\tremaining: 5.56s\n",
      "711:\tlearn: 0.0541317\ttotal: 13.7s\tremaining: 5.54s\n",
      "712:\tlearn: 0.0540569\ttotal: 13.7s\tremaining: 5.53s\n",
      "713:\tlearn: 0.0539614\ttotal: 13.8s\tremaining: 5.51s\n",
      "714:\tlearn: 0.0539338\ttotal: 13.8s\tremaining: 5.49s\n",
      "715:\tlearn: 0.0538974\ttotal: 13.8s\tremaining: 5.47s\n",
      "716:\tlearn: 0.0538448\ttotal: 13.8s\tremaining: 5.45s\n",
      "717:\tlearn: 0.0537341\ttotal: 13.8s\tremaining: 5.43s\n",
      "718:\tlearn: 0.0536306\ttotal: 13.9s\tremaining: 5.42s\n",
      "719:\tlearn: 0.0535936\ttotal: 13.9s\tremaining: 5.4s\n",
      "720:\tlearn: 0.0535358\ttotal: 13.9s\tremaining: 5.38s\n",
      "721:\tlearn: 0.0533894\ttotal: 13.9s\tremaining: 5.36s\n",
      "722:\tlearn: 0.0533823\ttotal: 13.9s\tremaining: 5.34s\n",
      "723:\tlearn: 0.0532780\ttotal: 14s\tremaining: 5.32s\n",
      "724:\tlearn: 0.0531829\ttotal: 14s\tremaining: 5.3s\n",
      "725:\tlearn: 0.0531147\ttotal: 14s\tremaining: 5.28s\n",
      "726:\tlearn: 0.0530801\ttotal: 14s\tremaining: 5.26s\n",
      "727:\tlearn: 0.0529816\ttotal: 14s\tremaining: 5.24s\n",
      "728:\tlearn: 0.0528890\ttotal: 14s\tremaining: 5.22s\n",
      "729:\tlearn: 0.0527773\ttotal: 14.1s\tremaining: 5.2s\n",
      "730:\tlearn: 0.0527145\ttotal: 14.1s\tremaining: 5.18s\n",
      "731:\tlearn: 0.0526118\ttotal: 14.1s\tremaining: 5.17s\n",
      "732:\tlearn: 0.0526059\ttotal: 14.1s\tremaining: 5.15s\n",
      "733:\tlearn: 0.0525367\ttotal: 14.2s\tremaining: 5.13s\n",
      "734:\tlearn: 0.0523989\ttotal: 14.2s\tremaining: 5.11s\n",
      "735:\tlearn: 0.0523025\ttotal: 14.2s\tremaining: 5.09s\n",
      "736:\tlearn: 0.0522338\ttotal: 14.2s\tremaining: 5.07s\n",
      "737:\tlearn: 0.0521057\ttotal: 14.2s\tremaining: 5.05s\n",
      "738:\tlearn: 0.0520122\ttotal: 14.2s\tremaining: 5.03s\n",
      "739:\tlearn: 0.0519340\ttotal: 14.3s\tremaining: 5.01s\n",
      "740:\tlearn: 0.0518286\ttotal: 14.3s\tremaining: 4.99s\n",
      "741:\tlearn: 0.0517794\ttotal: 14.3s\tremaining: 4.97s\n",
      "742:\tlearn: 0.0517488\ttotal: 14.3s\tremaining: 4.96s\n",
      "743:\tlearn: 0.0517426\ttotal: 14.3s\tremaining: 4.94s\n",
      "744:\tlearn: 0.0516006\ttotal: 14.4s\tremaining: 4.92s\n",
      "745:\tlearn: 0.0515408\ttotal: 14.4s\tremaining: 4.9s\n",
      "746:\tlearn: 0.0514474\ttotal: 14.4s\tremaining: 4.88s\n",
      "747:\tlearn: 0.0513504\ttotal: 14.4s\tremaining: 4.86s\n",
      "748:\tlearn: 0.0512696\ttotal: 14.5s\tremaining: 4.84s\n",
      "749:\tlearn: 0.0512052\ttotal: 14.5s\tremaining: 4.83s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750:\tlearn: 0.0510935\ttotal: 14.5s\tremaining: 4.81s\n",
      "751:\tlearn: 0.0510729\ttotal: 14.5s\tremaining: 4.79s\n",
      "752:\tlearn: 0.0509569\ttotal: 14.5s\tremaining: 4.77s\n",
      "753:\tlearn: 0.0508310\ttotal: 14.6s\tremaining: 4.75s\n",
      "754:\tlearn: 0.0508250\ttotal: 14.6s\tremaining: 4.73s\n",
      "755:\tlearn: 0.0506915\ttotal: 14.6s\tremaining: 4.71s\n",
      "756:\tlearn: 0.0505778\ttotal: 14.6s\tremaining: 4.7s\n",
      "757:\tlearn: 0.0505055\ttotal: 14.6s\tremaining: 4.68s\n",
      "758:\tlearn: 0.0504386\ttotal: 14.7s\tremaining: 4.66s\n",
      "759:\tlearn: 0.0504024\ttotal: 14.7s\tremaining: 4.64s\n",
      "760:\tlearn: 0.0502547\ttotal: 14.7s\tremaining: 4.62s\n",
      "761:\tlearn: 0.0501748\ttotal: 14.7s\tremaining: 4.6s\n",
      "762:\tlearn: 0.0501346\ttotal: 14.7s\tremaining: 4.58s\n",
      "763:\tlearn: 0.0501288\ttotal: 14.8s\tremaining: 4.56s\n",
      "764:\tlearn: 0.0499475\ttotal: 14.8s\tremaining: 4.54s\n",
      "765:\tlearn: 0.0498180\ttotal: 14.8s\tremaining: 4.52s\n",
      "766:\tlearn: 0.0497885\ttotal: 14.8s\tremaining: 4.5s\n",
      "767:\tlearn: 0.0497298\ttotal: 14.8s\tremaining: 4.49s\n",
      "768:\tlearn: 0.0496593\ttotal: 14.9s\tremaining: 4.47s\n",
      "769:\tlearn: 0.0495947\ttotal: 14.9s\tremaining: 4.45s\n",
      "770:\tlearn: 0.0494970\ttotal: 14.9s\tremaining: 4.43s\n",
      "771:\tlearn: 0.0493782\ttotal: 14.9s\tremaining: 4.41s\n",
      "772:\tlearn: 0.0493132\ttotal: 14.9s\tremaining: 4.39s\n",
      "773:\tlearn: 0.0492145\ttotal: 15s\tremaining: 4.37s\n",
      "774:\tlearn: 0.0491833\ttotal: 15s\tremaining: 4.35s\n",
      "775:\tlearn: 0.0491652\ttotal: 15s\tremaining: 4.33s\n",
      "776:\tlearn: 0.0490632\ttotal: 15s\tremaining: 4.31s\n",
      "777:\tlearn: 0.0489581\ttotal: 15s\tremaining: 4.29s\n",
      "778:\tlearn: 0.0488877\ttotal: 15.1s\tremaining: 4.27s\n",
      "779:\tlearn: 0.0488568\ttotal: 15.1s\tremaining: 4.25s\n",
      "780:\tlearn: 0.0487693\ttotal: 15.1s\tremaining: 4.23s\n",
      "781:\tlearn: 0.0486634\ttotal: 15.1s\tremaining: 4.21s\n",
      "782:\tlearn: 0.0485553\ttotal: 15.1s\tremaining: 4.19s\n",
      "783:\tlearn: 0.0484852\ttotal: 15.1s\tremaining: 4.17s\n",
      "784:\tlearn: 0.0484342\ttotal: 15.2s\tremaining: 4.15s\n",
      "785:\tlearn: 0.0482684\ttotal: 15.2s\tremaining: 4.13s\n",
      "786:\tlearn: 0.0482448\ttotal: 15.2s\tremaining: 4.12s\n",
      "787:\tlearn: 0.0481478\ttotal: 15.2s\tremaining: 4.1s\n",
      "788:\tlearn: 0.0481190\ttotal: 15.2s\tremaining: 4.08s\n",
      "789:\tlearn: 0.0480165\ttotal: 15.3s\tremaining: 4.06s\n",
      "790:\tlearn: 0.0479408\ttotal: 15.3s\tremaining: 4.04s\n",
      "791:\tlearn: 0.0478346\ttotal: 15.3s\tremaining: 4.02s\n",
      "792:\tlearn: 0.0477682\ttotal: 15.3s\tremaining: 4s\n",
      "793:\tlearn: 0.0477332\ttotal: 15.3s\tremaining: 3.98s\n",
      "794:\tlearn: 0.0476257\ttotal: 15.4s\tremaining: 3.96s\n",
      "795:\tlearn: 0.0475385\ttotal: 15.4s\tremaining: 3.94s\n",
      "796:\tlearn: 0.0475004\ttotal: 15.4s\tremaining: 3.92s\n",
      "797:\tlearn: 0.0474231\ttotal: 15.4s\tremaining: 3.9s\n",
      "798:\tlearn: 0.0473198\ttotal: 15.4s\tremaining: 3.88s\n",
      "799:\tlearn: 0.0472583\ttotal: 15.5s\tremaining: 3.86s\n",
      "800:\tlearn: 0.0471713\ttotal: 15.5s\tremaining: 3.84s\n",
      "801:\tlearn: 0.0470718\ttotal: 15.5s\tremaining: 3.82s\n",
      "802:\tlearn: 0.0470478\ttotal: 15.5s\tremaining: 3.81s\n",
      "803:\tlearn: 0.0469913\ttotal: 15.5s\tremaining: 3.79s\n",
      "804:\tlearn: 0.0469338\ttotal: 15.5s\tremaining: 3.77s\n",
      "805:\tlearn: 0.0468697\ttotal: 15.6s\tremaining: 3.75s\n",
      "806:\tlearn: 0.0467796\ttotal: 15.6s\tremaining: 3.73s\n",
      "807:\tlearn: 0.0467061\ttotal: 15.6s\tremaining: 3.71s\n",
      "808:\tlearn: 0.0467011\ttotal: 15.6s\tremaining: 3.69s\n",
      "809:\tlearn: 0.0466503\ttotal: 15.6s\tremaining: 3.67s\n",
      "810:\tlearn: 0.0465780\ttotal: 15.7s\tremaining: 3.65s\n",
      "811:\tlearn: 0.0465129\ttotal: 15.7s\tremaining: 3.63s\n",
      "812:\tlearn: 0.0464582\ttotal: 15.7s\tremaining: 3.61s\n",
      "813:\tlearn: 0.0463187\ttotal: 15.7s\tremaining: 3.59s\n",
      "814:\tlearn: 0.0462407\ttotal: 15.7s\tremaining: 3.57s\n",
      "815:\tlearn: 0.0462277\ttotal: 15.8s\tremaining: 3.55s\n",
      "816:\tlearn: 0.0461543\ttotal: 15.8s\tremaining: 3.53s\n",
      "817:\tlearn: 0.0460951\ttotal: 15.8s\tremaining: 3.51s\n",
      "818:\tlearn: 0.0460219\ttotal: 15.8s\tremaining: 3.49s\n",
      "819:\tlearn: 0.0459450\ttotal: 15.8s\tremaining: 3.47s\n",
      "820:\tlearn: 0.0459128\ttotal: 15.8s\tremaining: 3.45s\n",
      "821:\tlearn: 0.0458676\ttotal: 15.9s\tremaining: 3.44s\n",
      "822:\tlearn: 0.0457874\ttotal: 15.9s\tremaining: 3.42s\n",
      "823:\tlearn: 0.0457084\ttotal: 15.9s\tremaining: 3.4s\n",
      "824:\tlearn: 0.0456500\ttotal: 15.9s\tremaining: 3.38s\n",
      "825:\tlearn: 0.0455728\ttotal: 15.9s\tremaining: 3.36s\n",
      "826:\tlearn: 0.0455222\ttotal: 16s\tremaining: 3.34s\n",
      "827:\tlearn: 0.0454373\ttotal: 16s\tremaining: 3.32s\n",
      "828:\tlearn: 0.0453714\ttotal: 16s\tremaining: 3.3s\n",
      "829:\tlearn: 0.0452782\ttotal: 16s\tremaining: 3.28s\n",
      "830:\tlearn: 0.0452307\ttotal: 16s\tremaining: 3.26s\n",
      "831:\tlearn: 0.0452130\ttotal: 16.1s\tremaining: 3.24s\n",
      "832:\tlearn: 0.0451824\ttotal: 16.1s\tremaining: 3.22s\n",
      "833:\tlearn: 0.0451759\ttotal: 16.1s\tremaining: 3.2s\n",
      "834:\tlearn: 0.0450889\ttotal: 16.1s\tremaining: 3.18s\n",
      "835:\tlearn: 0.0450514\ttotal: 16.1s\tremaining: 3.16s\n",
      "836:\tlearn: 0.0450000\ttotal: 16.2s\tremaining: 3.15s\n",
      "837:\tlearn: 0.0449312\ttotal: 16.2s\tremaining: 3.13s\n",
      "838:\tlearn: 0.0449229\ttotal: 16.2s\tremaining: 3.11s\n",
      "839:\tlearn: 0.0448437\ttotal: 16.2s\tremaining: 3.09s\n",
      "840:\tlearn: 0.0447697\ttotal: 16.2s\tremaining: 3.07s\n",
      "841:\tlearn: 0.0447216\ttotal: 16.2s\tremaining: 3.05s\n",
      "842:\tlearn: 0.0447063\ttotal: 16.3s\tremaining: 3.03s\n",
      "843:\tlearn: 0.0446542\ttotal: 16.3s\tremaining: 3.01s\n",
      "844:\tlearn: 0.0446037\ttotal: 16.3s\tremaining: 2.99s\n",
      "845:\tlearn: 0.0445460\ttotal: 16.3s\tremaining: 2.98s\n",
      "846:\tlearn: 0.0444701\ttotal: 16.4s\tremaining: 2.96s\n",
      "847:\tlearn: 0.0444388\ttotal: 16.4s\tremaining: 2.94s\n",
      "848:\tlearn: 0.0443702\ttotal: 16.4s\tremaining: 2.92s\n",
      "849:\tlearn: 0.0443109\ttotal: 16.4s\tremaining: 2.9s\n",
      "850:\tlearn: 0.0442813\ttotal: 16.4s\tremaining: 2.88s\n",
      "851:\tlearn: 0.0441975\ttotal: 16.5s\tremaining: 2.86s\n",
      "852:\tlearn: 0.0440929\ttotal: 16.5s\tremaining: 2.84s\n",
      "853:\tlearn: 0.0440420\ttotal: 16.5s\tremaining: 2.82s\n",
      "854:\tlearn: 0.0440252\ttotal: 16.5s\tremaining: 2.8s\n",
      "855:\tlearn: 0.0439498\ttotal: 16.5s\tremaining: 2.78s\n",
      "856:\tlearn: 0.0438676\ttotal: 16.6s\tremaining: 2.76s\n",
      "857:\tlearn: 0.0437779\ttotal: 16.6s\tremaining: 2.74s\n",
      "858:\tlearn: 0.0436622\ttotal: 16.6s\tremaining: 2.72s\n",
      "859:\tlearn: 0.0436095\ttotal: 16.6s\tremaining: 2.7s\n",
      "860:\tlearn: 0.0435308\ttotal: 16.6s\tremaining: 2.69s\n",
      "861:\tlearn: 0.0434833\ttotal: 16.7s\tremaining: 2.67s\n",
      "862:\tlearn: 0.0434141\ttotal: 16.7s\tremaining: 2.65s\n",
      "863:\tlearn: 0.0433917\ttotal: 16.7s\tremaining: 2.63s\n",
      "864:\tlearn: 0.0433088\ttotal: 16.7s\tremaining: 2.61s\n",
      "865:\tlearn: 0.0432428\ttotal: 16.7s\tremaining: 2.59s\n",
      "866:\tlearn: 0.0431873\ttotal: 16.8s\tremaining: 2.57s\n",
      "867:\tlearn: 0.0431831\ttotal: 16.8s\tremaining: 2.55s\n",
      "868:\tlearn: 0.0430885\ttotal: 16.8s\tremaining: 2.53s\n",
      "869:\tlearn: 0.0430642\ttotal: 16.8s\tremaining: 2.51s\n",
      "870:\tlearn: 0.0430593\ttotal: 16.8s\tremaining: 2.49s\n",
      "871:\tlearn: 0.0429987\ttotal: 16.9s\tremaining: 2.47s\n",
      "872:\tlearn: 0.0429312\ttotal: 16.9s\tremaining: 2.46s\n",
      "873:\tlearn: 0.0428543\ttotal: 16.9s\tremaining: 2.44s\n",
      "874:\tlearn: 0.0427621\ttotal: 16.9s\tremaining: 2.42s\n",
      "875:\tlearn: 0.0427058\ttotal: 16.9s\tremaining: 2.4s\n",
      "876:\tlearn: 0.0426043\ttotal: 17s\tremaining: 2.38s\n",
      "877:\tlearn: 0.0425548\ttotal: 17s\tremaining: 2.36s\n",
      "878:\tlearn: 0.0425108\ttotal: 17s\tremaining: 2.34s\n",
      "879:\tlearn: 0.0424941\ttotal: 17s\tremaining: 2.32s\n",
      "880:\tlearn: 0.0424359\ttotal: 17s\tremaining: 2.3s\n",
      "881:\tlearn: 0.0423977\ttotal: 17s\tremaining: 2.28s\n",
      "882:\tlearn: 0.0423570\ttotal: 17.1s\tremaining: 2.26s\n",
      "883:\tlearn: 0.0422872\ttotal: 17.1s\tremaining: 2.24s\n",
      "884:\tlearn: 0.0422827\ttotal: 17.1s\tremaining: 2.22s\n",
      "885:\tlearn: 0.0422118\ttotal: 17.1s\tremaining: 2.2s\n",
      "886:\tlearn: 0.0421510\ttotal: 17.1s\tremaining: 2.18s\n",
      "887:\tlearn: 0.0421043\ttotal: 17.2s\tremaining: 2.16s\n",
      "888:\tlearn: 0.0420225\ttotal: 17.2s\tremaining: 2.14s\n",
      "889:\tlearn: 0.0420145\ttotal: 17.2s\tremaining: 2.12s\n",
      "890:\tlearn: 0.0419529\ttotal: 17.2s\tremaining: 2.1s\n",
      "891:\tlearn: 0.0419022\ttotal: 17.2s\tremaining: 2.08s\n",
      "892:\tlearn: 0.0418741\ttotal: 17.2s\tremaining: 2.07s\n",
      "893:\tlearn: 0.0418009\ttotal: 17.3s\tremaining: 2.05s\n",
      "894:\tlearn: 0.0417663\ttotal: 17.3s\tremaining: 2.03s\n",
      "895:\tlearn: 0.0417037\ttotal: 17.3s\tremaining: 2.01s\n",
      "896:\tlearn: 0.0416836\ttotal: 17.3s\tremaining: 1.99s\n",
      "897:\tlearn: 0.0416153\ttotal: 17.4s\tremaining: 1.97s\n",
      "898:\tlearn: 0.0415421\ttotal: 17.4s\tremaining: 1.95s\n",
      "899:\tlearn: 0.0414287\ttotal: 17.4s\tremaining: 1.93s\n",
      "900:\tlearn: 0.0414176\ttotal: 17.4s\tremaining: 1.91s\n",
      "901:\tlearn: 0.0413512\ttotal: 17.4s\tremaining: 1.89s\n",
      "902:\tlearn: 0.0413126\ttotal: 17.4s\tremaining: 1.87s\n",
      "903:\tlearn: 0.0412336\ttotal: 17.5s\tremaining: 1.85s\n",
      "904:\tlearn: 0.0411819\ttotal: 17.5s\tremaining: 1.84s\n",
      "905:\tlearn: 0.0411728\ttotal: 17.5s\tremaining: 1.82s\n",
      "906:\tlearn: 0.0411687\ttotal: 17.5s\tremaining: 1.8s\n",
      "907:\tlearn: 0.0411428\ttotal: 17.5s\tremaining: 1.78s\n",
      "908:\tlearn: 0.0410541\ttotal: 17.6s\tremaining: 1.76s\n",
      "909:\tlearn: 0.0409988\ttotal: 17.6s\tremaining: 1.74s\n",
      "910:\tlearn: 0.0409576\ttotal: 17.6s\tremaining: 1.72s\n",
      "911:\tlearn: 0.0408968\ttotal: 17.6s\tremaining: 1.7s\n",
      "912:\tlearn: 0.0408297\ttotal: 17.6s\tremaining: 1.68s\n",
      "913:\tlearn: 0.0407652\ttotal: 17.7s\tremaining: 1.66s\n",
      "914:\tlearn: 0.0407183\ttotal: 17.7s\tremaining: 1.64s\n",
      "915:\tlearn: 0.0406433\ttotal: 17.7s\tremaining: 1.62s\n",
      "916:\tlearn: 0.0405527\ttotal: 17.7s\tremaining: 1.6s\n",
      "917:\tlearn: 0.0405152\ttotal: 17.7s\tremaining: 1.58s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "918:\tlearn: 0.0405112\ttotal: 17.8s\tremaining: 1.56s\n",
      "919:\tlearn: 0.0404434\ttotal: 17.8s\tremaining: 1.55s\n",
      "920:\tlearn: 0.0403711\ttotal: 17.8s\tremaining: 1.53s\n",
      "921:\tlearn: 0.0402933\ttotal: 17.8s\tremaining: 1.51s\n",
      "922:\tlearn: 0.0402223\ttotal: 17.8s\tremaining: 1.49s\n",
      "923:\tlearn: 0.0401773\ttotal: 17.9s\tremaining: 1.47s\n",
      "924:\tlearn: 0.0401550\ttotal: 17.9s\tremaining: 1.45s\n",
      "925:\tlearn: 0.0401454\ttotal: 17.9s\tremaining: 1.43s\n",
      "926:\tlearn: 0.0400672\ttotal: 17.9s\tremaining: 1.41s\n",
      "927:\tlearn: 0.0400257\ttotal: 17.9s\tremaining: 1.39s\n",
      "928:\tlearn: 0.0400172\ttotal: 18s\tremaining: 1.37s\n",
      "929:\tlearn: 0.0399643\ttotal: 18s\tremaining: 1.35s\n",
      "930:\tlearn: 0.0399442\ttotal: 18s\tremaining: 1.33s\n",
      "931:\tlearn: 0.0399047\ttotal: 18s\tremaining: 1.31s\n",
      "932:\tlearn: 0.0398249\ttotal: 18s\tremaining: 1.29s\n",
      "933:\tlearn: 0.0398056\ttotal: 18s\tremaining: 1.27s\n",
      "934:\tlearn: 0.0396756\ttotal: 18.1s\tremaining: 1.25s\n",
      "935:\tlearn: 0.0396229\ttotal: 18.1s\tremaining: 1.24s\n",
      "936:\tlearn: 0.0396158\ttotal: 18.1s\tremaining: 1.22s\n",
      "937:\tlearn: 0.0395793\ttotal: 18.1s\tremaining: 1.2s\n",
      "938:\tlearn: 0.0394980\ttotal: 18.1s\tremaining: 1.18s\n",
      "939:\tlearn: 0.0394520\ttotal: 18.1s\tremaining: 1.16s\n",
      "940:\tlearn: 0.0393798\ttotal: 18.2s\tremaining: 1.14s\n",
      "941:\tlearn: 0.0393194\ttotal: 18.2s\tremaining: 1.12s\n",
      "942:\tlearn: 0.0392802\ttotal: 18.2s\tremaining: 1.1s\n",
      "943:\tlearn: 0.0392211\ttotal: 18.2s\tremaining: 1.08s\n",
      "944:\tlearn: 0.0391948\ttotal: 18.2s\tremaining: 1.06s\n",
      "945:\tlearn: 0.0391091\ttotal: 18.2s\tremaining: 1.04s\n",
      "946:\tlearn: 0.0390262\ttotal: 18.3s\tremaining: 1.02s\n",
      "947:\tlearn: 0.0389747\ttotal: 18.3s\tremaining: 1s\n",
      "948:\tlearn: 0.0389699\ttotal: 18.3s\tremaining: 983ms\n",
      "949:\tlearn: 0.0389209\ttotal: 18.3s\tremaining: 964ms\n",
      "950:\tlearn: 0.0388364\ttotal: 18.3s\tremaining: 945ms\n",
      "951:\tlearn: 0.0387889\ttotal: 18.4s\tremaining: 925ms\n",
      "952:\tlearn: 0.0387385\ttotal: 18.4s\tremaining: 906ms\n",
      "953:\tlearn: 0.0386755\ttotal: 18.4s\tremaining: 887ms\n",
      "954:\tlearn: 0.0386012\ttotal: 18.4s\tremaining: 867ms\n",
      "955:\tlearn: 0.0385776\ttotal: 18.4s\tremaining: 848ms\n",
      "956:\tlearn: 0.0384954\ttotal: 18.4s\tremaining: 828ms\n",
      "957:\tlearn: 0.0384302\ttotal: 18.5s\tremaining: 809ms\n",
      "958:\tlearn: 0.0384172\ttotal: 18.5s\tremaining: 790ms\n",
      "959:\tlearn: 0.0383937\ttotal: 18.5s\tremaining: 771ms\n",
      "960:\tlearn: 0.0383481\ttotal: 18.5s\tremaining: 751ms\n",
      "961:\tlearn: 0.0382866\ttotal: 18.5s\tremaining: 732ms\n",
      "962:\tlearn: 0.0382365\ttotal: 18.5s\tremaining: 713ms\n",
      "963:\tlearn: 0.0381756\ttotal: 18.6s\tremaining: 693ms\n",
      "964:\tlearn: 0.0381202\ttotal: 18.6s\tremaining: 674ms\n",
      "965:\tlearn: 0.0380715\ttotal: 18.6s\tremaining: 655ms\n",
      "966:\tlearn: 0.0380168\ttotal: 18.6s\tremaining: 636ms\n",
      "967:\tlearn: 0.0378476\ttotal: 18.6s\tremaining: 616ms\n",
      "968:\tlearn: 0.0377910\ttotal: 18.7s\tremaining: 597ms\n",
      "969:\tlearn: 0.0377706\ttotal: 18.7s\tremaining: 578ms\n",
      "970:\tlearn: 0.0377020\ttotal: 18.7s\tremaining: 559ms\n",
      "971:\tlearn: 0.0376387\ttotal: 18.7s\tremaining: 540ms\n",
      "972:\tlearn: 0.0376180\ttotal: 18.7s\tremaining: 520ms\n",
      "973:\tlearn: 0.0375446\ttotal: 18.8s\tremaining: 501ms\n",
      "974:\tlearn: 0.0375327\ttotal: 18.8s\tremaining: 482ms\n",
      "975:\tlearn: 0.0375142\ttotal: 18.8s\tremaining: 462ms\n",
      "976:\tlearn: 0.0374611\ttotal: 18.8s\tremaining: 443ms\n",
      "977:\tlearn: 0.0373959\ttotal: 18.8s\tremaining: 424ms\n",
      "978:\tlearn: 0.0373796\ttotal: 18.8s\tremaining: 404ms\n",
      "979:\tlearn: 0.0372907\ttotal: 18.9s\tremaining: 385ms\n",
      "980:\tlearn: 0.0372874\ttotal: 18.9s\tremaining: 366ms\n",
      "981:\tlearn: 0.0372450\ttotal: 18.9s\tremaining: 346ms\n",
      "982:\tlearn: 0.0372160\ttotal: 18.9s\tremaining: 327ms\n",
      "983:\tlearn: 0.0371636\ttotal: 18.9s\tremaining: 308ms\n",
      "984:\tlearn: 0.0371231\ttotal: 18.9s\tremaining: 289ms\n",
      "985:\tlearn: 0.0370572\ttotal: 19s\tremaining: 269ms\n",
      "986:\tlearn: 0.0370343\ttotal: 19s\tremaining: 250ms\n",
      "987:\tlearn: 0.0369766\ttotal: 19s\tremaining: 231ms\n",
      "988:\tlearn: 0.0369283\ttotal: 19s\tremaining: 212ms\n",
      "989:\tlearn: 0.0369242\ttotal: 19s\tremaining: 192ms\n",
      "990:\tlearn: 0.0368752\ttotal: 19.1s\tremaining: 173ms\n",
      "991:\tlearn: 0.0368027\ttotal: 19.1s\tremaining: 154ms\n",
      "992:\tlearn: 0.0367822\ttotal: 19.1s\tremaining: 135ms\n",
      "993:\tlearn: 0.0367248\ttotal: 19.1s\tremaining: 115ms\n",
      "994:\tlearn: 0.0366567\ttotal: 19.1s\tremaining: 96.2ms\n",
      "995:\tlearn: 0.0366037\ttotal: 19.2s\tremaining: 77ms\n",
      "996:\tlearn: 0.0366005\ttotal: 19.2s\tremaining: 57.7ms\n",
      "997:\tlearn: 0.0365294\ttotal: 19.2s\tremaining: 38.5ms\n",
      "998:\tlearn: 0.0364805\ttotal: 19.2s\tremaining: 19.2ms\n",
      "999:\tlearn: 0.0364139\ttotal: 19.2s\tremaining: 0us\n",
      "Learning rate set to 0.018891\n",
      "0:\tlearn: 0.6681439\ttotal: 22.9ms\tremaining: 22.9s\n",
      "1:\tlearn: 0.6461748\ttotal: 43.2ms\tremaining: 21.5s\n",
      "2:\tlearn: 0.6238874\ttotal: 63.7ms\tremaining: 21.2s\n",
      "3:\tlearn: 0.6033953\ttotal: 84.8ms\tremaining: 21.1s\n",
      "4:\tlearn: 0.5841681\ttotal: 106ms\tremaining: 21.1s\n",
      "5:\tlearn: 0.5640228\ttotal: 127ms\tremaining: 21s\n",
      "6:\tlearn: 0.5469258\ttotal: 152ms\tremaining: 21.6s\n",
      "7:\tlearn: 0.5297632\ttotal: 173ms\tremaining: 21.5s\n",
      "8:\tlearn: 0.5147994\ttotal: 195ms\tremaining: 21.5s\n",
      "9:\tlearn: 0.5096489\ttotal: 212ms\tremaining: 21s\n",
      "10:\tlearn: 0.4950606\ttotal: 228ms\tremaining: 20.5s\n",
      "11:\tlearn: 0.4811226\ttotal: 246ms\tremaining: 20.3s\n",
      "12:\tlearn: 0.4686314\ttotal: 267ms\tremaining: 20.3s\n",
      "13:\tlearn: 0.4581063\ttotal: 287ms\tremaining: 20.2s\n",
      "14:\tlearn: 0.4485066\ttotal: 308ms\tremaining: 20.2s\n",
      "15:\tlearn: 0.4386207\ttotal: 325ms\tremaining: 20s\n",
      "16:\tlearn: 0.4316234\ttotal: 345ms\tremaining: 20s\n",
      "17:\tlearn: 0.4216568\ttotal: 366ms\tremaining: 20s\n",
      "18:\tlearn: 0.4140483\ttotal: 383ms\tremaining: 19.8s\n",
      "19:\tlearn: 0.4096710\ttotal: 403ms\tremaining: 19.7s\n",
      "20:\tlearn: 0.4032663\ttotal: 424ms\tremaining: 19.8s\n",
      "21:\tlearn: 0.3943720\ttotal: 444ms\tremaining: 19.8s\n",
      "22:\tlearn: 0.3884446\ttotal: 465ms\tremaining: 19.7s\n",
      "23:\tlearn: 0.3842495\ttotal: 485ms\tremaining: 19.7s\n",
      "24:\tlearn: 0.3779136\ttotal: 501ms\tremaining: 19.6s\n",
      "25:\tlearn: 0.3753541\ttotal: 519ms\tremaining: 19.4s\n",
      "26:\tlearn: 0.3682865\ttotal: 539ms\tremaining: 19.4s\n",
      "27:\tlearn: 0.3642515\ttotal: 557ms\tremaining: 19.3s\n",
      "28:\tlearn: 0.3588011\ttotal: 574ms\tremaining: 19.2s\n",
      "29:\tlearn: 0.3537777\ttotal: 591ms\tremaining: 19.1s\n",
      "30:\tlearn: 0.3487666\ttotal: 609ms\tremaining: 19s\n",
      "31:\tlearn: 0.3432139\ttotal: 633ms\tremaining: 19.1s\n",
      "32:\tlearn: 0.3386846\ttotal: 654ms\tremaining: 19.2s\n",
      "33:\tlearn: 0.3361314\ttotal: 673ms\tremaining: 19.1s\n",
      "34:\tlearn: 0.3336702\ttotal: 690ms\tremaining: 19s\n",
      "35:\tlearn: 0.3311908\ttotal: 707ms\tremaining: 18.9s\n",
      "36:\tlearn: 0.3263064\ttotal: 725ms\tremaining: 18.9s\n",
      "37:\tlearn: 0.3228299\ttotal: 742ms\tremaining: 18.8s\n",
      "38:\tlearn: 0.3198409\ttotal: 759ms\tremaining: 18.7s\n",
      "39:\tlearn: 0.3169026\ttotal: 775ms\tremaining: 18.6s\n",
      "40:\tlearn: 0.3126075\ttotal: 792ms\tremaining: 18.5s\n",
      "41:\tlearn: 0.3089347\ttotal: 810ms\tremaining: 18.5s\n",
      "42:\tlearn: 0.3063923\ttotal: 831ms\tremaining: 18.5s\n",
      "43:\tlearn: 0.3025664\ttotal: 852ms\tremaining: 18.5s\n",
      "44:\tlearn: 0.2991137\ttotal: 873ms\tremaining: 18.5s\n",
      "45:\tlearn: 0.2956983\ttotal: 894ms\tremaining: 18.5s\n",
      "46:\tlearn: 0.2910637\ttotal: 914ms\tremaining: 18.5s\n",
      "47:\tlearn: 0.2890708\ttotal: 931ms\tremaining: 18.5s\n",
      "48:\tlearn: 0.2857813\ttotal: 951ms\tremaining: 18.5s\n",
      "49:\tlearn: 0.2837762\ttotal: 968ms\tremaining: 18.4s\n",
      "50:\tlearn: 0.2811453\ttotal: 985ms\tremaining: 18.3s\n",
      "51:\tlearn: 0.2790087\ttotal: 1s\tremaining: 18.3s\n",
      "52:\tlearn: 0.2773931\ttotal: 1.02s\tremaining: 18.3s\n",
      "53:\tlearn: 0.2746970\ttotal: 1.04s\tremaining: 18.3s\n",
      "54:\tlearn: 0.2728736\ttotal: 1.06s\tremaining: 18.2s\n",
      "55:\tlearn: 0.2711010\ttotal: 1.08s\tremaining: 18.1s\n",
      "56:\tlearn: 0.2692992\ttotal: 1.09s\tremaining: 18.1s\n",
      "57:\tlearn: 0.2665114\ttotal: 1.11s\tremaining: 18s\n",
      "58:\tlearn: 0.2634683\ttotal: 1.13s\tremaining: 18s\n",
      "59:\tlearn: 0.2605295\ttotal: 1.14s\tremaining: 17.9s\n",
      "60:\tlearn: 0.2588443\ttotal: 1.16s\tremaining: 17.9s\n",
      "61:\tlearn: 0.2573441\ttotal: 1.18s\tremaining: 17.9s\n",
      "62:\tlearn: 0.2561580\ttotal: 1.2s\tremaining: 17.8s\n",
      "63:\tlearn: 0.2546168\ttotal: 1.22s\tremaining: 17.8s\n",
      "64:\tlearn: 0.2528659\ttotal: 1.24s\tremaining: 17.8s\n",
      "65:\tlearn: 0.2510845\ttotal: 1.26s\tremaining: 17.8s\n",
      "66:\tlearn: 0.2498444\ttotal: 1.28s\tremaining: 17.8s\n",
      "67:\tlearn: 0.2475093\ttotal: 1.3s\tremaining: 17.8s\n",
      "68:\tlearn: 0.2447730\ttotal: 1.32s\tremaining: 17.8s\n",
      "69:\tlearn: 0.2432478\ttotal: 1.34s\tremaining: 17.8s\n",
      "70:\tlearn: 0.2419763\ttotal: 1.36s\tremaining: 17.9s\n",
      "71:\tlearn: 0.2403220\ttotal: 1.39s\tremaining: 17.9s\n",
      "72:\tlearn: 0.2389013\ttotal: 1.41s\tremaining: 17.8s\n",
      "73:\tlearn: 0.2377620\ttotal: 1.42s\tremaining: 17.8s\n",
      "74:\tlearn: 0.2358445\ttotal: 1.44s\tremaining: 17.8s\n",
      "75:\tlearn: 0.2349577\ttotal: 1.46s\tremaining: 17.7s\n",
      "76:\tlearn: 0.2336385\ttotal: 1.48s\tremaining: 17.7s\n",
      "77:\tlearn: 0.2324597\ttotal: 1.49s\tremaining: 17.7s\n",
      "78:\tlearn: 0.2308080\ttotal: 1.51s\tremaining: 17.6s\n",
      "79:\tlearn: 0.2298321\ttotal: 1.53s\tremaining: 17.6s\n",
      "80:\tlearn: 0.2289291\ttotal: 1.55s\tremaining: 17.6s\n",
      "81:\tlearn: 0.2275312\ttotal: 1.57s\tremaining: 17.6s\n",
      "82:\tlearn: 0.2260562\ttotal: 1.59s\tremaining: 17.6s\n",
      "83:\tlearn: 0.2251278\ttotal: 1.61s\tremaining: 17.6s\n",
      "84:\tlearn: 0.2235371\ttotal: 1.64s\tremaining: 17.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85:\tlearn: 0.2224943\ttotal: 1.65s\tremaining: 17.6s\n",
      "86:\tlearn: 0.2209768\ttotal: 1.67s\tremaining: 17.6s\n",
      "87:\tlearn: 0.2198947\ttotal: 1.69s\tremaining: 17.5s\n",
      "88:\tlearn: 0.2180929\ttotal: 1.71s\tremaining: 17.5s\n",
      "89:\tlearn: 0.2172916\ttotal: 1.72s\tremaining: 17.4s\n",
      "90:\tlearn: 0.2161540\ttotal: 1.74s\tremaining: 17.4s\n",
      "91:\tlearn: 0.2149261\ttotal: 1.76s\tremaining: 17.4s\n",
      "92:\tlearn: 0.2139299\ttotal: 1.78s\tremaining: 17.3s\n",
      "93:\tlearn: 0.2132066\ttotal: 1.8s\tremaining: 17.3s\n",
      "94:\tlearn: 0.2113835\ttotal: 1.82s\tremaining: 17.3s\n",
      "95:\tlearn: 0.2094823\ttotal: 1.84s\tremaining: 17.3s\n",
      "96:\tlearn: 0.2085537\ttotal: 1.86s\tremaining: 17.3s\n",
      "97:\tlearn: 0.2075749\ttotal: 1.88s\tremaining: 17.3s\n",
      "98:\tlearn: 0.2064943\ttotal: 1.9s\tremaining: 17.3s\n",
      "99:\tlearn: 0.2050813\ttotal: 1.92s\tremaining: 17.3s\n",
      "100:\tlearn: 0.2041914\ttotal: 1.94s\tremaining: 17.3s\n",
      "101:\tlearn: 0.2027286\ttotal: 1.96s\tremaining: 17.2s\n",
      "102:\tlearn: 0.2018776\ttotal: 1.97s\tremaining: 17.2s\n",
      "103:\tlearn: 0.2011117\ttotal: 1.99s\tremaining: 17.1s\n",
      "104:\tlearn: 0.2000259\ttotal: 2.01s\tremaining: 17.1s\n",
      "105:\tlearn: 0.1987728\ttotal: 2.02s\tremaining: 17.1s\n",
      "106:\tlearn: 0.1975260\ttotal: 2.04s\tremaining: 17s\n",
      "107:\tlearn: 0.1966483\ttotal: 2.06s\tremaining: 17s\n",
      "108:\tlearn: 0.1958083\ttotal: 2.08s\tremaining: 17s\n",
      "109:\tlearn: 0.1946165\ttotal: 2.1s\tremaining: 17s\n",
      "110:\tlearn: 0.1935834\ttotal: 2.11s\tremaining: 16.9s\n",
      "111:\tlearn: 0.1927435\ttotal: 2.13s\tremaining: 16.9s\n",
      "112:\tlearn: 0.1918948\ttotal: 2.15s\tremaining: 16.9s\n",
      "113:\tlearn: 0.1911779\ttotal: 2.17s\tremaining: 16.8s\n",
      "114:\tlearn: 0.1906800\ttotal: 2.18s\tremaining: 16.8s\n",
      "115:\tlearn: 0.1899747\ttotal: 2.2s\tremaining: 16.8s\n",
      "116:\tlearn: 0.1889044\ttotal: 2.22s\tremaining: 16.8s\n",
      "117:\tlearn: 0.1875421\ttotal: 2.25s\tremaining: 16.8s\n",
      "118:\tlearn: 0.1864495\ttotal: 2.27s\tremaining: 16.8s\n",
      "119:\tlearn: 0.1857880\ttotal: 2.29s\tremaining: 16.8s\n",
      "120:\tlearn: 0.1849473\ttotal: 2.3s\tremaining: 16.7s\n",
      "121:\tlearn: 0.1839368\ttotal: 2.32s\tremaining: 16.7s\n",
      "122:\tlearn: 0.1831855\ttotal: 2.35s\tremaining: 16.7s\n",
      "123:\tlearn: 0.1822958\ttotal: 2.37s\tremaining: 16.7s\n",
      "124:\tlearn: 0.1817974\ttotal: 2.38s\tremaining: 16.7s\n",
      "125:\tlearn: 0.1810043\ttotal: 2.4s\tremaining: 16.7s\n",
      "126:\tlearn: 0.1802968\ttotal: 2.42s\tremaining: 16.6s\n",
      "127:\tlearn: 0.1798239\ttotal: 2.44s\tremaining: 16.6s\n",
      "128:\tlearn: 0.1791141\ttotal: 2.46s\tremaining: 16.6s\n",
      "129:\tlearn: 0.1781145\ttotal: 2.48s\tremaining: 16.6s\n",
      "130:\tlearn: 0.1773516\ttotal: 2.5s\tremaining: 16.6s\n",
      "131:\tlearn: 0.1768512\ttotal: 2.52s\tremaining: 16.6s\n",
      "132:\tlearn: 0.1760643\ttotal: 2.54s\tremaining: 16.6s\n",
      "133:\tlearn: 0.1757198\ttotal: 2.56s\tremaining: 16.5s\n",
      "134:\tlearn: 0.1748846\ttotal: 2.58s\tremaining: 16.5s\n",
      "135:\tlearn: 0.1743383\ttotal: 2.6s\tremaining: 16.5s\n",
      "136:\tlearn: 0.1738075\ttotal: 2.62s\tremaining: 16.5s\n",
      "137:\tlearn: 0.1734024\ttotal: 2.63s\tremaining: 16.4s\n",
      "138:\tlearn: 0.1726237\ttotal: 2.65s\tremaining: 16.4s\n",
      "139:\tlearn: 0.1720563\ttotal: 2.67s\tremaining: 16.4s\n",
      "140:\tlearn: 0.1715292\ttotal: 2.69s\tremaining: 16.4s\n",
      "141:\tlearn: 0.1707801\ttotal: 2.71s\tremaining: 16.4s\n",
      "142:\tlearn: 0.1698639\ttotal: 2.73s\tremaining: 16.4s\n",
      "143:\tlearn: 0.1692931\ttotal: 2.75s\tremaining: 16.4s\n",
      "144:\tlearn: 0.1684411\ttotal: 2.77s\tremaining: 16.4s\n",
      "145:\tlearn: 0.1677698\ttotal: 2.79s\tremaining: 16.4s\n",
      "146:\tlearn: 0.1669906\ttotal: 2.81s\tremaining: 16.3s\n",
      "147:\tlearn: 0.1665253\ttotal: 2.84s\tremaining: 16.3s\n",
      "148:\tlearn: 0.1660796\ttotal: 2.86s\tremaining: 16.3s\n",
      "149:\tlearn: 0.1654150\ttotal: 2.88s\tremaining: 16.3s\n",
      "150:\tlearn: 0.1649072\ttotal: 2.9s\tremaining: 16.3s\n",
      "151:\tlearn: 0.1645038\ttotal: 2.92s\tremaining: 16.3s\n",
      "152:\tlearn: 0.1636525\ttotal: 2.94s\tremaining: 16.3s\n",
      "153:\tlearn: 0.1629076\ttotal: 2.96s\tremaining: 16.2s\n",
      "154:\tlearn: 0.1620450\ttotal: 2.98s\tremaining: 16.2s\n",
      "155:\tlearn: 0.1613772\ttotal: 2.99s\tremaining: 16.2s\n",
      "156:\tlearn: 0.1608984\ttotal: 3.01s\tremaining: 16.2s\n",
      "157:\tlearn: 0.1602161\ttotal: 3.03s\tremaining: 16.1s\n",
      "158:\tlearn: 0.1593561\ttotal: 3.05s\tremaining: 16.1s\n",
      "159:\tlearn: 0.1587949\ttotal: 3.06s\tremaining: 16.1s\n",
      "160:\tlearn: 0.1583393\ttotal: 3.08s\tremaining: 16.1s\n",
      "161:\tlearn: 0.1576487\ttotal: 3.1s\tremaining: 16s\n",
      "162:\tlearn: 0.1571209\ttotal: 3.11s\tremaining: 16s\n",
      "163:\tlearn: 0.1566335\ttotal: 3.13s\tremaining: 16s\n",
      "164:\tlearn: 0.1560852\ttotal: 3.15s\tremaining: 15.9s\n",
      "165:\tlearn: 0.1557095\ttotal: 3.16s\tremaining: 15.9s\n",
      "166:\tlearn: 0.1550493\ttotal: 3.18s\tremaining: 15.9s\n",
      "167:\tlearn: 0.1546046\ttotal: 3.2s\tremaining: 15.8s\n",
      "168:\tlearn: 0.1541857\ttotal: 3.22s\tremaining: 15.8s\n",
      "169:\tlearn: 0.1539360\ttotal: 3.23s\tremaining: 15.8s\n",
      "170:\tlearn: 0.1535027\ttotal: 3.25s\tremaining: 15.8s\n",
      "171:\tlearn: 0.1529073\ttotal: 3.27s\tremaining: 15.7s\n",
      "172:\tlearn: 0.1523771\ttotal: 3.28s\tremaining: 15.7s\n",
      "173:\tlearn: 0.1519130\ttotal: 3.3s\tremaining: 15.7s\n",
      "174:\tlearn: 0.1513949\ttotal: 3.32s\tremaining: 15.7s\n",
      "175:\tlearn: 0.1511429\ttotal: 3.34s\tremaining: 15.6s\n",
      "176:\tlearn: 0.1507131\ttotal: 3.36s\tremaining: 15.6s\n",
      "177:\tlearn: 0.1504351\ttotal: 3.37s\tremaining: 15.6s\n",
      "178:\tlearn: 0.1501274\ttotal: 3.4s\tremaining: 15.6s\n",
      "179:\tlearn: 0.1495563\ttotal: 3.42s\tremaining: 15.6s\n",
      "180:\tlearn: 0.1489555\ttotal: 3.44s\tremaining: 15.6s\n",
      "181:\tlearn: 0.1485510\ttotal: 3.46s\tremaining: 15.5s\n",
      "182:\tlearn: 0.1482320\ttotal: 3.47s\tremaining: 15.5s\n",
      "183:\tlearn: 0.1479297\ttotal: 3.49s\tremaining: 15.5s\n",
      "184:\tlearn: 0.1472747\ttotal: 3.51s\tremaining: 15.4s\n",
      "185:\tlearn: 0.1469389\ttotal: 3.52s\tremaining: 15.4s\n",
      "186:\tlearn: 0.1466877\ttotal: 3.54s\tremaining: 15.4s\n",
      "187:\tlearn: 0.1463507\ttotal: 3.56s\tremaining: 15.4s\n",
      "188:\tlearn: 0.1460992\ttotal: 3.58s\tremaining: 15.4s\n",
      "189:\tlearn: 0.1458741\ttotal: 3.6s\tremaining: 15.4s\n",
      "190:\tlearn: 0.1454504\ttotal: 3.63s\tremaining: 15.4s\n",
      "191:\tlearn: 0.1447931\ttotal: 3.65s\tremaining: 15.3s\n",
      "192:\tlearn: 0.1443616\ttotal: 3.67s\tremaining: 15.3s\n",
      "193:\tlearn: 0.1439308\ttotal: 3.69s\tremaining: 15.3s\n",
      "194:\tlearn: 0.1436315\ttotal: 3.71s\tremaining: 15.3s\n",
      "195:\tlearn: 0.1429029\ttotal: 3.73s\tremaining: 15.3s\n",
      "196:\tlearn: 0.1423645\ttotal: 3.75s\tremaining: 15.3s\n",
      "197:\tlearn: 0.1420276\ttotal: 3.77s\tremaining: 15.3s\n",
      "198:\tlearn: 0.1415333\ttotal: 3.79s\tremaining: 15.3s\n",
      "199:\tlearn: 0.1410650\ttotal: 3.81s\tremaining: 15.2s\n",
      "200:\tlearn: 0.1407712\ttotal: 3.83s\tremaining: 15.2s\n",
      "201:\tlearn: 0.1402397\ttotal: 3.85s\tremaining: 15.2s\n",
      "202:\tlearn: 0.1397292\ttotal: 3.87s\tremaining: 15.2s\n",
      "203:\tlearn: 0.1392334\ttotal: 3.89s\tremaining: 15.2s\n",
      "204:\tlearn: 0.1388392\ttotal: 3.92s\tremaining: 15.2s\n",
      "205:\tlearn: 0.1384475\ttotal: 3.94s\tremaining: 15.2s\n",
      "206:\tlearn: 0.1381349\ttotal: 3.95s\tremaining: 15.1s\n",
      "207:\tlearn: 0.1377807\ttotal: 3.98s\tremaining: 15.1s\n",
      "208:\tlearn: 0.1372365\ttotal: 4s\tremaining: 15.1s\n",
      "209:\tlearn: 0.1367757\ttotal: 4.01s\tremaining: 15.1s\n",
      "210:\tlearn: 0.1364171\ttotal: 4.03s\tremaining: 15.1s\n",
      "211:\tlearn: 0.1359191\ttotal: 4.06s\tremaining: 15.1s\n",
      "212:\tlearn: 0.1353717\ttotal: 4.08s\tremaining: 15.1s\n",
      "213:\tlearn: 0.1350974\ttotal: 4.1s\tremaining: 15.1s\n",
      "214:\tlearn: 0.1348960\ttotal: 4.12s\tremaining: 15.1s\n",
      "215:\tlearn: 0.1344837\ttotal: 4.15s\tremaining: 15s\n",
      "216:\tlearn: 0.1341420\ttotal: 4.17s\tremaining: 15s\n",
      "217:\tlearn: 0.1335818\ttotal: 4.19s\tremaining: 15s\n",
      "218:\tlearn: 0.1331594\ttotal: 4.21s\tremaining: 15s\n",
      "219:\tlearn: 0.1328424\ttotal: 4.23s\tremaining: 15s\n",
      "220:\tlearn: 0.1326259\ttotal: 4.25s\tremaining: 15s\n",
      "221:\tlearn: 0.1323234\ttotal: 4.27s\tremaining: 15s\n",
      "222:\tlearn: 0.1318664\ttotal: 4.29s\tremaining: 14.9s\n",
      "223:\tlearn: 0.1314900\ttotal: 4.31s\tremaining: 14.9s\n",
      "224:\tlearn: 0.1311187\ttotal: 4.33s\tremaining: 14.9s\n",
      "225:\tlearn: 0.1308582\ttotal: 4.35s\tremaining: 14.9s\n",
      "226:\tlearn: 0.1305542\ttotal: 4.37s\tremaining: 14.9s\n",
      "227:\tlearn: 0.1300047\ttotal: 4.39s\tremaining: 14.9s\n",
      "228:\tlearn: 0.1296433\ttotal: 4.42s\tremaining: 14.9s\n",
      "229:\tlearn: 0.1294340\ttotal: 4.44s\tremaining: 14.9s\n",
      "230:\tlearn: 0.1290971\ttotal: 4.47s\tremaining: 14.9s\n",
      "231:\tlearn: 0.1287616\ttotal: 4.51s\tremaining: 14.9s\n",
      "232:\tlearn: 0.1283170\ttotal: 4.54s\tremaining: 15s\n",
      "233:\tlearn: 0.1278785\ttotal: 4.57s\tremaining: 14.9s\n",
      "234:\tlearn: 0.1276181\ttotal: 4.59s\tremaining: 14.9s\n",
      "235:\tlearn: 0.1271686\ttotal: 4.61s\tremaining: 14.9s\n",
      "236:\tlearn: 0.1267459\ttotal: 4.63s\tremaining: 14.9s\n",
      "237:\tlearn: 0.1264633\ttotal: 4.66s\tremaining: 14.9s\n",
      "238:\tlearn: 0.1261555\ttotal: 4.68s\tremaining: 14.9s\n",
      "239:\tlearn: 0.1258731\ttotal: 4.7s\tremaining: 14.9s\n",
      "240:\tlearn: 0.1255517\ttotal: 4.73s\tremaining: 14.9s\n",
      "241:\tlearn: 0.1251707\ttotal: 4.75s\tremaining: 14.9s\n",
      "242:\tlearn: 0.1246942\ttotal: 4.76s\tremaining: 14.8s\n",
      "243:\tlearn: 0.1243642\ttotal: 4.79s\tremaining: 14.8s\n",
      "244:\tlearn: 0.1241139\ttotal: 4.81s\tremaining: 14.8s\n",
      "245:\tlearn: 0.1238028\ttotal: 4.84s\tremaining: 14.8s\n",
      "246:\tlearn: 0.1234849\ttotal: 4.86s\tremaining: 14.8s\n",
      "247:\tlearn: 0.1230728\ttotal: 4.88s\tremaining: 14.8s\n",
      "248:\tlearn: 0.1224707\ttotal: 4.91s\tremaining: 14.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249:\tlearn: 0.1221409\ttotal: 4.93s\tremaining: 14.8s\n",
      "250:\tlearn: 0.1218613\ttotal: 4.95s\tremaining: 14.8s\n",
      "251:\tlearn: 0.1216654\ttotal: 4.97s\tremaining: 14.8s\n",
      "252:\tlearn: 0.1214198\ttotal: 5s\tremaining: 14.8s\n",
      "253:\tlearn: 0.1211699\ttotal: 5.02s\tremaining: 14.7s\n",
      "254:\tlearn: 0.1207715\ttotal: 5.04s\tremaining: 14.7s\n",
      "255:\tlearn: 0.1205547\ttotal: 5.06s\tremaining: 14.7s\n",
      "256:\tlearn: 0.1203899\ttotal: 5.08s\tremaining: 14.7s\n",
      "257:\tlearn: 0.1201484\ttotal: 5.11s\tremaining: 14.7s\n",
      "258:\tlearn: 0.1199786\ttotal: 5.14s\tremaining: 14.7s\n",
      "259:\tlearn: 0.1196666\ttotal: 5.18s\tremaining: 14.8s\n",
      "260:\tlearn: 0.1193370\ttotal: 5.22s\tremaining: 14.8s\n",
      "261:\tlearn: 0.1190373\ttotal: 5.25s\tremaining: 14.8s\n",
      "262:\tlearn: 0.1188392\ttotal: 5.28s\tremaining: 14.8s\n",
      "263:\tlearn: 0.1186296\ttotal: 5.31s\tremaining: 14.8s\n",
      "264:\tlearn: 0.1184034\ttotal: 5.34s\tremaining: 14.8s\n",
      "265:\tlearn: 0.1182065\ttotal: 5.38s\tremaining: 14.8s\n",
      "266:\tlearn: 0.1178639\ttotal: 5.41s\tremaining: 14.9s\n",
      "267:\tlearn: 0.1175677\ttotal: 5.44s\tremaining: 14.9s\n",
      "268:\tlearn: 0.1173010\ttotal: 5.47s\tremaining: 14.9s\n",
      "269:\tlearn: 0.1168190\ttotal: 5.5s\tremaining: 14.9s\n",
      "270:\tlearn: 0.1165461\ttotal: 5.53s\tremaining: 14.9s\n",
      "271:\tlearn: 0.1162121\ttotal: 5.56s\tremaining: 14.9s\n",
      "272:\tlearn: 0.1158209\ttotal: 5.59s\tremaining: 14.9s\n",
      "273:\tlearn: 0.1155125\ttotal: 5.62s\tremaining: 14.9s\n",
      "274:\tlearn: 0.1153243\ttotal: 5.64s\tremaining: 14.9s\n",
      "275:\tlearn: 0.1150139\ttotal: 5.68s\tremaining: 14.9s\n",
      "276:\tlearn: 0.1147180\ttotal: 5.71s\tremaining: 14.9s\n",
      "277:\tlearn: 0.1144997\ttotal: 5.74s\tremaining: 14.9s\n",
      "278:\tlearn: 0.1142992\ttotal: 5.78s\tremaining: 14.9s\n",
      "279:\tlearn: 0.1139347\ttotal: 5.81s\tremaining: 14.9s\n",
      "280:\tlearn: 0.1137008\ttotal: 5.85s\tremaining: 15s\n",
      "281:\tlearn: 0.1134676\ttotal: 5.88s\tremaining: 15s\n",
      "282:\tlearn: 0.1132952\ttotal: 5.91s\tremaining: 15s\n",
      "283:\tlearn: 0.1131044\ttotal: 5.94s\tremaining: 15s\n",
      "284:\tlearn: 0.1126446\ttotal: 5.96s\tremaining: 15s\n",
      "285:\tlearn: 0.1124137\ttotal: 5.99s\tremaining: 15s\n",
      "286:\tlearn: 0.1122081\ttotal: 6.03s\tremaining: 15s\n",
      "287:\tlearn: 0.1120500\ttotal: 6.07s\tremaining: 15s\n",
      "288:\tlearn: 0.1118502\ttotal: 6.1s\tremaining: 15s\n",
      "289:\tlearn: 0.1115060\ttotal: 6.13s\tremaining: 15s\n",
      "290:\tlearn: 0.1111791\ttotal: 6.16s\tremaining: 15s\n",
      "291:\tlearn: 0.1108305\ttotal: 6.19s\tremaining: 15s\n",
      "292:\tlearn: 0.1106413\ttotal: 6.22s\tremaining: 15s\n",
      "293:\tlearn: 0.1102785\ttotal: 6.25s\tremaining: 15s\n",
      "294:\tlearn: 0.1100362\ttotal: 6.29s\tremaining: 15s\n",
      "295:\tlearn: 0.1098391\ttotal: 6.32s\tremaining: 15s\n",
      "296:\tlearn: 0.1094790\ttotal: 6.35s\tremaining: 15s\n",
      "297:\tlearn: 0.1092975\ttotal: 6.38s\tremaining: 15s\n",
      "298:\tlearn: 0.1091230\ttotal: 6.41s\tremaining: 15s\n",
      "299:\tlearn: 0.1088765\ttotal: 6.45s\tremaining: 15s\n",
      "300:\tlearn: 0.1086989\ttotal: 6.49s\tremaining: 15.1s\n",
      "301:\tlearn: 0.1084212\ttotal: 6.52s\tremaining: 15.1s\n",
      "302:\tlearn: 0.1082221\ttotal: 6.55s\tremaining: 15.1s\n",
      "303:\tlearn: 0.1079987\ttotal: 6.58s\tremaining: 15.1s\n",
      "304:\tlearn: 0.1078172\ttotal: 6.61s\tremaining: 15.1s\n",
      "305:\tlearn: 0.1076509\ttotal: 6.63s\tremaining: 15s\n",
      "306:\tlearn: 0.1075072\ttotal: 6.66s\tremaining: 15s\n",
      "307:\tlearn: 0.1073303\ttotal: 6.69s\tremaining: 15s\n",
      "308:\tlearn: 0.1071612\ttotal: 6.72s\tremaining: 15s\n",
      "309:\tlearn: 0.1069989\ttotal: 6.74s\tremaining: 15s\n",
      "310:\tlearn: 0.1067629\ttotal: 6.77s\tremaining: 15s\n",
      "311:\tlearn: 0.1065858\ttotal: 6.81s\tremaining: 15s\n",
      "312:\tlearn: 0.1063543\ttotal: 6.83s\tremaining: 15s\n",
      "313:\tlearn: 0.1061299\ttotal: 6.85s\tremaining: 15s\n",
      "314:\tlearn: 0.1058993\ttotal: 6.87s\tremaining: 14.9s\n",
      "315:\tlearn: 0.1057109\ttotal: 6.9s\tremaining: 14.9s\n",
      "316:\tlearn: 0.1054681\ttotal: 6.92s\tremaining: 14.9s\n",
      "317:\tlearn: 0.1052600\ttotal: 6.95s\tremaining: 14.9s\n",
      "318:\tlearn: 0.1050545\ttotal: 6.96s\tremaining: 14.9s\n",
      "319:\tlearn: 0.1047956\ttotal: 6.99s\tremaining: 14.9s\n",
      "320:\tlearn: 0.1046339\ttotal: 7.01s\tremaining: 14.8s\n",
      "321:\tlearn: 0.1044144\ttotal: 7.03s\tremaining: 14.8s\n",
      "322:\tlearn: 0.1041809\ttotal: 7.05s\tremaining: 14.8s\n",
      "323:\tlearn: 0.1039447\ttotal: 7.07s\tremaining: 14.8s\n",
      "324:\tlearn: 0.1038257\ttotal: 7.09s\tremaining: 14.7s\n",
      "325:\tlearn: 0.1035811\ttotal: 7.11s\tremaining: 14.7s\n",
      "326:\tlearn: 0.1033354\ttotal: 7.13s\tremaining: 14.7s\n",
      "327:\tlearn: 0.1031379\ttotal: 7.18s\tremaining: 14.7s\n",
      "328:\tlearn: 0.1028767\ttotal: 7.22s\tremaining: 14.7s\n",
      "329:\tlearn: 0.1026144\ttotal: 7.26s\tremaining: 14.7s\n",
      "330:\tlearn: 0.1024712\ttotal: 7.31s\tremaining: 14.8s\n",
      "331:\tlearn: 0.1022727\ttotal: 7.35s\tremaining: 14.8s\n",
      "332:\tlearn: 0.1021483\ttotal: 7.39s\tremaining: 14.8s\n",
      "333:\tlearn: 0.1018867\ttotal: 7.43s\tremaining: 14.8s\n",
      "334:\tlearn: 0.1017626\ttotal: 7.46s\tremaining: 14.8s\n",
      "335:\tlearn: 0.1016222\ttotal: 7.5s\tremaining: 14.8s\n",
      "336:\tlearn: 0.1014123\ttotal: 7.54s\tremaining: 14.8s\n",
      "337:\tlearn: 0.1011615\ttotal: 7.57s\tremaining: 14.8s\n",
      "338:\tlearn: 0.1009451\ttotal: 7.61s\tremaining: 14.8s\n",
      "339:\tlearn: 0.1006693\ttotal: 7.64s\tremaining: 14.8s\n",
      "340:\tlearn: 0.1004891\ttotal: 7.67s\tremaining: 14.8s\n",
      "341:\tlearn: 0.1003364\ttotal: 7.7s\tremaining: 14.8s\n",
      "342:\tlearn: 0.1001672\ttotal: 7.73s\tremaining: 14.8s\n",
      "343:\tlearn: 0.0999746\ttotal: 7.77s\tremaining: 14.8s\n",
      "344:\tlearn: 0.0997543\ttotal: 7.81s\tremaining: 14.8s\n",
      "345:\tlearn: 0.0995931\ttotal: 7.84s\tremaining: 14.8s\n",
      "346:\tlearn: 0.0994455\ttotal: 7.86s\tremaining: 14.8s\n",
      "347:\tlearn: 0.0992589\ttotal: 7.89s\tremaining: 14.8s\n",
      "348:\tlearn: 0.0991022\ttotal: 7.91s\tremaining: 14.8s\n",
      "349:\tlearn: 0.0988597\ttotal: 7.93s\tremaining: 14.7s\n",
      "350:\tlearn: 0.0986994\ttotal: 7.96s\tremaining: 14.7s\n",
      "351:\tlearn: 0.0984739\ttotal: 8s\tremaining: 14.7s\n",
      "352:\tlearn: 0.0983661\ttotal: 8.03s\tremaining: 14.7s\n",
      "353:\tlearn: 0.0981536\ttotal: 8.05s\tremaining: 14.7s\n",
      "354:\tlearn: 0.0980232\ttotal: 8.07s\tremaining: 14.7s\n",
      "355:\tlearn: 0.0977011\ttotal: 8.09s\tremaining: 14.6s\n",
      "356:\tlearn: 0.0974633\ttotal: 8.12s\tremaining: 14.6s\n",
      "357:\tlearn: 0.0973300\ttotal: 8.14s\tremaining: 14.6s\n",
      "358:\tlearn: 0.0971002\ttotal: 8.17s\tremaining: 14.6s\n",
      "359:\tlearn: 0.0968977\ttotal: 8.2s\tremaining: 14.6s\n",
      "360:\tlearn: 0.0966941\ttotal: 8.22s\tremaining: 14.5s\n",
      "361:\tlearn: 0.0964667\ttotal: 8.24s\tremaining: 14.5s\n",
      "362:\tlearn: 0.0961948\ttotal: 8.26s\tremaining: 14.5s\n",
      "363:\tlearn: 0.0960654\ttotal: 8.28s\tremaining: 14.5s\n",
      "364:\tlearn: 0.0958070\ttotal: 8.3s\tremaining: 14.4s\n",
      "365:\tlearn: 0.0956727\ttotal: 8.32s\tremaining: 14.4s\n",
      "366:\tlearn: 0.0955205\ttotal: 8.34s\tremaining: 14.4s\n",
      "367:\tlearn: 0.0954351\ttotal: 8.36s\tremaining: 14.4s\n",
      "368:\tlearn: 0.0952789\ttotal: 8.38s\tremaining: 14.3s\n",
      "369:\tlearn: 0.0951170\ttotal: 8.4s\tremaining: 14.3s\n",
      "370:\tlearn: 0.0948310\ttotal: 8.43s\tremaining: 14.3s\n",
      "371:\tlearn: 0.0947341\ttotal: 8.45s\tremaining: 14.3s\n",
      "372:\tlearn: 0.0946096\ttotal: 8.47s\tremaining: 14.2s\n",
      "373:\tlearn: 0.0944379\ttotal: 8.49s\tremaining: 14.2s\n",
      "374:\tlearn: 0.0942831\ttotal: 8.51s\tremaining: 14.2s\n",
      "375:\tlearn: 0.0940538\ttotal: 8.53s\tremaining: 14.2s\n",
      "376:\tlearn: 0.0939454\ttotal: 8.56s\tremaining: 14.1s\n",
      "377:\tlearn: 0.0938307\ttotal: 8.58s\tremaining: 14.1s\n",
      "378:\tlearn: 0.0936934\ttotal: 8.61s\tremaining: 14.1s\n",
      "379:\tlearn: 0.0935213\ttotal: 8.63s\tremaining: 14.1s\n",
      "380:\tlearn: 0.0933476\ttotal: 8.65s\tremaining: 14.1s\n",
      "381:\tlearn: 0.0932609\ttotal: 8.68s\tremaining: 14s\n",
      "382:\tlearn: 0.0930959\ttotal: 8.7s\tremaining: 14s\n",
      "383:\tlearn: 0.0929366\ttotal: 8.71s\tremaining: 14s\n",
      "384:\tlearn: 0.0928183\ttotal: 8.73s\tremaining: 14s\n",
      "385:\tlearn: 0.0926238\ttotal: 8.76s\tremaining: 13.9s\n",
      "386:\tlearn: 0.0924609\ttotal: 8.78s\tremaining: 13.9s\n",
      "387:\tlearn: 0.0923034\ttotal: 8.8s\tremaining: 13.9s\n",
      "388:\tlearn: 0.0921338\ttotal: 8.82s\tremaining: 13.9s\n",
      "389:\tlearn: 0.0920066\ttotal: 8.84s\tremaining: 13.8s\n",
      "390:\tlearn: 0.0917539\ttotal: 8.86s\tremaining: 13.8s\n",
      "391:\tlearn: 0.0915938\ttotal: 8.88s\tremaining: 13.8s\n",
      "392:\tlearn: 0.0914745\ttotal: 8.9s\tremaining: 13.7s\n",
      "393:\tlearn: 0.0913020\ttotal: 8.92s\tremaining: 13.7s\n",
      "394:\tlearn: 0.0911237\ttotal: 8.94s\tremaining: 13.7s\n",
      "395:\tlearn: 0.0909768\ttotal: 8.96s\tremaining: 13.7s\n",
      "396:\tlearn: 0.0907758\ttotal: 8.98s\tremaining: 13.6s\n",
      "397:\tlearn: 0.0906522\ttotal: 9s\tremaining: 13.6s\n",
      "398:\tlearn: 0.0904428\ttotal: 9.03s\tremaining: 13.6s\n",
      "399:\tlearn: 0.0902518\ttotal: 9.05s\tremaining: 13.6s\n",
      "400:\tlearn: 0.0900428\ttotal: 9.07s\tremaining: 13.6s\n",
      "401:\tlearn: 0.0897669\ttotal: 9.1s\tremaining: 13.5s\n",
      "402:\tlearn: 0.0895654\ttotal: 9.13s\tremaining: 13.5s\n",
      "403:\tlearn: 0.0893949\ttotal: 9.15s\tremaining: 13.5s\n",
      "404:\tlearn: 0.0892959\ttotal: 9.17s\tremaining: 13.5s\n",
      "405:\tlearn: 0.0891338\ttotal: 9.2s\tremaining: 13.5s\n",
      "406:\tlearn: 0.0888797\ttotal: 9.22s\tremaining: 13.4s\n",
      "407:\tlearn: 0.0886864\ttotal: 9.24s\tremaining: 13.4s\n",
      "408:\tlearn: 0.0884150\ttotal: 9.27s\tremaining: 13.4s\n",
      "409:\tlearn: 0.0882233\ttotal: 9.29s\tremaining: 13.4s\n",
      "410:\tlearn: 0.0880503\ttotal: 9.3s\tremaining: 13.3s\n",
      "411:\tlearn: 0.0878694\ttotal: 9.32s\tremaining: 13.3s\n",
      "412:\tlearn: 0.0874929\ttotal: 9.34s\tremaining: 13.3s\n",
      "413:\tlearn: 0.0873346\ttotal: 9.36s\tremaining: 13.2s\n",
      "414:\tlearn: 0.0871731\ttotal: 9.39s\tremaining: 13.2s\n",
      "415:\tlearn: 0.0869043\ttotal: 9.41s\tremaining: 13.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "416:\tlearn: 0.0867651\ttotal: 9.44s\tremaining: 13.2s\n",
      "417:\tlearn: 0.0865821\ttotal: 9.46s\tremaining: 13.2s\n",
      "418:\tlearn: 0.0864514\ttotal: 9.48s\tremaining: 13.2s\n",
      "419:\tlearn: 0.0862329\ttotal: 9.51s\tremaining: 13.1s\n",
      "420:\tlearn: 0.0861061\ttotal: 9.53s\tremaining: 13.1s\n",
      "421:\tlearn: 0.0860625\ttotal: 9.55s\tremaining: 13.1s\n",
      "422:\tlearn: 0.0858721\ttotal: 9.57s\tremaining: 13.1s\n",
      "423:\tlearn: 0.0857414\ttotal: 9.59s\tremaining: 13s\n",
      "424:\tlearn: 0.0855727\ttotal: 9.61s\tremaining: 13s\n",
      "425:\tlearn: 0.0854502\ttotal: 9.63s\tremaining: 13s\n",
      "426:\tlearn: 0.0852805\ttotal: 9.65s\tremaining: 12.9s\n",
      "427:\tlearn: 0.0851301\ttotal: 9.67s\tremaining: 12.9s\n",
      "428:\tlearn: 0.0850325\ttotal: 9.69s\tremaining: 12.9s\n",
      "429:\tlearn: 0.0848097\ttotal: 9.7s\tremaining: 12.9s\n",
      "430:\tlearn: 0.0846658\ttotal: 9.72s\tremaining: 12.8s\n",
      "431:\tlearn: 0.0844906\ttotal: 9.75s\tremaining: 12.8s\n",
      "432:\tlearn: 0.0844668\ttotal: 9.77s\tremaining: 12.8s\n",
      "433:\tlearn: 0.0843561\ttotal: 9.79s\tremaining: 12.8s\n",
      "434:\tlearn: 0.0842131\ttotal: 9.81s\tremaining: 12.7s\n",
      "435:\tlearn: 0.0840860\ttotal: 9.84s\tremaining: 12.7s\n",
      "436:\tlearn: 0.0839132\ttotal: 9.87s\tremaining: 12.7s\n",
      "437:\tlearn: 0.0838969\ttotal: 9.9s\tremaining: 12.7s\n",
      "438:\tlearn: 0.0837872\ttotal: 9.93s\tremaining: 12.7s\n",
      "439:\tlearn: 0.0836704\ttotal: 9.96s\tremaining: 12.7s\n",
      "440:\tlearn: 0.0835248\ttotal: 9.98s\tremaining: 12.6s\n",
      "441:\tlearn: 0.0832594\ttotal: 10s\tremaining: 12.6s\n",
      "442:\tlearn: 0.0831336\ttotal: 10s\tremaining: 12.6s\n",
      "443:\tlearn: 0.0829215\ttotal: 10s\tremaining: 12.6s\n",
      "444:\tlearn: 0.0827303\ttotal: 10.1s\tremaining: 12.6s\n",
      "445:\tlearn: 0.0826344\ttotal: 10.1s\tremaining: 12.5s\n",
      "446:\tlearn: 0.0826237\ttotal: 10.1s\tremaining: 12.5s\n",
      "447:\tlearn: 0.0824751\ttotal: 10.1s\tremaining: 12.5s\n",
      "448:\tlearn: 0.0823440\ttotal: 10.2s\tremaining: 12.5s\n",
      "449:\tlearn: 0.0821505\ttotal: 10.2s\tremaining: 12.4s\n",
      "450:\tlearn: 0.0820258\ttotal: 10.2s\tremaining: 12.4s\n",
      "451:\tlearn: 0.0819184\ttotal: 10.2s\tremaining: 12.4s\n",
      "452:\tlearn: 0.0817142\ttotal: 10.2s\tremaining: 12.4s\n",
      "453:\tlearn: 0.0815252\ttotal: 10.3s\tremaining: 12.3s\n",
      "454:\tlearn: 0.0813953\ttotal: 10.3s\tremaining: 12.3s\n",
      "455:\tlearn: 0.0811758\ttotal: 10.3s\tremaining: 12.3s\n",
      "456:\tlearn: 0.0809848\ttotal: 10.3s\tremaining: 12.3s\n",
      "457:\tlearn: 0.0808420\ttotal: 10.3s\tremaining: 12.2s\n",
      "458:\tlearn: 0.0806671\ttotal: 10.4s\tremaining: 12.2s\n",
      "459:\tlearn: 0.0804955\ttotal: 10.4s\tremaining: 12.2s\n",
      "460:\tlearn: 0.0802454\ttotal: 10.4s\tremaining: 12.2s\n",
      "461:\tlearn: 0.0801907\ttotal: 10.4s\tremaining: 12.1s\n",
      "462:\tlearn: 0.0799469\ttotal: 10.5s\tremaining: 12.1s\n",
      "463:\tlearn: 0.0798957\ttotal: 10.5s\tremaining: 12.1s\n",
      "464:\tlearn: 0.0797171\ttotal: 10.5s\tremaining: 12.1s\n",
      "465:\tlearn: 0.0795955\ttotal: 10.5s\tremaining: 12s\n",
      "466:\tlearn: 0.0794748\ttotal: 10.5s\tremaining: 12s\n",
      "467:\tlearn: 0.0792999\ttotal: 10.6s\tremaining: 12s\n",
      "468:\tlearn: 0.0792115\ttotal: 10.6s\tremaining: 12s\n",
      "469:\tlearn: 0.0790871\ttotal: 10.6s\tremaining: 11.9s\n",
      "470:\tlearn: 0.0790724\ttotal: 10.6s\tremaining: 11.9s\n",
      "471:\tlearn: 0.0789079\ttotal: 10.6s\tremaining: 11.9s\n",
      "472:\tlearn: 0.0787789\ttotal: 10.7s\tremaining: 11.9s\n",
      "473:\tlearn: 0.0786165\ttotal: 10.7s\tremaining: 11.9s\n",
      "474:\tlearn: 0.0784392\ttotal: 10.7s\tremaining: 11.8s\n",
      "475:\tlearn: 0.0783874\ttotal: 10.7s\tremaining: 11.8s\n",
      "476:\tlearn: 0.0782426\ttotal: 10.8s\tremaining: 11.8s\n",
      "477:\tlearn: 0.0781248\ttotal: 10.8s\tremaining: 11.8s\n",
      "478:\tlearn: 0.0779737\ttotal: 10.8s\tremaining: 11.7s\n",
      "479:\tlearn: 0.0777279\ttotal: 10.8s\tremaining: 11.7s\n",
      "480:\tlearn: 0.0775390\ttotal: 10.8s\tremaining: 11.7s\n",
      "481:\tlearn: 0.0774186\ttotal: 10.9s\tremaining: 11.7s\n",
      "482:\tlearn: 0.0772815\ttotal: 10.9s\tremaining: 11.6s\n",
      "483:\tlearn: 0.0772520\ttotal: 10.9s\tremaining: 11.6s\n",
      "484:\tlearn: 0.0772240\ttotal: 10.9s\tremaining: 11.6s\n",
      "485:\tlearn: 0.0770823\ttotal: 10.9s\tremaining: 11.6s\n",
      "486:\tlearn: 0.0769586\ttotal: 11s\tremaining: 11.5s\n",
      "487:\tlearn: 0.0769041\ttotal: 11s\tremaining: 11.5s\n",
      "488:\tlearn: 0.0767690\ttotal: 11s\tremaining: 11.5s\n",
      "489:\tlearn: 0.0767500\ttotal: 11s\tremaining: 11.5s\n",
      "490:\tlearn: 0.0765193\ttotal: 11s\tremaining: 11.4s\n",
      "491:\tlearn: 0.0764890\ttotal: 11.1s\tremaining: 11.4s\n",
      "492:\tlearn: 0.0763307\ttotal: 11.1s\tremaining: 11.4s\n",
      "493:\tlearn: 0.0761873\ttotal: 11.1s\tremaining: 11.4s\n",
      "494:\tlearn: 0.0760296\ttotal: 11.1s\tremaining: 11.4s\n",
      "495:\tlearn: 0.0759085\ttotal: 11.2s\tremaining: 11.3s\n",
      "496:\tlearn: 0.0757345\ttotal: 11.2s\tremaining: 11.3s\n",
      "497:\tlearn: 0.0756439\ttotal: 11.2s\tremaining: 11.3s\n",
      "498:\tlearn: 0.0754874\ttotal: 11.2s\tremaining: 11.3s\n",
      "499:\tlearn: 0.0753417\ttotal: 11.2s\tremaining: 11.2s\n",
      "500:\tlearn: 0.0751664\ttotal: 11.3s\tremaining: 11.2s\n",
      "501:\tlearn: 0.0750674\ttotal: 11.3s\tremaining: 11.2s\n",
      "502:\tlearn: 0.0748558\ttotal: 11.3s\tremaining: 11.2s\n",
      "503:\tlearn: 0.0747498\ttotal: 11.3s\tremaining: 11.2s\n",
      "504:\tlearn: 0.0747066\ttotal: 11.4s\tremaining: 11.1s\n",
      "505:\tlearn: 0.0745788\ttotal: 11.4s\tremaining: 11.1s\n",
      "506:\tlearn: 0.0743844\ttotal: 11.4s\tremaining: 11.1s\n",
      "507:\tlearn: 0.0742853\ttotal: 11.4s\tremaining: 11.1s\n",
      "508:\tlearn: 0.0740691\ttotal: 11.4s\tremaining: 11s\n",
      "509:\tlearn: 0.0738960\ttotal: 11.5s\tremaining: 11s\n",
      "510:\tlearn: 0.0737558\ttotal: 11.5s\tremaining: 11s\n",
      "511:\tlearn: 0.0735079\ttotal: 11.5s\tremaining: 11s\n",
      "512:\tlearn: 0.0732541\ttotal: 11.5s\tremaining: 10.9s\n",
      "513:\tlearn: 0.0729936\ttotal: 11.6s\tremaining: 10.9s\n",
      "514:\tlearn: 0.0726958\ttotal: 11.6s\tremaining: 10.9s\n",
      "515:\tlearn: 0.0724276\ttotal: 11.6s\tremaining: 10.9s\n",
      "516:\tlearn: 0.0723309\ttotal: 11.6s\tremaining: 10.8s\n",
      "517:\tlearn: 0.0722776\ttotal: 11.6s\tremaining: 10.8s\n",
      "518:\tlearn: 0.0722482\ttotal: 11.6s\tremaining: 10.8s\n",
      "519:\tlearn: 0.0720791\ttotal: 11.7s\tremaining: 10.8s\n",
      "520:\tlearn: 0.0720585\ttotal: 11.7s\tremaining: 10.8s\n",
      "521:\tlearn: 0.0720483\ttotal: 11.7s\tremaining: 10.7s\n",
      "522:\tlearn: 0.0719418\ttotal: 11.7s\tremaining: 10.7s\n",
      "523:\tlearn: 0.0718112\ttotal: 11.8s\tremaining: 10.7s\n",
      "524:\tlearn: 0.0716725\ttotal: 11.8s\tremaining: 10.7s\n",
      "525:\tlearn: 0.0716602\ttotal: 11.8s\tremaining: 10.6s\n",
      "526:\tlearn: 0.0714746\ttotal: 11.8s\tremaining: 10.6s\n",
      "527:\tlearn: 0.0714646\ttotal: 11.8s\tremaining: 10.6s\n",
      "528:\tlearn: 0.0713267\ttotal: 11.9s\tremaining: 10.6s\n",
      "529:\tlearn: 0.0711679\ttotal: 11.9s\tremaining: 10.5s\n",
      "530:\tlearn: 0.0710668\ttotal: 11.9s\tremaining: 10.5s\n",
      "531:\tlearn: 0.0708725\ttotal: 11.9s\tremaining: 10.5s\n",
      "532:\tlearn: 0.0708617\ttotal: 12s\tremaining: 10.5s\n",
      "533:\tlearn: 0.0708515\ttotal: 12s\tremaining: 10.5s\n",
      "534:\tlearn: 0.0707915\ttotal: 12s\tremaining: 10.4s\n",
      "535:\tlearn: 0.0706252\ttotal: 12s\tremaining: 10.4s\n",
      "536:\tlearn: 0.0705628\ttotal: 12s\tremaining: 10.4s\n",
      "537:\tlearn: 0.0703820\ttotal: 12.1s\tremaining: 10.4s\n",
      "538:\tlearn: 0.0703728\ttotal: 12.1s\tremaining: 10.3s\n",
      "539:\tlearn: 0.0701691\ttotal: 12.1s\tremaining: 10.3s\n",
      "540:\tlearn: 0.0701592\ttotal: 12.1s\tremaining: 10.3s\n",
      "541:\tlearn: 0.0699856\ttotal: 12.2s\tremaining: 10.3s\n",
      "542:\tlearn: 0.0698324\ttotal: 12.2s\tremaining: 10.2s\n",
      "543:\tlearn: 0.0698235\ttotal: 12.2s\tremaining: 10.2s\n",
      "544:\tlearn: 0.0697181\ttotal: 12.2s\tremaining: 10.2s\n",
      "545:\tlearn: 0.0696385\ttotal: 12.2s\tremaining: 10.2s\n",
      "546:\tlearn: 0.0694485\ttotal: 12.3s\tremaining: 10.2s\n",
      "547:\tlearn: 0.0693087\ttotal: 12.3s\tremaining: 10.1s\n",
      "548:\tlearn: 0.0691941\ttotal: 12.3s\tremaining: 10.1s\n",
      "549:\tlearn: 0.0690003\ttotal: 12.3s\tremaining: 10.1s\n",
      "550:\tlearn: 0.0688327\ttotal: 12.3s\tremaining: 10.1s\n",
      "551:\tlearn: 0.0687177\ttotal: 12.4s\tremaining: 10s\n",
      "552:\tlearn: 0.0687087\ttotal: 12.4s\tremaining: 10s\n",
      "553:\tlearn: 0.0687003\ttotal: 12.4s\tremaining: 9.98s\n",
      "554:\tlearn: 0.0684675\ttotal: 12.4s\tremaining: 9.96s\n",
      "555:\tlearn: 0.0683692\ttotal: 12.4s\tremaining: 9.93s\n",
      "556:\tlearn: 0.0682497\ttotal: 12.5s\tremaining: 9.9s\n",
      "557:\tlearn: 0.0680944\ttotal: 12.5s\tremaining: 9.88s\n",
      "558:\tlearn: 0.0678951\ttotal: 12.5s\tremaining: 9.86s\n",
      "559:\tlearn: 0.0677451\ttotal: 12.5s\tremaining: 9.84s\n",
      "560:\tlearn: 0.0677076\ttotal: 12.5s\tremaining: 9.82s\n",
      "561:\tlearn: 0.0674675\ttotal: 12.6s\tremaining: 9.8s\n",
      "562:\tlearn: 0.0674585\ttotal: 12.6s\tremaining: 9.77s\n",
      "563:\tlearn: 0.0673000\ttotal: 12.6s\tremaining: 9.76s\n",
      "564:\tlearn: 0.0672912\ttotal: 12.6s\tremaining: 9.74s\n",
      "565:\tlearn: 0.0671298\ttotal: 12.7s\tremaining: 9.72s\n",
      "566:\tlearn: 0.0670239\ttotal: 12.7s\tremaining: 9.7s\n",
      "567:\tlearn: 0.0669829\ttotal: 12.7s\tremaining: 9.67s\n",
      "568:\tlearn: 0.0667632\ttotal: 12.7s\tremaining: 9.66s\n",
      "569:\tlearn: 0.0666104\ttotal: 12.8s\tremaining: 9.63s\n",
      "570:\tlearn: 0.0664445\ttotal: 12.8s\tremaining: 9.61s\n",
      "571:\tlearn: 0.0663646\ttotal: 12.8s\tremaining: 9.59s\n",
      "572:\tlearn: 0.0662694\ttotal: 12.8s\tremaining: 9.56s\n",
      "573:\tlearn: 0.0661603\ttotal: 12.8s\tremaining: 9.53s\n",
      "574:\tlearn: 0.0660140\ttotal: 12.9s\tremaining: 9.51s\n",
      "575:\tlearn: 0.0659964\ttotal: 12.9s\tremaining: 9.48s\n",
      "576:\tlearn: 0.0658902\ttotal: 12.9s\tremaining: 9.46s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "577:\tlearn: 0.0658715\ttotal: 12.9s\tremaining: 9.44s\n",
      "578:\tlearn: 0.0658002\ttotal: 12.9s\tremaining: 9.41s\n",
      "579:\tlearn: 0.0656916\ttotal: 13s\tremaining: 9.39s\n",
      "580:\tlearn: 0.0655582\ttotal: 13s\tremaining: 9.37s\n",
      "581:\tlearn: 0.0654372\ttotal: 13s\tremaining: 9.35s\n",
      "582:\tlearn: 0.0653298\ttotal: 13s\tremaining: 9.32s\n",
      "583:\tlearn: 0.0651301\ttotal: 13.1s\tremaining: 9.3s\n",
      "584:\tlearn: 0.0651215\ttotal: 13.1s\tremaining: 9.28s\n",
      "585:\tlearn: 0.0649446\ttotal: 13.1s\tremaining: 9.25s\n",
      "586:\tlearn: 0.0648803\ttotal: 13.1s\tremaining: 9.23s\n",
      "587:\tlearn: 0.0647899\ttotal: 13.1s\tremaining: 9.21s\n",
      "588:\tlearn: 0.0646712\ttotal: 13.2s\tremaining: 9.18s\n",
      "589:\tlearn: 0.0645092\ttotal: 13.2s\tremaining: 9.16s\n",
      "590:\tlearn: 0.0644371\ttotal: 13.2s\tremaining: 9.13s\n",
      "591:\tlearn: 0.0644288\ttotal: 13.2s\tremaining: 9.11s\n",
      "592:\tlearn: 0.0642962\ttotal: 13.2s\tremaining: 9.08s\n",
      "593:\tlearn: 0.0641738\ttotal: 13.3s\tremaining: 9.06s\n",
      "594:\tlearn: 0.0640710\ttotal: 13.3s\tremaining: 9.04s\n",
      "595:\tlearn: 0.0638893\ttotal: 13.3s\tremaining: 9.02s\n",
      "596:\tlearn: 0.0638233\ttotal: 13.3s\tremaining: 8.99s\n",
      "597:\tlearn: 0.0637571\ttotal: 13.3s\tremaining: 8.97s\n",
      "598:\tlearn: 0.0637433\ttotal: 13.4s\tremaining: 8.95s\n",
      "599:\tlearn: 0.0637355\ttotal: 13.4s\tremaining: 8.92s\n",
      "600:\tlearn: 0.0635896\ttotal: 13.4s\tremaining: 8.9s\n",
      "601:\tlearn: 0.0634761\ttotal: 13.4s\tremaining: 8.87s\n",
      "602:\tlearn: 0.0634265\ttotal: 13.4s\tremaining: 8.85s\n",
      "603:\tlearn: 0.0633384\ttotal: 13.5s\tremaining: 8.82s\n",
      "604:\tlearn: 0.0631963\ttotal: 13.5s\tremaining: 8.8s\n",
      "605:\tlearn: 0.0630351\ttotal: 13.5s\tremaining: 8.78s\n",
      "606:\tlearn: 0.0628713\ttotal: 13.5s\tremaining: 8.75s\n",
      "607:\tlearn: 0.0628600\ttotal: 13.5s\tremaining: 8.73s\n",
      "608:\tlearn: 0.0626966\ttotal: 13.6s\tremaining: 8.71s\n",
      "609:\tlearn: 0.0625789\ttotal: 13.6s\tremaining: 8.69s\n",
      "610:\tlearn: 0.0624737\ttotal: 13.6s\tremaining: 8.67s\n",
      "611:\tlearn: 0.0623420\ttotal: 13.6s\tremaining: 8.64s\n",
      "612:\tlearn: 0.0621767\ttotal: 13.7s\tremaining: 8.63s\n",
      "613:\tlearn: 0.0620456\ttotal: 13.7s\tremaining: 8.6s\n",
      "614:\tlearn: 0.0619502\ttotal: 13.7s\tremaining: 8.58s\n",
      "615:\tlearn: 0.0619203\ttotal: 13.7s\tremaining: 8.56s\n",
      "616:\tlearn: 0.0619127\ttotal: 13.8s\tremaining: 8.54s\n",
      "617:\tlearn: 0.0619053\ttotal: 13.8s\tremaining: 8.52s\n",
      "618:\tlearn: 0.0618907\ttotal: 13.8s\tremaining: 8.49s\n",
      "619:\tlearn: 0.0617464\ttotal: 13.8s\tremaining: 8.47s\n",
      "620:\tlearn: 0.0617265\ttotal: 13.8s\tremaining: 8.45s\n",
      "621:\tlearn: 0.0616180\ttotal: 13.9s\tremaining: 8.42s\n",
      "622:\tlearn: 0.0615011\ttotal: 13.9s\tremaining: 8.4s\n",
      "623:\tlearn: 0.0614377\ttotal: 13.9s\tremaining: 8.38s\n",
      "624:\tlearn: 0.0613183\ttotal: 13.9s\tremaining: 8.36s\n",
      "625:\tlearn: 0.0612077\ttotal: 14s\tremaining: 8.34s\n",
      "626:\tlearn: 0.0610621\ttotal: 14s\tremaining: 8.31s\n",
      "627:\tlearn: 0.0610451\ttotal: 14s\tremaining: 8.29s\n",
      "628:\tlearn: 0.0610307\ttotal: 14s\tremaining: 8.26s\n",
      "629:\tlearn: 0.0608787\ttotal: 14s\tremaining: 8.24s\n",
      "630:\tlearn: 0.0607324\ttotal: 14.1s\tremaining: 8.22s\n",
      "631:\tlearn: 0.0606865\ttotal: 14.1s\tremaining: 8.2s\n",
      "632:\tlearn: 0.0605981\ttotal: 14.1s\tremaining: 8.17s\n",
      "633:\tlearn: 0.0605583\ttotal: 14.1s\tremaining: 8.15s\n",
      "634:\tlearn: 0.0604660\ttotal: 14.1s\tremaining: 8.13s\n",
      "635:\tlearn: 0.0603753\ttotal: 14.2s\tremaining: 8.11s\n",
      "636:\tlearn: 0.0602554\ttotal: 14.2s\tremaining: 8.08s\n",
      "637:\tlearn: 0.0601590\ttotal: 14.2s\tremaining: 8.06s\n",
      "638:\tlearn: 0.0600727\ttotal: 14.2s\tremaining: 8.04s\n",
      "639:\tlearn: 0.0599685\ttotal: 14.3s\tremaining: 8.02s\n",
      "640:\tlearn: 0.0598489\ttotal: 14.3s\tremaining: 7.99s\n",
      "641:\tlearn: 0.0597427\ttotal: 14.3s\tremaining: 7.97s\n",
      "642:\tlearn: 0.0596491\ttotal: 14.3s\tremaining: 7.95s\n",
      "643:\tlearn: 0.0595011\ttotal: 14.3s\tremaining: 7.93s\n",
      "644:\tlearn: 0.0594746\ttotal: 14.4s\tremaining: 7.91s\n",
      "645:\tlearn: 0.0593614\ttotal: 14.4s\tremaining: 7.89s\n",
      "646:\tlearn: 0.0592714\ttotal: 14.4s\tremaining: 7.87s\n",
      "647:\tlearn: 0.0591681\ttotal: 14.4s\tremaining: 7.84s\n",
      "648:\tlearn: 0.0591260\ttotal: 14.5s\tremaining: 7.82s\n",
      "649:\tlearn: 0.0590282\ttotal: 14.5s\tremaining: 7.8s\n",
      "650:\tlearn: 0.0588833\ttotal: 14.5s\tremaining: 7.78s\n",
      "651:\tlearn: 0.0588112\ttotal: 14.5s\tremaining: 7.75s\n",
      "652:\tlearn: 0.0586953\ttotal: 14.6s\tremaining: 7.73s\n",
      "653:\tlearn: 0.0586012\ttotal: 14.6s\tremaining: 7.71s\n",
      "654:\tlearn: 0.0585146\ttotal: 14.6s\tremaining: 7.69s\n",
      "655:\tlearn: 0.0584995\ttotal: 14.6s\tremaining: 7.66s\n",
      "656:\tlearn: 0.0583853\ttotal: 14.6s\tremaining: 7.64s\n",
      "657:\tlearn: 0.0582737\ttotal: 14.7s\tremaining: 7.62s\n",
      "658:\tlearn: 0.0582598\ttotal: 14.7s\tremaining: 7.59s\n",
      "659:\tlearn: 0.0581435\ttotal: 14.7s\tremaining: 7.59s\n",
      "660:\tlearn: 0.0581369\ttotal: 14.8s\tremaining: 7.57s\n",
      "661:\tlearn: 0.0580505\ttotal: 14.8s\tremaining: 7.55s\n",
      "662:\tlearn: 0.0579524\ttotal: 14.8s\tremaining: 7.53s\n",
      "663:\tlearn: 0.0578923\ttotal: 14.8s\tremaining: 7.51s\n",
      "664:\tlearn: 0.0577365\ttotal: 14.8s\tremaining: 7.48s\n",
      "665:\tlearn: 0.0577301\ttotal: 14.9s\tremaining: 7.46s\n",
      "666:\tlearn: 0.0577239\ttotal: 14.9s\tremaining: 7.43s\n",
      "667:\tlearn: 0.0576218\ttotal: 14.9s\tremaining: 7.41s\n",
      "668:\tlearn: 0.0574612\ttotal: 14.9s\tremaining: 7.39s\n",
      "669:\tlearn: 0.0573682\ttotal: 14.9s\tremaining: 7.36s\n",
      "670:\tlearn: 0.0572414\ttotal: 15s\tremaining: 7.34s\n",
      "671:\tlearn: 0.0572156\ttotal: 15s\tremaining: 7.32s\n",
      "672:\tlearn: 0.0571495\ttotal: 15s\tremaining: 7.3s\n",
      "673:\tlearn: 0.0570751\ttotal: 15s\tremaining: 7.28s\n",
      "674:\tlearn: 0.0569318\ttotal: 15.1s\tremaining: 7.25s\n",
      "675:\tlearn: 0.0568538\ttotal: 15.1s\tremaining: 7.23s\n",
      "676:\tlearn: 0.0567515\ttotal: 15.1s\tremaining: 7.2s\n",
      "677:\tlearn: 0.0566799\ttotal: 15.1s\tremaining: 7.18s\n",
      "678:\tlearn: 0.0566690\ttotal: 15.1s\tremaining: 7.16s\n",
      "679:\tlearn: 0.0565734\ttotal: 15.2s\tremaining: 7.14s\n",
      "680:\tlearn: 0.0564786\ttotal: 15.2s\tremaining: 7.11s\n",
      "681:\tlearn: 0.0564154\ttotal: 15.2s\tremaining: 7.09s\n",
      "682:\tlearn: 0.0563090\ttotal: 15.2s\tremaining: 7.07s\n",
      "683:\tlearn: 0.0562444\ttotal: 15.2s\tremaining: 7.04s\n",
      "684:\tlearn: 0.0561775\ttotal: 15.3s\tremaining: 7.02s\n",
      "685:\tlearn: 0.0560780\ttotal: 15.3s\tremaining: 7s\n",
      "686:\tlearn: 0.0560580\ttotal: 15.3s\tremaining: 6.97s\n",
      "687:\tlearn: 0.0559999\ttotal: 15.3s\tremaining: 6.95s\n",
      "688:\tlearn: 0.0559270\ttotal: 15.4s\tremaining: 6.93s\n",
      "689:\tlearn: 0.0559188\ttotal: 15.4s\tremaining: 6.91s\n",
      "690:\tlearn: 0.0558154\ttotal: 15.4s\tremaining: 6.88s\n",
      "691:\tlearn: 0.0557392\ttotal: 15.4s\tremaining: 6.86s\n",
      "692:\tlearn: 0.0556499\ttotal: 15.4s\tremaining: 6.84s\n",
      "693:\tlearn: 0.0555502\ttotal: 15.5s\tremaining: 6.81s\n",
      "694:\tlearn: 0.0554400\ttotal: 15.5s\tremaining: 6.79s\n",
      "695:\tlearn: 0.0554321\ttotal: 15.5s\tremaining: 6.77s\n",
      "696:\tlearn: 0.0553921\ttotal: 15.5s\tremaining: 6.75s\n",
      "697:\tlearn: 0.0552876\ttotal: 15.5s\tremaining: 6.73s\n",
      "698:\tlearn: 0.0551960\ttotal: 15.6s\tremaining: 6.71s\n",
      "699:\tlearn: 0.0551691\ttotal: 15.6s\tremaining: 6.68s\n",
      "700:\tlearn: 0.0550445\ttotal: 15.6s\tremaining: 6.66s\n",
      "701:\tlearn: 0.0549346\ttotal: 15.6s\tremaining: 6.64s\n",
      "702:\tlearn: 0.0548132\ttotal: 15.7s\tremaining: 6.61s\n",
      "703:\tlearn: 0.0547273\ttotal: 15.7s\tremaining: 6.59s\n",
      "704:\tlearn: 0.0546179\ttotal: 15.7s\tremaining: 6.57s\n",
      "705:\tlearn: 0.0545666\ttotal: 15.7s\tremaining: 6.55s\n",
      "706:\tlearn: 0.0544480\ttotal: 15.7s\tremaining: 6.53s\n",
      "707:\tlearn: 0.0543583\ttotal: 15.8s\tremaining: 6.5s\n",
      "708:\tlearn: 0.0543510\ttotal: 15.8s\tremaining: 6.48s\n",
      "709:\tlearn: 0.0542805\ttotal: 15.8s\tremaining: 6.46s\n",
      "710:\tlearn: 0.0541968\ttotal: 15.8s\tremaining: 6.44s\n",
      "711:\tlearn: 0.0541317\ttotal: 15.9s\tremaining: 6.42s\n",
      "712:\tlearn: 0.0540569\ttotal: 15.9s\tremaining: 6.39s\n",
      "713:\tlearn: 0.0539614\ttotal: 15.9s\tremaining: 6.37s\n",
      "714:\tlearn: 0.0539338\ttotal: 15.9s\tremaining: 6.35s\n",
      "715:\tlearn: 0.0538974\ttotal: 15.9s\tremaining: 6.32s\n",
      "716:\tlearn: 0.0538448\ttotal: 16s\tremaining: 6.3s\n",
      "717:\tlearn: 0.0537341\ttotal: 16s\tremaining: 6.28s\n",
      "718:\tlearn: 0.0536306\ttotal: 16s\tremaining: 6.25s\n",
      "719:\tlearn: 0.0535936\ttotal: 16s\tremaining: 6.23s\n",
      "720:\tlearn: 0.0535358\ttotal: 16s\tremaining: 6.2s\n",
      "721:\tlearn: 0.0533894\ttotal: 16.1s\tremaining: 6.18s\n",
      "722:\tlearn: 0.0533823\ttotal: 16.1s\tremaining: 6.16s\n",
      "723:\tlearn: 0.0532780\ttotal: 16.1s\tremaining: 6.13s\n",
      "724:\tlearn: 0.0531829\ttotal: 16.1s\tremaining: 6.11s\n",
      "725:\tlearn: 0.0531147\ttotal: 16.1s\tremaining: 6.09s\n",
      "726:\tlearn: 0.0530801\ttotal: 16.1s\tremaining: 6.06s\n",
      "727:\tlearn: 0.0529816\ttotal: 16.2s\tremaining: 6.04s\n",
      "728:\tlearn: 0.0528890\ttotal: 16.2s\tremaining: 6.02s\n",
      "729:\tlearn: 0.0527773\ttotal: 16.2s\tremaining: 6s\n",
      "730:\tlearn: 0.0527145\ttotal: 16.2s\tremaining: 5.98s\n",
      "731:\tlearn: 0.0526118\ttotal: 16.3s\tremaining: 5.96s\n",
      "732:\tlearn: 0.0526059\ttotal: 16.3s\tremaining: 5.93s\n",
      "733:\tlearn: 0.0525367\ttotal: 16.3s\tremaining: 5.91s\n",
      "734:\tlearn: 0.0523989\ttotal: 16.3s\tremaining: 5.89s\n",
      "735:\tlearn: 0.0523025\ttotal: 16.4s\tremaining: 5.87s\n",
      "736:\tlearn: 0.0522338\ttotal: 16.4s\tremaining: 5.84s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "737:\tlearn: 0.0521057\ttotal: 16.4s\tremaining: 5.82s\n",
      "738:\tlearn: 0.0520122\ttotal: 16.4s\tremaining: 5.8s\n",
      "739:\tlearn: 0.0519340\ttotal: 16.4s\tremaining: 5.78s\n",
      "740:\tlearn: 0.0518286\ttotal: 16.5s\tremaining: 5.76s\n",
      "741:\tlearn: 0.0517794\ttotal: 16.5s\tremaining: 5.73s\n",
      "742:\tlearn: 0.0517488\ttotal: 16.5s\tremaining: 5.71s\n",
      "743:\tlearn: 0.0517426\ttotal: 16.5s\tremaining: 5.69s\n",
      "744:\tlearn: 0.0516006\ttotal: 16.6s\tremaining: 5.67s\n",
      "745:\tlearn: 0.0515408\ttotal: 16.6s\tremaining: 5.65s\n",
      "746:\tlearn: 0.0514474\ttotal: 16.6s\tremaining: 5.62s\n",
      "747:\tlearn: 0.0513504\ttotal: 16.6s\tremaining: 5.6s\n",
      "748:\tlearn: 0.0512696\ttotal: 16.6s\tremaining: 5.58s\n",
      "749:\tlearn: 0.0512052\ttotal: 16.7s\tremaining: 5.55s\n",
      "750:\tlearn: 0.0510935\ttotal: 16.7s\tremaining: 5.53s\n",
      "751:\tlearn: 0.0510729\ttotal: 16.7s\tremaining: 5.51s\n",
      "752:\tlearn: 0.0509569\ttotal: 16.7s\tremaining: 5.49s\n",
      "753:\tlearn: 0.0508310\ttotal: 16.7s\tremaining: 5.46s\n",
      "754:\tlearn: 0.0508250\ttotal: 16.8s\tremaining: 5.44s\n",
      "755:\tlearn: 0.0506915\ttotal: 16.8s\tremaining: 5.42s\n",
      "756:\tlearn: 0.0505778\ttotal: 16.8s\tremaining: 5.39s\n",
      "757:\tlearn: 0.0505055\ttotal: 16.8s\tremaining: 5.37s\n",
      "758:\tlearn: 0.0504386\ttotal: 16.9s\tremaining: 5.35s\n",
      "759:\tlearn: 0.0504024\ttotal: 16.9s\tremaining: 5.33s\n",
      "760:\tlearn: 0.0502547\ttotal: 16.9s\tremaining: 5.31s\n",
      "761:\tlearn: 0.0501748\ttotal: 16.9s\tremaining: 5.29s\n",
      "762:\tlearn: 0.0501346\ttotal: 17s\tremaining: 5.27s\n",
      "763:\tlearn: 0.0501288\ttotal: 17s\tremaining: 5.24s\n",
      "764:\tlearn: 0.0499475\ttotal: 17s\tremaining: 5.22s\n",
      "765:\tlearn: 0.0498180\ttotal: 17s\tremaining: 5.2s\n",
      "766:\tlearn: 0.0497885\ttotal: 17s\tremaining: 5.18s\n",
      "767:\tlearn: 0.0497298\ttotal: 17.1s\tremaining: 5.15s\n",
      "768:\tlearn: 0.0496593\ttotal: 17.1s\tremaining: 5.13s\n",
      "769:\tlearn: 0.0495947\ttotal: 17.1s\tremaining: 5.11s\n",
      "770:\tlearn: 0.0494970\ttotal: 17.1s\tremaining: 5.08s\n",
      "771:\tlearn: 0.0493782\ttotal: 17.1s\tremaining: 5.06s\n",
      "772:\tlearn: 0.0493132\ttotal: 17.1s\tremaining: 5.04s\n",
      "773:\tlearn: 0.0492145\ttotal: 17.2s\tremaining: 5.01s\n",
      "774:\tlearn: 0.0491833\ttotal: 17.2s\tremaining: 4.99s\n",
      "775:\tlearn: 0.0491652\ttotal: 17.2s\tremaining: 4.97s\n",
      "776:\tlearn: 0.0490632\ttotal: 17.2s\tremaining: 4.95s\n",
      "777:\tlearn: 0.0489581\ttotal: 17.3s\tremaining: 4.92s\n",
      "778:\tlearn: 0.0488877\ttotal: 17.3s\tremaining: 4.9s\n",
      "779:\tlearn: 0.0488568\ttotal: 17.3s\tremaining: 4.88s\n",
      "780:\tlearn: 0.0487693\ttotal: 17.3s\tremaining: 4.86s\n",
      "781:\tlearn: 0.0486634\ttotal: 17.3s\tremaining: 4.83s\n",
      "782:\tlearn: 0.0485553\ttotal: 17.4s\tremaining: 4.81s\n",
      "783:\tlearn: 0.0484852\ttotal: 17.4s\tremaining: 4.79s\n",
      "784:\tlearn: 0.0484342\ttotal: 17.4s\tremaining: 4.77s\n",
      "785:\tlearn: 0.0482684\ttotal: 17.4s\tremaining: 4.75s\n",
      "786:\tlearn: 0.0482448\ttotal: 17.5s\tremaining: 4.72s\n",
      "787:\tlearn: 0.0481478\ttotal: 17.5s\tremaining: 4.7s\n",
      "788:\tlearn: 0.0481190\ttotal: 17.5s\tremaining: 4.68s\n",
      "789:\tlearn: 0.0480165\ttotal: 17.5s\tremaining: 4.66s\n",
      "790:\tlearn: 0.0479408\ttotal: 17.6s\tremaining: 4.64s\n",
      "791:\tlearn: 0.0478346\ttotal: 17.6s\tremaining: 4.62s\n",
      "792:\tlearn: 0.0477682\ttotal: 17.6s\tremaining: 4.59s\n",
      "793:\tlearn: 0.0477332\ttotal: 17.6s\tremaining: 4.57s\n",
      "794:\tlearn: 0.0476257\ttotal: 17.6s\tremaining: 4.55s\n",
      "795:\tlearn: 0.0475385\ttotal: 17.7s\tremaining: 4.53s\n",
      "796:\tlearn: 0.0475004\ttotal: 17.7s\tremaining: 4.5s\n",
      "797:\tlearn: 0.0474231\ttotal: 17.7s\tremaining: 4.48s\n",
      "798:\tlearn: 0.0473198\ttotal: 17.7s\tremaining: 4.46s\n",
      "799:\tlearn: 0.0472583\ttotal: 17.8s\tremaining: 4.44s\n",
      "800:\tlearn: 0.0471713\ttotal: 17.8s\tremaining: 4.42s\n",
      "801:\tlearn: 0.0470718\ttotal: 17.8s\tremaining: 4.39s\n",
      "802:\tlearn: 0.0470478\ttotal: 17.8s\tremaining: 4.37s\n",
      "803:\tlearn: 0.0469913\ttotal: 17.8s\tremaining: 4.34s\n",
      "804:\tlearn: 0.0469338\ttotal: 17.9s\tremaining: 4.32s\n",
      "805:\tlearn: 0.0468697\ttotal: 17.9s\tremaining: 4.3s\n",
      "806:\tlearn: 0.0467796\ttotal: 17.9s\tremaining: 4.28s\n",
      "807:\tlearn: 0.0467061\ttotal: 17.9s\tremaining: 4.26s\n",
      "808:\tlearn: 0.0467011\ttotal: 17.9s\tremaining: 4.24s\n",
      "809:\tlearn: 0.0466503\ttotal: 18s\tremaining: 4.21s\n",
      "810:\tlearn: 0.0465780\ttotal: 18s\tremaining: 4.19s\n",
      "811:\tlearn: 0.0465129\ttotal: 18s\tremaining: 4.17s\n",
      "812:\tlearn: 0.0464582\ttotal: 18s\tremaining: 4.15s\n",
      "813:\tlearn: 0.0463187\ttotal: 18s\tremaining: 4.12s\n",
      "814:\tlearn: 0.0462407\ttotal: 18.1s\tremaining: 4.1s\n",
      "815:\tlearn: 0.0462277\ttotal: 18.1s\tremaining: 4.08s\n",
      "816:\tlearn: 0.0461543\ttotal: 18.1s\tremaining: 4.05s\n",
      "817:\tlearn: 0.0460951\ttotal: 18.1s\tremaining: 4.03s\n",
      "818:\tlearn: 0.0460219\ttotal: 18.2s\tremaining: 4.01s\n",
      "819:\tlearn: 0.0459450\ttotal: 18.2s\tremaining: 3.99s\n",
      "820:\tlearn: 0.0459128\ttotal: 18.2s\tremaining: 3.97s\n",
      "821:\tlearn: 0.0458676\ttotal: 18.2s\tremaining: 3.95s\n",
      "822:\tlearn: 0.0457874\ttotal: 18.2s\tremaining: 3.92s\n",
      "823:\tlearn: 0.0457084\ttotal: 18.3s\tremaining: 3.9s\n",
      "824:\tlearn: 0.0456500\ttotal: 18.3s\tremaining: 3.88s\n",
      "825:\tlearn: 0.0455728\ttotal: 18.3s\tremaining: 3.86s\n",
      "826:\tlearn: 0.0455222\ttotal: 18.3s\tremaining: 3.84s\n",
      "827:\tlearn: 0.0454373\ttotal: 18.4s\tremaining: 3.82s\n",
      "828:\tlearn: 0.0453714\ttotal: 18.4s\tremaining: 3.79s\n",
      "829:\tlearn: 0.0452782\ttotal: 18.4s\tremaining: 3.77s\n",
      "830:\tlearn: 0.0452307\ttotal: 18.4s\tremaining: 3.75s\n",
      "831:\tlearn: 0.0452130\ttotal: 18.5s\tremaining: 3.73s\n",
      "832:\tlearn: 0.0451824\ttotal: 18.5s\tremaining: 3.7s\n",
      "833:\tlearn: 0.0451759\ttotal: 18.5s\tremaining: 3.68s\n",
      "834:\tlearn: 0.0450889\ttotal: 18.5s\tremaining: 3.66s\n",
      "835:\tlearn: 0.0450514\ttotal: 18.5s\tremaining: 3.64s\n",
      "836:\tlearn: 0.0450000\ttotal: 18.6s\tremaining: 3.62s\n",
      "837:\tlearn: 0.0449312\ttotal: 18.6s\tremaining: 3.59s\n",
      "838:\tlearn: 0.0449229\ttotal: 18.6s\tremaining: 3.57s\n",
      "839:\tlearn: 0.0448437\ttotal: 18.6s\tremaining: 3.55s\n",
      "840:\tlearn: 0.0447697\ttotal: 18.7s\tremaining: 3.53s\n",
      "841:\tlearn: 0.0447216\ttotal: 18.7s\tremaining: 3.51s\n",
      "842:\tlearn: 0.0447063\ttotal: 18.7s\tremaining: 3.48s\n",
      "843:\tlearn: 0.0446542\ttotal: 18.7s\tremaining: 3.46s\n",
      "844:\tlearn: 0.0446037\ttotal: 18.7s\tremaining: 3.44s\n",
      "845:\tlearn: 0.0445460\ttotal: 18.8s\tremaining: 3.42s\n",
      "846:\tlearn: 0.0444701\ttotal: 18.8s\tremaining: 3.39s\n",
      "847:\tlearn: 0.0444388\ttotal: 18.8s\tremaining: 3.37s\n",
      "848:\tlearn: 0.0443702\ttotal: 18.8s\tremaining: 3.35s\n",
      "849:\tlearn: 0.0443109\ttotal: 18.8s\tremaining: 3.33s\n",
      "850:\tlearn: 0.0442813\ttotal: 18.9s\tremaining: 3.3s\n",
      "851:\tlearn: 0.0441975\ttotal: 18.9s\tremaining: 3.28s\n",
      "852:\tlearn: 0.0440929\ttotal: 18.9s\tremaining: 3.26s\n",
      "853:\tlearn: 0.0440420\ttotal: 18.9s\tremaining: 3.24s\n",
      "854:\tlearn: 0.0440252\ttotal: 19s\tremaining: 3.21s\n",
      "855:\tlearn: 0.0439498\ttotal: 19s\tremaining: 3.19s\n",
      "856:\tlearn: 0.0438676\ttotal: 19s\tremaining: 3.17s\n",
      "857:\tlearn: 0.0437779\ttotal: 19s\tremaining: 3.15s\n",
      "858:\tlearn: 0.0436622\ttotal: 19.1s\tremaining: 3.13s\n",
      "859:\tlearn: 0.0436095\ttotal: 19.1s\tremaining: 3.1s\n",
      "860:\tlearn: 0.0435308\ttotal: 19.1s\tremaining: 3.08s\n",
      "861:\tlearn: 0.0434833\ttotal: 19.1s\tremaining: 3.06s\n",
      "862:\tlearn: 0.0434141\ttotal: 19.1s\tremaining: 3.04s\n",
      "863:\tlearn: 0.0433917\ttotal: 19.2s\tremaining: 3.02s\n",
      "864:\tlearn: 0.0433088\ttotal: 19.2s\tremaining: 2.99s\n",
      "865:\tlearn: 0.0432428\ttotal: 19.2s\tremaining: 2.97s\n",
      "866:\tlearn: 0.0431873\ttotal: 19.2s\tremaining: 2.95s\n",
      "867:\tlearn: 0.0431831\ttotal: 19.3s\tremaining: 2.93s\n",
      "868:\tlearn: 0.0430885\ttotal: 19.3s\tremaining: 2.91s\n",
      "869:\tlearn: 0.0430642\ttotal: 19.3s\tremaining: 2.88s\n",
      "870:\tlearn: 0.0430593\ttotal: 19.3s\tremaining: 2.86s\n",
      "871:\tlearn: 0.0429987\ttotal: 19.3s\tremaining: 2.84s\n",
      "872:\tlearn: 0.0429312\ttotal: 19.4s\tremaining: 2.82s\n",
      "873:\tlearn: 0.0428543\ttotal: 19.4s\tremaining: 2.79s\n",
      "874:\tlearn: 0.0427621\ttotal: 19.4s\tremaining: 2.77s\n",
      "875:\tlearn: 0.0427058\ttotal: 19.4s\tremaining: 2.75s\n",
      "876:\tlearn: 0.0426043\ttotal: 19.5s\tremaining: 2.73s\n",
      "877:\tlearn: 0.0425548\ttotal: 19.5s\tremaining: 2.71s\n",
      "878:\tlearn: 0.0425108\ttotal: 19.5s\tremaining: 2.68s\n",
      "879:\tlearn: 0.0424941\ttotal: 19.5s\tremaining: 2.66s\n",
      "880:\tlearn: 0.0424359\ttotal: 19.5s\tremaining: 2.64s\n",
      "881:\tlearn: 0.0423977\ttotal: 19.6s\tremaining: 2.62s\n",
      "882:\tlearn: 0.0423570\ttotal: 19.6s\tremaining: 2.6s\n",
      "883:\tlearn: 0.0422872\ttotal: 19.6s\tremaining: 2.57s\n",
      "884:\tlearn: 0.0422827\ttotal: 19.6s\tremaining: 2.55s\n",
      "885:\tlearn: 0.0422118\ttotal: 19.7s\tremaining: 2.53s\n",
      "886:\tlearn: 0.0421510\ttotal: 19.7s\tremaining: 2.51s\n",
      "887:\tlearn: 0.0421043\ttotal: 19.7s\tremaining: 2.48s\n",
      "888:\tlearn: 0.0420225\ttotal: 19.7s\tremaining: 2.46s\n",
      "889:\tlearn: 0.0420145\ttotal: 19.7s\tremaining: 2.44s\n",
      "890:\tlearn: 0.0419529\ttotal: 19.8s\tremaining: 2.42s\n",
      "891:\tlearn: 0.0419022\ttotal: 19.8s\tremaining: 2.4s\n",
      "892:\tlearn: 0.0418741\ttotal: 19.8s\tremaining: 2.37s\n",
      "893:\tlearn: 0.0418009\ttotal: 19.8s\tremaining: 2.35s\n",
      "894:\tlearn: 0.0417663\ttotal: 19.9s\tremaining: 2.33s\n",
      "895:\tlearn: 0.0417037\ttotal: 19.9s\tremaining: 2.31s\n",
      "896:\tlearn: 0.0416836\ttotal: 19.9s\tremaining: 2.28s\n",
      "897:\tlearn: 0.0416153\ttotal: 19.9s\tremaining: 2.26s\n",
      "898:\tlearn: 0.0415421\ttotal: 19.9s\tremaining: 2.24s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "899:\tlearn: 0.0414287\ttotal: 20s\tremaining: 2.22s\n",
      "900:\tlearn: 0.0414176\ttotal: 20s\tremaining: 2.19s\n",
      "901:\tlearn: 0.0413512\ttotal: 20s\tremaining: 2.17s\n",
      "902:\tlearn: 0.0413126\ttotal: 20s\tremaining: 2.15s\n",
      "903:\tlearn: 0.0412336\ttotal: 20s\tremaining: 2.13s\n",
      "904:\tlearn: 0.0411819\ttotal: 20.1s\tremaining: 2.11s\n",
      "905:\tlearn: 0.0411728\ttotal: 20.1s\tremaining: 2.08s\n",
      "906:\tlearn: 0.0411687\ttotal: 20.1s\tremaining: 2.06s\n",
      "907:\tlearn: 0.0411428\ttotal: 20.1s\tremaining: 2.04s\n",
      "908:\tlearn: 0.0410541\ttotal: 20.2s\tremaining: 2.02s\n",
      "909:\tlearn: 0.0409988\ttotal: 20.2s\tremaining: 2s\n",
      "910:\tlearn: 0.0409576\ttotal: 20.2s\tremaining: 1.97s\n",
      "911:\tlearn: 0.0408968\ttotal: 20.2s\tremaining: 1.95s\n",
      "912:\tlearn: 0.0408297\ttotal: 20.2s\tremaining: 1.93s\n",
      "913:\tlearn: 0.0407652\ttotal: 20.3s\tremaining: 1.91s\n",
      "914:\tlearn: 0.0407183\ttotal: 20.3s\tremaining: 1.88s\n",
      "915:\tlearn: 0.0406433\ttotal: 20.3s\tremaining: 1.86s\n",
      "916:\tlearn: 0.0405527\ttotal: 20.3s\tremaining: 1.84s\n",
      "917:\tlearn: 0.0405152\ttotal: 20.3s\tremaining: 1.82s\n",
      "918:\tlearn: 0.0405112\ttotal: 20.4s\tremaining: 1.79s\n",
      "919:\tlearn: 0.0404434\ttotal: 20.4s\tremaining: 1.77s\n",
      "920:\tlearn: 0.0403711\ttotal: 20.4s\tremaining: 1.75s\n",
      "921:\tlearn: 0.0402933\ttotal: 20.4s\tremaining: 1.73s\n",
      "922:\tlearn: 0.0402223\ttotal: 20.5s\tremaining: 1.71s\n",
      "923:\tlearn: 0.0401773\ttotal: 20.5s\tremaining: 1.68s\n",
      "924:\tlearn: 0.0401550\ttotal: 20.5s\tremaining: 1.66s\n",
      "925:\tlearn: 0.0401454\ttotal: 20.5s\tremaining: 1.64s\n",
      "926:\tlearn: 0.0400672\ttotal: 20.5s\tremaining: 1.62s\n",
      "927:\tlearn: 0.0400257\ttotal: 20.6s\tremaining: 1.6s\n",
      "928:\tlearn: 0.0400172\ttotal: 20.6s\tremaining: 1.57s\n",
      "929:\tlearn: 0.0399643\ttotal: 20.6s\tremaining: 1.55s\n",
      "930:\tlearn: 0.0399442\ttotal: 20.6s\tremaining: 1.53s\n",
      "931:\tlearn: 0.0399047\ttotal: 20.7s\tremaining: 1.51s\n",
      "932:\tlearn: 0.0398249\ttotal: 20.7s\tremaining: 1.48s\n",
      "933:\tlearn: 0.0398056\ttotal: 20.7s\tremaining: 1.46s\n",
      "934:\tlearn: 0.0396756\ttotal: 20.7s\tremaining: 1.44s\n",
      "935:\tlearn: 0.0396229\ttotal: 20.7s\tremaining: 1.42s\n",
      "936:\tlearn: 0.0396158\ttotal: 20.8s\tremaining: 1.4s\n",
      "937:\tlearn: 0.0395793\ttotal: 20.8s\tremaining: 1.37s\n",
      "938:\tlearn: 0.0394980\ttotal: 20.8s\tremaining: 1.35s\n",
      "939:\tlearn: 0.0394520\ttotal: 20.8s\tremaining: 1.33s\n",
      "940:\tlearn: 0.0393798\ttotal: 20.8s\tremaining: 1.31s\n",
      "941:\tlearn: 0.0393194\ttotal: 20.9s\tremaining: 1.28s\n",
      "942:\tlearn: 0.0392802\ttotal: 20.9s\tremaining: 1.26s\n",
      "943:\tlearn: 0.0392211\ttotal: 20.9s\tremaining: 1.24s\n",
      "944:\tlearn: 0.0391948\ttotal: 21s\tremaining: 1.22s\n",
      "945:\tlearn: 0.0391091\ttotal: 21s\tremaining: 1.2s\n",
      "946:\tlearn: 0.0390262\ttotal: 21s\tremaining: 1.18s\n",
      "947:\tlearn: 0.0389747\ttotal: 21.1s\tremaining: 1.16s\n",
      "948:\tlearn: 0.0389699\ttotal: 21.1s\tremaining: 1.13s\n",
      "949:\tlearn: 0.0389209\ttotal: 21.1s\tremaining: 1.11s\n",
      "950:\tlearn: 0.0388364\ttotal: 21.1s\tremaining: 1.09s\n",
      "951:\tlearn: 0.0387889\ttotal: 21.2s\tremaining: 1.07s\n",
      "952:\tlearn: 0.0387385\ttotal: 21.2s\tremaining: 1.04s\n",
      "953:\tlearn: 0.0386755\ttotal: 21.2s\tremaining: 1.02s\n",
      "954:\tlearn: 0.0386012\ttotal: 21.3s\tremaining: 1s\n",
      "955:\tlearn: 0.0385776\ttotal: 21.3s\tremaining: 981ms\n",
      "956:\tlearn: 0.0384954\ttotal: 21.3s\tremaining: 959ms\n",
      "957:\tlearn: 0.0384302\ttotal: 21.4s\tremaining: 937ms\n",
      "958:\tlearn: 0.0384172\ttotal: 21.4s\tremaining: 915ms\n",
      "959:\tlearn: 0.0383937\ttotal: 21.4s\tremaining: 892ms\n",
      "960:\tlearn: 0.0383481\ttotal: 21.4s\tremaining: 870ms\n",
      "961:\tlearn: 0.0382866\ttotal: 21.5s\tremaining: 848ms\n",
      "962:\tlearn: 0.0382365\ttotal: 21.5s\tremaining: 826ms\n",
      "963:\tlearn: 0.0381756\ttotal: 21.5s\tremaining: 804ms\n",
      "964:\tlearn: 0.0381202\ttotal: 21.6s\tremaining: 782ms\n",
      "965:\tlearn: 0.0380715\ttotal: 21.6s\tremaining: 760ms\n",
      "966:\tlearn: 0.0380168\ttotal: 21.6s\tremaining: 738ms\n",
      "967:\tlearn: 0.0378476\ttotal: 21.7s\tremaining: 716ms\n",
      "968:\tlearn: 0.0377910\ttotal: 21.7s\tremaining: 694ms\n",
      "969:\tlearn: 0.0377706\ttotal: 21.7s\tremaining: 672ms\n",
      "970:\tlearn: 0.0377020\ttotal: 21.8s\tremaining: 650ms\n",
      "971:\tlearn: 0.0376387\ttotal: 21.8s\tremaining: 627ms\n",
      "972:\tlearn: 0.0376180\ttotal: 21.8s\tremaining: 605ms\n",
      "973:\tlearn: 0.0375446\ttotal: 21.8s\tremaining: 583ms\n",
      "974:\tlearn: 0.0375327\ttotal: 21.9s\tremaining: 561ms\n",
      "975:\tlearn: 0.0375142\ttotal: 21.9s\tremaining: 538ms\n",
      "976:\tlearn: 0.0374611\ttotal: 21.9s\tremaining: 516ms\n",
      "977:\tlearn: 0.0373959\ttotal: 22s\tremaining: 494ms\n",
      "978:\tlearn: 0.0373796\ttotal: 22s\tremaining: 472ms\n",
      "979:\tlearn: 0.0372907\ttotal: 22s\tremaining: 449ms\n",
      "980:\tlearn: 0.0372874\ttotal: 22s\tremaining: 427ms\n",
      "981:\tlearn: 0.0372450\ttotal: 22.1s\tremaining: 404ms\n",
      "982:\tlearn: 0.0372160\ttotal: 22.1s\tremaining: 382ms\n",
      "983:\tlearn: 0.0371636\ttotal: 22.1s\tremaining: 360ms\n",
      "984:\tlearn: 0.0371231\ttotal: 22.2s\tremaining: 338ms\n",
      "985:\tlearn: 0.0370572\ttotal: 22.2s\tremaining: 315ms\n",
      "986:\tlearn: 0.0370343\ttotal: 22.2s\tremaining: 293ms\n",
      "987:\tlearn: 0.0369766\ttotal: 22.3s\tremaining: 270ms\n",
      "988:\tlearn: 0.0369283\ttotal: 22.3s\tremaining: 248ms\n",
      "989:\tlearn: 0.0369242\ttotal: 22.3s\tremaining: 225ms\n",
      "990:\tlearn: 0.0368752\ttotal: 22.3s\tremaining: 203ms\n",
      "991:\tlearn: 0.0368027\ttotal: 22.4s\tremaining: 180ms\n",
      "992:\tlearn: 0.0367822\ttotal: 22.4s\tremaining: 158ms\n",
      "993:\tlearn: 0.0367248\ttotal: 22.4s\tremaining: 135ms\n",
      "994:\tlearn: 0.0366567\ttotal: 22.5s\tremaining: 113ms\n",
      "995:\tlearn: 0.0366037\ttotal: 22.5s\tremaining: 90.3ms\n",
      "996:\tlearn: 0.0366005\ttotal: 22.5s\tremaining: 67.8ms\n",
      "997:\tlearn: 0.0365294\ttotal: 22.6s\tremaining: 45.2ms\n",
      "998:\tlearn: 0.0364805\ttotal: 22.6s\tremaining: 22.6ms\n",
      "999:\tlearn: 0.0364139\ttotal: 22.6s\tremaining: 0us\n",
      "Learning rate set to 0.018891\n",
      "0:\tlearn: 0.6681439\ttotal: 26ms\tremaining: 26s\n",
      "1:\tlearn: 0.6461748\ttotal: 46.9ms\tremaining: 23.4s\n",
      "2:\tlearn: 0.6238874\ttotal: 67.9ms\tremaining: 22.6s\n",
      "3:\tlearn: 0.6033953\ttotal: 89.1ms\tremaining: 22.2s\n",
      "4:\tlearn: 0.5841681\ttotal: 110ms\tremaining: 21.9s\n",
      "5:\tlearn: 0.5640228\ttotal: 130ms\tremaining: 21.6s\n",
      "6:\tlearn: 0.5469258\ttotal: 151ms\tremaining: 21.4s\n",
      "7:\tlearn: 0.5297632\ttotal: 167ms\tremaining: 20.7s\n",
      "8:\tlearn: 0.5147994\ttotal: 185ms\tremaining: 20.4s\n",
      "9:\tlearn: 0.5096489\ttotal: 204ms\tremaining: 20.2s\n",
      "10:\tlearn: 0.4950606\ttotal: 225ms\tremaining: 20.3s\n",
      "11:\tlearn: 0.4811226\ttotal: 246ms\tremaining: 20.2s\n",
      "12:\tlearn: 0.4686314\ttotal: 263ms\tremaining: 20s\n",
      "13:\tlearn: 0.4581063\ttotal: 280ms\tremaining: 19.7s\n",
      "14:\tlearn: 0.4485066\ttotal: 299ms\tremaining: 19.6s\n",
      "15:\tlearn: 0.4386207\ttotal: 317ms\tremaining: 19.5s\n",
      "16:\tlearn: 0.4316234\ttotal: 338ms\tremaining: 19.6s\n",
      "17:\tlearn: 0.4216568\ttotal: 359ms\tremaining: 19.6s\n",
      "18:\tlearn: 0.4140483\ttotal: 387ms\tremaining: 20s\n",
      "19:\tlearn: 0.4096710\ttotal: 407ms\tremaining: 20s\n",
      "20:\tlearn: 0.4032663\ttotal: 424ms\tremaining: 19.8s\n",
      "21:\tlearn: 0.3943720\ttotal: 441ms\tremaining: 19.6s\n",
      "22:\tlearn: 0.3884446\ttotal: 458ms\tremaining: 19.4s\n",
      "23:\tlearn: 0.3842495\ttotal: 474ms\tremaining: 19.3s\n",
      "24:\tlearn: 0.3779136\ttotal: 490ms\tremaining: 19.1s\n",
      "25:\tlearn: 0.3753541\ttotal: 508ms\tremaining: 19s\n",
      "26:\tlearn: 0.3682865\ttotal: 528ms\tremaining: 19s\n",
      "27:\tlearn: 0.3642515\ttotal: 549ms\tremaining: 19.1s\n",
      "28:\tlearn: 0.3588011\ttotal: 570ms\tremaining: 19.1s\n",
      "29:\tlearn: 0.3537777\ttotal: 592ms\tremaining: 19.1s\n",
      "30:\tlearn: 0.3487666\ttotal: 615ms\tremaining: 19.2s\n",
      "31:\tlearn: 0.3432139\ttotal: 637ms\tremaining: 19.3s\n",
      "32:\tlearn: 0.3386846\ttotal: 657ms\tremaining: 19.3s\n",
      "33:\tlearn: 0.3361314\ttotal: 678ms\tremaining: 19.3s\n",
      "34:\tlearn: 0.3336702\ttotal: 697ms\tremaining: 19.2s\n",
      "35:\tlearn: 0.3311908\ttotal: 716ms\tremaining: 19.2s\n",
      "36:\tlearn: 0.3263064\ttotal: 734ms\tremaining: 19.1s\n",
      "37:\tlearn: 0.3228299\ttotal: 755ms\tremaining: 19.1s\n",
      "38:\tlearn: 0.3198409\ttotal: 776ms\tremaining: 19.1s\n",
      "39:\tlearn: 0.3169026\ttotal: 797ms\tremaining: 19.1s\n",
      "40:\tlearn: 0.3126075\ttotal: 833ms\tremaining: 19.5s\n",
      "41:\tlearn: 0.3089347\ttotal: 853ms\tremaining: 19.5s\n",
      "42:\tlearn: 0.3063923\ttotal: 875ms\tremaining: 19.5s\n",
      "43:\tlearn: 0.3025664\ttotal: 895ms\tremaining: 19.5s\n",
      "44:\tlearn: 0.2991137\ttotal: 914ms\tremaining: 19.4s\n",
      "45:\tlearn: 0.2956983\ttotal: 931ms\tremaining: 19.3s\n",
      "46:\tlearn: 0.2910637\ttotal: 949ms\tremaining: 19.2s\n",
      "47:\tlearn: 0.2890708\ttotal: 967ms\tremaining: 19.2s\n",
      "48:\tlearn: 0.2857813\ttotal: 987ms\tremaining: 19.2s\n",
      "49:\tlearn: 0.2837762\ttotal: 1s\tremaining: 19.1s\n",
      "50:\tlearn: 0.2811453\ttotal: 1.03s\tremaining: 19.1s\n",
      "51:\tlearn: 0.2790087\ttotal: 1.05s\tremaining: 19.2s\n",
      "52:\tlearn: 0.2773931\ttotal: 1.07s\tremaining: 19.2s\n",
      "53:\tlearn: 0.2746970\ttotal: 1.1s\tremaining: 19.2s\n",
      "54:\tlearn: 0.2728736\ttotal: 1.12s\tremaining: 19.2s\n",
      "55:\tlearn: 0.2711010\ttotal: 1.14s\tremaining: 19.2s\n",
      "56:\tlearn: 0.2692992\ttotal: 1.16s\tremaining: 19.3s\n",
      "57:\tlearn: 0.2665114\ttotal: 1.19s\tremaining: 19.3s\n",
      "58:\tlearn: 0.2634683\ttotal: 1.21s\tremaining: 19.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59:\tlearn: 0.2605295\ttotal: 1.24s\tremaining: 19.3s\n",
      "60:\tlearn: 0.2588443\ttotal: 1.26s\tremaining: 19.4s\n",
      "61:\tlearn: 0.2573441\ttotal: 1.28s\tremaining: 19.4s\n",
      "62:\tlearn: 0.2561580\ttotal: 1.3s\tremaining: 19.4s\n",
      "63:\tlearn: 0.2546168\ttotal: 1.33s\tremaining: 19.4s\n",
      "64:\tlearn: 0.2528659\ttotal: 1.35s\tremaining: 19.4s\n",
      "65:\tlearn: 0.2510845\ttotal: 1.37s\tremaining: 19.4s\n",
      "66:\tlearn: 0.2498444\ttotal: 1.39s\tremaining: 19.4s\n",
      "67:\tlearn: 0.2475093\ttotal: 1.42s\tremaining: 19.4s\n",
      "68:\tlearn: 0.2447730\ttotal: 1.46s\tremaining: 19.7s\n",
      "69:\tlearn: 0.2432478\ttotal: 1.48s\tremaining: 19.6s\n",
      "70:\tlearn: 0.2419763\ttotal: 1.5s\tremaining: 19.6s\n",
      "71:\tlearn: 0.2403220\ttotal: 1.52s\tremaining: 19.6s\n",
      "72:\tlearn: 0.2389013\ttotal: 1.54s\tremaining: 19.6s\n",
      "73:\tlearn: 0.2377620\ttotal: 1.56s\tremaining: 19.6s\n",
      "74:\tlearn: 0.2358445\ttotal: 1.58s\tremaining: 19.6s\n",
      "75:\tlearn: 0.2349577\ttotal: 1.6s\tremaining: 19.5s\n",
      "76:\tlearn: 0.2336385\ttotal: 1.63s\tremaining: 19.5s\n",
      "77:\tlearn: 0.2324597\ttotal: 1.65s\tremaining: 19.4s\n",
      "78:\tlearn: 0.2308080\ttotal: 1.67s\tremaining: 19.5s\n",
      "79:\tlearn: 0.2298321\ttotal: 1.69s\tremaining: 19.5s\n",
      "80:\tlearn: 0.2289291\ttotal: 1.71s\tremaining: 19.5s\n",
      "81:\tlearn: 0.2275312\ttotal: 1.73s\tremaining: 19.4s\n",
      "82:\tlearn: 0.2260562\ttotal: 1.75s\tremaining: 19.4s\n",
      "83:\tlearn: 0.2251278\ttotal: 1.77s\tremaining: 19.4s\n",
      "84:\tlearn: 0.2235371\ttotal: 1.79s\tremaining: 19.3s\n",
      "85:\tlearn: 0.2224943\ttotal: 1.82s\tremaining: 19.3s\n",
      "86:\tlearn: 0.2209768\ttotal: 1.84s\tremaining: 19.4s\n",
      "87:\tlearn: 0.2198947\ttotal: 1.87s\tremaining: 19.4s\n",
      "88:\tlearn: 0.2180929\ttotal: 1.89s\tremaining: 19.4s\n",
      "89:\tlearn: 0.2172916\ttotal: 1.91s\tremaining: 19.3s\n",
      "90:\tlearn: 0.2161540\ttotal: 1.94s\tremaining: 19.3s\n",
      "91:\tlearn: 0.2149261\ttotal: 1.96s\tremaining: 19.3s\n",
      "92:\tlearn: 0.2139299\ttotal: 1.98s\tremaining: 19.3s\n",
      "93:\tlearn: 0.2132066\ttotal: 2.01s\tremaining: 19.3s\n",
      "94:\tlearn: 0.2113835\ttotal: 2.03s\tremaining: 19.3s\n",
      "95:\tlearn: 0.2094823\ttotal: 2.05s\tremaining: 19.3s\n",
      "96:\tlearn: 0.2085537\ttotal: 2.07s\tremaining: 19.3s\n",
      "97:\tlearn: 0.2075749\ttotal: 2.09s\tremaining: 19.2s\n",
      "98:\tlearn: 0.2064943\ttotal: 2.11s\tremaining: 19.2s\n",
      "99:\tlearn: 0.2050813\ttotal: 2.13s\tremaining: 19.2s\n",
      "100:\tlearn: 0.2041914\ttotal: 2.16s\tremaining: 19.2s\n",
      "101:\tlearn: 0.2027286\ttotal: 2.18s\tremaining: 19.2s\n",
      "102:\tlearn: 0.2018776\ttotal: 2.21s\tremaining: 19.2s\n",
      "103:\tlearn: 0.2011117\ttotal: 2.23s\tremaining: 19.2s\n",
      "104:\tlearn: 0.2000259\ttotal: 2.26s\tremaining: 19.2s\n",
      "105:\tlearn: 0.1987728\ttotal: 2.29s\tremaining: 19.3s\n",
      "106:\tlearn: 0.1975260\ttotal: 2.31s\tremaining: 19.3s\n",
      "107:\tlearn: 0.1966483\ttotal: 2.34s\tremaining: 19.3s\n",
      "108:\tlearn: 0.1958083\ttotal: 2.36s\tremaining: 19.3s\n",
      "109:\tlearn: 0.1946165\ttotal: 2.38s\tremaining: 19.2s\n",
      "110:\tlearn: 0.1935834\ttotal: 2.4s\tremaining: 19.2s\n",
      "111:\tlearn: 0.1927435\ttotal: 2.42s\tremaining: 19.2s\n",
      "112:\tlearn: 0.1918948\ttotal: 2.44s\tremaining: 19.1s\n",
      "113:\tlearn: 0.1911779\ttotal: 2.46s\tremaining: 19.1s\n",
      "114:\tlearn: 0.1906800\ttotal: 2.49s\tremaining: 19.2s\n",
      "115:\tlearn: 0.1899747\ttotal: 2.52s\tremaining: 19.2s\n",
      "116:\tlearn: 0.1889044\ttotal: 2.54s\tremaining: 19.2s\n",
      "117:\tlearn: 0.1875421\ttotal: 2.57s\tremaining: 19.2s\n",
      "118:\tlearn: 0.1864495\ttotal: 2.59s\tremaining: 19.2s\n",
      "119:\tlearn: 0.1857880\ttotal: 2.61s\tremaining: 19.1s\n",
      "120:\tlearn: 0.1849473\ttotal: 2.63s\tremaining: 19.1s\n",
      "121:\tlearn: 0.1839368\ttotal: 2.65s\tremaining: 19.1s\n",
      "122:\tlearn: 0.1831855\ttotal: 2.67s\tremaining: 19s\n",
      "123:\tlearn: 0.1822958\ttotal: 2.69s\tremaining: 19s\n",
      "124:\tlearn: 0.1817974\ttotal: 2.7s\tremaining: 18.9s\n",
      "125:\tlearn: 0.1810043\ttotal: 2.72s\tremaining: 18.9s\n",
      "126:\tlearn: 0.1802968\ttotal: 2.74s\tremaining: 18.9s\n",
      "127:\tlearn: 0.1798239\ttotal: 2.76s\tremaining: 18.8s\n",
      "128:\tlearn: 0.1791141\ttotal: 2.78s\tremaining: 18.8s\n",
      "129:\tlearn: 0.1781145\ttotal: 2.8s\tremaining: 18.7s\n",
      "130:\tlearn: 0.1773516\ttotal: 2.82s\tremaining: 18.7s\n",
      "131:\tlearn: 0.1768512\ttotal: 2.84s\tremaining: 18.7s\n",
      "132:\tlearn: 0.1760643\ttotal: 2.86s\tremaining: 18.7s\n",
      "133:\tlearn: 0.1757198\ttotal: 2.89s\tremaining: 18.7s\n",
      "134:\tlearn: 0.1748846\ttotal: 2.91s\tremaining: 18.6s\n",
      "135:\tlearn: 0.1743383\ttotal: 2.93s\tremaining: 18.6s\n",
      "136:\tlearn: 0.1738075\ttotal: 2.95s\tremaining: 18.6s\n",
      "137:\tlearn: 0.1734024\ttotal: 2.98s\tremaining: 18.6s\n",
      "138:\tlearn: 0.1726237\ttotal: 3s\tremaining: 18.6s\n",
      "139:\tlearn: 0.1720563\ttotal: 3.03s\tremaining: 18.6s\n",
      "140:\tlearn: 0.1715292\ttotal: 3.05s\tremaining: 18.6s\n",
      "141:\tlearn: 0.1707801\ttotal: 3.08s\tremaining: 18.6s\n",
      "142:\tlearn: 0.1698639\ttotal: 3.1s\tremaining: 18.6s\n",
      "143:\tlearn: 0.1692931\ttotal: 3.12s\tremaining: 18.6s\n",
      "144:\tlearn: 0.1684411\ttotal: 3.16s\tremaining: 18.6s\n",
      "145:\tlearn: 0.1677698\ttotal: 3.18s\tremaining: 18.6s\n",
      "146:\tlearn: 0.1669906\ttotal: 3.2s\tremaining: 18.6s\n",
      "147:\tlearn: 0.1665253\ttotal: 3.22s\tremaining: 18.6s\n",
      "148:\tlearn: 0.1660796\ttotal: 3.25s\tremaining: 18.5s\n",
      "149:\tlearn: 0.1654150\ttotal: 3.27s\tremaining: 18.5s\n",
      "150:\tlearn: 0.1649072\ttotal: 3.29s\tremaining: 18.5s\n",
      "151:\tlearn: 0.1645038\ttotal: 3.31s\tremaining: 18.5s\n",
      "152:\tlearn: 0.1636525\ttotal: 3.34s\tremaining: 18.5s\n",
      "153:\tlearn: 0.1629076\ttotal: 3.36s\tremaining: 18.5s\n",
      "154:\tlearn: 0.1620450\ttotal: 3.38s\tremaining: 18.5s\n",
      "155:\tlearn: 0.1613772\ttotal: 3.41s\tremaining: 18.4s\n",
      "156:\tlearn: 0.1608984\ttotal: 3.43s\tremaining: 18.4s\n",
      "157:\tlearn: 0.1602161\ttotal: 3.46s\tremaining: 18.4s\n",
      "158:\tlearn: 0.1593561\ttotal: 3.47s\tremaining: 18.4s\n",
      "159:\tlearn: 0.1587949\ttotal: 3.49s\tremaining: 18.3s\n",
      "160:\tlearn: 0.1583393\ttotal: 3.51s\tremaining: 18.3s\n",
      "161:\tlearn: 0.1576487\ttotal: 3.53s\tremaining: 18.3s\n",
      "162:\tlearn: 0.1571209\ttotal: 3.55s\tremaining: 18.2s\n",
      "163:\tlearn: 0.1566335\ttotal: 3.57s\tremaining: 18.2s\n",
      "164:\tlearn: 0.1560852\ttotal: 3.59s\tremaining: 18.2s\n",
      "165:\tlearn: 0.1557095\ttotal: 3.61s\tremaining: 18.1s\n",
      "166:\tlearn: 0.1550493\ttotal: 3.63s\tremaining: 18.1s\n",
      "167:\tlearn: 0.1546046\ttotal: 3.65s\tremaining: 18.1s\n",
      "168:\tlearn: 0.1541857\ttotal: 3.67s\tremaining: 18.1s\n",
      "169:\tlearn: 0.1539360\ttotal: 3.69s\tremaining: 18s\n",
      "170:\tlearn: 0.1535027\ttotal: 3.71s\tremaining: 18s\n",
      "171:\tlearn: 0.1529073\ttotal: 3.74s\tremaining: 18s\n",
      "172:\tlearn: 0.1523771\ttotal: 3.75s\tremaining: 18s\n",
      "173:\tlearn: 0.1519130\ttotal: 3.77s\tremaining: 17.9s\n",
      "174:\tlearn: 0.1513949\ttotal: 3.79s\tremaining: 17.9s\n",
      "175:\tlearn: 0.1511429\ttotal: 3.81s\tremaining: 17.9s\n",
      "176:\tlearn: 0.1507131\ttotal: 3.84s\tremaining: 17.9s\n",
      "177:\tlearn: 0.1504351\ttotal: 3.86s\tremaining: 17.8s\n",
      "178:\tlearn: 0.1501274\ttotal: 3.88s\tremaining: 17.8s\n",
      "179:\tlearn: 0.1495563\ttotal: 3.91s\tremaining: 17.8s\n",
      "180:\tlearn: 0.1489555\ttotal: 3.93s\tremaining: 17.8s\n",
      "181:\tlearn: 0.1485510\ttotal: 3.95s\tremaining: 17.8s\n",
      "182:\tlearn: 0.1482320\ttotal: 3.98s\tremaining: 17.8s\n",
      "183:\tlearn: 0.1479297\ttotal: 4s\tremaining: 17.7s\n",
      "184:\tlearn: 0.1472747\ttotal: 4.02s\tremaining: 17.7s\n",
      "185:\tlearn: 0.1469389\ttotal: 4.05s\tremaining: 17.7s\n",
      "186:\tlearn: 0.1466877\ttotal: 4.07s\tremaining: 17.7s\n",
      "187:\tlearn: 0.1463507\ttotal: 4.09s\tremaining: 17.7s\n",
      "188:\tlearn: 0.1460992\ttotal: 4.12s\tremaining: 17.7s\n",
      "189:\tlearn: 0.1458741\ttotal: 4.14s\tremaining: 17.7s\n",
      "190:\tlearn: 0.1454504\ttotal: 4.17s\tremaining: 17.6s\n",
      "191:\tlearn: 0.1447931\ttotal: 4.19s\tremaining: 17.6s\n",
      "192:\tlearn: 0.1443616\ttotal: 4.21s\tremaining: 17.6s\n",
      "193:\tlearn: 0.1439308\ttotal: 4.23s\tremaining: 17.6s\n",
      "194:\tlearn: 0.1436315\ttotal: 4.25s\tremaining: 17.6s\n",
      "195:\tlearn: 0.1429029\ttotal: 4.28s\tremaining: 17.6s\n",
      "196:\tlearn: 0.1423645\ttotal: 4.3s\tremaining: 17.5s\n",
      "197:\tlearn: 0.1420276\ttotal: 4.32s\tremaining: 17.5s\n",
      "198:\tlearn: 0.1415333\ttotal: 4.34s\tremaining: 17.5s\n",
      "199:\tlearn: 0.1410650\ttotal: 4.37s\tremaining: 17.5s\n",
      "200:\tlearn: 0.1407712\ttotal: 4.39s\tremaining: 17.4s\n",
      "201:\tlearn: 0.1402397\ttotal: 4.41s\tremaining: 17.4s\n",
      "202:\tlearn: 0.1397292\ttotal: 4.43s\tremaining: 17.4s\n",
      "203:\tlearn: 0.1392334\ttotal: 4.46s\tremaining: 17.4s\n",
      "204:\tlearn: 0.1388392\ttotal: 4.47s\tremaining: 17.4s\n",
      "205:\tlearn: 0.1384475\ttotal: 4.49s\tremaining: 17.3s\n",
      "206:\tlearn: 0.1381349\ttotal: 4.52s\tremaining: 17.3s\n",
      "207:\tlearn: 0.1377807\ttotal: 4.54s\tremaining: 17.3s\n",
      "208:\tlearn: 0.1372365\ttotal: 4.57s\tremaining: 17.3s\n",
      "209:\tlearn: 0.1367757\ttotal: 4.59s\tremaining: 17.3s\n",
      "210:\tlearn: 0.1364171\ttotal: 4.63s\tremaining: 17.3s\n",
      "211:\tlearn: 0.1359191\ttotal: 4.66s\tremaining: 17.3s\n",
      "212:\tlearn: 0.1353717\ttotal: 4.68s\tremaining: 17.3s\n",
      "213:\tlearn: 0.1350974\ttotal: 4.71s\tremaining: 17.3s\n",
      "214:\tlearn: 0.1348960\ttotal: 4.73s\tremaining: 17.3s\n",
      "215:\tlearn: 0.1344837\ttotal: 4.76s\tremaining: 17.3s\n",
      "216:\tlearn: 0.1341420\ttotal: 4.78s\tremaining: 17.3s\n",
      "217:\tlearn: 0.1335818\ttotal: 4.8s\tremaining: 17.2s\n",
      "218:\tlearn: 0.1331594\ttotal: 4.82s\tremaining: 17.2s\n",
      "219:\tlearn: 0.1328424\ttotal: 4.84s\tremaining: 17.2s\n",
      "220:\tlearn: 0.1326259\ttotal: 4.86s\tremaining: 17.1s\n",
      "221:\tlearn: 0.1323234\ttotal: 4.89s\tremaining: 17.1s\n",
      "222:\tlearn: 0.1318664\ttotal: 4.91s\tremaining: 17.1s\n",
      "223:\tlearn: 0.1314900\ttotal: 4.93s\tremaining: 17.1s\n",
      "224:\tlearn: 0.1311187\ttotal: 4.95s\tremaining: 17.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225:\tlearn: 0.1308582\ttotal: 4.97s\tremaining: 17s\n",
      "226:\tlearn: 0.1305542\ttotal: 4.99s\tremaining: 17s\n",
      "227:\tlearn: 0.1300047\ttotal: 5.02s\tremaining: 17s\n",
      "228:\tlearn: 0.1296433\ttotal: 5.04s\tremaining: 17s\n",
      "229:\tlearn: 0.1294340\ttotal: 5.06s\tremaining: 16.9s\n",
      "230:\tlearn: 0.1290971\ttotal: 5.08s\tremaining: 16.9s\n",
      "231:\tlearn: 0.1287616\ttotal: 5.1s\tremaining: 16.9s\n",
      "232:\tlearn: 0.1283170\ttotal: 5.12s\tremaining: 16.9s\n",
      "233:\tlearn: 0.1278785\ttotal: 5.14s\tremaining: 16.8s\n",
      "234:\tlearn: 0.1276181\ttotal: 5.17s\tremaining: 16.8s\n",
      "235:\tlearn: 0.1271686\ttotal: 5.2s\tremaining: 16.8s\n",
      "236:\tlearn: 0.1267459\ttotal: 5.22s\tremaining: 16.8s\n",
      "237:\tlearn: 0.1264633\ttotal: 5.24s\tremaining: 16.8s\n",
      "238:\tlearn: 0.1261555\ttotal: 5.26s\tremaining: 16.8s\n",
      "239:\tlearn: 0.1258731\ttotal: 5.28s\tremaining: 16.7s\n",
      "240:\tlearn: 0.1255517\ttotal: 5.3s\tremaining: 16.7s\n",
      "241:\tlearn: 0.1251707\ttotal: 5.32s\tremaining: 16.7s\n",
      "242:\tlearn: 0.1246942\ttotal: 5.35s\tremaining: 16.7s\n",
      "243:\tlearn: 0.1243642\ttotal: 5.37s\tremaining: 16.6s\n",
      "244:\tlearn: 0.1241139\ttotal: 5.39s\tremaining: 16.6s\n",
      "245:\tlearn: 0.1238028\ttotal: 5.42s\tremaining: 16.6s\n",
      "246:\tlearn: 0.1234849\ttotal: 5.44s\tremaining: 16.6s\n",
      "247:\tlearn: 0.1230728\ttotal: 5.46s\tremaining: 16.6s\n",
      "248:\tlearn: 0.1224707\ttotal: 5.48s\tremaining: 16.5s\n",
      "249:\tlearn: 0.1221409\ttotal: 5.5s\tremaining: 16.5s\n",
      "250:\tlearn: 0.1218613\ttotal: 5.53s\tremaining: 16.5s\n",
      "251:\tlearn: 0.1216654\ttotal: 5.55s\tremaining: 16.5s\n",
      "252:\tlearn: 0.1214198\ttotal: 5.57s\tremaining: 16.5s\n",
      "253:\tlearn: 0.1211699\ttotal: 5.6s\tremaining: 16.4s\n",
      "254:\tlearn: 0.1207715\ttotal: 5.62s\tremaining: 16.4s\n",
      "255:\tlearn: 0.1205547\ttotal: 5.64s\tremaining: 16.4s\n",
      "256:\tlearn: 0.1203899\ttotal: 5.67s\tremaining: 16.4s\n",
      "257:\tlearn: 0.1201484\ttotal: 5.69s\tremaining: 16.4s\n",
      "258:\tlearn: 0.1199786\ttotal: 5.71s\tremaining: 16.3s\n",
      "259:\tlearn: 0.1196666\ttotal: 5.73s\tremaining: 16.3s\n",
      "260:\tlearn: 0.1193370\ttotal: 5.76s\tremaining: 16.3s\n",
      "261:\tlearn: 0.1190373\ttotal: 5.78s\tremaining: 16.3s\n",
      "262:\tlearn: 0.1188392\ttotal: 5.8s\tremaining: 16.3s\n",
      "263:\tlearn: 0.1186296\ttotal: 5.82s\tremaining: 16.2s\n",
      "264:\tlearn: 0.1184034\ttotal: 5.84s\tremaining: 16.2s\n",
      "265:\tlearn: 0.1182065\ttotal: 5.86s\tremaining: 16.2s\n",
      "266:\tlearn: 0.1178639\ttotal: 5.88s\tremaining: 16.1s\n",
      "267:\tlearn: 0.1175677\ttotal: 5.9s\tremaining: 16.1s\n",
      "268:\tlearn: 0.1173010\ttotal: 5.93s\tremaining: 16.1s\n",
      "269:\tlearn: 0.1168190\ttotal: 5.95s\tremaining: 16.1s\n",
      "270:\tlearn: 0.1165461\ttotal: 5.97s\tremaining: 16.1s\n",
      "271:\tlearn: 0.1162121\ttotal: 6s\tremaining: 16.1s\n",
      "272:\tlearn: 0.1158209\ttotal: 6.02s\tremaining: 16s\n",
      "273:\tlearn: 0.1155125\ttotal: 6.04s\tremaining: 16s\n",
      "274:\tlearn: 0.1153243\ttotal: 6.06s\tremaining: 16s\n",
      "275:\tlearn: 0.1150139\ttotal: 6.09s\tremaining: 16s\n",
      "276:\tlearn: 0.1147180\ttotal: 6.11s\tremaining: 16s\n",
      "277:\tlearn: 0.1144997\ttotal: 6.14s\tremaining: 15.9s\n",
      "278:\tlearn: 0.1142992\ttotal: 6.16s\tremaining: 15.9s\n",
      "279:\tlearn: 0.1139347\ttotal: 6.18s\tremaining: 15.9s\n",
      "280:\tlearn: 0.1137008\ttotal: 6.21s\tremaining: 15.9s\n",
      "281:\tlearn: 0.1134676\ttotal: 6.23s\tremaining: 15.9s\n",
      "282:\tlearn: 0.1132952\ttotal: 6.26s\tremaining: 15.9s\n",
      "283:\tlearn: 0.1131044\ttotal: 6.28s\tremaining: 15.8s\n",
      "284:\tlearn: 0.1126446\ttotal: 6.3s\tremaining: 15.8s\n",
      "285:\tlearn: 0.1124137\ttotal: 6.33s\tremaining: 15.8s\n",
      "286:\tlearn: 0.1122081\ttotal: 6.35s\tremaining: 15.8s\n",
      "287:\tlearn: 0.1120500\ttotal: 6.37s\tremaining: 15.7s\n",
      "288:\tlearn: 0.1118502\ttotal: 6.39s\tremaining: 15.7s\n",
      "289:\tlearn: 0.1115060\ttotal: 6.41s\tremaining: 15.7s\n",
      "290:\tlearn: 0.1111791\ttotal: 6.44s\tremaining: 15.7s\n",
      "291:\tlearn: 0.1108305\ttotal: 6.46s\tremaining: 15.7s\n",
      "292:\tlearn: 0.1106413\ttotal: 6.48s\tremaining: 15.6s\n",
      "293:\tlearn: 0.1102785\ttotal: 6.5s\tremaining: 15.6s\n",
      "294:\tlearn: 0.1100362\ttotal: 6.53s\tremaining: 15.6s\n",
      "295:\tlearn: 0.1098391\ttotal: 6.55s\tremaining: 15.6s\n",
      "296:\tlearn: 0.1094790\ttotal: 6.58s\tremaining: 15.6s\n",
      "297:\tlearn: 0.1092975\ttotal: 6.6s\tremaining: 15.5s\n",
      "298:\tlearn: 0.1091230\ttotal: 6.62s\tremaining: 15.5s\n",
      "299:\tlearn: 0.1088765\ttotal: 6.64s\tremaining: 15.5s\n",
      "300:\tlearn: 0.1086989\ttotal: 6.67s\tremaining: 15.5s\n",
      "301:\tlearn: 0.1084212\ttotal: 6.69s\tremaining: 15.5s\n",
      "302:\tlearn: 0.1082221\ttotal: 6.71s\tremaining: 15.4s\n",
      "303:\tlearn: 0.1079987\ttotal: 6.73s\tremaining: 15.4s\n",
      "304:\tlearn: 0.1078172\ttotal: 6.75s\tremaining: 15.4s\n",
      "305:\tlearn: 0.1076509\ttotal: 6.77s\tremaining: 15.4s\n",
      "306:\tlearn: 0.1075072\ttotal: 6.79s\tremaining: 15.3s\n",
      "307:\tlearn: 0.1073303\ttotal: 6.82s\tremaining: 15.3s\n",
      "308:\tlearn: 0.1071612\ttotal: 6.84s\tremaining: 15.3s\n",
      "309:\tlearn: 0.1069989\ttotal: 6.86s\tremaining: 15.3s\n",
      "310:\tlearn: 0.1067629\ttotal: 6.89s\tremaining: 15.3s\n",
      "311:\tlearn: 0.1065858\ttotal: 6.91s\tremaining: 15.2s\n",
      "312:\tlearn: 0.1063543\ttotal: 6.93s\tremaining: 15.2s\n",
      "313:\tlearn: 0.1061299\ttotal: 6.96s\tremaining: 15.2s\n",
      "314:\tlearn: 0.1058993\ttotal: 6.98s\tremaining: 15.2s\n",
      "315:\tlearn: 0.1057109\ttotal: 7s\tremaining: 15.2s\n",
      "316:\tlearn: 0.1054681\ttotal: 7.02s\tremaining: 15.1s\n",
      "317:\tlearn: 0.1052600\ttotal: 7.04s\tremaining: 15.1s\n",
      "318:\tlearn: 0.1050545\ttotal: 7.06s\tremaining: 15.1s\n",
      "319:\tlearn: 0.1047956\ttotal: 7.08s\tremaining: 15s\n",
      "320:\tlearn: 0.1046339\ttotal: 7.11s\tremaining: 15s\n",
      "321:\tlearn: 0.1044144\ttotal: 7.13s\tremaining: 15s\n",
      "322:\tlearn: 0.1041809\ttotal: 7.15s\tremaining: 15s\n",
      "323:\tlearn: 0.1039447\ttotal: 7.17s\tremaining: 15s\n",
      "324:\tlearn: 0.1038257\ttotal: 7.2s\tremaining: 15s\n",
      "325:\tlearn: 0.1035811\ttotal: 7.22s\tremaining: 14.9s\n",
      "326:\tlearn: 0.1033354\ttotal: 7.24s\tremaining: 14.9s\n",
      "327:\tlearn: 0.1031379\ttotal: 7.26s\tremaining: 14.9s\n",
      "328:\tlearn: 0.1028767\ttotal: 7.28s\tremaining: 14.9s\n",
      "329:\tlearn: 0.1026144\ttotal: 7.3s\tremaining: 14.8s\n",
      "330:\tlearn: 0.1024712\ttotal: 7.32s\tremaining: 14.8s\n",
      "331:\tlearn: 0.1022727\ttotal: 7.34s\tremaining: 14.8s\n",
      "332:\tlearn: 0.1021483\ttotal: 7.36s\tremaining: 14.8s\n",
      "333:\tlearn: 0.1018867\ttotal: 7.39s\tremaining: 14.7s\n",
      "334:\tlearn: 0.1017626\ttotal: 7.42s\tremaining: 14.7s\n",
      "335:\tlearn: 0.1016222\ttotal: 7.45s\tremaining: 14.7s\n",
      "336:\tlearn: 0.1014123\ttotal: 7.47s\tremaining: 14.7s\n",
      "337:\tlearn: 0.1011615\ttotal: 7.49s\tremaining: 14.7s\n",
      "338:\tlearn: 0.1009451\ttotal: 7.52s\tremaining: 14.7s\n",
      "339:\tlearn: 0.1006693\ttotal: 7.54s\tremaining: 14.6s\n",
      "340:\tlearn: 0.1004891\ttotal: 7.56s\tremaining: 14.6s\n",
      "341:\tlearn: 0.1003364\ttotal: 7.58s\tremaining: 14.6s\n",
      "342:\tlearn: 0.1001672\ttotal: 7.61s\tremaining: 14.6s\n",
      "343:\tlearn: 0.0999746\ttotal: 7.63s\tremaining: 14.6s\n",
      "344:\tlearn: 0.0997543\ttotal: 7.66s\tremaining: 14.5s\n",
      "345:\tlearn: 0.0995931\ttotal: 7.68s\tremaining: 14.5s\n",
      "346:\tlearn: 0.0994455\ttotal: 7.7s\tremaining: 14.5s\n",
      "347:\tlearn: 0.0992589\ttotal: 7.71s\tremaining: 14.5s\n",
      "348:\tlearn: 0.0991022\ttotal: 7.74s\tremaining: 14.4s\n",
      "349:\tlearn: 0.0988597\ttotal: 7.76s\tremaining: 14.4s\n",
      "350:\tlearn: 0.0986994\ttotal: 7.78s\tremaining: 14.4s\n",
      "351:\tlearn: 0.0984739\ttotal: 7.81s\tremaining: 14.4s\n",
      "352:\tlearn: 0.0983661\ttotal: 7.83s\tremaining: 14.3s\n",
      "353:\tlearn: 0.0981536\ttotal: 7.85s\tremaining: 14.3s\n",
      "354:\tlearn: 0.0980232\ttotal: 7.87s\tremaining: 14.3s\n",
      "355:\tlearn: 0.0977011\ttotal: 7.88s\tremaining: 14.3s\n",
      "356:\tlearn: 0.0974633\ttotal: 7.9s\tremaining: 14.2s\n",
      "357:\tlearn: 0.0973300\ttotal: 7.92s\tremaining: 14.2s\n",
      "358:\tlearn: 0.0971002\ttotal: 7.94s\tremaining: 14.2s\n",
      "359:\tlearn: 0.0968977\ttotal: 7.97s\tremaining: 14.2s\n",
      "360:\tlearn: 0.0966941\ttotal: 7.99s\tremaining: 14.1s\n",
      "361:\tlearn: 0.0964667\ttotal: 8.01s\tremaining: 14.1s\n",
      "362:\tlearn: 0.0961948\ttotal: 8.03s\tremaining: 14.1s\n",
      "363:\tlearn: 0.0960654\ttotal: 8.05s\tremaining: 14.1s\n",
      "364:\tlearn: 0.0958070\ttotal: 8.07s\tremaining: 14s\n",
      "365:\tlearn: 0.0956727\ttotal: 8.09s\tremaining: 14s\n",
      "366:\tlearn: 0.0955205\ttotal: 8.12s\tremaining: 14s\n",
      "367:\tlearn: 0.0954351\ttotal: 8.13s\tremaining: 14s\n",
      "368:\tlearn: 0.0952789\ttotal: 8.16s\tremaining: 14s\n",
      "369:\tlearn: 0.0951170\ttotal: 8.18s\tremaining: 13.9s\n",
      "370:\tlearn: 0.0948310\ttotal: 8.2s\tremaining: 13.9s\n",
      "371:\tlearn: 0.0947341\ttotal: 8.22s\tremaining: 13.9s\n",
      "372:\tlearn: 0.0946096\ttotal: 8.24s\tremaining: 13.9s\n",
      "373:\tlearn: 0.0944379\ttotal: 8.27s\tremaining: 13.8s\n",
      "374:\tlearn: 0.0942831\ttotal: 8.3s\tremaining: 13.8s\n",
      "375:\tlearn: 0.0940538\ttotal: 8.32s\tremaining: 13.8s\n",
      "376:\tlearn: 0.0939454\ttotal: 8.35s\tremaining: 13.8s\n",
      "377:\tlearn: 0.0938307\ttotal: 8.37s\tremaining: 13.8s\n",
      "378:\tlearn: 0.0936934\ttotal: 8.39s\tremaining: 13.7s\n",
      "379:\tlearn: 0.0935213\ttotal: 8.41s\tremaining: 13.7s\n",
      "380:\tlearn: 0.0933476\ttotal: 8.44s\tremaining: 13.7s\n",
      "381:\tlearn: 0.0932609\ttotal: 8.46s\tremaining: 13.7s\n",
      "382:\tlearn: 0.0930959\ttotal: 8.48s\tremaining: 13.7s\n",
      "383:\tlearn: 0.0929366\ttotal: 8.49s\tremaining: 13.6s\n",
      "384:\tlearn: 0.0928183\ttotal: 8.51s\tremaining: 13.6s\n",
      "385:\tlearn: 0.0926238\ttotal: 8.53s\tremaining: 13.6s\n",
      "386:\tlearn: 0.0924609\ttotal: 8.55s\tremaining: 13.5s\n",
      "387:\tlearn: 0.0923034\ttotal: 8.57s\tremaining: 13.5s\n",
      "388:\tlearn: 0.0921338\ttotal: 8.59s\tremaining: 13.5s\n",
      "389:\tlearn: 0.0920066\ttotal: 8.61s\tremaining: 13.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390:\tlearn: 0.0917539\ttotal: 8.63s\tremaining: 13.4s\n",
      "391:\tlearn: 0.0915938\ttotal: 8.66s\tremaining: 13.4s\n",
      "392:\tlearn: 0.0914745\ttotal: 8.68s\tremaining: 13.4s\n",
      "393:\tlearn: 0.0913020\ttotal: 8.71s\tremaining: 13.4s\n",
      "394:\tlearn: 0.0911237\ttotal: 8.73s\tremaining: 13.4s\n",
      "395:\tlearn: 0.0909768\ttotal: 8.75s\tremaining: 13.3s\n",
      "396:\tlearn: 0.0907758\ttotal: 8.78s\tremaining: 13.3s\n",
      "397:\tlearn: 0.0906522\ttotal: 8.79s\tremaining: 13.3s\n",
      "398:\tlearn: 0.0904428\ttotal: 8.81s\tremaining: 13.3s\n",
      "399:\tlearn: 0.0902518\ttotal: 8.84s\tremaining: 13.3s\n",
      "400:\tlearn: 0.0900428\ttotal: 8.86s\tremaining: 13.2s\n",
      "401:\tlearn: 0.0897669\ttotal: 8.88s\tremaining: 13.2s\n",
      "402:\tlearn: 0.0895654\ttotal: 8.9s\tremaining: 13.2s\n",
      "403:\tlearn: 0.0893949\ttotal: 8.93s\tremaining: 13.2s\n",
      "404:\tlearn: 0.0892959\ttotal: 8.95s\tremaining: 13.2s\n",
      "405:\tlearn: 0.0891338\ttotal: 8.97s\tremaining: 13.1s\n",
      "406:\tlearn: 0.0888797\ttotal: 8.99s\tremaining: 13.1s\n",
      "407:\tlearn: 0.0886864\ttotal: 9.01s\tremaining: 13.1s\n",
      "408:\tlearn: 0.0884150\ttotal: 9.04s\tremaining: 13.1s\n",
      "409:\tlearn: 0.0882233\ttotal: 9.06s\tremaining: 13s\n",
      "410:\tlearn: 0.0880503\ttotal: 9.09s\tremaining: 13s\n",
      "411:\tlearn: 0.0878694\ttotal: 9.11s\tremaining: 13s\n",
      "412:\tlearn: 0.0874929\ttotal: 9.13s\tremaining: 13s\n",
      "413:\tlearn: 0.0873346\ttotal: 9.16s\tremaining: 13s\n",
      "414:\tlearn: 0.0871731\ttotal: 9.18s\tremaining: 12.9s\n",
      "415:\tlearn: 0.0869043\ttotal: 9.21s\tremaining: 12.9s\n",
      "416:\tlearn: 0.0867651\ttotal: 9.23s\tremaining: 12.9s\n",
      "417:\tlearn: 0.0865821\ttotal: 9.25s\tremaining: 12.9s\n",
      "418:\tlearn: 0.0864514\ttotal: 9.27s\tremaining: 12.9s\n",
      "419:\tlearn: 0.0862329\ttotal: 9.29s\tremaining: 12.8s\n",
      "420:\tlearn: 0.0861061\ttotal: 9.3s\tremaining: 12.8s\n",
      "421:\tlearn: 0.0860625\ttotal: 9.32s\tremaining: 12.8s\n",
      "422:\tlearn: 0.0858721\ttotal: 9.34s\tremaining: 12.7s\n",
      "423:\tlearn: 0.0857414\ttotal: 9.37s\tremaining: 12.7s\n",
      "424:\tlearn: 0.0855727\ttotal: 9.39s\tremaining: 12.7s\n",
      "425:\tlearn: 0.0854502\ttotal: 9.41s\tremaining: 12.7s\n",
      "426:\tlearn: 0.0852805\ttotal: 9.43s\tremaining: 12.7s\n",
      "427:\tlearn: 0.0851301\ttotal: 9.45s\tremaining: 12.6s\n",
      "428:\tlearn: 0.0850325\ttotal: 9.47s\tremaining: 12.6s\n",
      "429:\tlearn: 0.0848097\ttotal: 9.49s\tremaining: 12.6s\n",
      "430:\tlearn: 0.0846658\ttotal: 9.51s\tremaining: 12.6s\n",
      "431:\tlearn: 0.0844906\ttotal: 9.53s\tremaining: 12.5s\n",
      "432:\tlearn: 0.0844668\ttotal: 9.55s\tremaining: 12.5s\n",
      "433:\tlearn: 0.0843561\ttotal: 9.57s\tremaining: 12.5s\n",
      "434:\tlearn: 0.0842131\ttotal: 9.6s\tremaining: 12.5s\n",
      "435:\tlearn: 0.0840860\ttotal: 9.62s\tremaining: 12.4s\n",
      "436:\tlearn: 0.0839132\ttotal: 9.64s\tremaining: 12.4s\n",
      "437:\tlearn: 0.0838969\ttotal: 9.67s\tremaining: 12.4s\n",
      "438:\tlearn: 0.0837872\ttotal: 9.69s\tremaining: 12.4s\n",
      "439:\tlearn: 0.0836704\ttotal: 9.7s\tremaining: 12.3s\n",
      "440:\tlearn: 0.0835248\ttotal: 9.72s\tremaining: 12.3s\n",
      "441:\tlearn: 0.0832594\ttotal: 9.75s\tremaining: 12.3s\n",
      "442:\tlearn: 0.0831336\ttotal: 9.77s\tremaining: 12.3s\n",
      "443:\tlearn: 0.0829215\ttotal: 9.79s\tremaining: 12.3s\n",
      "444:\tlearn: 0.0827303\ttotal: 9.81s\tremaining: 12.2s\n",
      "445:\tlearn: 0.0826344\ttotal: 9.83s\tremaining: 12.2s\n",
      "446:\tlearn: 0.0826237\ttotal: 9.85s\tremaining: 12.2s\n",
      "447:\tlearn: 0.0824751\ttotal: 9.87s\tremaining: 12.2s\n",
      "448:\tlearn: 0.0823440\ttotal: 9.89s\tremaining: 12.1s\n",
      "449:\tlearn: 0.0821505\ttotal: 9.9s\tremaining: 12.1s\n",
      "450:\tlearn: 0.0820258\ttotal: 9.93s\tremaining: 12.1s\n",
      "451:\tlearn: 0.0819184\ttotal: 9.95s\tremaining: 12.1s\n",
      "452:\tlearn: 0.0817142\ttotal: 9.97s\tremaining: 12s\n",
      "453:\tlearn: 0.0815252\ttotal: 9.99s\tremaining: 12s\n",
      "454:\tlearn: 0.0813953\ttotal: 10s\tremaining: 12s\n",
      "455:\tlearn: 0.0811758\ttotal: 10s\tremaining: 12s\n",
      "456:\tlearn: 0.0809848\ttotal: 10s\tremaining: 11.9s\n",
      "457:\tlearn: 0.0808420\ttotal: 10.1s\tremaining: 11.9s\n",
      "458:\tlearn: 0.0806671\ttotal: 10.1s\tremaining: 11.9s\n",
      "459:\tlearn: 0.0804955\ttotal: 10.1s\tremaining: 11.9s\n",
      "460:\tlearn: 0.0802454\ttotal: 10.1s\tremaining: 11.9s\n",
      "461:\tlearn: 0.0801907\ttotal: 10.2s\tremaining: 11.8s\n",
      "462:\tlearn: 0.0799469\ttotal: 10.2s\tremaining: 11.8s\n",
      "463:\tlearn: 0.0798957\ttotal: 10.2s\tremaining: 11.8s\n",
      "464:\tlearn: 0.0797171\ttotal: 10.2s\tremaining: 11.8s\n",
      "465:\tlearn: 0.0795955\ttotal: 10.3s\tremaining: 11.7s\n",
      "466:\tlearn: 0.0794748\ttotal: 10.3s\tremaining: 11.7s\n",
      "467:\tlearn: 0.0792999\ttotal: 10.3s\tremaining: 11.7s\n",
      "468:\tlearn: 0.0792115\ttotal: 10.3s\tremaining: 11.7s\n",
      "469:\tlearn: 0.0790871\ttotal: 10.3s\tremaining: 11.7s\n",
      "470:\tlearn: 0.0790724\ttotal: 10.4s\tremaining: 11.6s\n",
      "471:\tlearn: 0.0789079\ttotal: 10.4s\tremaining: 11.6s\n",
      "472:\tlearn: 0.0787789\ttotal: 10.4s\tremaining: 11.6s\n",
      "473:\tlearn: 0.0786165\ttotal: 10.4s\tremaining: 11.6s\n",
      "474:\tlearn: 0.0784392\ttotal: 10.4s\tremaining: 11.5s\n",
      "475:\tlearn: 0.0783874\ttotal: 10.5s\tremaining: 11.5s\n",
      "476:\tlearn: 0.0782426\ttotal: 10.5s\tremaining: 11.5s\n",
      "477:\tlearn: 0.0781248\ttotal: 10.5s\tremaining: 11.5s\n",
      "478:\tlearn: 0.0779737\ttotal: 10.5s\tremaining: 11.4s\n",
      "479:\tlearn: 0.0777279\ttotal: 10.5s\tremaining: 11.4s\n",
      "480:\tlearn: 0.0775390\ttotal: 10.6s\tremaining: 11.4s\n",
      "481:\tlearn: 0.0774186\ttotal: 10.6s\tremaining: 11.4s\n",
      "482:\tlearn: 0.0772815\ttotal: 10.6s\tremaining: 11.3s\n",
      "483:\tlearn: 0.0772520\ttotal: 10.6s\tremaining: 11.3s\n",
      "484:\tlearn: 0.0772240\ttotal: 10.6s\tremaining: 11.3s\n",
      "485:\tlearn: 0.0770823\ttotal: 10.7s\tremaining: 11.3s\n",
      "486:\tlearn: 0.0769586\ttotal: 10.7s\tremaining: 11.3s\n",
      "487:\tlearn: 0.0769041\ttotal: 10.7s\tremaining: 11.2s\n",
      "488:\tlearn: 0.0767690\ttotal: 10.7s\tremaining: 11.2s\n",
      "489:\tlearn: 0.0767500\ttotal: 10.7s\tremaining: 11.2s\n",
      "490:\tlearn: 0.0765193\ttotal: 10.8s\tremaining: 11.2s\n",
      "491:\tlearn: 0.0764890\ttotal: 10.8s\tremaining: 11.2s\n",
      "492:\tlearn: 0.0763307\ttotal: 10.8s\tremaining: 11.1s\n",
      "493:\tlearn: 0.0761873\ttotal: 10.8s\tremaining: 11.1s\n",
      "494:\tlearn: 0.0760296\ttotal: 10.9s\tremaining: 11.1s\n",
      "495:\tlearn: 0.0759085\ttotal: 10.9s\tremaining: 11.1s\n",
      "496:\tlearn: 0.0757345\ttotal: 10.9s\tremaining: 11s\n",
      "497:\tlearn: 0.0756439\ttotal: 10.9s\tremaining: 11s\n",
      "498:\tlearn: 0.0754874\ttotal: 11s\tremaining: 11s\n",
      "499:\tlearn: 0.0753417\ttotal: 11s\tremaining: 11s\n",
      "500:\tlearn: 0.0751664\ttotal: 11.1s\tremaining: 11s\n",
      "501:\tlearn: 0.0750674\ttotal: 11.1s\tremaining: 11s\n",
      "502:\tlearn: 0.0748558\ttotal: 11.1s\tremaining: 11s\n",
      "503:\tlearn: 0.0747498\ttotal: 11.2s\tremaining: 11s\n",
      "504:\tlearn: 0.0747066\ttotal: 11.2s\tremaining: 11s\n",
      "505:\tlearn: 0.0745788\ttotal: 11.2s\tremaining: 10.9s\n",
      "506:\tlearn: 0.0743844\ttotal: 11.2s\tremaining: 10.9s\n",
      "507:\tlearn: 0.0742853\ttotal: 11.3s\tremaining: 10.9s\n",
      "508:\tlearn: 0.0740691\ttotal: 11.3s\tremaining: 10.9s\n",
      "509:\tlearn: 0.0738960\ttotal: 11.3s\tremaining: 10.9s\n",
      "510:\tlearn: 0.0737558\ttotal: 11.4s\tremaining: 10.9s\n",
      "511:\tlearn: 0.0735079\ttotal: 11.4s\tremaining: 10.9s\n",
      "512:\tlearn: 0.0732541\ttotal: 11.4s\tremaining: 10.9s\n",
      "513:\tlearn: 0.0729936\ttotal: 11.5s\tremaining: 10.8s\n",
      "514:\tlearn: 0.0726958\ttotal: 11.5s\tremaining: 10.8s\n",
      "515:\tlearn: 0.0724276\ttotal: 11.5s\tremaining: 10.8s\n",
      "516:\tlearn: 0.0723309\ttotal: 11.5s\tremaining: 10.8s\n",
      "517:\tlearn: 0.0722776\ttotal: 11.6s\tremaining: 10.8s\n",
      "518:\tlearn: 0.0722482\ttotal: 11.6s\tremaining: 10.8s\n",
      "519:\tlearn: 0.0720791\ttotal: 11.6s\tremaining: 10.7s\n",
      "520:\tlearn: 0.0720585\ttotal: 11.7s\tremaining: 10.7s\n",
      "521:\tlearn: 0.0720483\ttotal: 11.7s\tremaining: 10.7s\n",
      "522:\tlearn: 0.0719418\ttotal: 11.7s\tremaining: 10.7s\n",
      "523:\tlearn: 0.0718112\ttotal: 11.8s\tremaining: 10.7s\n",
      "524:\tlearn: 0.0716725\ttotal: 11.8s\tremaining: 10.7s\n",
      "525:\tlearn: 0.0716602\ttotal: 11.8s\tremaining: 10.6s\n",
      "526:\tlearn: 0.0714746\ttotal: 11.8s\tremaining: 10.6s\n",
      "527:\tlearn: 0.0714646\ttotal: 11.9s\tremaining: 10.6s\n",
      "528:\tlearn: 0.0713267\ttotal: 11.9s\tremaining: 10.6s\n",
      "529:\tlearn: 0.0711679\ttotal: 11.9s\tremaining: 10.6s\n",
      "530:\tlearn: 0.0710668\ttotal: 12s\tremaining: 10.6s\n",
      "531:\tlearn: 0.0708725\ttotal: 12s\tremaining: 10.6s\n",
      "532:\tlearn: 0.0708617\ttotal: 12s\tremaining: 10.5s\n",
      "533:\tlearn: 0.0708515\ttotal: 12.1s\tremaining: 10.5s\n",
      "534:\tlearn: 0.0707915\ttotal: 12.1s\tremaining: 10.5s\n",
      "535:\tlearn: 0.0706252\ttotal: 12.1s\tremaining: 10.5s\n",
      "536:\tlearn: 0.0705628\ttotal: 12.1s\tremaining: 10.5s\n",
      "537:\tlearn: 0.0703820\ttotal: 12.2s\tremaining: 10.5s\n",
      "538:\tlearn: 0.0703728\ttotal: 12.2s\tremaining: 10.4s\n",
      "539:\tlearn: 0.0701691\ttotal: 12.2s\tremaining: 10.4s\n",
      "540:\tlearn: 0.0701592\ttotal: 12.3s\tremaining: 10.4s\n",
      "541:\tlearn: 0.0699856\ttotal: 12.3s\tremaining: 10.4s\n",
      "542:\tlearn: 0.0698324\ttotal: 12.3s\tremaining: 10.4s\n",
      "543:\tlearn: 0.0698235\ttotal: 12.4s\tremaining: 10.4s\n",
      "544:\tlearn: 0.0697181\ttotal: 12.4s\tremaining: 10.3s\n",
      "545:\tlearn: 0.0696385\ttotal: 12.4s\tremaining: 10.3s\n",
      "546:\tlearn: 0.0694485\ttotal: 12.4s\tremaining: 10.3s\n",
      "547:\tlearn: 0.0693087\ttotal: 12.5s\tremaining: 10.3s\n",
      "548:\tlearn: 0.0691941\ttotal: 12.5s\tremaining: 10.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "549:\tlearn: 0.0690003\ttotal: 12.5s\tremaining: 10.3s\n",
      "550:\tlearn: 0.0688327\ttotal: 12.6s\tremaining: 10.2s\n",
      "551:\tlearn: 0.0687177\ttotal: 12.6s\tremaining: 10.2s\n",
      "552:\tlearn: 0.0687087\ttotal: 12.6s\tremaining: 10.2s\n",
      "553:\tlearn: 0.0687003\ttotal: 12.7s\tremaining: 10.2s\n",
      "554:\tlearn: 0.0684675\ttotal: 12.7s\tremaining: 10.2s\n",
      "555:\tlearn: 0.0683692\ttotal: 12.7s\tremaining: 10.2s\n",
      "556:\tlearn: 0.0682497\ttotal: 12.7s\tremaining: 10.1s\n",
      "557:\tlearn: 0.0680944\ttotal: 12.8s\tremaining: 10.1s\n",
      "558:\tlearn: 0.0678951\ttotal: 12.8s\tremaining: 10.1s\n",
      "559:\tlearn: 0.0677451\ttotal: 12.8s\tremaining: 10.1s\n",
      "560:\tlearn: 0.0677076\ttotal: 12.8s\tremaining: 10s\n",
      "561:\tlearn: 0.0674675\ttotal: 12.9s\tremaining: 10s\n",
      "562:\tlearn: 0.0674585\ttotal: 12.9s\tremaining: 10s\n",
      "563:\tlearn: 0.0673000\ttotal: 12.9s\tremaining: 9.98s\n",
      "564:\tlearn: 0.0672912\ttotal: 12.9s\tremaining: 9.96s\n",
      "565:\tlearn: 0.0671298\ttotal: 13s\tremaining: 9.94s\n",
      "566:\tlearn: 0.0670239\ttotal: 13s\tremaining: 9.91s\n",
      "567:\tlearn: 0.0669829\ttotal: 13s\tremaining: 9.89s\n",
      "568:\tlearn: 0.0667632\ttotal: 13s\tremaining: 9.86s\n",
      "569:\tlearn: 0.0666104\ttotal: 13.1s\tremaining: 9.86s\n",
      "570:\tlearn: 0.0664445\ttotal: 13.1s\tremaining: 9.85s\n",
      "571:\tlearn: 0.0663646\ttotal: 13.1s\tremaining: 9.84s\n",
      "572:\tlearn: 0.0662694\ttotal: 13.2s\tremaining: 9.82s\n",
      "573:\tlearn: 0.0661603\ttotal: 13.2s\tremaining: 9.8s\n",
      "574:\tlearn: 0.0660140\ttotal: 13.2s\tremaining: 9.78s\n",
      "575:\tlearn: 0.0659964\ttotal: 13.3s\tremaining: 9.77s\n",
      "576:\tlearn: 0.0658902\ttotal: 13.3s\tremaining: 9.75s\n",
      "577:\tlearn: 0.0658715\ttotal: 13.3s\tremaining: 9.73s\n",
      "578:\tlearn: 0.0658002\ttotal: 13.4s\tremaining: 9.71s\n",
      "579:\tlearn: 0.0656916\ttotal: 13.4s\tremaining: 9.7s\n",
      "580:\tlearn: 0.0655582\ttotal: 13.4s\tremaining: 9.68s\n",
      "581:\tlearn: 0.0654372\ttotal: 13.5s\tremaining: 9.67s\n",
      "582:\tlearn: 0.0653298\ttotal: 13.5s\tremaining: 9.66s\n",
      "583:\tlearn: 0.0651301\ttotal: 13.5s\tremaining: 9.64s\n",
      "584:\tlearn: 0.0651215\ttotal: 13.6s\tremaining: 9.62s\n",
      "585:\tlearn: 0.0649446\ttotal: 13.6s\tremaining: 9.61s\n",
      "586:\tlearn: 0.0648803\ttotal: 13.6s\tremaining: 9.58s\n",
      "587:\tlearn: 0.0647899\ttotal: 13.7s\tremaining: 9.57s\n",
      "588:\tlearn: 0.0646712\ttotal: 13.7s\tremaining: 9.56s\n",
      "589:\tlearn: 0.0645092\ttotal: 13.7s\tremaining: 9.54s\n",
      "590:\tlearn: 0.0644371\ttotal: 13.8s\tremaining: 9.52s\n",
      "591:\tlearn: 0.0644288\ttotal: 13.8s\tremaining: 9.5s\n",
      "592:\tlearn: 0.0642962\ttotal: 13.8s\tremaining: 9.47s\n",
      "593:\tlearn: 0.0641738\ttotal: 13.8s\tremaining: 9.45s\n",
      "594:\tlearn: 0.0640710\ttotal: 13.9s\tremaining: 9.43s\n",
      "595:\tlearn: 0.0638893\ttotal: 13.9s\tremaining: 9.41s\n",
      "596:\tlearn: 0.0638233\ttotal: 13.9s\tremaining: 9.4s\n",
      "597:\tlearn: 0.0637571\ttotal: 13.9s\tremaining: 9.37s\n",
      "598:\tlearn: 0.0637433\ttotal: 14s\tremaining: 9.35s\n",
      "599:\tlearn: 0.0637355\ttotal: 14s\tremaining: 9.32s\n",
      "600:\tlearn: 0.0635896\ttotal: 14s\tremaining: 9.3s\n",
      "601:\tlearn: 0.0634761\ttotal: 14s\tremaining: 9.27s\n",
      "602:\tlearn: 0.0634265\ttotal: 14s\tremaining: 9.25s\n",
      "603:\tlearn: 0.0633384\ttotal: 14.1s\tremaining: 9.22s\n",
      "604:\tlearn: 0.0631963\ttotal: 14.1s\tremaining: 9.2s\n",
      "605:\tlearn: 0.0630351\ttotal: 14.1s\tremaining: 9.17s\n",
      "606:\tlearn: 0.0628713\ttotal: 14.1s\tremaining: 9.14s\n",
      "607:\tlearn: 0.0628600\ttotal: 14.1s\tremaining: 9.12s\n",
      "608:\tlearn: 0.0626966\ttotal: 14.2s\tremaining: 9.09s\n",
      "609:\tlearn: 0.0625789\ttotal: 14.2s\tremaining: 9.06s\n",
      "610:\tlearn: 0.0624737\ttotal: 14.2s\tremaining: 9.04s\n",
      "611:\tlearn: 0.0623420\ttotal: 14.2s\tremaining: 9.01s\n",
      "612:\tlearn: 0.0621767\ttotal: 14.2s\tremaining: 8.99s\n",
      "613:\tlearn: 0.0620456\ttotal: 14.3s\tremaining: 8.96s\n",
      "614:\tlearn: 0.0619502\ttotal: 14.3s\tremaining: 8.94s\n",
      "615:\tlearn: 0.0619203\ttotal: 14.3s\tremaining: 8.91s\n",
      "616:\tlearn: 0.0619127\ttotal: 14.3s\tremaining: 8.88s\n",
      "617:\tlearn: 0.0619053\ttotal: 14.3s\tremaining: 8.86s\n",
      "618:\tlearn: 0.0618907\ttotal: 14.4s\tremaining: 8.84s\n",
      "619:\tlearn: 0.0617464\ttotal: 14.4s\tremaining: 8.82s\n",
      "620:\tlearn: 0.0617265\ttotal: 14.4s\tremaining: 8.79s\n",
      "621:\tlearn: 0.0616180\ttotal: 14.4s\tremaining: 8.77s\n",
      "622:\tlearn: 0.0615011\ttotal: 14.4s\tremaining: 8.74s\n",
      "623:\tlearn: 0.0614377\ttotal: 14.5s\tremaining: 8.72s\n",
      "624:\tlearn: 0.0613183\ttotal: 14.5s\tremaining: 8.69s\n",
      "625:\tlearn: 0.0612077\ttotal: 14.5s\tremaining: 8.67s\n",
      "626:\tlearn: 0.0610621\ttotal: 14.5s\tremaining: 8.64s\n",
      "627:\tlearn: 0.0610451\ttotal: 14.5s\tremaining: 8.62s\n",
      "628:\tlearn: 0.0610307\ttotal: 14.6s\tremaining: 8.59s\n",
      "629:\tlearn: 0.0608787\ttotal: 14.6s\tremaining: 8.57s\n",
      "630:\tlearn: 0.0607324\ttotal: 14.6s\tremaining: 8.55s\n",
      "631:\tlearn: 0.0606865\ttotal: 14.6s\tremaining: 8.53s\n",
      "632:\tlearn: 0.0605981\ttotal: 14.7s\tremaining: 8.5s\n",
      "633:\tlearn: 0.0605583\ttotal: 14.7s\tremaining: 8.48s\n",
      "634:\tlearn: 0.0604660\ttotal: 14.7s\tremaining: 8.46s\n",
      "635:\tlearn: 0.0603753\ttotal: 14.7s\tremaining: 8.44s\n",
      "636:\tlearn: 0.0602554\ttotal: 14.8s\tremaining: 8.41s\n",
      "637:\tlearn: 0.0601590\ttotal: 14.8s\tremaining: 8.39s\n",
      "638:\tlearn: 0.0600727\ttotal: 14.8s\tremaining: 8.37s\n",
      "639:\tlearn: 0.0599685\ttotal: 14.8s\tremaining: 8.34s\n",
      "640:\tlearn: 0.0598489\ttotal: 14.9s\tremaining: 8.32s\n",
      "641:\tlearn: 0.0597427\ttotal: 14.9s\tremaining: 8.3s\n",
      "642:\tlearn: 0.0596491\ttotal: 14.9s\tremaining: 8.27s\n",
      "643:\tlearn: 0.0595011\ttotal: 14.9s\tremaining: 8.25s\n",
      "644:\tlearn: 0.0594746\ttotal: 14.9s\tremaining: 8.22s\n",
      "645:\tlearn: 0.0593614\ttotal: 15s\tremaining: 8.2s\n",
      "646:\tlearn: 0.0592714\ttotal: 15s\tremaining: 8.17s\n",
      "647:\tlearn: 0.0591681\ttotal: 15s\tremaining: 8.15s\n",
      "648:\tlearn: 0.0591260\ttotal: 15s\tremaining: 8.12s\n",
      "649:\tlearn: 0.0590282\ttotal: 15s\tremaining: 8.1s\n",
      "650:\tlearn: 0.0588833\ttotal: 15.1s\tremaining: 8.08s\n",
      "651:\tlearn: 0.0588112\ttotal: 15.1s\tremaining: 8.05s\n",
      "652:\tlearn: 0.0586953\ttotal: 15.1s\tremaining: 8.03s\n",
      "653:\tlearn: 0.0586012\ttotal: 15.1s\tremaining: 8.01s\n",
      "654:\tlearn: 0.0585146\ttotal: 15.2s\tremaining: 7.98s\n",
      "655:\tlearn: 0.0584995\ttotal: 15.2s\tremaining: 7.96s\n",
      "656:\tlearn: 0.0583853\ttotal: 15.2s\tremaining: 7.93s\n",
      "657:\tlearn: 0.0582737\ttotal: 15.2s\tremaining: 7.91s\n",
      "658:\tlearn: 0.0582598\ttotal: 15.3s\tremaining: 7.89s\n",
      "659:\tlearn: 0.0581435\ttotal: 15.3s\tremaining: 7.87s\n",
      "660:\tlearn: 0.0581369\ttotal: 15.3s\tremaining: 7.84s\n",
      "661:\tlearn: 0.0580505\ttotal: 15.3s\tremaining: 7.82s\n",
      "662:\tlearn: 0.0579524\ttotal: 15.3s\tremaining: 7.79s\n",
      "663:\tlearn: 0.0578923\ttotal: 15.4s\tremaining: 7.77s\n",
      "664:\tlearn: 0.0577365\ttotal: 15.4s\tremaining: 7.74s\n",
      "665:\tlearn: 0.0577301\ttotal: 15.4s\tremaining: 7.72s\n",
      "666:\tlearn: 0.0577239\ttotal: 15.4s\tremaining: 7.69s\n",
      "667:\tlearn: 0.0576218\ttotal: 15.4s\tremaining: 7.67s\n",
      "668:\tlearn: 0.0574612\ttotal: 15.5s\tremaining: 7.65s\n",
      "669:\tlearn: 0.0573682\ttotal: 15.5s\tremaining: 7.62s\n",
      "670:\tlearn: 0.0572414\ttotal: 15.5s\tremaining: 7.6s\n",
      "671:\tlearn: 0.0572156\ttotal: 15.5s\tremaining: 7.58s\n",
      "672:\tlearn: 0.0571495\ttotal: 15.5s\tremaining: 7.55s\n",
      "673:\tlearn: 0.0570751\ttotal: 15.6s\tremaining: 7.53s\n",
      "674:\tlearn: 0.0569318\ttotal: 15.6s\tremaining: 7.5s\n",
      "675:\tlearn: 0.0568538\ttotal: 15.6s\tremaining: 7.48s\n",
      "676:\tlearn: 0.0567515\ttotal: 15.6s\tremaining: 7.46s\n",
      "677:\tlearn: 0.0566799\ttotal: 15.7s\tremaining: 7.43s\n",
      "678:\tlearn: 0.0566690\ttotal: 15.7s\tremaining: 7.41s\n",
      "679:\tlearn: 0.0565734\ttotal: 15.7s\tremaining: 7.39s\n",
      "680:\tlearn: 0.0564786\ttotal: 15.7s\tremaining: 7.37s\n",
      "681:\tlearn: 0.0564154\ttotal: 15.8s\tremaining: 7.35s\n",
      "682:\tlearn: 0.0563090\ttotal: 15.8s\tremaining: 7.32s\n",
      "683:\tlearn: 0.0562444\ttotal: 15.8s\tremaining: 7.3s\n",
      "684:\tlearn: 0.0561775\ttotal: 15.8s\tremaining: 7.28s\n",
      "685:\tlearn: 0.0560780\ttotal: 15.8s\tremaining: 7.25s\n",
      "686:\tlearn: 0.0560580\ttotal: 15.9s\tremaining: 7.24s\n",
      "687:\tlearn: 0.0559999\ttotal: 15.9s\tremaining: 7.21s\n",
      "688:\tlearn: 0.0559270\ttotal: 15.9s\tremaining: 7.19s\n",
      "689:\tlearn: 0.0559188\ttotal: 15.9s\tremaining: 7.16s\n",
      "690:\tlearn: 0.0558154\ttotal: 16s\tremaining: 7.14s\n",
      "691:\tlearn: 0.0557392\ttotal: 16s\tremaining: 7.12s\n",
      "692:\tlearn: 0.0556499\ttotal: 16s\tremaining: 7.09s\n",
      "693:\tlearn: 0.0555502\ttotal: 16s\tremaining: 7.07s\n",
      "694:\tlearn: 0.0554400\ttotal: 16.1s\tremaining: 7.05s\n",
      "695:\tlearn: 0.0554321\ttotal: 16.1s\tremaining: 7.02s\n",
      "696:\tlearn: 0.0553921\ttotal: 16.1s\tremaining: 7s\n",
      "697:\tlearn: 0.0552876\ttotal: 16.1s\tremaining: 6.98s\n",
      "698:\tlearn: 0.0551960\ttotal: 16.1s\tremaining: 6.95s\n",
      "699:\tlearn: 0.0551691\ttotal: 16.2s\tremaining: 6.93s\n",
      "700:\tlearn: 0.0550445\ttotal: 16.2s\tremaining: 6.91s\n",
      "701:\tlearn: 0.0549346\ttotal: 16.2s\tremaining: 6.88s\n",
      "702:\tlearn: 0.0548132\ttotal: 16.2s\tremaining: 6.86s\n",
      "703:\tlearn: 0.0547273\ttotal: 16.2s\tremaining: 6.83s\n",
      "704:\tlearn: 0.0546179\ttotal: 16.3s\tremaining: 6.81s\n",
      "705:\tlearn: 0.0545666\ttotal: 16.3s\tremaining: 6.78s\n",
      "706:\tlearn: 0.0544480\ttotal: 16.3s\tremaining: 6.76s\n",
      "707:\tlearn: 0.0543583\ttotal: 16.3s\tremaining: 6.74s\n",
      "708:\tlearn: 0.0543510\ttotal: 16.4s\tremaining: 6.71s\n",
      "709:\tlearn: 0.0542805\ttotal: 16.4s\tremaining: 6.69s\n",
      "710:\tlearn: 0.0541968\ttotal: 16.4s\tremaining: 6.67s\n",
      "711:\tlearn: 0.0541317\ttotal: 16.4s\tremaining: 6.64s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712:\tlearn: 0.0540569\ttotal: 16.5s\tremaining: 6.62s\n",
      "713:\tlearn: 0.0539614\ttotal: 16.5s\tremaining: 6.6s\n",
      "714:\tlearn: 0.0539338\ttotal: 16.5s\tremaining: 6.58s\n",
      "715:\tlearn: 0.0538974\ttotal: 16.5s\tremaining: 6.55s\n",
      "716:\tlearn: 0.0538448\ttotal: 16.5s\tremaining: 6.53s\n",
      "717:\tlearn: 0.0537341\ttotal: 16.6s\tremaining: 6.51s\n",
      "718:\tlearn: 0.0536306\ttotal: 16.6s\tremaining: 6.48s\n",
      "719:\tlearn: 0.0535936\ttotal: 16.6s\tremaining: 6.46s\n",
      "720:\tlearn: 0.0535358\ttotal: 16.6s\tremaining: 6.44s\n",
      "721:\tlearn: 0.0533894\ttotal: 16.7s\tremaining: 6.42s\n",
      "722:\tlearn: 0.0533823\ttotal: 16.7s\tremaining: 6.39s\n",
      "723:\tlearn: 0.0532780\ttotal: 16.7s\tremaining: 6.37s\n",
      "724:\tlearn: 0.0531829\ttotal: 16.7s\tremaining: 6.35s\n",
      "725:\tlearn: 0.0531147\ttotal: 16.8s\tremaining: 6.32s\n",
      "726:\tlearn: 0.0530801\ttotal: 16.8s\tremaining: 6.3s\n",
      "727:\tlearn: 0.0529816\ttotal: 16.8s\tremaining: 6.27s\n",
      "728:\tlearn: 0.0528890\ttotal: 16.8s\tremaining: 6.25s\n",
      "729:\tlearn: 0.0527773\ttotal: 16.8s\tremaining: 6.23s\n",
      "730:\tlearn: 0.0527145\ttotal: 16.9s\tremaining: 6.2s\n",
      "731:\tlearn: 0.0526118\ttotal: 16.9s\tremaining: 6.18s\n",
      "732:\tlearn: 0.0526059\ttotal: 16.9s\tremaining: 6.16s\n",
      "733:\tlearn: 0.0525367\ttotal: 16.9s\tremaining: 6.13s\n",
      "734:\tlearn: 0.0523989\ttotal: 16.9s\tremaining: 6.11s\n",
      "735:\tlearn: 0.0523025\ttotal: 17s\tremaining: 6.08s\n",
      "736:\tlearn: 0.0522338\ttotal: 17s\tremaining: 6.06s\n",
      "737:\tlearn: 0.0521057\ttotal: 17s\tremaining: 6.04s\n",
      "738:\tlearn: 0.0520122\ttotal: 17.1s\tremaining: 6.02s\n",
      "739:\tlearn: 0.0519340\ttotal: 17.1s\tremaining: 6s\n",
      "740:\tlearn: 0.0518286\ttotal: 17.1s\tremaining: 5.98s\n",
      "741:\tlearn: 0.0517794\ttotal: 17.1s\tremaining: 5.96s\n",
      "742:\tlearn: 0.0517488\ttotal: 17.2s\tremaining: 5.93s\n",
      "743:\tlearn: 0.0517426\ttotal: 17.2s\tremaining: 5.91s\n",
      "744:\tlearn: 0.0516006\ttotal: 17.2s\tremaining: 5.89s\n",
      "745:\tlearn: 0.0515408\ttotal: 17.2s\tremaining: 5.87s\n",
      "746:\tlearn: 0.0514474\ttotal: 17.3s\tremaining: 5.84s\n",
      "747:\tlearn: 0.0513504\ttotal: 17.3s\tremaining: 5.82s\n",
      "748:\tlearn: 0.0512696\ttotal: 17.3s\tremaining: 5.8s\n",
      "749:\tlearn: 0.0512052\ttotal: 17.3s\tremaining: 5.77s\n",
      "750:\tlearn: 0.0510935\ttotal: 17.3s\tremaining: 5.75s\n",
      "751:\tlearn: 0.0510729\ttotal: 17.4s\tremaining: 5.73s\n",
      "752:\tlearn: 0.0509569\ttotal: 17.4s\tremaining: 5.71s\n",
      "753:\tlearn: 0.0508310\ttotal: 17.4s\tremaining: 5.68s\n",
      "754:\tlearn: 0.0508250\ttotal: 17.4s\tremaining: 5.66s\n",
      "755:\tlearn: 0.0506915\ttotal: 17.5s\tremaining: 5.64s\n",
      "756:\tlearn: 0.0505778\ttotal: 17.5s\tremaining: 5.61s\n",
      "757:\tlearn: 0.0505055\ttotal: 17.5s\tremaining: 5.59s\n",
      "758:\tlearn: 0.0504386\ttotal: 17.5s\tremaining: 5.57s\n",
      "759:\tlearn: 0.0504024\ttotal: 17.6s\tremaining: 5.54s\n",
      "760:\tlearn: 0.0502547\ttotal: 17.6s\tremaining: 5.52s\n",
      "761:\tlearn: 0.0501748\ttotal: 17.6s\tremaining: 5.5s\n",
      "762:\tlearn: 0.0501346\ttotal: 17.6s\tremaining: 5.48s\n",
      "763:\tlearn: 0.0501288\ttotal: 17.7s\tremaining: 5.46s\n",
      "764:\tlearn: 0.0499475\ttotal: 17.7s\tremaining: 5.43s\n",
      "765:\tlearn: 0.0498180\ttotal: 17.7s\tremaining: 5.41s\n",
      "766:\tlearn: 0.0497885\ttotal: 17.7s\tremaining: 5.39s\n",
      "767:\tlearn: 0.0497298\ttotal: 17.8s\tremaining: 5.37s\n",
      "768:\tlearn: 0.0496593\ttotal: 17.8s\tremaining: 5.34s\n",
      "769:\tlearn: 0.0495947\ttotal: 17.8s\tremaining: 5.32s\n",
      "770:\tlearn: 0.0494970\ttotal: 17.8s\tremaining: 5.29s\n",
      "771:\tlearn: 0.0493782\ttotal: 17.9s\tremaining: 5.27s\n",
      "772:\tlearn: 0.0493132\ttotal: 17.9s\tremaining: 5.25s\n",
      "773:\tlearn: 0.0492145\ttotal: 17.9s\tremaining: 5.22s\n",
      "774:\tlearn: 0.0491833\ttotal: 17.9s\tremaining: 5.2s\n",
      "775:\tlearn: 0.0491652\ttotal: 17.9s\tremaining: 5.18s\n",
      "776:\tlearn: 0.0490632\ttotal: 18s\tremaining: 5.15s\n",
      "777:\tlearn: 0.0489581\ttotal: 18s\tremaining: 5.13s\n",
      "778:\tlearn: 0.0488877\ttotal: 18s\tremaining: 5.11s\n",
      "779:\tlearn: 0.0488568\ttotal: 18s\tremaining: 5.08s\n",
      "780:\tlearn: 0.0487693\ttotal: 18.1s\tremaining: 5.06s\n",
      "781:\tlearn: 0.0486634\ttotal: 18.1s\tremaining: 5.04s\n",
      "782:\tlearn: 0.0485553\ttotal: 18.1s\tremaining: 5.01s\n",
      "783:\tlearn: 0.0484852\ttotal: 18.1s\tremaining: 4.99s\n",
      "784:\tlearn: 0.0484342\ttotal: 18.1s\tremaining: 4.96s\n",
      "785:\tlearn: 0.0482684\ttotal: 18.1s\tremaining: 4.94s\n",
      "786:\tlearn: 0.0482448\ttotal: 18.2s\tremaining: 4.92s\n",
      "787:\tlearn: 0.0481478\ttotal: 18.2s\tremaining: 4.89s\n",
      "788:\tlearn: 0.0481190\ttotal: 18.2s\tremaining: 4.87s\n",
      "789:\tlearn: 0.0480165\ttotal: 18.2s\tremaining: 4.84s\n",
      "790:\tlearn: 0.0479408\ttotal: 18.2s\tremaining: 4.82s\n",
      "791:\tlearn: 0.0478346\ttotal: 18.3s\tremaining: 4.8s\n",
      "792:\tlearn: 0.0477682\ttotal: 18.3s\tremaining: 4.77s\n",
      "793:\tlearn: 0.0477332\ttotal: 18.3s\tremaining: 4.75s\n",
      "794:\tlearn: 0.0476257\ttotal: 18.3s\tremaining: 4.72s\n",
      "795:\tlearn: 0.0475385\ttotal: 18.4s\tremaining: 4.7s\n",
      "796:\tlearn: 0.0475004\ttotal: 18.4s\tremaining: 4.68s\n",
      "797:\tlearn: 0.0474231\ttotal: 18.4s\tremaining: 4.66s\n",
      "798:\tlearn: 0.0473198\ttotal: 18.4s\tremaining: 4.63s\n",
      "799:\tlearn: 0.0472583\ttotal: 18.5s\tremaining: 4.61s\n",
      "800:\tlearn: 0.0471713\ttotal: 18.5s\tremaining: 4.59s\n",
      "801:\tlearn: 0.0470718\ttotal: 18.5s\tremaining: 4.57s\n",
      "802:\tlearn: 0.0470478\ttotal: 18.5s\tremaining: 4.54s\n",
      "803:\tlearn: 0.0469913\ttotal: 18.5s\tremaining: 4.52s\n",
      "804:\tlearn: 0.0469338\ttotal: 18.6s\tremaining: 4.5s\n",
      "805:\tlearn: 0.0468697\ttotal: 18.6s\tremaining: 4.47s\n",
      "806:\tlearn: 0.0467796\ttotal: 18.6s\tremaining: 4.45s\n",
      "807:\tlearn: 0.0467061\ttotal: 18.6s\tremaining: 4.43s\n",
      "808:\tlearn: 0.0467011\ttotal: 18.7s\tremaining: 4.41s\n",
      "809:\tlearn: 0.0466503\ttotal: 18.7s\tremaining: 4.38s\n",
      "810:\tlearn: 0.0465780\ttotal: 18.7s\tremaining: 4.36s\n",
      "811:\tlearn: 0.0465129\ttotal: 18.7s\tremaining: 4.33s\n",
      "812:\tlearn: 0.0464582\ttotal: 18.7s\tremaining: 4.31s\n",
      "813:\tlearn: 0.0463187\ttotal: 18.8s\tremaining: 4.29s\n",
      "814:\tlearn: 0.0462407\ttotal: 18.8s\tremaining: 4.26s\n",
      "815:\tlearn: 0.0462277\ttotal: 18.8s\tremaining: 4.24s\n",
      "816:\tlearn: 0.0461543\ttotal: 18.8s\tremaining: 4.22s\n",
      "817:\tlearn: 0.0460951\ttotal: 18.9s\tremaining: 4.19s\n",
      "818:\tlearn: 0.0460219\ttotal: 18.9s\tremaining: 4.17s\n",
      "819:\tlearn: 0.0459450\ttotal: 18.9s\tremaining: 4.15s\n",
      "820:\tlearn: 0.0459128\ttotal: 18.9s\tremaining: 4.13s\n",
      "821:\tlearn: 0.0458676\ttotal: 19s\tremaining: 4.1s\n",
      "822:\tlearn: 0.0457874\ttotal: 19s\tremaining: 4.08s\n",
      "823:\tlearn: 0.0457084\ttotal: 19s\tremaining: 4.06s\n",
      "824:\tlearn: 0.0456500\ttotal: 19s\tremaining: 4.03s\n",
      "825:\tlearn: 0.0455728\ttotal: 19s\tremaining: 4.01s\n",
      "826:\tlearn: 0.0455222\ttotal: 19s\tremaining: 3.98s\n",
      "827:\tlearn: 0.0454373\ttotal: 19.1s\tremaining: 3.96s\n",
      "828:\tlearn: 0.0453714\ttotal: 19.1s\tremaining: 3.94s\n",
      "829:\tlearn: 0.0452782\ttotal: 19.1s\tremaining: 3.91s\n",
      "830:\tlearn: 0.0452307\ttotal: 19.1s\tremaining: 3.89s\n",
      "831:\tlearn: 0.0452130\ttotal: 19.1s\tremaining: 3.87s\n",
      "832:\tlearn: 0.0451824\ttotal: 19.2s\tremaining: 3.84s\n",
      "833:\tlearn: 0.0451759\ttotal: 19.2s\tremaining: 3.82s\n",
      "834:\tlearn: 0.0450889\ttotal: 19.2s\tremaining: 3.8s\n",
      "835:\tlearn: 0.0450514\ttotal: 19.2s\tremaining: 3.77s\n",
      "836:\tlearn: 0.0450000\ttotal: 19.3s\tremaining: 3.75s\n",
      "837:\tlearn: 0.0449312\ttotal: 19.3s\tremaining: 3.73s\n",
      "838:\tlearn: 0.0449229\ttotal: 19.3s\tremaining: 3.7s\n",
      "839:\tlearn: 0.0448437\ttotal: 19.3s\tremaining: 3.68s\n",
      "840:\tlearn: 0.0447697\ttotal: 19.3s\tremaining: 3.66s\n",
      "841:\tlearn: 0.0447216\ttotal: 19.4s\tremaining: 3.63s\n",
      "842:\tlearn: 0.0447063\ttotal: 19.4s\tremaining: 3.61s\n",
      "843:\tlearn: 0.0446542\ttotal: 19.4s\tremaining: 3.59s\n",
      "844:\tlearn: 0.0446037\ttotal: 19.4s\tremaining: 3.56s\n",
      "845:\tlearn: 0.0445460\ttotal: 19.5s\tremaining: 3.54s\n",
      "846:\tlearn: 0.0444701\ttotal: 19.5s\tremaining: 3.52s\n",
      "847:\tlearn: 0.0444388\ttotal: 19.5s\tremaining: 3.49s\n",
      "848:\tlearn: 0.0443702\ttotal: 19.5s\tremaining: 3.47s\n",
      "849:\tlearn: 0.0443109\ttotal: 19.5s\tremaining: 3.45s\n",
      "850:\tlearn: 0.0442813\ttotal: 19.6s\tremaining: 3.42s\n",
      "851:\tlearn: 0.0441975\ttotal: 19.6s\tremaining: 3.4s\n",
      "852:\tlearn: 0.0440929\ttotal: 19.6s\tremaining: 3.38s\n",
      "853:\tlearn: 0.0440420\ttotal: 19.6s\tremaining: 3.35s\n",
      "854:\tlearn: 0.0440252\ttotal: 19.6s\tremaining: 3.33s\n",
      "855:\tlearn: 0.0439498\ttotal: 19.7s\tremaining: 3.31s\n",
      "856:\tlearn: 0.0438676\ttotal: 19.7s\tremaining: 3.28s\n",
      "857:\tlearn: 0.0437779\ttotal: 19.7s\tremaining: 3.26s\n",
      "858:\tlearn: 0.0436622\ttotal: 19.7s\tremaining: 3.24s\n",
      "859:\tlearn: 0.0436095\ttotal: 19.7s\tremaining: 3.21s\n",
      "860:\tlearn: 0.0435308\ttotal: 19.8s\tremaining: 3.19s\n",
      "861:\tlearn: 0.0434833\ttotal: 19.8s\tremaining: 3.17s\n",
      "862:\tlearn: 0.0434141\ttotal: 19.8s\tremaining: 3.15s\n",
      "863:\tlearn: 0.0433917\ttotal: 19.9s\tremaining: 3.13s\n",
      "864:\tlearn: 0.0433088\ttotal: 19.9s\tremaining: 3.1s\n",
      "865:\tlearn: 0.0432428\ttotal: 19.9s\tremaining: 3.08s\n",
      "866:\tlearn: 0.0431873\ttotal: 19.9s\tremaining: 3.06s\n",
      "867:\tlearn: 0.0431831\ttotal: 20s\tremaining: 3.03s\n",
      "868:\tlearn: 0.0430885\ttotal: 20s\tremaining: 3.01s\n",
      "869:\tlearn: 0.0430642\ttotal: 20s\tremaining: 2.99s\n",
      "870:\tlearn: 0.0430593\ttotal: 20s\tremaining: 2.97s\n",
      "871:\tlearn: 0.0429987\ttotal: 20.1s\tremaining: 2.94s\n",
      "872:\tlearn: 0.0429312\ttotal: 20.1s\tremaining: 2.92s\n",
      "873:\tlearn: 0.0428543\ttotal: 20.1s\tremaining: 2.9s\n",
      "874:\tlearn: 0.0427621\ttotal: 20.1s\tremaining: 2.88s\n",
      "875:\tlearn: 0.0427058\ttotal: 20.2s\tremaining: 2.85s\n",
      "876:\tlearn: 0.0426043\ttotal: 20.2s\tremaining: 2.83s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "877:\tlearn: 0.0425548\ttotal: 20.2s\tremaining: 2.81s\n",
      "878:\tlearn: 0.0425108\ttotal: 20.2s\tremaining: 2.79s\n",
      "879:\tlearn: 0.0424941\ttotal: 20.3s\tremaining: 2.76s\n",
      "880:\tlearn: 0.0424359\ttotal: 20.3s\tremaining: 2.74s\n",
      "881:\tlearn: 0.0423977\ttotal: 20.3s\tremaining: 2.71s\n",
      "882:\tlearn: 0.0423570\ttotal: 20.3s\tremaining: 2.69s\n",
      "883:\tlearn: 0.0422872\ttotal: 20.3s\tremaining: 2.67s\n",
      "884:\tlearn: 0.0422827\ttotal: 20.4s\tremaining: 2.65s\n",
      "885:\tlearn: 0.0422118\ttotal: 20.4s\tremaining: 2.62s\n",
      "886:\tlearn: 0.0421510\ttotal: 20.4s\tremaining: 2.6s\n",
      "887:\tlearn: 0.0421043\ttotal: 20.4s\tremaining: 2.58s\n",
      "888:\tlearn: 0.0420225\ttotal: 20.5s\tremaining: 2.55s\n",
      "889:\tlearn: 0.0420145\ttotal: 20.5s\tremaining: 2.53s\n",
      "890:\tlearn: 0.0419529\ttotal: 20.5s\tremaining: 2.51s\n",
      "891:\tlearn: 0.0419022\ttotal: 20.5s\tremaining: 2.48s\n",
      "892:\tlearn: 0.0418741\ttotal: 20.5s\tremaining: 2.46s\n",
      "893:\tlearn: 0.0418009\ttotal: 20.6s\tremaining: 2.44s\n",
      "894:\tlearn: 0.0417663\ttotal: 20.6s\tremaining: 2.41s\n",
      "895:\tlearn: 0.0417037\ttotal: 20.6s\tremaining: 2.39s\n",
      "896:\tlearn: 0.0416836\ttotal: 20.6s\tremaining: 2.37s\n",
      "897:\tlearn: 0.0416153\ttotal: 20.6s\tremaining: 2.35s\n",
      "898:\tlearn: 0.0415421\ttotal: 20.7s\tremaining: 2.32s\n",
      "899:\tlearn: 0.0414287\ttotal: 20.7s\tremaining: 2.3s\n",
      "900:\tlearn: 0.0414176\ttotal: 20.7s\tremaining: 2.28s\n",
      "901:\tlearn: 0.0413512\ttotal: 20.7s\tremaining: 2.25s\n",
      "902:\tlearn: 0.0413126\ttotal: 20.8s\tremaining: 2.23s\n",
      "903:\tlearn: 0.0412336\ttotal: 20.8s\tremaining: 2.21s\n",
      "904:\tlearn: 0.0411819\ttotal: 20.8s\tremaining: 2.18s\n",
      "905:\tlearn: 0.0411728\ttotal: 20.8s\tremaining: 2.16s\n",
      "906:\tlearn: 0.0411687\ttotal: 20.9s\tremaining: 2.14s\n",
      "907:\tlearn: 0.0411428\ttotal: 20.9s\tremaining: 2.11s\n",
      "908:\tlearn: 0.0410541\ttotal: 20.9s\tremaining: 2.09s\n",
      "909:\tlearn: 0.0409988\ttotal: 20.9s\tremaining: 2.07s\n",
      "910:\tlearn: 0.0409576\ttotal: 20.9s\tremaining: 2.04s\n",
      "911:\tlearn: 0.0408968\ttotal: 21s\tremaining: 2.02s\n",
      "912:\tlearn: 0.0408297\ttotal: 21s\tremaining: 2s\n",
      "913:\tlearn: 0.0407652\ttotal: 21s\tremaining: 1.98s\n",
      "914:\tlearn: 0.0407183\ttotal: 21s\tremaining: 1.95s\n",
      "915:\tlearn: 0.0406433\ttotal: 21.1s\tremaining: 1.93s\n",
      "916:\tlearn: 0.0405527\ttotal: 21.1s\tremaining: 1.91s\n",
      "917:\tlearn: 0.0405152\ttotal: 21.1s\tremaining: 1.88s\n",
      "918:\tlearn: 0.0405112\ttotal: 21.1s\tremaining: 1.86s\n",
      "919:\tlearn: 0.0404434\ttotal: 21.1s\tremaining: 1.84s\n",
      "920:\tlearn: 0.0403711\ttotal: 21.2s\tremaining: 1.81s\n",
      "921:\tlearn: 0.0402933\ttotal: 21.2s\tremaining: 1.79s\n",
      "922:\tlearn: 0.0402223\ttotal: 21.2s\tremaining: 1.77s\n",
      "923:\tlearn: 0.0401773\ttotal: 21.2s\tremaining: 1.75s\n",
      "924:\tlearn: 0.0401550\ttotal: 21.2s\tremaining: 1.72s\n",
      "925:\tlearn: 0.0401454\ttotal: 21.3s\tremaining: 1.7s\n",
      "926:\tlearn: 0.0400672\ttotal: 21.3s\tremaining: 1.68s\n",
      "927:\tlearn: 0.0400257\ttotal: 21.3s\tremaining: 1.65s\n",
      "928:\tlearn: 0.0400172\ttotal: 21.3s\tremaining: 1.63s\n",
      "929:\tlearn: 0.0399643\ttotal: 21.4s\tremaining: 1.61s\n",
      "930:\tlearn: 0.0399442\ttotal: 21.4s\tremaining: 1.58s\n",
      "931:\tlearn: 0.0399047\ttotal: 21.4s\tremaining: 1.56s\n",
      "932:\tlearn: 0.0398249\ttotal: 21.4s\tremaining: 1.54s\n",
      "933:\tlearn: 0.0398056\ttotal: 21.5s\tremaining: 1.51s\n",
      "934:\tlearn: 0.0396756\ttotal: 21.5s\tremaining: 1.49s\n",
      "935:\tlearn: 0.0396229\ttotal: 21.5s\tremaining: 1.47s\n",
      "936:\tlearn: 0.0396158\ttotal: 21.5s\tremaining: 1.45s\n",
      "937:\tlearn: 0.0395793\ttotal: 21.5s\tremaining: 1.42s\n",
      "938:\tlearn: 0.0394980\ttotal: 21.6s\tremaining: 1.4s\n",
      "939:\tlearn: 0.0394520\ttotal: 21.6s\tremaining: 1.38s\n",
      "940:\tlearn: 0.0393798\ttotal: 21.6s\tremaining: 1.35s\n",
      "941:\tlearn: 0.0393194\ttotal: 21.6s\tremaining: 1.33s\n",
      "942:\tlearn: 0.0392802\ttotal: 21.6s\tremaining: 1.31s\n",
      "943:\tlearn: 0.0392211\ttotal: 21.7s\tremaining: 1.28s\n",
      "944:\tlearn: 0.0391948\ttotal: 21.7s\tremaining: 1.26s\n",
      "945:\tlearn: 0.0391091\ttotal: 21.7s\tremaining: 1.24s\n",
      "946:\tlearn: 0.0390262\ttotal: 21.7s\tremaining: 1.22s\n",
      "947:\tlearn: 0.0389747\ttotal: 21.8s\tremaining: 1.19s\n",
      "948:\tlearn: 0.0389699\ttotal: 21.8s\tremaining: 1.17s\n",
      "949:\tlearn: 0.0389209\ttotal: 21.8s\tremaining: 1.15s\n",
      "950:\tlearn: 0.0388364\ttotal: 21.8s\tremaining: 1.12s\n",
      "951:\tlearn: 0.0387889\ttotal: 21.9s\tremaining: 1.1s\n",
      "952:\tlearn: 0.0387385\ttotal: 21.9s\tremaining: 1.08s\n",
      "953:\tlearn: 0.0386755\ttotal: 21.9s\tremaining: 1.05s\n",
      "954:\tlearn: 0.0386012\ttotal: 21.9s\tremaining: 1.03s\n",
      "955:\tlearn: 0.0385776\ttotal: 21.9s\tremaining: 1.01s\n",
      "956:\tlearn: 0.0384954\ttotal: 22s\tremaining: 987ms\n",
      "957:\tlearn: 0.0384302\ttotal: 22s\tremaining: 964ms\n",
      "958:\tlearn: 0.0384172\ttotal: 22s\tremaining: 941ms\n",
      "959:\tlearn: 0.0383937\ttotal: 22s\tremaining: 918ms\n",
      "960:\tlearn: 0.0383481\ttotal: 22.1s\tremaining: 895ms\n",
      "961:\tlearn: 0.0382866\ttotal: 22.1s\tremaining: 872ms\n",
      "962:\tlearn: 0.0382365\ttotal: 22.1s\tremaining: 849ms\n",
      "963:\tlearn: 0.0381756\ttotal: 22.1s\tremaining: 826ms\n",
      "964:\tlearn: 0.0381202\ttotal: 22.1s\tremaining: 803ms\n",
      "965:\tlearn: 0.0380715\ttotal: 22.2s\tremaining: 780ms\n",
      "966:\tlearn: 0.0380168\ttotal: 22.2s\tremaining: 757ms\n",
      "967:\tlearn: 0.0378476\ttotal: 22.2s\tremaining: 734ms\n",
      "968:\tlearn: 0.0377910\ttotal: 22.2s\tremaining: 711ms\n",
      "969:\tlearn: 0.0377706\ttotal: 22.2s\tremaining: 688ms\n",
      "970:\tlearn: 0.0377020\ttotal: 22.3s\tremaining: 665ms\n",
      "971:\tlearn: 0.0376387\ttotal: 22.3s\tremaining: 642ms\n",
      "972:\tlearn: 0.0376180\ttotal: 22.3s\tremaining: 619ms\n",
      "973:\tlearn: 0.0375446\ttotal: 22.3s\tremaining: 596ms\n",
      "974:\tlearn: 0.0375327\ttotal: 22.4s\tremaining: 573ms\n",
      "975:\tlearn: 0.0375142\ttotal: 22.4s\tremaining: 550ms\n",
      "976:\tlearn: 0.0374611\ttotal: 22.4s\tremaining: 527ms\n",
      "977:\tlearn: 0.0373959\ttotal: 22.4s\tremaining: 504ms\n",
      "978:\tlearn: 0.0373796\ttotal: 22.4s\tremaining: 481ms\n",
      "979:\tlearn: 0.0372907\ttotal: 22.5s\tremaining: 458ms\n",
      "980:\tlearn: 0.0372874\ttotal: 22.5s\tremaining: 435ms\n",
      "981:\tlearn: 0.0372450\ttotal: 22.5s\tremaining: 412ms\n",
      "982:\tlearn: 0.0372160\ttotal: 22.5s\tremaining: 389ms\n",
      "983:\tlearn: 0.0371636\ttotal: 22.5s\tremaining: 367ms\n",
      "984:\tlearn: 0.0371231\ttotal: 22.6s\tremaining: 344ms\n",
      "985:\tlearn: 0.0370572\ttotal: 22.6s\tremaining: 321ms\n",
      "986:\tlearn: 0.0370343\ttotal: 22.6s\tremaining: 298ms\n",
      "987:\tlearn: 0.0369766\ttotal: 22.6s\tremaining: 275ms\n",
      "988:\tlearn: 0.0369283\ttotal: 22.6s\tremaining: 252ms\n",
      "989:\tlearn: 0.0369242\ttotal: 22.7s\tremaining: 229ms\n",
      "990:\tlearn: 0.0368752\ttotal: 22.7s\tremaining: 206ms\n",
      "991:\tlearn: 0.0368027\ttotal: 22.7s\tremaining: 183ms\n",
      "992:\tlearn: 0.0367822\ttotal: 22.7s\tremaining: 160ms\n",
      "993:\tlearn: 0.0367248\ttotal: 22.8s\tremaining: 137ms\n",
      "994:\tlearn: 0.0366567\ttotal: 22.8s\tremaining: 114ms\n",
      "995:\tlearn: 0.0366037\ttotal: 22.8s\tremaining: 91.6ms\n",
      "996:\tlearn: 0.0366005\ttotal: 22.8s\tremaining: 68.7ms\n",
      "997:\tlearn: 0.0365294\ttotal: 22.8s\tremaining: 45.8ms\n",
      "998:\tlearn: 0.0364805\ttotal: 22.9s\tremaining: 22.9ms\n",
      "999:\tlearn: 0.0364139\ttotal: 22.9s\tremaining: 0us\n",
      "Learning rate set to 0.018893\n",
      "0:\tlearn: 0.6675876\ttotal: 36.3ms\tremaining: 36.3s\n",
      "1:\tlearn: 0.6424392\ttotal: 60.7ms\tremaining: 30.3s\n",
      "2:\tlearn: 0.6222066\ttotal: 87.5ms\tremaining: 29.1s\n",
      "3:\tlearn: 0.6023577\ttotal: 110ms\tremaining: 27.5s\n",
      "4:\tlearn: 0.5854606\ttotal: 133ms\tremaining: 26.4s\n",
      "5:\tlearn: 0.5639603\ttotal: 152ms\tremaining: 25.2s\n",
      "6:\tlearn: 0.5482255\ttotal: 172ms\tremaining: 24.4s\n",
      "7:\tlearn: 0.5358321\ttotal: 194ms\tremaining: 24.1s\n",
      "8:\tlearn: 0.5193996\ttotal: 214ms\tremaining: 23.6s\n",
      "9:\tlearn: 0.5062073\ttotal: 236ms\tremaining: 23.3s\n",
      "10:\tlearn: 0.4989738\ttotal: 253ms\tremaining: 22.7s\n",
      "11:\tlearn: 0.4870253\ttotal: 271ms\tremaining: 22.3s\n",
      "12:\tlearn: 0.4750338\ttotal: 292ms\tremaining: 22.2s\n",
      "13:\tlearn: 0.4623075\ttotal: 312ms\tremaining: 22s\n",
      "14:\tlearn: 0.4528044\ttotal: 333ms\tremaining: 21.9s\n",
      "15:\tlearn: 0.4480425\ttotal: 352ms\tremaining: 21.7s\n",
      "16:\tlearn: 0.4380185\ttotal: 373ms\tremaining: 21.5s\n",
      "17:\tlearn: 0.4291668\ttotal: 393ms\tremaining: 21.4s\n",
      "18:\tlearn: 0.4186203\ttotal: 413ms\tremaining: 21.3s\n",
      "19:\tlearn: 0.4103539\ttotal: 435ms\tremaining: 21.3s\n",
      "20:\tlearn: 0.4016368\ttotal: 458ms\tremaining: 21.3s\n",
      "21:\tlearn: 0.3938512\ttotal: 480ms\tremaining: 21.3s\n",
      "22:\tlearn: 0.3879999\ttotal: 502ms\tremaining: 21.3s\n",
      "23:\tlearn: 0.3844783\ttotal: 524ms\tremaining: 21.3s\n",
      "24:\tlearn: 0.3781542\ttotal: 545ms\tremaining: 21.3s\n",
      "25:\tlearn: 0.3735345\ttotal: 567ms\tremaining: 21.3s\n",
      "26:\tlearn: 0.3677917\ttotal: 589ms\tremaining: 21.2s\n",
      "27:\tlearn: 0.3649653\ttotal: 613ms\tremaining: 21.3s\n",
      "28:\tlearn: 0.3584960\ttotal: 632ms\tremaining: 21.2s\n",
      "29:\tlearn: 0.3533299\ttotal: 652ms\tremaining: 21.1s\n",
      "30:\tlearn: 0.3503782\ttotal: 674ms\tremaining: 21.1s\n",
      "31:\tlearn: 0.3475654\ttotal: 694ms\tremaining: 21s\n",
      "32:\tlearn: 0.3413433\ttotal: 714ms\tremaining: 20.9s\n",
      "33:\tlearn: 0.3373884\ttotal: 733ms\tremaining: 20.8s\n",
      "34:\tlearn: 0.3352645\ttotal: 752ms\tremaining: 20.7s\n",
      "35:\tlearn: 0.3310620\ttotal: 774ms\tremaining: 20.7s\n",
      "36:\tlearn: 0.3291236\ttotal: 796ms\tremaining: 20.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37:\tlearn: 0.3261429\ttotal: 818ms\tremaining: 20.7s\n",
      "38:\tlearn: 0.3220714\ttotal: 839ms\tremaining: 20.7s\n",
      "39:\tlearn: 0.3193186\ttotal: 861ms\tremaining: 20.7s\n",
      "40:\tlearn: 0.3165580\ttotal: 883ms\tremaining: 20.7s\n",
      "41:\tlearn: 0.3132869\ttotal: 906ms\tremaining: 20.7s\n",
      "42:\tlearn: 0.3102363\ttotal: 928ms\tremaining: 20.6s\n",
      "43:\tlearn: 0.3066945\ttotal: 949ms\tremaining: 20.6s\n",
      "44:\tlearn: 0.3022531\ttotal: 983ms\tremaining: 20.9s\n",
      "45:\tlearn: 0.2997273\ttotal: 1.1s\tremaining: 22.8s\n",
      "46:\tlearn: 0.2958809\ttotal: 1.14s\tremaining: 23.2s\n",
      "47:\tlearn: 0.2933859\ttotal: 1.2s\tremaining: 23.7s\n",
      "48:\tlearn: 0.2915760\ttotal: 1.23s\tremaining: 24s\n",
      "49:\tlearn: 0.2874505\ttotal: 1.27s\tremaining: 24.2s\n",
      "50:\tlearn: 0.2846390\ttotal: 1.3s\tremaining: 24.3s\n",
      "51:\tlearn: 0.2822847\ttotal: 1.33s\tremaining: 24.3s\n",
      "52:\tlearn: 0.2787005\ttotal: 1.36s\tremaining: 24.3s\n",
      "53:\tlearn: 0.2757225\ttotal: 1.39s\tremaining: 24.3s\n",
      "54:\tlearn: 0.2729118\ttotal: 1.42s\tremaining: 24.4s\n",
      "55:\tlearn: 0.2694590\ttotal: 1.45s\tremaining: 24.4s\n",
      "56:\tlearn: 0.2677788\ttotal: 1.47s\tremaining: 24.4s\n",
      "57:\tlearn: 0.2653048\ttotal: 1.5s\tremaining: 24.4s\n",
      "58:\tlearn: 0.2623910\ttotal: 1.53s\tremaining: 24.4s\n",
      "59:\tlearn: 0.2606318\ttotal: 1.55s\tremaining: 24.3s\n",
      "60:\tlearn: 0.2581120\ttotal: 1.58s\tremaining: 24.4s\n",
      "61:\tlearn: 0.2567755\ttotal: 1.61s\tremaining: 24.3s\n",
      "62:\tlearn: 0.2550579\ttotal: 1.64s\tremaining: 24.3s\n",
      "63:\tlearn: 0.2520427\ttotal: 1.67s\tremaining: 24.4s\n",
      "64:\tlearn: 0.2502787\ttotal: 1.7s\tremaining: 24.4s\n",
      "65:\tlearn: 0.2477840\ttotal: 1.73s\tremaining: 24.5s\n",
      "66:\tlearn: 0.2464422\ttotal: 1.75s\tremaining: 24.5s\n",
      "67:\tlearn: 0.2441914\ttotal: 1.8s\tremaining: 24.6s\n",
      "68:\tlearn: 0.2420465\ttotal: 1.83s\tremaining: 24.6s\n",
      "69:\tlearn: 0.2409675\ttotal: 1.86s\tremaining: 24.7s\n",
      "70:\tlearn: 0.2391224\ttotal: 1.89s\tremaining: 24.7s\n",
      "71:\tlearn: 0.2371145\ttotal: 1.92s\tremaining: 24.8s\n",
      "72:\tlearn: 0.2355378\ttotal: 1.96s\tremaining: 24.8s\n",
      "73:\tlearn: 0.2344931\ttotal: 1.99s\tremaining: 24.9s\n",
      "74:\tlearn: 0.2332065\ttotal: 2.02s\tremaining: 24.9s\n",
      "75:\tlearn: 0.2316329\ttotal: 2.05s\tremaining: 25s\n",
      "76:\tlearn: 0.2303304\ttotal: 2.09s\tremaining: 25s\n",
      "77:\tlearn: 0.2292287\ttotal: 2.12s\tremaining: 25s\n",
      "78:\tlearn: 0.2283274\ttotal: 2.15s\tremaining: 25.1s\n",
      "79:\tlearn: 0.2267453\ttotal: 2.18s\tremaining: 25.1s\n",
      "80:\tlearn: 0.2260597\ttotal: 2.23s\tremaining: 25.3s\n",
      "81:\tlearn: 0.2242133\ttotal: 2.26s\tremaining: 25.3s\n",
      "82:\tlearn: 0.2226687\ttotal: 2.29s\tremaining: 25.3s\n",
      "83:\tlearn: 0.2216254\ttotal: 2.32s\tremaining: 25.4s\n",
      "84:\tlearn: 0.2205905\ttotal: 2.35s\tremaining: 25.4s\n",
      "85:\tlearn: 0.2187367\ttotal: 2.38s\tremaining: 25.3s\n",
      "86:\tlearn: 0.2173941\ttotal: 2.41s\tremaining: 25.3s\n",
      "87:\tlearn: 0.2165730\ttotal: 2.44s\tremaining: 25.3s\n",
      "88:\tlearn: 0.2153512\ttotal: 2.49s\tremaining: 25.5s\n",
      "89:\tlearn: 0.2144367\ttotal: 2.53s\tremaining: 25.6s\n",
      "90:\tlearn: 0.2133093\ttotal: 2.58s\tremaining: 25.7s\n",
      "91:\tlearn: 0.2120484\ttotal: 2.61s\tremaining: 25.8s\n",
      "92:\tlearn: 0.2109713\ttotal: 2.65s\tremaining: 25.8s\n",
      "93:\tlearn: 0.2096796\ttotal: 2.67s\tremaining: 25.8s\n",
      "94:\tlearn: 0.2080468\ttotal: 2.7s\tremaining: 25.8s\n",
      "95:\tlearn: 0.2071948\ttotal: 2.73s\tremaining: 25.7s\n",
      "96:\tlearn: 0.2064974\ttotal: 2.76s\tremaining: 25.7s\n",
      "97:\tlearn: 0.2056981\ttotal: 2.79s\tremaining: 25.6s\n",
      "98:\tlearn: 0.2047497\ttotal: 2.81s\tremaining: 25.6s\n",
      "99:\tlearn: 0.2037112\ttotal: 2.84s\tremaining: 25.5s\n",
      "100:\tlearn: 0.2023832\ttotal: 2.86s\tremaining: 25.5s\n",
      "101:\tlearn: 0.2014239\ttotal: 2.89s\tremaining: 25.4s\n",
      "102:\tlearn: 0.2002869\ttotal: 2.91s\tremaining: 25.4s\n",
      "103:\tlearn: 0.1992645\ttotal: 2.94s\tremaining: 25.3s\n",
      "104:\tlearn: 0.1976850\ttotal: 2.97s\tremaining: 25.3s\n",
      "105:\tlearn: 0.1966944\ttotal: 3s\tremaining: 25.3s\n",
      "106:\tlearn: 0.1958437\ttotal: 3.02s\tremaining: 25.2s\n",
      "107:\tlearn: 0.1950505\ttotal: 3.05s\tremaining: 25.2s\n",
      "108:\tlearn: 0.1942879\ttotal: 3.08s\tremaining: 25.2s\n",
      "109:\tlearn: 0.1930925\ttotal: 3.1s\tremaining: 25.1s\n",
      "110:\tlearn: 0.1923886\ttotal: 3.13s\tremaining: 25.1s\n",
      "111:\tlearn: 0.1917872\ttotal: 3.16s\tremaining: 25.1s\n",
      "112:\tlearn: 0.1907749\ttotal: 3.19s\tremaining: 25s\n",
      "113:\tlearn: 0.1901619\ttotal: 3.22s\tremaining: 25s\n",
      "114:\tlearn: 0.1894267\ttotal: 3.25s\tremaining: 25s\n",
      "115:\tlearn: 0.1884693\ttotal: 3.27s\tremaining: 24.9s\n",
      "116:\tlearn: 0.1877945\ttotal: 3.3s\tremaining: 24.9s\n",
      "117:\tlearn: 0.1865109\ttotal: 3.33s\tremaining: 24.9s\n",
      "118:\tlearn: 0.1860403\ttotal: 3.35s\tremaining: 24.8s\n",
      "119:\tlearn: 0.1852816\ttotal: 3.38s\tremaining: 24.8s\n",
      "120:\tlearn: 0.1845263\ttotal: 3.4s\tremaining: 24.7s\n",
      "121:\tlearn: 0.1832112\ttotal: 3.43s\tremaining: 24.7s\n",
      "122:\tlearn: 0.1827394\ttotal: 3.46s\tremaining: 24.6s\n",
      "123:\tlearn: 0.1821913\ttotal: 3.48s\tremaining: 24.6s\n",
      "124:\tlearn: 0.1815680\ttotal: 3.51s\tremaining: 24.5s\n",
      "125:\tlearn: 0.1811420\ttotal: 3.53s\tremaining: 24.5s\n",
      "126:\tlearn: 0.1800201\ttotal: 3.56s\tremaining: 24.5s\n",
      "127:\tlearn: 0.1789509\ttotal: 3.58s\tremaining: 24.4s\n",
      "128:\tlearn: 0.1775213\ttotal: 3.61s\tremaining: 24.4s\n",
      "129:\tlearn: 0.1768473\ttotal: 3.64s\tremaining: 24.3s\n",
      "130:\tlearn: 0.1759229\ttotal: 3.67s\tremaining: 24.3s\n",
      "131:\tlearn: 0.1755489\ttotal: 3.69s\tremaining: 24.3s\n",
      "132:\tlearn: 0.1745943\ttotal: 3.72s\tremaining: 24.3s\n",
      "133:\tlearn: 0.1736372\ttotal: 3.75s\tremaining: 24.2s\n",
      "134:\tlearn: 0.1727770\ttotal: 3.78s\tremaining: 24.2s\n",
      "135:\tlearn: 0.1720474\ttotal: 3.81s\tremaining: 24.2s\n",
      "136:\tlearn: 0.1711457\ttotal: 3.84s\tremaining: 24.2s\n",
      "137:\tlearn: 0.1704392\ttotal: 3.86s\tremaining: 24.1s\n",
      "138:\tlearn: 0.1699658\ttotal: 3.89s\tremaining: 24.1s\n",
      "139:\tlearn: 0.1693692\ttotal: 3.91s\tremaining: 24s\n",
      "140:\tlearn: 0.1688755\ttotal: 3.94s\tremaining: 24s\n",
      "141:\tlearn: 0.1681956\ttotal: 3.96s\tremaining: 23.9s\n",
      "142:\tlearn: 0.1676374\ttotal: 3.98s\tremaining: 23.9s\n",
      "143:\tlearn: 0.1671071\ttotal: 4.01s\tremaining: 23.8s\n",
      "144:\tlearn: 0.1663944\ttotal: 4.04s\tremaining: 23.8s\n",
      "145:\tlearn: 0.1658448\ttotal: 4.06s\tremaining: 23.8s\n",
      "146:\tlearn: 0.1652635\ttotal: 4.09s\tremaining: 23.7s\n",
      "147:\tlearn: 0.1648168\ttotal: 4.12s\tremaining: 23.7s\n",
      "148:\tlearn: 0.1641497\ttotal: 4.14s\tremaining: 23.7s\n",
      "149:\tlearn: 0.1634756\ttotal: 4.18s\tremaining: 23.7s\n",
      "150:\tlearn: 0.1628136\ttotal: 4.21s\tremaining: 23.7s\n",
      "151:\tlearn: 0.1623914\ttotal: 4.24s\tremaining: 23.7s\n",
      "152:\tlearn: 0.1618859\ttotal: 4.27s\tremaining: 23.7s\n",
      "153:\tlearn: 0.1614994\ttotal: 4.3s\tremaining: 23.6s\n",
      "154:\tlearn: 0.1605529\ttotal: 4.32s\tremaining: 23.6s\n",
      "155:\tlearn: 0.1598390\ttotal: 4.35s\tremaining: 23.5s\n",
      "156:\tlearn: 0.1592169\ttotal: 4.38s\tremaining: 23.5s\n",
      "157:\tlearn: 0.1589122\ttotal: 4.4s\tremaining: 23.5s\n",
      "158:\tlearn: 0.1580766\ttotal: 4.43s\tremaining: 23.4s\n",
      "159:\tlearn: 0.1576736\ttotal: 4.45s\tremaining: 23.4s\n",
      "160:\tlearn: 0.1571935\ttotal: 4.47s\tremaining: 23.3s\n",
      "161:\tlearn: 0.1567844\ttotal: 4.5s\tremaining: 23.3s\n",
      "162:\tlearn: 0.1563796\ttotal: 4.52s\tremaining: 23.2s\n",
      "163:\tlearn: 0.1558112\ttotal: 4.54s\tremaining: 23.1s\n",
      "164:\tlearn: 0.1552061\ttotal: 4.55s\tremaining: 23.1s\n",
      "165:\tlearn: 0.1546323\ttotal: 4.58s\tremaining: 23s\n",
      "166:\tlearn: 0.1540046\ttotal: 4.61s\tremaining: 23s\n",
      "167:\tlearn: 0.1535666\ttotal: 4.64s\tremaining: 23s\n",
      "168:\tlearn: 0.1531194\ttotal: 4.67s\tremaining: 23s\n",
      "169:\tlearn: 0.1526140\ttotal: 4.69s\tremaining: 22.9s\n",
      "170:\tlearn: 0.1521123\ttotal: 4.72s\tremaining: 22.9s\n",
      "171:\tlearn: 0.1515226\ttotal: 4.74s\tremaining: 22.8s\n",
      "172:\tlearn: 0.1510213\ttotal: 4.77s\tremaining: 22.8s\n",
      "173:\tlearn: 0.1506652\ttotal: 4.79s\tremaining: 22.7s\n",
      "174:\tlearn: 0.1499605\ttotal: 4.81s\tremaining: 22.7s\n",
      "175:\tlearn: 0.1496320\ttotal: 4.83s\tremaining: 22.6s\n",
      "176:\tlearn: 0.1493217\ttotal: 4.86s\tremaining: 22.6s\n",
      "177:\tlearn: 0.1487362\ttotal: 4.88s\tremaining: 22.6s\n",
      "178:\tlearn: 0.1481049\ttotal: 4.91s\tremaining: 22.5s\n",
      "179:\tlearn: 0.1476097\ttotal: 4.93s\tremaining: 22.5s\n",
      "180:\tlearn: 0.1470096\ttotal: 4.95s\tremaining: 22.4s\n",
      "181:\tlearn: 0.1465761\ttotal: 4.97s\tremaining: 22.4s\n",
      "182:\tlearn: 0.1461189\ttotal: 4.99s\tremaining: 22.3s\n",
      "183:\tlearn: 0.1454008\ttotal: 5.01s\tremaining: 22.2s\n",
      "184:\tlearn: 0.1448306\ttotal: 5.04s\tremaining: 22.2s\n",
      "185:\tlearn: 0.1444413\ttotal: 5.07s\tremaining: 22.2s\n",
      "186:\tlearn: 0.1440678\ttotal: 5.1s\tremaining: 22.2s\n",
      "187:\tlearn: 0.1437375\ttotal: 5.13s\tremaining: 22.2s\n",
      "188:\tlearn: 0.1433244\ttotal: 5.16s\tremaining: 22.1s\n",
      "189:\tlearn: 0.1430053\ttotal: 5.18s\tremaining: 22.1s\n",
      "190:\tlearn: 0.1424646\ttotal: 5.21s\tremaining: 22.1s\n",
      "191:\tlearn: 0.1419718\ttotal: 5.24s\tremaining: 22s\n",
      "192:\tlearn: 0.1416118\ttotal: 5.26s\tremaining: 22s\n",
      "193:\tlearn: 0.1411409\ttotal: 5.29s\tremaining: 22s\n",
      "194:\tlearn: 0.1406975\ttotal: 5.32s\tremaining: 21.9s\n",
      "195:\tlearn: 0.1403040\ttotal: 5.34s\tremaining: 21.9s\n",
      "196:\tlearn: 0.1399405\ttotal: 5.37s\tremaining: 21.9s\n",
      "197:\tlearn: 0.1395660\ttotal: 5.39s\tremaining: 21.8s\n",
      "198:\tlearn: 0.1389338\ttotal: 5.41s\tremaining: 21.8s\n",
      "199:\tlearn: 0.1385802\ttotal: 5.43s\tremaining: 21.7s\n",
      "200:\tlearn: 0.1381184\ttotal: 5.46s\tremaining: 21.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201:\tlearn: 0.1373885\ttotal: 5.48s\tremaining: 21.7s\n",
      "202:\tlearn: 0.1370132\ttotal: 5.51s\tremaining: 21.6s\n",
      "203:\tlearn: 0.1363628\ttotal: 5.53s\tremaining: 21.6s\n",
      "204:\tlearn: 0.1359037\ttotal: 5.55s\tremaining: 21.5s\n",
      "205:\tlearn: 0.1356687\ttotal: 5.58s\tremaining: 21.5s\n",
      "206:\tlearn: 0.1351653\ttotal: 5.6s\tremaining: 21.4s\n",
      "207:\tlearn: 0.1346839\ttotal: 5.62s\tremaining: 21.4s\n",
      "208:\tlearn: 0.1342997\ttotal: 5.64s\tremaining: 21.3s\n",
      "209:\tlearn: 0.1338781\ttotal: 5.66s\tremaining: 21.3s\n",
      "210:\tlearn: 0.1333585\ttotal: 5.68s\tremaining: 21.3s\n",
      "211:\tlearn: 0.1328799\ttotal: 5.71s\tremaining: 21.2s\n",
      "212:\tlearn: 0.1324001\ttotal: 5.73s\tremaining: 21.2s\n",
      "213:\tlearn: 0.1321020\ttotal: 5.75s\tremaining: 21.1s\n",
      "214:\tlearn: 0.1316608\ttotal: 5.77s\tremaining: 21.1s\n",
      "215:\tlearn: 0.1312219\ttotal: 5.79s\tremaining: 21s\n",
      "216:\tlearn: 0.1307803\ttotal: 5.81s\tremaining: 21s\n",
      "217:\tlearn: 0.1302535\ttotal: 5.83s\tremaining: 20.9s\n",
      "218:\tlearn: 0.1299565\ttotal: 5.86s\tremaining: 20.9s\n",
      "219:\tlearn: 0.1293729\ttotal: 5.88s\tremaining: 20.8s\n",
      "220:\tlearn: 0.1289499\ttotal: 5.9s\tremaining: 20.8s\n",
      "221:\tlearn: 0.1284756\ttotal: 5.93s\tremaining: 20.8s\n",
      "222:\tlearn: 0.1280965\ttotal: 5.95s\tremaining: 20.7s\n",
      "223:\tlearn: 0.1278001\ttotal: 5.97s\tremaining: 20.7s\n",
      "224:\tlearn: 0.1275351\ttotal: 5.99s\tremaining: 20.6s\n",
      "225:\tlearn: 0.1273157\ttotal: 6.01s\tremaining: 20.6s\n",
      "226:\tlearn: 0.1268804\ttotal: 6.04s\tremaining: 20.6s\n",
      "227:\tlearn: 0.1266606\ttotal: 6.07s\tremaining: 20.6s\n",
      "228:\tlearn: 0.1260960\ttotal: 6.1s\tremaining: 20.5s\n",
      "229:\tlearn: 0.1258581\ttotal: 6.12s\tremaining: 20.5s\n",
      "230:\tlearn: 0.1256688\ttotal: 6.15s\tremaining: 20.5s\n",
      "231:\tlearn: 0.1252299\ttotal: 6.17s\tremaining: 20.4s\n",
      "232:\tlearn: 0.1249553\ttotal: 6.19s\tremaining: 20.4s\n",
      "233:\tlearn: 0.1247022\ttotal: 6.22s\tremaining: 20.4s\n",
      "234:\tlearn: 0.1243941\ttotal: 6.24s\tremaining: 20.3s\n",
      "235:\tlearn: 0.1240401\ttotal: 6.26s\tremaining: 20.3s\n",
      "236:\tlearn: 0.1236229\ttotal: 6.28s\tremaining: 20.2s\n",
      "237:\tlearn: 0.1234487\ttotal: 6.31s\tremaining: 20.2s\n",
      "238:\tlearn: 0.1231849\ttotal: 6.33s\tremaining: 20.2s\n",
      "239:\tlearn: 0.1227959\ttotal: 6.35s\tremaining: 20.1s\n",
      "240:\tlearn: 0.1225144\ttotal: 6.38s\tremaining: 20.1s\n",
      "241:\tlearn: 0.1219922\ttotal: 6.4s\tremaining: 20s\n",
      "242:\tlearn: 0.1215584\ttotal: 6.42s\tremaining: 20s\n",
      "243:\tlearn: 0.1211502\ttotal: 6.44s\tremaining: 20s\n",
      "244:\tlearn: 0.1208685\ttotal: 6.46s\tremaining: 19.9s\n",
      "245:\tlearn: 0.1203970\ttotal: 6.49s\tremaining: 19.9s\n",
      "246:\tlearn: 0.1201785\ttotal: 6.51s\tremaining: 19.9s\n",
      "247:\tlearn: 0.1199122\ttotal: 6.54s\tremaining: 19.8s\n",
      "248:\tlearn: 0.1196777\ttotal: 6.56s\tremaining: 19.8s\n",
      "249:\tlearn: 0.1195142\ttotal: 6.58s\tremaining: 19.8s\n",
      "250:\tlearn: 0.1191378\ttotal: 6.61s\tremaining: 19.7s\n",
      "251:\tlearn: 0.1188878\ttotal: 6.63s\tremaining: 19.7s\n",
      "252:\tlearn: 0.1187062\ttotal: 6.65s\tremaining: 19.6s\n",
      "253:\tlearn: 0.1183994\ttotal: 6.67s\tremaining: 19.6s\n",
      "254:\tlearn: 0.1181482\ttotal: 6.69s\tremaining: 19.6s\n",
      "255:\tlearn: 0.1180174\ttotal: 6.71s\tremaining: 19.5s\n",
      "256:\tlearn: 0.1177753\ttotal: 6.74s\tremaining: 19.5s\n",
      "257:\tlearn: 0.1176106\ttotal: 6.76s\tremaining: 19.4s\n",
      "258:\tlearn: 0.1172357\ttotal: 6.79s\tremaining: 19.4s\n",
      "259:\tlearn: 0.1171004\ttotal: 6.81s\tremaining: 19.4s\n",
      "260:\tlearn: 0.1166466\ttotal: 6.83s\tremaining: 19.3s\n",
      "261:\tlearn: 0.1163510\ttotal: 6.85s\tremaining: 19.3s\n",
      "262:\tlearn: 0.1160222\ttotal: 6.87s\tremaining: 19.2s\n",
      "263:\tlearn: 0.1156373\ttotal: 6.89s\tremaining: 19.2s\n",
      "264:\tlearn: 0.1153176\ttotal: 6.92s\tremaining: 19.2s\n",
      "265:\tlearn: 0.1151698\ttotal: 6.95s\tremaining: 19.2s\n",
      "266:\tlearn: 0.1148412\ttotal: 6.97s\tremaining: 19.1s\n",
      "267:\tlearn: 0.1144957\ttotal: 7s\tremaining: 19.1s\n",
      "268:\tlearn: 0.1142867\ttotal: 7.02s\tremaining: 19.1s\n",
      "269:\tlearn: 0.1139677\ttotal: 7.04s\tremaining: 19s\n",
      "270:\tlearn: 0.1136483\ttotal: 7.06s\tremaining: 19s\n",
      "271:\tlearn: 0.1134710\ttotal: 7.08s\tremaining: 18.9s\n",
      "272:\tlearn: 0.1131199\ttotal: 7.1s\tremaining: 18.9s\n",
      "273:\tlearn: 0.1128108\ttotal: 7.12s\tremaining: 18.9s\n",
      "274:\tlearn: 0.1125281\ttotal: 7.14s\tremaining: 18.8s\n",
      "275:\tlearn: 0.1122525\ttotal: 7.16s\tremaining: 18.8s\n",
      "276:\tlearn: 0.1121309\ttotal: 7.18s\tremaining: 18.7s\n",
      "277:\tlearn: 0.1119645\ttotal: 7.2s\tremaining: 18.7s\n",
      "278:\tlearn: 0.1116346\ttotal: 7.23s\tremaining: 18.7s\n",
      "279:\tlearn: 0.1111975\ttotal: 7.26s\tremaining: 18.7s\n",
      "280:\tlearn: 0.1109975\ttotal: 7.28s\tremaining: 18.6s\n",
      "281:\tlearn: 0.1108633\ttotal: 7.3s\tremaining: 18.6s\n",
      "282:\tlearn: 0.1106534\ttotal: 7.32s\tremaining: 18.6s\n",
      "283:\tlearn: 0.1104184\ttotal: 7.35s\tremaining: 18.5s\n",
      "284:\tlearn: 0.1101508\ttotal: 7.37s\tremaining: 18.5s\n",
      "285:\tlearn: 0.1099004\ttotal: 7.39s\tremaining: 18.5s\n",
      "286:\tlearn: 0.1096890\ttotal: 7.42s\tremaining: 18.4s\n",
      "287:\tlearn: 0.1094122\ttotal: 7.45s\tremaining: 18.4s\n",
      "288:\tlearn: 0.1092390\ttotal: 7.46s\tremaining: 18.4s\n",
      "289:\tlearn: 0.1089785\ttotal: 7.48s\tremaining: 18.3s\n",
      "290:\tlearn: 0.1086938\ttotal: 7.5s\tremaining: 18.3s\n",
      "291:\tlearn: 0.1083942\ttotal: 7.52s\tremaining: 18.2s\n",
      "292:\tlearn: 0.1082053\ttotal: 7.54s\tremaining: 18.2s\n",
      "293:\tlearn: 0.1079881\ttotal: 7.57s\tremaining: 18.2s\n",
      "294:\tlearn: 0.1076699\ttotal: 7.59s\tremaining: 18.1s\n",
      "295:\tlearn: 0.1074860\ttotal: 7.61s\tremaining: 18.1s\n",
      "296:\tlearn: 0.1071846\ttotal: 7.63s\tremaining: 18.1s\n",
      "297:\tlearn: 0.1067748\ttotal: 7.66s\tremaining: 18s\n",
      "298:\tlearn: 0.1065374\ttotal: 7.68s\tremaining: 18s\n",
      "299:\tlearn: 0.1063917\ttotal: 7.71s\tremaining: 18s\n",
      "300:\tlearn: 0.1062375\ttotal: 7.73s\tremaining: 17.9s\n",
      "301:\tlearn: 0.1059652\ttotal: 7.75s\tremaining: 17.9s\n",
      "302:\tlearn: 0.1058107\ttotal: 7.77s\tremaining: 17.9s\n",
      "303:\tlearn: 0.1055092\ttotal: 7.8s\tremaining: 17.8s\n",
      "304:\tlearn: 0.1052763\ttotal: 7.81s\tremaining: 17.8s\n",
      "305:\tlearn: 0.1050630\ttotal: 7.83s\tremaining: 17.8s\n",
      "306:\tlearn: 0.1048423\ttotal: 7.86s\tremaining: 17.7s\n",
      "307:\tlearn: 0.1046702\ttotal: 7.89s\tremaining: 17.7s\n",
      "308:\tlearn: 0.1044356\ttotal: 7.91s\tremaining: 17.7s\n",
      "309:\tlearn: 0.1041679\ttotal: 7.93s\tremaining: 17.6s\n",
      "310:\tlearn: 0.1039956\ttotal: 7.95s\tremaining: 17.6s\n",
      "311:\tlearn: 0.1038098\ttotal: 7.97s\tremaining: 17.6s\n",
      "312:\tlearn: 0.1036505\ttotal: 7.99s\tremaining: 17.5s\n",
      "313:\tlearn: 0.1034878\ttotal: 8.01s\tremaining: 17.5s\n",
      "314:\tlearn: 0.1032641\ttotal: 8.03s\tremaining: 17.5s\n",
      "315:\tlearn: 0.1030448\ttotal: 8.05s\tremaining: 17.4s\n",
      "316:\tlearn: 0.1028482\ttotal: 8.08s\tremaining: 17.4s\n",
      "317:\tlearn: 0.1026598\ttotal: 8.1s\tremaining: 17.4s\n",
      "318:\tlearn: 0.1024196\ttotal: 8.13s\tremaining: 17.3s\n",
      "319:\tlearn: 0.1020721\ttotal: 8.15s\tremaining: 17.3s\n",
      "320:\tlearn: 0.1019252\ttotal: 8.17s\tremaining: 17.3s\n",
      "321:\tlearn: 0.1017101\ttotal: 8.19s\tremaining: 17.2s\n",
      "322:\tlearn: 0.1015507\ttotal: 8.21s\tremaining: 17.2s\n",
      "323:\tlearn: 0.1013267\ttotal: 8.22s\tremaining: 17.2s\n",
      "324:\tlearn: 0.1011780\ttotal: 8.24s\tremaining: 17.1s\n",
      "325:\tlearn: 0.1009862\ttotal: 8.26s\tremaining: 17.1s\n",
      "326:\tlearn: 0.1007987\ttotal: 8.28s\tremaining: 17s\n",
      "327:\tlearn: 0.1006645\ttotal: 8.31s\tremaining: 17s\n",
      "328:\tlearn: 0.1004548\ttotal: 8.33s\tremaining: 17s\n",
      "329:\tlearn: 0.1002944\ttotal: 8.35s\tremaining: 17s\n",
      "330:\tlearn: 0.1001288\ttotal: 8.38s\tremaining: 16.9s\n",
      "331:\tlearn: 0.0997957\ttotal: 8.4s\tremaining: 16.9s\n",
      "332:\tlearn: 0.0995901\ttotal: 8.42s\tremaining: 16.9s\n",
      "333:\tlearn: 0.0992104\ttotal: 8.44s\tremaining: 16.8s\n",
      "334:\tlearn: 0.0989366\ttotal: 8.46s\tremaining: 16.8s\n",
      "335:\tlearn: 0.0987827\ttotal: 8.49s\tremaining: 16.8s\n",
      "336:\tlearn: 0.0985205\ttotal: 8.51s\tremaining: 16.7s\n",
      "337:\tlearn: 0.0982972\ttotal: 8.54s\tremaining: 16.7s\n",
      "338:\tlearn: 0.0980069\ttotal: 8.57s\tremaining: 16.7s\n",
      "339:\tlearn: 0.0978375\ttotal: 8.59s\tremaining: 16.7s\n",
      "340:\tlearn: 0.0977690\ttotal: 8.61s\tremaining: 16.6s\n",
      "341:\tlearn: 0.0975058\ttotal: 8.63s\tremaining: 16.6s\n",
      "342:\tlearn: 0.0973097\ttotal: 8.65s\tremaining: 16.6s\n",
      "343:\tlearn: 0.0970743\ttotal: 8.68s\tremaining: 16.5s\n",
      "344:\tlearn: 0.0968746\ttotal: 8.7s\tremaining: 16.5s\n",
      "345:\tlearn: 0.0967622\ttotal: 8.72s\tremaining: 16.5s\n",
      "346:\tlearn: 0.0965892\ttotal: 8.75s\tremaining: 16.5s\n",
      "347:\tlearn: 0.0963964\ttotal: 8.78s\tremaining: 16.4s\n",
      "348:\tlearn: 0.0961947\ttotal: 8.8s\tremaining: 16.4s\n",
      "349:\tlearn: 0.0960082\ttotal: 8.82s\tremaining: 16.4s\n",
      "350:\tlearn: 0.0958374\ttotal: 8.84s\tremaining: 16.3s\n",
      "351:\tlearn: 0.0956522\ttotal: 8.86s\tremaining: 16.3s\n",
      "352:\tlearn: 0.0954966\ttotal: 8.88s\tremaining: 16.3s\n",
      "353:\tlearn: 0.0953289\ttotal: 8.9s\tremaining: 16.2s\n",
      "354:\tlearn: 0.0951099\ttotal: 8.92s\tremaining: 16.2s\n",
      "355:\tlearn: 0.0949046\ttotal: 8.94s\tremaining: 16.2s\n",
      "356:\tlearn: 0.0946966\ttotal: 8.97s\tremaining: 16.2s\n",
      "357:\tlearn: 0.0946152\ttotal: 8.99s\tremaining: 16.1s\n",
      "358:\tlearn: 0.0945007\ttotal: 9.04s\tremaining: 16.1s\n",
      "359:\tlearn: 0.0943382\ttotal: 9.06s\tremaining: 16.1s\n",
      "360:\tlearn: 0.0942152\ttotal: 9.08s\tremaining: 16.1s\n",
      "361:\tlearn: 0.0940467\ttotal: 9.1s\tremaining: 16s\n",
      "362:\tlearn: 0.0938378\ttotal: 9.13s\tremaining: 16s\n",
      "363:\tlearn: 0.0936326\ttotal: 9.16s\tremaining: 16s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "364:\tlearn: 0.0934855\ttotal: 9.19s\tremaining: 16s\n",
      "365:\tlearn: 0.0933247\ttotal: 9.21s\tremaining: 16s\n",
      "366:\tlearn: 0.0932448\ttotal: 9.24s\tremaining: 15.9s\n",
      "367:\tlearn: 0.0931034\ttotal: 9.27s\tremaining: 15.9s\n",
      "368:\tlearn: 0.0928042\ttotal: 9.31s\tremaining: 15.9s\n",
      "369:\tlearn: 0.0926352\ttotal: 9.34s\tremaining: 15.9s\n",
      "370:\tlearn: 0.0924169\ttotal: 9.37s\tremaining: 15.9s\n",
      "371:\tlearn: 0.0923132\ttotal: 9.39s\tremaining: 15.9s\n",
      "372:\tlearn: 0.0922073\ttotal: 9.42s\tremaining: 15.8s\n",
      "373:\tlearn: 0.0920962\ttotal: 9.45s\tremaining: 15.8s\n",
      "374:\tlearn: 0.0919732\ttotal: 9.47s\tremaining: 15.8s\n",
      "375:\tlearn: 0.0917374\ttotal: 9.5s\tremaining: 15.8s\n",
      "376:\tlearn: 0.0916268\ttotal: 9.52s\tremaining: 15.7s\n",
      "377:\tlearn: 0.0916178\ttotal: 9.54s\tremaining: 15.7s\n",
      "378:\tlearn: 0.0914760\ttotal: 9.57s\tremaining: 15.7s\n",
      "379:\tlearn: 0.0912658\ttotal: 9.59s\tremaining: 15.6s\n",
      "380:\tlearn: 0.0910693\ttotal: 9.62s\tremaining: 15.6s\n",
      "381:\tlearn: 0.0909257\ttotal: 9.65s\tremaining: 15.6s\n",
      "382:\tlearn: 0.0909174\ttotal: 9.67s\tremaining: 15.6s\n",
      "383:\tlearn: 0.0907662\ttotal: 9.7s\tremaining: 15.6s\n",
      "384:\tlearn: 0.0905547\ttotal: 9.73s\tremaining: 15.5s\n",
      "385:\tlearn: 0.0904717\ttotal: 9.76s\tremaining: 15.5s\n",
      "386:\tlearn: 0.0904316\ttotal: 9.79s\tremaining: 15.5s\n",
      "387:\tlearn: 0.0902403\ttotal: 9.82s\tremaining: 15.5s\n",
      "388:\tlearn: 0.0900807\ttotal: 9.84s\tremaining: 15.5s\n",
      "389:\tlearn: 0.0899380\ttotal: 9.86s\tremaining: 15.4s\n",
      "390:\tlearn: 0.0897787\ttotal: 9.89s\tremaining: 15.4s\n",
      "391:\tlearn: 0.0896198\ttotal: 9.91s\tremaining: 15.4s\n",
      "392:\tlearn: 0.0893776\ttotal: 9.93s\tremaining: 15.3s\n",
      "393:\tlearn: 0.0891943\ttotal: 9.95s\tremaining: 15.3s\n",
      "394:\tlearn: 0.0890542\ttotal: 9.97s\tremaining: 15.3s\n",
      "395:\tlearn: 0.0888942\ttotal: 10s\tremaining: 15.3s\n",
      "396:\tlearn: 0.0887453\ttotal: 10s\tremaining: 15.2s\n",
      "397:\tlearn: 0.0885828\ttotal: 10.1s\tremaining: 15.2s\n",
      "398:\tlearn: 0.0884210\ttotal: 10.1s\tremaining: 15.2s\n",
      "399:\tlearn: 0.0882964\ttotal: 10.1s\tremaining: 15.2s\n",
      "400:\tlearn: 0.0881454\ttotal: 10.1s\tremaining: 15.1s\n",
      "401:\tlearn: 0.0880587\ttotal: 10.1s\tremaining: 15.1s\n",
      "402:\tlearn: 0.0878848\ttotal: 10.2s\tremaining: 15.1s\n",
      "403:\tlearn: 0.0877077\ttotal: 10.2s\tremaining: 15s\n",
      "404:\tlearn: 0.0875237\ttotal: 10.2s\tremaining: 15s\n",
      "405:\tlearn: 0.0874591\ttotal: 10.2s\tremaining: 15s\n",
      "406:\tlearn: 0.0873491\ttotal: 10.3s\tremaining: 14.9s\n",
      "407:\tlearn: 0.0872592\ttotal: 10.3s\tremaining: 14.9s\n",
      "408:\tlearn: 0.0871126\ttotal: 10.3s\tremaining: 14.9s\n",
      "409:\tlearn: 0.0869706\ttotal: 10.3s\tremaining: 14.9s\n",
      "410:\tlearn: 0.0867172\ttotal: 10.3s\tremaining: 14.8s\n",
      "411:\tlearn: 0.0864798\ttotal: 10.4s\tremaining: 14.8s\n",
      "412:\tlearn: 0.0863992\ttotal: 10.4s\tremaining: 14.8s\n",
      "413:\tlearn: 0.0861962\ttotal: 10.4s\tremaining: 14.7s\n",
      "414:\tlearn: 0.0860366\ttotal: 10.4s\tremaining: 14.7s\n",
      "415:\tlearn: 0.0858307\ttotal: 10.5s\tremaining: 14.7s\n",
      "416:\tlearn: 0.0856955\ttotal: 10.5s\tremaining: 14.7s\n",
      "417:\tlearn: 0.0855454\ttotal: 10.5s\tremaining: 14.6s\n",
      "418:\tlearn: 0.0852782\ttotal: 10.5s\tremaining: 14.6s\n",
      "419:\tlearn: 0.0851190\ttotal: 10.6s\tremaining: 14.6s\n",
      "420:\tlearn: 0.0849178\ttotal: 10.6s\tremaining: 14.5s\n",
      "421:\tlearn: 0.0847159\ttotal: 10.6s\tremaining: 14.5s\n",
      "422:\tlearn: 0.0845966\ttotal: 10.6s\tremaining: 14.5s\n",
      "423:\tlearn: 0.0844248\ttotal: 10.6s\tremaining: 14.5s\n",
      "424:\tlearn: 0.0841775\ttotal: 10.7s\tremaining: 14.4s\n",
      "425:\tlearn: 0.0840507\ttotal: 10.7s\tremaining: 14.4s\n",
      "426:\tlearn: 0.0838940\ttotal: 10.7s\tremaining: 14.4s\n",
      "427:\tlearn: 0.0837481\ttotal: 10.7s\tremaining: 14.4s\n",
      "428:\tlearn: 0.0836373\ttotal: 10.8s\tremaining: 14.3s\n",
      "429:\tlearn: 0.0834233\ttotal: 10.8s\tremaining: 14.3s\n",
      "430:\tlearn: 0.0834084\ttotal: 10.8s\tremaining: 14.3s\n",
      "431:\tlearn: 0.0833875\ttotal: 10.8s\tremaining: 14.2s\n",
      "432:\tlearn: 0.0832678\ttotal: 10.9s\tremaining: 14.2s\n",
      "433:\tlearn: 0.0831365\ttotal: 10.9s\tremaining: 14.2s\n",
      "434:\tlearn: 0.0830095\ttotal: 10.9s\tremaining: 14.2s\n",
      "435:\tlearn: 0.0828176\ttotal: 10.9s\tremaining: 14.1s\n",
      "436:\tlearn: 0.0827066\ttotal: 10.9s\tremaining: 14.1s\n",
      "437:\tlearn: 0.0825293\ttotal: 11s\tremaining: 14.1s\n",
      "438:\tlearn: 0.0823968\ttotal: 11s\tremaining: 14s\n",
      "439:\tlearn: 0.0823800\ttotal: 11s\tremaining: 14s\n",
      "440:\tlearn: 0.0821935\ttotal: 11s\tremaining: 14s\n",
      "441:\tlearn: 0.0819814\ttotal: 11.1s\tremaining: 14s\n",
      "442:\tlearn: 0.0818196\ttotal: 11.1s\tremaining: 13.9s\n",
      "443:\tlearn: 0.0816855\ttotal: 11.1s\tremaining: 13.9s\n",
      "444:\tlearn: 0.0816740\ttotal: 11.1s\tremaining: 13.9s\n",
      "445:\tlearn: 0.0814833\ttotal: 11.2s\tremaining: 13.9s\n",
      "446:\tlearn: 0.0813236\ttotal: 11.2s\tremaining: 13.8s\n",
      "447:\tlearn: 0.0811606\ttotal: 11.2s\tremaining: 13.8s\n",
      "448:\tlearn: 0.0809920\ttotal: 11.2s\tremaining: 13.8s\n",
      "449:\tlearn: 0.0808175\ttotal: 11.2s\tremaining: 13.7s\n",
      "450:\tlearn: 0.0807488\ttotal: 11.3s\tremaining: 13.7s\n",
      "451:\tlearn: 0.0806856\ttotal: 11.3s\tremaining: 13.7s\n",
      "452:\tlearn: 0.0806511\ttotal: 11.3s\tremaining: 13.6s\n",
      "453:\tlearn: 0.0804865\ttotal: 11.3s\tremaining: 13.6s\n",
      "454:\tlearn: 0.0802069\ttotal: 11.4s\tremaining: 13.6s\n",
      "455:\tlearn: 0.0800536\ttotal: 11.4s\tremaining: 13.6s\n",
      "456:\tlearn: 0.0799222\ttotal: 11.4s\tremaining: 13.5s\n",
      "457:\tlearn: 0.0797151\ttotal: 11.4s\tremaining: 13.5s\n",
      "458:\tlearn: 0.0795055\ttotal: 11.4s\tremaining: 13.5s\n",
      "459:\tlearn: 0.0792500\ttotal: 11.5s\tremaining: 13.5s\n",
      "460:\tlearn: 0.0790490\ttotal: 11.5s\tremaining: 13.4s\n",
      "461:\tlearn: 0.0788539\ttotal: 11.5s\tremaining: 13.4s\n",
      "462:\tlearn: 0.0786295\ttotal: 11.5s\tremaining: 13.4s\n",
      "463:\tlearn: 0.0785443\ttotal: 11.6s\tremaining: 13.3s\n",
      "464:\tlearn: 0.0783238\ttotal: 11.6s\tremaining: 13.3s\n",
      "465:\tlearn: 0.0782054\ttotal: 11.6s\tremaining: 13.3s\n",
      "466:\tlearn: 0.0780239\ttotal: 11.6s\tremaining: 13.3s\n",
      "467:\tlearn: 0.0778778\ttotal: 11.6s\tremaining: 13.2s\n",
      "468:\tlearn: 0.0778486\ttotal: 11.7s\tremaining: 13.2s\n",
      "469:\tlearn: 0.0777363\ttotal: 11.7s\tremaining: 13.2s\n",
      "470:\tlearn: 0.0776171\ttotal: 11.7s\tremaining: 13.2s\n",
      "471:\tlearn: 0.0774830\ttotal: 11.7s\tremaining: 13.1s\n",
      "472:\tlearn: 0.0773416\ttotal: 11.8s\tremaining: 13.1s\n",
      "473:\tlearn: 0.0771324\ttotal: 11.8s\tremaining: 13.1s\n",
      "474:\tlearn: 0.0771104\ttotal: 11.8s\tremaining: 13s\n",
      "475:\tlearn: 0.0770365\ttotal: 11.8s\tremaining: 13s\n",
      "476:\tlearn: 0.0768670\ttotal: 11.8s\tremaining: 13s\n",
      "477:\tlearn: 0.0767652\ttotal: 11.9s\tremaining: 13s\n",
      "478:\tlearn: 0.0765907\ttotal: 11.9s\tremaining: 12.9s\n",
      "479:\tlearn: 0.0764431\ttotal: 11.9s\tremaining: 12.9s\n",
      "480:\tlearn: 0.0764210\ttotal: 11.9s\tremaining: 12.9s\n",
      "481:\tlearn: 0.0763017\ttotal: 11.9s\tremaining: 12.8s\n",
      "482:\tlearn: 0.0762779\ttotal: 12s\tremaining: 12.8s\n",
      "483:\tlearn: 0.0762176\ttotal: 12s\tremaining: 12.8s\n",
      "484:\tlearn: 0.0761112\ttotal: 12s\tremaining: 12.8s\n",
      "485:\tlearn: 0.0760879\ttotal: 12s\tremaining: 12.7s\n",
      "486:\tlearn: 0.0759584\ttotal: 12.1s\tremaining: 12.7s\n",
      "487:\tlearn: 0.0758332\ttotal: 12.1s\tremaining: 12.7s\n",
      "488:\tlearn: 0.0756566\ttotal: 12.1s\tremaining: 12.6s\n",
      "489:\tlearn: 0.0756404\ttotal: 12.1s\tremaining: 12.6s\n",
      "490:\tlearn: 0.0753302\ttotal: 12.1s\tremaining: 12.6s\n",
      "491:\tlearn: 0.0752142\ttotal: 12.2s\tremaining: 12.6s\n",
      "492:\tlearn: 0.0750721\ttotal: 12.2s\tremaining: 12.5s\n",
      "493:\tlearn: 0.0749302\ttotal: 12.2s\tremaining: 12.5s\n",
      "494:\tlearn: 0.0747788\ttotal: 12.2s\tremaining: 12.5s\n",
      "495:\tlearn: 0.0747667\ttotal: 12.3s\tremaining: 12.5s\n",
      "496:\tlearn: 0.0746274\ttotal: 12.3s\tremaining: 12.4s\n",
      "497:\tlearn: 0.0743913\ttotal: 12.3s\tremaining: 12.4s\n",
      "498:\tlearn: 0.0742275\ttotal: 12.3s\tremaining: 12.4s\n",
      "499:\tlearn: 0.0742141\ttotal: 12.4s\tremaining: 12.4s\n",
      "500:\tlearn: 0.0740231\ttotal: 12.4s\tremaining: 12.3s\n",
      "501:\tlearn: 0.0738667\ttotal: 12.4s\tremaining: 12.3s\n",
      "502:\tlearn: 0.0737521\ttotal: 12.4s\tremaining: 12.3s\n",
      "503:\tlearn: 0.0737354\ttotal: 12.4s\tremaining: 12.2s\n",
      "504:\tlearn: 0.0737165\ttotal: 12.5s\tremaining: 12.2s\n",
      "505:\tlearn: 0.0736383\ttotal: 12.5s\tremaining: 12.2s\n",
      "506:\tlearn: 0.0735212\ttotal: 12.5s\tremaining: 12.2s\n",
      "507:\tlearn: 0.0733627\ttotal: 12.5s\tremaining: 12.1s\n",
      "508:\tlearn: 0.0732967\ttotal: 12.6s\tremaining: 12.1s\n",
      "509:\tlearn: 0.0732836\ttotal: 12.6s\tremaining: 12.1s\n",
      "510:\tlearn: 0.0731546\ttotal: 12.6s\tremaining: 12.1s\n",
      "511:\tlearn: 0.0729843\ttotal: 12.6s\tremaining: 12s\n",
      "512:\tlearn: 0.0728641\ttotal: 12.7s\tremaining: 12s\n",
      "513:\tlearn: 0.0728539\ttotal: 12.7s\tremaining: 12s\n",
      "514:\tlearn: 0.0727970\ttotal: 12.7s\tremaining: 12s\n",
      "515:\tlearn: 0.0727674\ttotal: 12.7s\tremaining: 11.9s\n",
      "516:\tlearn: 0.0727526\ttotal: 12.7s\tremaining: 11.9s\n",
      "517:\tlearn: 0.0725834\ttotal: 12.8s\tremaining: 11.9s\n",
      "518:\tlearn: 0.0723769\ttotal: 12.8s\tremaining: 11.9s\n",
      "519:\tlearn: 0.0722329\ttotal: 12.8s\tremaining: 11.8s\n",
      "520:\tlearn: 0.0720518\ttotal: 12.8s\tremaining: 11.8s\n",
      "521:\tlearn: 0.0719321\ttotal: 12.9s\tremaining: 11.8s\n",
      "522:\tlearn: 0.0717245\ttotal: 12.9s\tremaining: 11.7s\n",
      "523:\tlearn: 0.0717105\ttotal: 12.9s\tremaining: 11.7s\n",
      "524:\tlearn: 0.0715764\ttotal: 12.9s\tremaining: 11.7s\n",
      "525:\tlearn: 0.0714986\ttotal: 13s\tremaining: 11.7s\n",
      "526:\tlearn: 0.0714168\ttotal: 13s\tremaining: 11.6s\n",
      "527:\tlearn: 0.0713081\ttotal: 13s\tremaining: 11.6s\n",
      "528:\tlearn: 0.0710377\ttotal: 13s\tremaining: 11.6s\n",
      "529:\tlearn: 0.0708677\ttotal: 13s\tremaining: 11.6s\n",
      "530:\tlearn: 0.0708246\ttotal: 13.1s\tremaining: 11.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "531:\tlearn: 0.0706739\ttotal: 13.1s\tremaining: 11.5s\n",
      "532:\tlearn: 0.0704929\ttotal: 13.1s\tremaining: 11.5s\n",
      "533:\tlearn: 0.0703427\ttotal: 13.1s\tremaining: 11.5s\n",
      "534:\tlearn: 0.0701487\ttotal: 13.2s\tremaining: 11.4s\n",
      "535:\tlearn: 0.0700023\ttotal: 13.2s\tremaining: 11.4s\n",
      "536:\tlearn: 0.0698671\ttotal: 13.2s\tremaining: 11.4s\n",
      "537:\tlearn: 0.0697211\ttotal: 13.2s\tremaining: 11.4s\n",
      "538:\tlearn: 0.0695898\ttotal: 13.2s\tremaining: 11.3s\n",
      "539:\tlearn: 0.0694194\ttotal: 13.3s\tremaining: 11.3s\n",
      "540:\tlearn: 0.0693503\ttotal: 13.3s\tremaining: 11.3s\n",
      "541:\tlearn: 0.0692727\ttotal: 13.3s\tremaining: 11.2s\n",
      "542:\tlearn: 0.0692496\ttotal: 13.3s\tremaining: 11.2s\n",
      "543:\tlearn: 0.0691436\ttotal: 13.4s\tremaining: 11.2s\n",
      "544:\tlearn: 0.0689881\ttotal: 13.4s\tremaining: 11.2s\n",
      "545:\tlearn: 0.0688280\ttotal: 13.4s\tremaining: 11.1s\n",
      "546:\tlearn: 0.0687685\ttotal: 13.4s\tremaining: 11.1s\n",
      "547:\tlearn: 0.0686508\ttotal: 13.4s\tremaining: 11.1s\n",
      "548:\tlearn: 0.0685230\ttotal: 13.4s\tremaining: 11s\n",
      "549:\tlearn: 0.0684001\ttotal: 13.5s\tremaining: 11s\n",
      "550:\tlearn: 0.0683726\ttotal: 13.5s\tremaining: 11s\n",
      "551:\tlearn: 0.0683608\ttotal: 13.5s\tremaining: 11s\n",
      "552:\tlearn: 0.0682326\ttotal: 13.5s\tremaining: 10.9s\n",
      "553:\tlearn: 0.0681058\ttotal: 13.6s\tremaining: 10.9s\n",
      "554:\tlearn: 0.0679648\ttotal: 13.6s\tremaining: 10.9s\n",
      "555:\tlearn: 0.0679526\ttotal: 13.6s\tremaining: 10.9s\n",
      "556:\tlearn: 0.0679440\ttotal: 13.6s\tremaining: 10.8s\n",
      "557:\tlearn: 0.0678553\ttotal: 13.6s\tremaining: 10.8s\n",
      "558:\tlearn: 0.0677043\ttotal: 13.7s\tremaining: 10.8s\n",
      "559:\tlearn: 0.0676689\ttotal: 13.7s\tremaining: 10.7s\n",
      "560:\tlearn: 0.0675742\ttotal: 13.7s\tremaining: 10.7s\n",
      "561:\tlearn: 0.0674030\ttotal: 13.7s\tremaining: 10.7s\n",
      "562:\tlearn: 0.0672725\ttotal: 13.7s\tremaining: 10.7s\n",
      "563:\tlearn: 0.0671567\ttotal: 13.8s\tremaining: 10.6s\n",
      "564:\tlearn: 0.0670275\ttotal: 13.8s\tremaining: 10.6s\n",
      "565:\tlearn: 0.0669124\ttotal: 13.8s\tremaining: 10.6s\n",
      "566:\tlearn: 0.0669033\ttotal: 13.8s\tremaining: 10.6s\n",
      "567:\tlearn: 0.0668109\ttotal: 13.9s\tremaining: 10.5s\n",
      "568:\tlearn: 0.0668016\ttotal: 13.9s\tremaining: 10.5s\n",
      "569:\tlearn: 0.0666643\ttotal: 13.9s\tremaining: 10.5s\n",
      "570:\tlearn: 0.0665225\ttotal: 13.9s\tremaining: 10.5s\n",
      "571:\tlearn: 0.0664141\ttotal: 13.9s\tremaining: 10.4s\n",
      "572:\tlearn: 0.0662521\ttotal: 14s\tremaining: 10.4s\n",
      "573:\tlearn: 0.0661115\ttotal: 14s\tremaining: 10.4s\n",
      "574:\tlearn: 0.0659657\ttotal: 14s\tremaining: 10.4s\n",
      "575:\tlearn: 0.0659443\ttotal: 14s\tremaining: 10.3s\n",
      "576:\tlearn: 0.0658420\ttotal: 14s\tremaining: 10.3s\n",
      "577:\tlearn: 0.0657332\ttotal: 14.1s\tremaining: 10.3s\n",
      "578:\tlearn: 0.0656457\ttotal: 14.1s\tremaining: 10.2s\n",
      "579:\tlearn: 0.0655164\ttotal: 14.1s\tremaining: 10.2s\n",
      "580:\tlearn: 0.0653796\ttotal: 14.1s\tremaining: 10.2s\n",
      "581:\tlearn: 0.0651928\ttotal: 14.2s\tremaining: 10.2s\n",
      "582:\tlearn: 0.0650972\ttotal: 14.2s\tremaining: 10.1s\n",
      "583:\tlearn: 0.0650843\ttotal: 14.2s\tremaining: 10.1s\n",
      "584:\tlearn: 0.0649410\ttotal: 14.2s\tremaining: 10.1s\n",
      "585:\tlearn: 0.0648327\ttotal: 14.3s\tremaining: 10.1s\n",
      "586:\tlearn: 0.0647398\ttotal: 14.3s\tremaining: 10.1s\n",
      "587:\tlearn: 0.0645955\ttotal: 14.3s\tremaining: 10s\n",
      "588:\tlearn: 0.0644791\ttotal: 14.3s\tremaining: 10s\n",
      "589:\tlearn: 0.0643293\ttotal: 14.4s\tremaining: 9.98s\n",
      "590:\tlearn: 0.0642322\ttotal: 14.4s\tremaining: 9.95s\n",
      "591:\tlearn: 0.0641608\ttotal: 14.4s\tremaining: 9.92s\n",
      "592:\tlearn: 0.0640282\ttotal: 14.4s\tremaining: 9.9s\n",
      "593:\tlearn: 0.0639601\ttotal: 14.4s\tremaining: 9.87s\n",
      "594:\tlearn: 0.0638123\ttotal: 14.5s\tremaining: 9.84s\n",
      "595:\tlearn: 0.0636743\ttotal: 14.5s\tremaining: 9.81s\n",
      "596:\tlearn: 0.0636665\ttotal: 14.5s\tremaining: 9.78s\n",
      "597:\tlearn: 0.0635182\ttotal: 14.5s\tremaining: 9.76s\n",
      "598:\tlearn: 0.0633823\ttotal: 14.5s\tremaining: 9.73s\n",
      "599:\tlearn: 0.0633649\ttotal: 14.6s\tremaining: 9.7s\n",
      "600:\tlearn: 0.0632711\ttotal: 14.6s\tremaining: 9.67s\n",
      "601:\tlearn: 0.0631389\ttotal: 14.6s\tremaining: 9.65s\n",
      "602:\tlearn: 0.0630289\ttotal: 14.6s\tremaining: 9.63s\n",
      "603:\tlearn: 0.0629047\ttotal: 14.7s\tremaining: 9.61s\n",
      "604:\tlearn: 0.0627526\ttotal: 14.7s\tremaining: 9.58s\n",
      "605:\tlearn: 0.0626778\ttotal: 14.7s\tremaining: 9.55s\n",
      "606:\tlearn: 0.0625395\ttotal: 14.7s\tremaining: 9.53s\n",
      "607:\tlearn: 0.0625315\ttotal: 14.7s\tremaining: 9.5s\n",
      "608:\tlearn: 0.0623556\ttotal: 14.8s\tremaining: 9.48s\n",
      "609:\tlearn: 0.0621614\ttotal: 14.8s\tremaining: 9.45s\n",
      "610:\tlearn: 0.0620779\ttotal: 14.8s\tremaining: 9.43s\n",
      "611:\tlearn: 0.0619137\ttotal: 14.8s\tremaining: 9.4s\n",
      "612:\tlearn: 0.0618973\ttotal: 14.8s\tremaining: 9.38s\n",
      "613:\tlearn: 0.0617795\ttotal: 14.9s\tremaining: 9.35s\n",
      "614:\tlearn: 0.0617276\ttotal: 14.9s\tremaining: 9.32s\n",
      "615:\tlearn: 0.0616427\ttotal: 14.9s\tremaining: 9.3s\n",
      "616:\tlearn: 0.0615342\ttotal: 14.9s\tremaining: 9.27s\n",
      "617:\tlearn: 0.0613355\ttotal: 15s\tremaining: 9.25s\n",
      "618:\tlearn: 0.0613186\ttotal: 15s\tremaining: 9.22s\n",
      "619:\tlearn: 0.0612381\ttotal: 15s\tremaining: 9.2s\n",
      "620:\tlearn: 0.0611475\ttotal: 15s\tremaining: 9.17s\n",
      "621:\tlearn: 0.0610609\ttotal: 15.1s\tremaining: 9.15s\n",
      "622:\tlearn: 0.0609778\ttotal: 15.1s\tremaining: 9.12s\n",
      "623:\tlearn: 0.0608959\ttotal: 15.1s\tremaining: 9.1s\n",
      "624:\tlearn: 0.0608029\ttotal: 15.1s\tremaining: 9.07s\n",
      "625:\tlearn: 0.0606778\ttotal: 15.1s\tremaining: 9.05s\n",
      "626:\tlearn: 0.0605631\ttotal: 15.2s\tremaining: 9.02s\n",
      "627:\tlearn: 0.0604519\ttotal: 15.2s\tremaining: 9s\n",
      "628:\tlearn: 0.0603598\ttotal: 15.2s\tremaining: 8.97s\n",
      "629:\tlearn: 0.0602693\ttotal: 15.2s\tremaining: 8.95s\n",
      "630:\tlearn: 0.0601849\ttotal: 15.3s\tremaining: 8.93s\n",
      "631:\tlearn: 0.0600762\ttotal: 15.3s\tremaining: 8.9s\n",
      "632:\tlearn: 0.0599681\ttotal: 15.3s\tremaining: 8.88s\n",
      "633:\tlearn: 0.0598503\ttotal: 15.3s\tremaining: 8.85s\n",
      "634:\tlearn: 0.0597690\ttotal: 15.3s\tremaining: 8.82s\n",
      "635:\tlearn: 0.0595959\ttotal: 15.4s\tremaining: 8.8s\n",
      "636:\tlearn: 0.0595886\ttotal: 15.4s\tremaining: 8.77s\n",
      "637:\tlearn: 0.0594672\ttotal: 15.4s\tremaining: 8.75s\n",
      "638:\tlearn: 0.0593482\ttotal: 15.4s\tremaining: 8.72s\n",
      "639:\tlearn: 0.0591587\ttotal: 15.5s\tremaining: 8.7s\n",
      "640:\tlearn: 0.0590473\ttotal: 15.5s\tremaining: 8.67s\n",
      "641:\tlearn: 0.0589535\ttotal: 15.5s\tremaining: 8.64s\n",
      "642:\tlearn: 0.0588698\ttotal: 15.5s\tremaining: 8.62s\n",
      "643:\tlearn: 0.0588613\ttotal: 15.5s\tremaining: 8.59s\n",
      "644:\tlearn: 0.0587014\ttotal: 15.6s\tremaining: 8.56s\n",
      "645:\tlearn: 0.0585935\ttotal: 15.6s\tremaining: 8.53s\n",
      "646:\tlearn: 0.0584460\ttotal: 15.6s\tremaining: 8.51s\n",
      "647:\tlearn: 0.0583700\ttotal: 15.6s\tremaining: 8.48s\n",
      "648:\tlearn: 0.0582355\ttotal: 15.6s\tremaining: 8.45s\n",
      "649:\tlearn: 0.0581767\ttotal: 15.7s\tremaining: 8.43s\n",
      "650:\tlearn: 0.0580892\ttotal: 15.7s\tremaining: 8.4s\n",
      "651:\tlearn: 0.0579988\ttotal: 15.7s\tremaining: 8.38s\n",
      "652:\tlearn: 0.0578902\ttotal: 15.7s\tremaining: 8.35s\n",
      "653:\tlearn: 0.0578832\ttotal: 15.7s\tremaining: 8.33s\n",
      "654:\tlearn: 0.0577695\ttotal: 15.8s\tremaining: 8.3s\n",
      "655:\tlearn: 0.0576342\ttotal: 15.8s\tremaining: 8.28s\n",
      "656:\tlearn: 0.0575297\ttotal: 15.8s\tremaining: 8.26s\n",
      "657:\tlearn: 0.0574518\ttotal: 15.8s\tremaining: 8.23s\n",
      "658:\tlearn: 0.0573709\ttotal: 15.9s\tremaining: 8.21s\n",
      "659:\tlearn: 0.0573475\ttotal: 15.9s\tremaining: 8.18s\n",
      "660:\tlearn: 0.0571440\ttotal: 15.9s\tremaining: 8.16s\n",
      "661:\tlearn: 0.0570310\ttotal: 15.9s\tremaining: 8.13s\n",
      "662:\tlearn: 0.0569586\ttotal: 15.9s\tremaining: 8.11s\n",
      "663:\tlearn: 0.0568222\ttotal: 16s\tremaining: 8.08s\n",
      "664:\tlearn: 0.0567735\ttotal: 16s\tremaining: 8.06s\n",
      "665:\tlearn: 0.0566904\ttotal: 16s\tremaining: 8.03s\n",
      "666:\tlearn: 0.0565774\ttotal: 16s\tremaining: 8.01s\n",
      "667:\tlearn: 0.0565635\ttotal: 16.1s\tremaining: 7.98s\n",
      "668:\tlearn: 0.0564480\ttotal: 16.1s\tremaining: 7.96s\n",
      "669:\tlearn: 0.0563254\ttotal: 16.1s\tremaining: 7.94s\n",
      "670:\tlearn: 0.0563101\ttotal: 16.1s\tremaining: 7.91s\n",
      "671:\tlearn: 0.0562328\ttotal: 16.2s\tremaining: 7.89s\n",
      "672:\tlearn: 0.0561448\ttotal: 16.2s\tremaining: 7.86s\n",
      "673:\tlearn: 0.0560763\ttotal: 16.2s\tremaining: 7.83s\n",
      "674:\tlearn: 0.0560110\ttotal: 16.2s\tremaining: 7.81s\n",
      "675:\tlearn: 0.0558559\ttotal: 16.2s\tremaining: 7.78s\n",
      "676:\tlearn: 0.0558463\ttotal: 16.3s\tremaining: 7.75s\n",
      "677:\tlearn: 0.0558138\ttotal: 16.3s\tremaining: 7.73s\n",
      "678:\tlearn: 0.0557142\ttotal: 16.3s\tremaining: 7.7s\n",
      "679:\tlearn: 0.0556450\ttotal: 16.3s\tremaining: 7.68s\n",
      "680:\tlearn: 0.0555824\ttotal: 16.3s\tremaining: 7.65s\n",
      "681:\tlearn: 0.0554975\ttotal: 16.4s\tremaining: 7.63s\n",
      "682:\tlearn: 0.0554911\ttotal: 16.4s\tremaining: 7.6s\n",
      "683:\tlearn: 0.0554848\ttotal: 16.4s\tremaining: 7.58s\n",
      "684:\tlearn: 0.0554531\ttotal: 16.4s\tremaining: 7.55s\n",
      "685:\tlearn: 0.0553580\ttotal: 16.4s\tremaining: 7.53s\n",
      "686:\tlearn: 0.0552674\ttotal: 16.5s\tremaining: 7.5s\n",
      "687:\tlearn: 0.0551684\ttotal: 16.5s\tremaining: 7.48s\n",
      "688:\tlearn: 0.0550581\ttotal: 16.5s\tremaining: 7.45s\n",
      "689:\tlearn: 0.0549679\ttotal: 16.5s\tremaining: 7.43s\n",
      "690:\tlearn: 0.0548761\ttotal: 16.6s\tremaining: 7.41s\n",
      "691:\tlearn: 0.0547826\ttotal: 16.6s\tremaining: 7.38s\n",
      "692:\tlearn: 0.0547116\ttotal: 16.6s\tremaining: 7.36s\n",
      "693:\tlearn: 0.0545871\ttotal: 16.6s\tremaining: 7.33s\n",
      "694:\tlearn: 0.0545506\ttotal: 16.7s\tremaining: 7.31s\n",
      "695:\tlearn: 0.0545043\ttotal: 16.7s\tremaining: 7.28s\n",
      "696:\tlearn: 0.0544343\ttotal: 16.7s\tremaining: 7.26s\n",
      "697:\tlearn: 0.0543396\ttotal: 16.7s\tremaining: 7.23s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "698:\tlearn: 0.0543239\ttotal: 16.7s\tremaining: 7.21s\n",
      "699:\tlearn: 0.0542425\ttotal: 16.8s\tremaining: 7.19s\n",
      "700:\tlearn: 0.0541768\ttotal: 16.8s\tremaining: 7.17s\n",
      "701:\tlearn: 0.0541005\ttotal: 16.8s\tremaining: 7.14s\n",
      "702:\tlearn: 0.0539840\ttotal: 16.9s\tremaining: 7.12s\n",
      "703:\tlearn: 0.0539412\ttotal: 16.9s\tremaining: 7.1s\n",
      "704:\tlearn: 0.0538458\ttotal: 16.9s\tremaining: 7.08s\n",
      "705:\tlearn: 0.0538105\ttotal: 16.9s\tremaining: 7.05s\n",
      "706:\tlearn: 0.0536975\ttotal: 17s\tremaining: 7.03s\n",
      "707:\tlearn: 0.0535843\ttotal: 17s\tremaining: 7.01s\n",
      "708:\tlearn: 0.0535173\ttotal: 17s\tremaining: 6.99s\n",
      "709:\tlearn: 0.0534057\ttotal: 17.1s\tremaining: 6.97s\n",
      "710:\tlearn: 0.0533025\ttotal: 17.1s\tremaining: 6.96s\n",
      "711:\tlearn: 0.0532075\ttotal: 17.1s\tremaining: 6.94s\n",
      "712:\tlearn: 0.0531918\ttotal: 17.2s\tremaining: 6.92s\n",
      "713:\tlearn: 0.0531441\ttotal: 17.2s\tremaining: 6.89s\n",
      "714:\tlearn: 0.0531044\ttotal: 17.3s\tremaining: 6.88s\n",
      "715:\tlearn: 0.0530036\ttotal: 17.3s\tremaining: 6.86s\n",
      "716:\tlearn: 0.0529376\ttotal: 17.3s\tremaining: 6.84s\n",
      "717:\tlearn: 0.0528494\ttotal: 17.4s\tremaining: 6.82s\n",
      "718:\tlearn: 0.0528344\ttotal: 17.4s\tremaining: 6.8s\n",
      "719:\tlearn: 0.0527449\ttotal: 17.4s\tremaining: 6.78s\n",
      "720:\tlearn: 0.0526537\ttotal: 17.5s\tremaining: 6.76s\n",
      "721:\tlearn: 0.0525460\ttotal: 17.5s\tremaining: 6.74s\n",
      "722:\tlearn: 0.0524820\ttotal: 17.5s\tremaining: 6.71s\n",
      "723:\tlearn: 0.0524124\ttotal: 17.6s\tremaining: 6.69s\n",
      "724:\tlearn: 0.0523522\ttotal: 17.6s\tremaining: 6.67s\n",
      "725:\tlearn: 0.0522492\ttotal: 17.6s\tremaining: 6.65s\n",
      "726:\tlearn: 0.0521747\ttotal: 17.7s\tremaining: 6.63s\n",
      "727:\tlearn: 0.0520745\ttotal: 17.7s\tremaining: 6.61s\n",
      "728:\tlearn: 0.0520688\ttotal: 17.7s\tremaining: 6.58s\n",
      "729:\tlearn: 0.0519774\ttotal: 17.7s\tremaining: 6.56s\n",
      "730:\tlearn: 0.0518949\ttotal: 17.8s\tremaining: 6.54s\n",
      "731:\tlearn: 0.0517921\ttotal: 17.8s\tremaining: 6.51s\n",
      "732:\tlearn: 0.0517016\ttotal: 17.8s\tremaining: 6.49s\n",
      "733:\tlearn: 0.0516012\ttotal: 17.9s\tremaining: 6.47s\n",
      "734:\tlearn: 0.0515956\ttotal: 17.9s\tremaining: 6.45s\n",
      "735:\tlearn: 0.0515107\ttotal: 17.9s\tremaining: 6.43s\n",
      "736:\tlearn: 0.0514316\ttotal: 18s\tremaining: 6.41s\n",
      "737:\tlearn: 0.0513593\ttotal: 18s\tremaining: 6.38s\n",
      "738:\tlearn: 0.0513538\ttotal: 18s\tremaining: 6.36s\n",
      "739:\tlearn: 0.0512938\ttotal: 18s\tremaining: 6.34s\n",
      "740:\tlearn: 0.0512028\ttotal: 18.1s\tremaining: 6.32s\n",
      "741:\tlearn: 0.0510707\ttotal: 18.1s\tremaining: 6.3s\n",
      "742:\tlearn: 0.0510092\ttotal: 18.2s\tremaining: 6.28s\n",
      "743:\tlearn: 0.0509071\ttotal: 18.2s\tremaining: 6.26s\n",
      "744:\tlearn: 0.0509003\ttotal: 18.2s\tremaining: 6.24s\n",
      "745:\tlearn: 0.0508601\ttotal: 18.3s\tremaining: 6.22s\n",
      "746:\tlearn: 0.0507866\ttotal: 18.3s\tremaining: 6.19s\n",
      "747:\tlearn: 0.0506763\ttotal: 18.3s\tremaining: 6.17s\n",
      "748:\tlearn: 0.0506264\ttotal: 18.3s\tremaining: 6.15s\n",
      "749:\tlearn: 0.0505030\ttotal: 18.4s\tremaining: 6.12s\n",
      "750:\tlearn: 0.0504110\ttotal: 18.4s\tremaining: 6.1s\n",
      "751:\tlearn: 0.0503338\ttotal: 18.4s\tremaining: 6.07s\n",
      "752:\tlearn: 0.0503204\ttotal: 18.4s\tremaining: 6.05s\n",
      "753:\tlearn: 0.0502536\ttotal: 18.5s\tremaining: 6.02s\n",
      "754:\tlearn: 0.0501089\ttotal: 18.5s\tremaining: 6s\n",
      "755:\tlearn: 0.0500133\ttotal: 18.5s\tremaining: 5.97s\n",
      "756:\tlearn: 0.0499240\ttotal: 18.5s\tremaining: 5.95s\n",
      "757:\tlearn: 0.0499173\ttotal: 18.6s\tremaining: 5.92s\n",
      "758:\tlearn: 0.0498360\ttotal: 18.6s\tremaining: 5.9s\n",
      "759:\tlearn: 0.0497016\ttotal: 18.6s\tremaining: 5.88s\n",
      "760:\tlearn: 0.0496686\ttotal: 18.6s\tremaining: 5.85s\n",
      "761:\tlearn: 0.0495707\ttotal: 18.7s\tremaining: 5.83s\n",
      "762:\tlearn: 0.0494780\ttotal: 18.7s\tremaining: 5.81s\n",
      "763:\tlearn: 0.0494722\ttotal: 18.7s\tremaining: 5.79s\n",
      "764:\tlearn: 0.0494407\ttotal: 18.8s\tremaining: 5.76s\n",
      "765:\tlearn: 0.0493726\ttotal: 18.8s\tremaining: 5.75s\n",
      "766:\tlearn: 0.0493656\ttotal: 18.8s\tremaining: 5.72s\n",
      "767:\tlearn: 0.0493091\ttotal: 18.9s\tremaining: 5.7s\n",
      "768:\tlearn: 0.0492011\ttotal: 18.9s\tremaining: 5.68s\n",
      "769:\tlearn: 0.0491092\ttotal: 18.9s\tremaining: 5.66s\n",
      "770:\tlearn: 0.0490162\ttotal: 19s\tremaining: 5.63s\n",
      "771:\tlearn: 0.0489388\ttotal: 19s\tremaining: 5.61s\n",
      "772:\tlearn: 0.0489000\ttotal: 19s\tremaining: 5.59s\n",
      "773:\tlearn: 0.0488684\ttotal: 19.1s\tremaining: 5.57s\n",
      "774:\tlearn: 0.0488006\ttotal: 19.1s\tremaining: 5.55s\n",
      "775:\tlearn: 0.0486961\ttotal: 19.1s\tremaining: 5.53s\n",
      "776:\tlearn: 0.0486911\ttotal: 19.2s\tremaining: 5.5s\n",
      "777:\tlearn: 0.0486338\ttotal: 19.2s\tremaining: 5.48s\n",
      "778:\tlearn: 0.0486289\ttotal: 19.2s\tremaining: 5.46s\n",
      "779:\tlearn: 0.0486046\ttotal: 19.3s\tremaining: 5.44s\n",
      "780:\tlearn: 0.0485656\ttotal: 19.3s\tremaining: 5.41s\n",
      "781:\tlearn: 0.0485074\ttotal: 19.3s\tremaining: 5.39s\n",
      "782:\tlearn: 0.0484435\ttotal: 19.4s\tremaining: 5.37s\n",
      "783:\tlearn: 0.0483658\ttotal: 19.4s\tremaining: 5.34s\n",
      "784:\tlearn: 0.0483112\ttotal: 19.4s\tremaining: 5.32s\n",
      "785:\tlearn: 0.0481732\ttotal: 19.4s\tremaining: 5.29s\n",
      "786:\tlearn: 0.0480888\ttotal: 19.5s\tremaining: 5.27s\n",
      "787:\tlearn: 0.0480217\ttotal: 19.5s\tremaining: 5.25s\n",
      "788:\tlearn: 0.0478957\ttotal: 19.5s\tremaining: 5.23s\n",
      "789:\tlearn: 0.0478522\ttotal: 19.6s\tremaining: 5.2s\n",
      "790:\tlearn: 0.0478474\ttotal: 19.6s\tremaining: 5.17s\n",
      "791:\tlearn: 0.0477804\ttotal: 19.6s\tremaining: 5.15s\n",
      "792:\tlearn: 0.0477205\ttotal: 19.6s\tremaining: 5.12s\n",
      "793:\tlearn: 0.0476619\ttotal: 19.6s\tremaining: 5.1s\n",
      "794:\tlearn: 0.0476412\ttotal: 19.7s\tremaining: 5.07s\n",
      "795:\tlearn: 0.0475681\ttotal: 19.7s\tremaining: 5.04s\n",
      "796:\tlearn: 0.0474977\ttotal: 19.7s\tremaining: 5.02s\n",
      "797:\tlearn: 0.0474929\ttotal: 19.7s\tremaining: 4.99s\n",
      "798:\tlearn: 0.0474815\ttotal: 19.7s\tremaining: 4.97s\n",
      "799:\tlearn: 0.0474211\ttotal: 19.8s\tremaining: 4.94s\n",
      "800:\tlearn: 0.0473337\ttotal: 19.8s\tremaining: 4.92s\n",
      "801:\tlearn: 0.0472374\ttotal: 19.8s\tremaining: 4.89s\n",
      "802:\tlearn: 0.0471557\ttotal: 19.8s\tremaining: 4.87s\n",
      "803:\tlearn: 0.0471167\ttotal: 19.9s\tremaining: 4.84s\n",
      "804:\tlearn: 0.0469944\ttotal: 19.9s\tremaining: 4.82s\n",
      "805:\tlearn: 0.0469225\ttotal: 19.9s\tremaining: 4.79s\n",
      "806:\tlearn: 0.0468196\ttotal: 19.9s\tremaining: 4.76s\n",
      "807:\tlearn: 0.0467238\ttotal: 19.9s\tremaining: 4.74s\n",
      "808:\tlearn: 0.0466339\ttotal: 20s\tremaining: 4.71s\n",
      "809:\tlearn: 0.0465607\ttotal: 20s\tremaining: 4.69s\n",
      "810:\tlearn: 0.0464917\ttotal: 20s\tremaining: 4.66s\n",
      "811:\tlearn: 0.0463869\ttotal: 20s\tremaining: 4.63s\n",
      "812:\tlearn: 0.0463094\ttotal: 20.1s\tremaining: 4.61s\n",
      "813:\tlearn: 0.0462167\ttotal: 20.1s\tremaining: 4.59s\n",
      "814:\tlearn: 0.0461540\ttotal: 20.1s\tremaining: 4.57s\n",
      "815:\tlearn: 0.0461406\ttotal: 20.1s\tremaining: 4.54s\n",
      "816:\tlearn: 0.0461359\ttotal: 20.2s\tremaining: 4.52s\n",
      "817:\tlearn: 0.0460862\ttotal: 20.2s\tremaining: 4.49s\n",
      "818:\tlearn: 0.0460352\ttotal: 20.2s\tremaining: 4.47s\n",
      "819:\tlearn: 0.0460272\ttotal: 20.2s\tremaining: 4.44s\n",
      "820:\tlearn: 0.0459503\ttotal: 20.3s\tremaining: 4.42s\n",
      "821:\tlearn: 0.0459149\ttotal: 20.3s\tremaining: 4.39s\n",
      "822:\tlearn: 0.0458755\ttotal: 20.3s\tremaining: 4.37s\n",
      "823:\tlearn: 0.0458233\ttotal: 20.3s\tremaining: 4.34s\n",
      "824:\tlearn: 0.0457616\ttotal: 20.4s\tremaining: 4.32s\n",
      "825:\tlearn: 0.0457043\ttotal: 20.4s\tremaining: 4.29s\n",
      "826:\tlearn: 0.0455668\ttotal: 20.4s\tremaining: 4.27s\n",
      "827:\tlearn: 0.0454933\ttotal: 20.4s\tremaining: 4.24s\n",
      "828:\tlearn: 0.0454885\ttotal: 20.5s\tremaining: 4.22s\n",
      "829:\tlearn: 0.0454320\ttotal: 20.5s\tremaining: 4.19s\n",
      "830:\tlearn: 0.0453416\ttotal: 20.5s\tremaining: 4.17s\n",
      "831:\tlearn: 0.0452512\ttotal: 20.5s\tremaining: 4.15s\n",
      "832:\tlearn: 0.0452318\ttotal: 20.6s\tremaining: 4.12s\n",
      "833:\tlearn: 0.0452270\ttotal: 20.6s\tremaining: 4.09s\n",
      "834:\tlearn: 0.0451426\ttotal: 20.6s\tremaining: 4.07s\n",
      "835:\tlearn: 0.0450973\ttotal: 20.6s\tremaining: 4.05s\n",
      "836:\tlearn: 0.0450933\ttotal: 20.6s\tremaining: 4.02s\n",
      "837:\tlearn: 0.0450892\ttotal: 20.7s\tremaining: 4s\n",
      "838:\tlearn: 0.0450352\ttotal: 20.7s\tremaining: 3.97s\n",
      "839:\tlearn: 0.0450239\ttotal: 20.7s\tremaining: 3.95s\n",
      "840:\tlearn: 0.0449482\ttotal: 20.7s\tremaining: 3.92s\n",
      "841:\tlearn: 0.0448576\ttotal: 20.8s\tremaining: 3.9s\n",
      "842:\tlearn: 0.0448476\ttotal: 20.8s\tremaining: 3.87s\n",
      "843:\tlearn: 0.0447832\ttotal: 20.8s\tremaining: 3.85s\n",
      "844:\tlearn: 0.0447780\ttotal: 20.9s\tremaining: 3.83s\n",
      "845:\tlearn: 0.0447200\ttotal: 20.9s\tremaining: 3.8s\n",
      "846:\tlearn: 0.0446283\ttotal: 20.9s\tremaining: 3.78s\n",
      "847:\tlearn: 0.0446090\ttotal: 20.9s\tremaining: 3.75s\n",
      "848:\tlearn: 0.0445754\ttotal: 21s\tremaining: 3.73s\n",
      "849:\tlearn: 0.0445310\ttotal: 21s\tremaining: 3.7s\n",
      "850:\tlearn: 0.0444602\ttotal: 21s\tremaining: 3.68s\n",
      "851:\tlearn: 0.0444158\ttotal: 21s\tremaining: 3.65s\n",
      "852:\tlearn: 0.0443311\ttotal: 21s\tremaining: 3.63s\n",
      "853:\tlearn: 0.0442592\ttotal: 21.1s\tremaining: 3.6s\n",
      "854:\tlearn: 0.0441910\ttotal: 21.1s\tremaining: 3.58s\n",
      "855:\tlearn: 0.0441381\ttotal: 21.1s\tremaining: 3.55s\n",
      "856:\tlearn: 0.0440825\ttotal: 21.1s\tremaining: 3.53s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "857:\tlearn: 0.0440283\ttotal: 21.2s\tremaining: 3.5s\n",
      "858:\tlearn: 0.0439846\ttotal: 21.2s\tremaining: 3.48s\n",
      "859:\tlearn: 0.0439212\ttotal: 21.2s\tremaining: 3.45s\n",
      "860:\tlearn: 0.0439174\ttotal: 21.2s\tremaining: 3.43s\n",
      "861:\tlearn: 0.0438841\ttotal: 21.2s\tremaining: 3.4s\n",
      "862:\tlearn: 0.0437962\ttotal: 21.3s\tremaining: 3.38s\n",
      "863:\tlearn: 0.0437718\ttotal: 21.3s\tremaining: 3.35s\n",
      "864:\tlearn: 0.0437082\ttotal: 21.3s\tremaining: 3.33s\n",
      "865:\tlearn: 0.0437033\ttotal: 21.3s\tremaining: 3.3s\n",
      "866:\tlearn: 0.0436335\ttotal: 21.4s\tremaining: 3.28s\n",
      "867:\tlearn: 0.0435775\ttotal: 21.4s\tremaining: 3.25s\n",
      "868:\tlearn: 0.0434929\ttotal: 21.4s\tremaining: 3.23s\n",
      "869:\tlearn: 0.0434319\ttotal: 21.4s\tremaining: 3.2s\n",
      "870:\tlearn: 0.0434274\ttotal: 21.4s\tremaining: 3.17s\n",
      "871:\tlearn: 0.0433703\ttotal: 21.5s\tremaining: 3.15s\n",
      "872:\tlearn: 0.0433453\ttotal: 21.5s\tremaining: 3.13s\n",
      "873:\tlearn: 0.0433062\ttotal: 21.5s\tremaining: 3.1s\n",
      "874:\tlearn: 0.0432233\ttotal: 21.5s\tremaining: 3.08s\n",
      "875:\tlearn: 0.0432184\ttotal: 21.6s\tremaining: 3.05s\n",
      "876:\tlearn: 0.0431935\ttotal: 21.6s\tremaining: 3.03s\n",
      "877:\tlearn: 0.0431619\ttotal: 21.6s\tremaining: 3s\n",
      "878:\tlearn: 0.0430667\ttotal: 21.6s\tremaining: 2.98s\n",
      "879:\tlearn: 0.0430501\ttotal: 21.6s\tremaining: 2.95s\n",
      "880:\tlearn: 0.0430461\ttotal: 21.7s\tremaining: 2.93s\n",
      "881:\tlearn: 0.0429868\ttotal: 21.7s\tremaining: 2.9s\n",
      "882:\tlearn: 0.0429236\ttotal: 21.7s\tremaining: 2.88s\n",
      "883:\tlearn: 0.0428619\ttotal: 21.7s\tremaining: 2.85s\n",
      "884:\tlearn: 0.0428144\ttotal: 21.8s\tremaining: 2.83s\n",
      "885:\tlearn: 0.0428075\ttotal: 21.8s\tremaining: 2.8s\n",
      "886:\tlearn: 0.0428034\ttotal: 21.8s\tremaining: 2.78s\n",
      "887:\tlearn: 0.0427492\ttotal: 21.8s\tremaining: 2.75s\n",
      "888:\tlearn: 0.0426907\ttotal: 21.9s\tremaining: 2.73s\n",
      "889:\tlearn: 0.0426438\ttotal: 21.9s\tremaining: 2.7s\n",
      "890:\tlearn: 0.0425509\ttotal: 21.9s\tremaining: 2.68s\n",
      "891:\tlearn: 0.0424951\ttotal: 21.9s\tremaining: 2.65s\n",
      "892:\tlearn: 0.0424410\ttotal: 21.9s\tremaining: 2.63s\n",
      "893:\tlearn: 0.0424027\ttotal: 22s\tremaining: 2.6s\n",
      "894:\tlearn: 0.0423569\ttotal: 22s\tremaining: 2.58s\n",
      "895:\tlearn: 0.0422972\ttotal: 22s\tremaining: 2.55s\n",
      "896:\tlearn: 0.0422331\ttotal: 22s\tremaining: 2.53s\n",
      "897:\tlearn: 0.0421438\ttotal: 22.1s\tremaining: 2.51s\n",
      "898:\tlearn: 0.0421402\ttotal: 22.1s\tremaining: 2.48s\n",
      "899:\tlearn: 0.0420733\ttotal: 22.1s\tremaining: 2.46s\n",
      "900:\tlearn: 0.0420698\ttotal: 22.1s\tremaining: 2.43s\n",
      "901:\tlearn: 0.0420476\ttotal: 22.1s\tremaining: 2.41s\n",
      "902:\tlearn: 0.0419966\ttotal: 22.2s\tremaining: 2.38s\n",
      "903:\tlearn: 0.0419933\ttotal: 22.2s\tremaining: 2.36s\n",
      "904:\tlearn: 0.0419443\ttotal: 22.2s\tremaining: 2.33s\n",
      "905:\tlearn: 0.0418983\ttotal: 22.2s\tremaining: 2.31s\n",
      "906:\tlearn: 0.0418228\ttotal: 22.3s\tremaining: 2.28s\n",
      "907:\tlearn: 0.0417503\ttotal: 22.3s\tremaining: 2.26s\n",
      "908:\tlearn: 0.0417318\ttotal: 22.3s\tremaining: 2.23s\n",
      "909:\tlearn: 0.0416485\ttotal: 22.3s\tremaining: 2.21s\n",
      "910:\tlearn: 0.0416204\ttotal: 22.4s\tremaining: 2.19s\n",
      "911:\tlearn: 0.0415565\ttotal: 22.4s\tremaining: 2.16s\n",
      "912:\tlearn: 0.0415173\ttotal: 22.4s\tremaining: 2.13s\n",
      "913:\tlearn: 0.0415138\ttotal: 22.4s\tremaining: 2.11s\n",
      "914:\tlearn: 0.0414698\ttotal: 22.5s\tremaining: 2.09s\n",
      "915:\tlearn: 0.0414135\ttotal: 22.5s\tremaining: 2.06s\n",
      "916:\tlearn: 0.0413801\ttotal: 22.5s\tremaining: 2.04s\n",
      "917:\tlearn: 0.0413376\ttotal: 22.5s\tremaining: 2.01s\n",
      "918:\tlearn: 0.0412955\ttotal: 22.6s\tremaining: 1.99s\n",
      "919:\tlearn: 0.0412391\ttotal: 22.6s\tremaining: 1.96s\n",
      "920:\tlearn: 0.0411938\ttotal: 22.6s\tremaining: 1.94s\n",
      "921:\tlearn: 0.0411452\ttotal: 22.6s\tremaining: 1.91s\n",
      "922:\tlearn: 0.0411414\ttotal: 22.6s\tremaining: 1.89s\n",
      "923:\tlearn: 0.0410158\ttotal: 22.7s\tremaining: 1.86s\n",
      "924:\tlearn: 0.0410014\ttotal: 22.7s\tremaining: 1.84s\n",
      "925:\tlearn: 0.0409237\ttotal: 22.7s\tremaining: 1.81s\n",
      "926:\tlearn: 0.0409204\ttotal: 22.7s\tremaining: 1.79s\n",
      "927:\tlearn: 0.0408940\ttotal: 22.8s\tremaining: 1.77s\n",
      "928:\tlearn: 0.0408256\ttotal: 22.8s\tremaining: 1.74s\n",
      "929:\tlearn: 0.0408169\ttotal: 22.8s\tremaining: 1.72s\n",
      "930:\tlearn: 0.0407946\ttotal: 22.8s\tremaining: 1.69s\n",
      "931:\tlearn: 0.0407334\ttotal: 22.9s\tremaining: 1.67s\n",
      "932:\tlearn: 0.0406313\ttotal: 22.9s\tremaining: 1.64s\n",
      "933:\tlearn: 0.0406217\ttotal: 22.9s\tremaining: 1.62s\n",
      "934:\tlearn: 0.0405483\ttotal: 22.9s\tremaining: 1.59s\n",
      "935:\tlearn: 0.0405006\ttotal: 23s\tremaining: 1.57s\n",
      "936:\tlearn: 0.0404409\ttotal: 23s\tremaining: 1.54s\n",
      "937:\tlearn: 0.0403923\ttotal: 23s\tremaining: 1.52s\n",
      "938:\tlearn: 0.0403412\ttotal: 23s\tremaining: 1.5s\n",
      "939:\tlearn: 0.0403066\ttotal: 23s\tremaining: 1.47s\n",
      "940:\tlearn: 0.0402427\ttotal: 23.1s\tremaining: 1.45s\n",
      "941:\tlearn: 0.0401762\ttotal: 23.1s\tremaining: 1.42s\n",
      "942:\tlearn: 0.0401090\ttotal: 23.1s\tremaining: 1.4s\n",
      "943:\tlearn: 0.0400417\ttotal: 23.1s\tremaining: 1.37s\n",
      "944:\tlearn: 0.0399935\ttotal: 23.2s\tremaining: 1.35s\n",
      "945:\tlearn: 0.0399864\ttotal: 23.2s\tremaining: 1.32s\n",
      "946:\tlearn: 0.0399833\ttotal: 23.2s\tremaining: 1.3s\n",
      "947:\tlearn: 0.0398974\ttotal: 23.2s\tremaining: 1.27s\n",
      "948:\tlearn: 0.0398354\ttotal: 23.2s\tremaining: 1.25s\n",
      "949:\tlearn: 0.0397855\ttotal: 23.3s\tremaining: 1.22s\n",
      "950:\tlearn: 0.0397516\ttotal: 23.3s\tremaining: 1.2s\n",
      "951:\tlearn: 0.0397485\ttotal: 23.3s\tremaining: 1.18s\n",
      "952:\tlearn: 0.0397181\ttotal: 23.3s\tremaining: 1.15s\n",
      "953:\tlearn: 0.0396536\ttotal: 23.4s\tremaining: 1.13s\n",
      "954:\tlearn: 0.0395975\ttotal: 23.4s\tremaining: 1.1s\n",
      "955:\tlearn: 0.0395944\ttotal: 23.4s\tremaining: 1.08s\n",
      "956:\tlearn: 0.0395277\ttotal: 23.4s\tremaining: 1.05s\n",
      "957:\tlearn: 0.0394864\ttotal: 23.5s\tremaining: 1.03s\n",
      "958:\tlearn: 0.0394165\ttotal: 23.5s\tremaining: 1s\n",
      "959:\tlearn: 0.0393779\ttotal: 23.5s\tremaining: 979ms\n",
      "960:\tlearn: 0.0393433\ttotal: 23.5s\tremaining: 955ms\n",
      "961:\tlearn: 0.0392814\ttotal: 23.5s\tremaining: 930ms\n",
      "962:\tlearn: 0.0392379\ttotal: 23.6s\tremaining: 906ms\n",
      "963:\tlearn: 0.0391579\ttotal: 23.6s\tremaining: 881ms\n",
      "964:\tlearn: 0.0390530\ttotal: 23.6s\tremaining: 857ms\n",
      "965:\tlearn: 0.0390143\ttotal: 23.6s\tremaining: 832ms\n",
      "966:\tlearn: 0.0389386\ttotal: 23.7s\tremaining: 807ms\n",
      "967:\tlearn: 0.0388654\ttotal: 23.7s\tremaining: 783ms\n",
      "968:\tlearn: 0.0388564\ttotal: 23.7s\tremaining: 758ms\n",
      "969:\tlearn: 0.0387758\ttotal: 23.7s\tremaining: 733ms\n",
      "970:\tlearn: 0.0387030\ttotal: 23.7s\tremaining: 709ms\n",
      "971:\tlearn: 0.0386823\ttotal: 23.8s\tremaining: 684ms\n",
      "972:\tlearn: 0.0386624\ttotal: 23.8s\tremaining: 660ms\n",
      "973:\tlearn: 0.0386220\ttotal: 23.8s\tremaining: 635ms\n",
      "974:\tlearn: 0.0386190\ttotal: 23.8s\tremaining: 611ms\n",
      "975:\tlearn: 0.0385699\ttotal: 23.9s\tremaining: 587ms\n",
      "976:\tlearn: 0.0385262\ttotal: 23.9s\tremaining: 562ms\n",
      "977:\tlearn: 0.0384912\ttotal: 23.9s\tremaining: 538ms\n",
      "978:\tlearn: 0.0384623\ttotal: 23.9s\tremaining: 513ms\n",
      "979:\tlearn: 0.0383744\ttotal: 23.9s\tremaining: 489ms\n",
      "980:\tlearn: 0.0383366\ttotal: 24s\tremaining: 464ms\n",
      "981:\tlearn: 0.0382876\ttotal: 24s\tremaining: 440ms\n",
      "982:\tlearn: 0.0382845\ttotal: 24s\tremaining: 416ms\n",
      "983:\tlearn: 0.0382230\ttotal: 24.1s\tremaining: 391ms\n",
      "984:\tlearn: 0.0381954\ttotal: 24.1s\tremaining: 367ms\n",
      "985:\tlearn: 0.0381073\ttotal: 24.1s\tremaining: 342ms\n",
      "986:\tlearn: 0.0380700\ttotal: 24.1s\tremaining: 318ms\n",
      "987:\tlearn: 0.0380572\ttotal: 24.1s\tremaining: 293ms\n",
      "988:\tlearn: 0.0380108\ttotal: 24.2s\tremaining: 269ms\n",
      "989:\tlearn: 0.0379538\ttotal: 24.2s\tremaining: 244ms\n",
      "990:\tlearn: 0.0379320\ttotal: 24.2s\tremaining: 220ms\n",
      "991:\tlearn: 0.0378886\ttotal: 24.2s\tremaining: 195ms\n",
      "992:\tlearn: 0.0377910\ttotal: 24.3s\tremaining: 171ms\n",
      "993:\tlearn: 0.0377760\ttotal: 24.3s\tremaining: 147ms\n",
      "994:\tlearn: 0.0377496\ttotal: 24.3s\tremaining: 122ms\n",
      "995:\tlearn: 0.0376982\ttotal: 24.3s\tremaining: 97.7ms\n",
      "996:\tlearn: 0.0376216\ttotal: 24.3s\tremaining: 73.3ms\n",
      "997:\tlearn: 0.0376049\ttotal: 24.4s\tremaining: 48.8ms\n",
      "998:\tlearn: 0.0375420\ttotal: 24.4s\tremaining: 24.4ms\n",
      "999:\tlearn: 0.0375006\ttotal: 24.4s\tremaining: 0us\n",
      "Learning rate set to 0.018893\n",
      "0:\tlearn: 0.6675876\ttotal: 22.6ms\tremaining: 22.6s\n",
      "1:\tlearn: 0.6424392\ttotal: 42.9ms\tremaining: 21.4s\n",
      "2:\tlearn: 0.6222066\ttotal: 63.3ms\tremaining: 21s\n",
      "3:\tlearn: 0.6023577\ttotal: 84.1ms\tremaining: 20.9s\n",
      "4:\tlearn: 0.5854606\ttotal: 105ms\tremaining: 20.9s\n",
      "5:\tlearn: 0.5639603\ttotal: 125ms\tremaining: 20.8s\n",
      "6:\tlearn: 0.5482255\ttotal: 146ms\tremaining: 20.7s\n",
      "7:\tlearn: 0.5358321\ttotal: 166ms\tremaining: 20.6s\n",
      "8:\tlearn: 0.5193996\ttotal: 186ms\tremaining: 20.5s\n",
      "9:\tlearn: 0.5062073\ttotal: 208ms\tremaining: 20.6s\n",
      "10:\tlearn: 0.4989738\ttotal: 242ms\tremaining: 21.7s\n",
      "11:\tlearn: 0.4870253\ttotal: 260ms\tremaining: 21.4s\n",
      "12:\tlearn: 0.4750338\ttotal: 280ms\tremaining: 21.3s\n",
      "13:\tlearn: 0.4623075\ttotal: 300ms\tremaining: 21.2s\n",
      "14:\tlearn: 0.4528044\ttotal: 321ms\tremaining: 21.1s\n",
      "15:\tlearn: 0.4480425\ttotal: 341ms\tremaining: 21s\n",
      "16:\tlearn: 0.4380185\ttotal: 361ms\tremaining: 20.9s\n",
      "17:\tlearn: 0.4291668\ttotal: 382ms\tremaining: 20.8s\n",
      "18:\tlearn: 0.4186203\ttotal: 402ms\tremaining: 20.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:\tlearn: 0.4103539\ttotal: 425ms\tremaining: 20.8s\n",
      "20:\tlearn: 0.4016368\ttotal: 445ms\tremaining: 20.7s\n",
      "21:\tlearn: 0.3938512\ttotal: 463ms\tremaining: 20.6s\n",
      "22:\tlearn: 0.3879999\ttotal: 483ms\tremaining: 20.5s\n",
      "23:\tlearn: 0.3844783\ttotal: 502ms\tremaining: 20.4s\n",
      "24:\tlearn: 0.3781542\ttotal: 519ms\tremaining: 20.2s\n",
      "25:\tlearn: 0.3735345\ttotal: 537ms\tremaining: 20.1s\n",
      "26:\tlearn: 0.3677917\ttotal: 557ms\tremaining: 20.1s\n",
      "27:\tlearn: 0.3649653\ttotal: 575ms\tremaining: 20s\n",
      "28:\tlearn: 0.3584960\ttotal: 596ms\tremaining: 20s\n",
      "29:\tlearn: 0.3533299\ttotal: 617ms\tremaining: 19.9s\n",
      "30:\tlearn: 0.3503782\ttotal: 641ms\tremaining: 20s\n",
      "31:\tlearn: 0.3475654\ttotal: 661ms\tremaining: 20s\n",
      "32:\tlearn: 0.3413433\ttotal: 682ms\tremaining: 20s\n",
      "33:\tlearn: 0.3373884\ttotal: 703ms\tremaining: 20s\n",
      "34:\tlearn: 0.3352645\ttotal: 723ms\tremaining: 19.9s\n",
      "35:\tlearn: 0.3310620\ttotal: 744ms\tremaining: 19.9s\n",
      "36:\tlearn: 0.3291236\ttotal: 764ms\tremaining: 19.9s\n",
      "37:\tlearn: 0.3261429\ttotal: 783ms\tremaining: 19.8s\n",
      "38:\tlearn: 0.3220714\ttotal: 804ms\tremaining: 19.8s\n",
      "39:\tlearn: 0.3193186\ttotal: 824ms\tremaining: 19.8s\n",
      "40:\tlearn: 0.3165580\ttotal: 845ms\tremaining: 19.8s\n",
      "41:\tlearn: 0.3132869\ttotal: 866ms\tremaining: 19.8s\n",
      "42:\tlearn: 0.3102363\ttotal: 887ms\tremaining: 19.7s\n",
      "43:\tlearn: 0.3066945\ttotal: 907ms\tremaining: 19.7s\n",
      "44:\tlearn: 0.3022531\ttotal: 927ms\tremaining: 19.7s\n",
      "45:\tlearn: 0.2997273\ttotal: 944ms\tremaining: 19.6s\n",
      "46:\tlearn: 0.2958809\ttotal: 960ms\tremaining: 19.5s\n",
      "47:\tlearn: 0.2933859\ttotal: 977ms\tremaining: 19.4s\n",
      "48:\tlearn: 0.2915760\ttotal: 994ms\tremaining: 19.3s\n",
      "49:\tlearn: 0.2874505\ttotal: 1.01s\tremaining: 19.2s\n",
      "50:\tlearn: 0.2846390\ttotal: 1.03s\tremaining: 19.2s\n",
      "51:\tlearn: 0.2822847\ttotal: 1.05s\tremaining: 19.1s\n",
      "52:\tlearn: 0.2787005\ttotal: 1.07s\tremaining: 19.1s\n",
      "53:\tlearn: 0.2757225\ttotal: 1.09s\tremaining: 19.1s\n",
      "54:\tlearn: 0.2729118\ttotal: 1.11s\tremaining: 19s\n",
      "55:\tlearn: 0.2694590\ttotal: 1.13s\tremaining: 19s\n",
      "56:\tlearn: 0.2677788\ttotal: 1.14s\tremaining: 18.9s\n",
      "57:\tlearn: 0.2653048\ttotal: 1.16s\tremaining: 18.8s\n",
      "58:\tlearn: 0.2623910\ttotal: 1.18s\tremaining: 18.8s\n",
      "59:\tlearn: 0.2606318\ttotal: 1.19s\tremaining: 18.7s\n",
      "60:\tlearn: 0.2581120\ttotal: 1.21s\tremaining: 18.6s\n",
      "61:\tlearn: 0.2567755\ttotal: 1.23s\tremaining: 18.6s\n",
      "62:\tlearn: 0.2550579\ttotal: 1.24s\tremaining: 18.5s\n",
      "63:\tlearn: 0.2520427\ttotal: 1.26s\tremaining: 18.4s\n",
      "64:\tlearn: 0.2502787\ttotal: 1.28s\tremaining: 18.4s\n",
      "65:\tlearn: 0.2477840\ttotal: 1.3s\tremaining: 18.4s\n",
      "66:\tlearn: 0.2464422\ttotal: 1.32s\tremaining: 18.4s\n",
      "67:\tlearn: 0.2441914\ttotal: 1.34s\tremaining: 18.3s\n",
      "68:\tlearn: 0.2420465\ttotal: 1.36s\tremaining: 18.3s\n",
      "69:\tlearn: 0.2409675\ttotal: 1.38s\tremaining: 18.3s\n",
      "70:\tlearn: 0.2391224\ttotal: 1.4s\tremaining: 18.3s\n",
      "71:\tlearn: 0.2371145\ttotal: 1.42s\tremaining: 18.3s\n",
      "72:\tlearn: 0.2355378\ttotal: 1.44s\tremaining: 18.3s\n",
      "73:\tlearn: 0.2344931\ttotal: 1.46s\tremaining: 18.3s\n",
      "74:\tlearn: 0.2332065\ttotal: 1.48s\tremaining: 18.3s\n",
      "75:\tlearn: 0.2316329\ttotal: 1.5s\tremaining: 18.2s\n",
      "76:\tlearn: 0.2303304\ttotal: 1.52s\tremaining: 18.2s\n",
      "77:\tlearn: 0.2292287\ttotal: 1.54s\tremaining: 18.2s\n",
      "78:\tlearn: 0.2283274\ttotal: 1.56s\tremaining: 18.2s\n",
      "79:\tlearn: 0.2267453\ttotal: 1.58s\tremaining: 18.2s\n",
      "80:\tlearn: 0.2260597\ttotal: 1.6s\tremaining: 18.1s\n",
      "81:\tlearn: 0.2242133\ttotal: 1.62s\tremaining: 18.1s\n",
      "82:\tlearn: 0.2226687\ttotal: 1.64s\tremaining: 18.1s\n",
      "83:\tlearn: 0.2216254\ttotal: 1.66s\tremaining: 18.1s\n",
      "84:\tlearn: 0.2205905\ttotal: 1.68s\tremaining: 18.1s\n",
      "85:\tlearn: 0.2187367\ttotal: 1.7s\tremaining: 18.1s\n",
      "86:\tlearn: 0.2173941\ttotal: 1.73s\tremaining: 18.1s\n",
      "87:\tlearn: 0.2165730\ttotal: 1.74s\tremaining: 18.1s\n",
      "88:\tlearn: 0.2153512\ttotal: 1.76s\tremaining: 18s\n",
      "89:\tlearn: 0.2144367\ttotal: 1.78s\tremaining: 18s\n",
      "90:\tlearn: 0.2133093\ttotal: 1.8s\tremaining: 18s\n",
      "91:\tlearn: 0.2120484\ttotal: 1.82s\tremaining: 17.9s\n",
      "92:\tlearn: 0.2109713\ttotal: 1.83s\tremaining: 17.9s\n",
      "93:\tlearn: 0.2096796\ttotal: 1.85s\tremaining: 17.8s\n",
      "94:\tlearn: 0.2080468\ttotal: 1.87s\tremaining: 17.8s\n",
      "95:\tlearn: 0.2071948\ttotal: 1.89s\tremaining: 17.8s\n",
      "96:\tlearn: 0.2064974\ttotal: 1.91s\tremaining: 17.7s\n",
      "97:\tlearn: 0.2056981\ttotal: 1.92s\tremaining: 17.7s\n",
      "98:\tlearn: 0.2047497\ttotal: 1.95s\tremaining: 17.7s\n",
      "99:\tlearn: 0.2037112\ttotal: 1.97s\tremaining: 17.7s\n",
      "100:\tlearn: 0.2023832\ttotal: 1.99s\tremaining: 17.7s\n",
      "101:\tlearn: 0.2014239\ttotal: 2.01s\tremaining: 17.7s\n",
      "102:\tlearn: 0.2002869\ttotal: 2.02s\tremaining: 17.6s\n",
      "103:\tlearn: 0.1992645\ttotal: 2.04s\tremaining: 17.6s\n",
      "104:\tlearn: 0.1976850\ttotal: 2.06s\tremaining: 17.6s\n",
      "105:\tlearn: 0.1966944\ttotal: 2.08s\tremaining: 17.6s\n",
      "106:\tlearn: 0.1958437\ttotal: 2.1s\tremaining: 17.5s\n",
      "107:\tlearn: 0.1950505\ttotal: 2.12s\tremaining: 17.5s\n",
      "108:\tlearn: 0.1942879\ttotal: 2.13s\tremaining: 17.5s\n",
      "109:\tlearn: 0.1930925\ttotal: 2.16s\tremaining: 17.5s\n",
      "110:\tlearn: 0.1923886\ttotal: 2.18s\tremaining: 17.4s\n",
      "111:\tlearn: 0.1917872\ttotal: 2.2s\tremaining: 17.4s\n",
      "112:\tlearn: 0.1907749\ttotal: 2.22s\tremaining: 17.4s\n",
      "113:\tlearn: 0.1901619\ttotal: 2.24s\tremaining: 17.4s\n",
      "114:\tlearn: 0.1894267\ttotal: 2.26s\tremaining: 17.4s\n",
      "115:\tlearn: 0.1884693\ttotal: 2.28s\tremaining: 17.4s\n",
      "116:\tlearn: 0.1877945\ttotal: 2.3s\tremaining: 17.3s\n",
      "117:\tlearn: 0.1865109\ttotal: 2.32s\tremaining: 17.3s\n",
      "118:\tlearn: 0.1860403\ttotal: 2.34s\tremaining: 17.3s\n",
      "119:\tlearn: 0.1852816\ttotal: 2.36s\tremaining: 17.3s\n",
      "120:\tlearn: 0.1845263\ttotal: 2.38s\tremaining: 17.3s\n",
      "121:\tlearn: 0.1832112\ttotal: 2.4s\tremaining: 17.3s\n",
      "122:\tlearn: 0.1827394\ttotal: 2.42s\tremaining: 17.2s\n",
      "123:\tlearn: 0.1821913\ttotal: 2.44s\tremaining: 17.2s\n",
      "124:\tlearn: 0.1815680\ttotal: 2.45s\tremaining: 17.2s\n",
      "125:\tlearn: 0.1811420\ttotal: 2.47s\tremaining: 17.1s\n",
      "126:\tlearn: 0.1800201\ttotal: 2.49s\tremaining: 17.1s\n",
      "127:\tlearn: 0.1789509\ttotal: 2.5s\tremaining: 17.1s\n",
      "128:\tlearn: 0.1775213\ttotal: 2.52s\tremaining: 17s\n",
      "129:\tlearn: 0.1768473\ttotal: 2.54s\tremaining: 17s\n",
      "130:\tlearn: 0.1759229\ttotal: 2.55s\tremaining: 16.9s\n",
      "131:\tlearn: 0.1755489\ttotal: 2.58s\tremaining: 16.9s\n",
      "132:\tlearn: 0.1745943\ttotal: 2.6s\tremaining: 16.9s\n",
      "133:\tlearn: 0.1736372\ttotal: 2.62s\tremaining: 16.9s\n",
      "134:\tlearn: 0.1727770\ttotal: 2.64s\tremaining: 16.9s\n",
      "135:\tlearn: 0.1720474\ttotal: 2.66s\tremaining: 16.9s\n",
      "136:\tlearn: 0.1711457\ttotal: 2.68s\tremaining: 16.9s\n",
      "137:\tlearn: 0.1704392\ttotal: 2.7s\tremaining: 16.9s\n",
      "138:\tlearn: 0.1699658\ttotal: 2.73s\tremaining: 16.9s\n",
      "139:\tlearn: 0.1693692\ttotal: 2.74s\tremaining: 16.8s\n",
      "140:\tlearn: 0.1688755\ttotal: 2.77s\tremaining: 16.8s\n",
      "141:\tlearn: 0.1681956\ttotal: 2.79s\tremaining: 16.9s\n",
      "142:\tlearn: 0.1676374\ttotal: 2.82s\tremaining: 16.9s\n",
      "143:\tlearn: 0.1671071\ttotal: 2.84s\tremaining: 16.9s\n",
      "144:\tlearn: 0.1663944\ttotal: 2.86s\tremaining: 16.8s\n",
      "145:\tlearn: 0.1658448\ttotal: 2.88s\tremaining: 16.8s\n",
      "146:\tlearn: 0.1652635\ttotal: 2.9s\tremaining: 16.8s\n",
      "147:\tlearn: 0.1648168\ttotal: 2.93s\tremaining: 16.9s\n",
      "148:\tlearn: 0.1641497\ttotal: 2.95s\tremaining: 16.9s\n",
      "149:\tlearn: 0.1634756\ttotal: 2.98s\tremaining: 16.9s\n",
      "150:\tlearn: 0.1628136\ttotal: 3s\tremaining: 16.9s\n",
      "151:\tlearn: 0.1623914\ttotal: 3.03s\tremaining: 16.9s\n",
      "152:\tlearn: 0.1618859\ttotal: 3.05s\tremaining: 16.9s\n",
      "153:\tlearn: 0.1614994\ttotal: 3.08s\tremaining: 16.9s\n",
      "154:\tlearn: 0.1605529\ttotal: 3.1s\tremaining: 16.9s\n",
      "155:\tlearn: 0.1598390\ttotal: 3.12s\tremaining: 16.9s\n",
      "156:\tlearn: 0.1592169\ttotal: 3.15s\tremaining: 16.9s\n",
      "157:\tlearn: 0.1589122\ttotal: 3.17s\tremaining: 16.9s\n",
      "158:\tlearn: 0.1580766\ttotal: 3.19s\tremaining: 16.8s\n",
      "159:\tlearn: 0.1576736\ttotal: 3.21s\tremaining: 16.8s\n",
      "160:\tlearn: 0.1571935\ttotal: 3.23s\tremaining: 16.9s\n",
      "161:\tlearn: 0.1567844\ttotal: 3.26s\tremaining: 16.9s\n",
      "162:\tlearn: 0.1563796\ttotal: 3.28s\tremaining: 16.9s\n",
      "163:\tlearn: 0.1558112\ttotal: 3.3s\tremaining: 16.8s\n",
      "164:\tlearn: 0.1552061\ttotal: 3.32s\tremaining: 16.8s\n",
      "165:\tlearn: 0.1546323\ttotal: 3.34s\tremaining: 16.8s\n",
      "166:\tlearn: 0.1540046\ttotal: 3.36s\tremaining: 16.8s\n",
      "167:\tlearn: 0.1535666\ttotal: 3.39s\tremaining: 16.8s\n",
      "168:\tlearn: 0.1531194\ttotal: 3.41s\tremaining: 16.8s\n",
      "169:\tlearn: 0.1526140\ttotal: 3.43s\tremaining: 16.8s\n",
      "170:\tlearn: 0.1521123\ttotal: 3.46s\tremaining: 16.8s\n",
      "171:\tlearn: 0.1515226\ttotal: 3.48s\tremaining: 16.8s\n",
      "172:\tlearn: 0.1510213\ttotal: 3.5s\tremaining: 16.8s\n",
      "173:\tlearn: 0.1506652\ttotal: 3.53s\tremaining: 16.8s\n",
      "174:\tlearn: 0.1499605\ttotal: 3.55s\tremaining: 16.8s\n",
      "175:\tlearn: 0.1496320\ttotal: 3.58s\tremaining: 16.7s\n",
      "176:\tlearn: 0.1493217\ttotal: 3.59s\tremaining: 16.7s\n",
      "177:\tlearn: 0.1487362\ttotal: 3.61s\tremaining: 16.7s\n",
      "178:\tlearn: 0.1481049\ttotal: 3.63s\tremaining: 16.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179:\tlearn: 0.1476097\ttotal: 3.66s\tremaining: 16.7s\n",
      "180:\tlearn: 0.1470096\ttotal: 3.7s\tremaining: 16.8s\n",
      "181:\tlearn: 0.1465761\ttotal: 3.72s\tremaining: 16.7s\n",
      "182:\tlearn: 0.1461189\ttotal: 3.74s\tremaining: 16.7s\n",
      "183:\tlearn: 0.1454008\ttotal: 3.76s\tremaining: 16.7s\n",
      "184:\tlearn: 0.1448306\ttotal: 3.79s\tremaining: 16.7s\n",
      "185:\tlearn: 0.1444413\ttotal: 3.81s\tremaining: 16.7s\n",
      "186:\tlearn: 0.1440678\ttotal: 3.83s\tremaining: 16.7s\n",
      "187:\tlearn: 0.1437375\ttotal: 3.86s\tremaining: 16.7s\n",
      "188:\tlearn: 0.1433244\ttotal: 3.89s\tremaining: 16.7s\n",
      "189:\tlearn: 0.1430053\ttotal: 3.91s\tremaining: 16.7s\n",
      "190:\tlearn: 0.1424646\ttotal: 3.94s\tremaining: 16.7s\n",
      "191:\tlearn: 0.1419718\ttotal: 3.96s\tremaining: 16.6s\n",
      "192:\tlearn: 0.1416118\ttotal: 3.98s\tremaining: 16.6s\n",
      "193:\tlearn: 0.1411409\ttotal: 4s\tremaining: 16.6s\n",
      "194:\tlearn: 0.1406975\ttotal: 4.01s\tremaining: 16.6s\n",
      "195:\tlearn: 0.1403040\ttotal: 4.04s\tremaining: 16.6s\n",
      "196:\tlearn: 0.1399405\ttotal: 4.06s\tremaining: 16.6s\n",
      "197:\tlearn: 0.1395660\ttotal: 4.09s\tremaining: 16.6s\n",
      "198:\tlearn: 0.1389338\ttotal: 4.11s\tremaining: 16.5s\n",
      "199:\tlearn: 0.1385802\ttotal: 4.13s\tremaining: 16.5s\n",
      "200:\tlearn: 0.1381184\ttotal: 4.14s\tremaining: 16.5s\n",
      "201:\tlearn: 0.1373885\ttotal: 4.16s\tremaining: 16.5s\n",
      "202:\tlearn: 0.1370132\ttotal: 4.18s\tremaining: 16.4s\n",
      "203:\tlearn: 0.1363628\ttotal: 4.2s\tremaining: 16.4s\n",
      "204:\tlearn: 0.1359037\ttotal: 4.22s\tremaining: 16.4s\n",
      "205:\tlearn: 0.1356687\ttotal: 4.24s\tremaining: 16.3s\n",
      "206:\tlearn: 0.1351653\ttotal: 4.26s\tremaining: 16.3s\n",
      "207:\tlearn: 0.1346839\ttotal: 4.29s\tremaining: 16.3s\n",
      "208:\tlearn: 0.1342997\ttotal: 4.32s\tremaining: 16.3s\n",
      "209:\tlearn: 0.1338781\ttotal: 4.34s\tremaining: 16.3s\n",
      "210:\tlearn: 0.1333585\ttotal: 4.37s\tremaining: 16.3s\n",
      "211:\tlearn: 0.1328799\ttotal: 4.38s\tremaining: 16.3s\n",
      "212:\tlearn: 0.1324001\ttotal: 4.4s\tremaining: 16.3s\n",
      "213:\tlearn: 0.1321020\ttotal: 4.42s\tremaining: 16.2s\n",
      "214:\tlearn: 0.1316608\ttotal: 4.44s\tremaining: 16.2s\n",
      "215:\tlearn: 0.1312219\ttotal: 4.47s\tremaining: 16.2s\n",
      "216:\tlearn: 0.1307803\ttotal: 4.49s\tremaining: 16.2s\n",
      "217:\tlearn: 0.1302535\ttotal: 4.52s\tremaining: 16.2s\n",
      "218:\tlearn: 0.1299565\ttotal: 4.54s\tremaining: 16.2s\n",
      "219:\tlearn: 0.1293729\ttotal: 4.57s\tremaining: 16.2s\n",
      "220:\tlearn: 0.1289499\ttotal: 4.58s\tremaining: 16.2s\n",
      "221:\tlearn: 0.1284756\ttotal: 4.6s\tremaining: 16.1s\n",
      "222:\tlearn: 0.1280965\ttotal: 4.62s\tremaining: 16.1s\n",
      "223:\tlearn: 0.1278001\ttotal: 4.64s\tremaining: 16.1s\n",
      "224:\tlearn: 0.1275351\ttotal: 4.66s\tremaining: 16s\n",
      "225:\tlearn: 0.1273157\ttotal: 4.68s\tremaining: 16s\n",
      "226:\tlearn: 0.1268804\ttotal: 4.7s\tremaining: 16s\n",
      "227:\tlearn: 0.1266606\ttotal: 4.72s\tremaining: 16s\n",
      "228:\tlearn: 0.1260960\ttotal: 4.75s\tremaining: 16s\n",
      "229:\tlearn: 0.1258581\ttotal: 4.77s\tremaining: 16s\n",
      "230:\tlearn: 0.1256688\ttotal: 4.8s\tremaining: 16s\n",
      "231:\tlearn: 0.1252299\ttotal: 4.83s\tremaining: 16s\n",
      "232:\tlearn: 0.1249553\ttotal: 4.86s\tremaining: 16s\n",
      "233:\tlearn: 0.1247022\ttotal: 4.9s\tremaining: 16s\n",
      "234:\tlearn: 0.1243941\ttotal: 4.93s\tremaining: 16s\n",
      "235:\tlearn: 0.1240401\ttotal: 4.96s\tremaining: 16s\n",
      "236:\tlearn: 0.1236229\ttotal: 4.99s\tremaining: 16.1s\n",
      "237:\tlearn: 0.1234487\ttotal: 5.02s\tremaining: 16.1s\n",
      "238:\tlearn: 0.1231849\ttotal: 5.05s\tremaining: 16.1s\n",
      "239:\tlearn: 0.1227959\ttotal: 5.08s\tremaining: 16.1s\n",
      "240:\tlearn: 0.1225144\ttotal: 5.11s\tremaining: 16.1s\n",
      "241:\tlearn: 0.1219922\ttotal: 5.14s\tremaining: 16.1s\n",
      "242:\tlearn: 0.1215584\ttotal: 5.17s\tremaining: 16.1s\n",
      "243:\tlearn: 0.1211502\ttotal: 5.21s\tremaining: 16.1s\n",
      "244:\tlearn: 0.1208685\ttotal: 5.24s\tremaining: 16.1s\n",
      "245:\tlearn: 0.1203970\ttotal: 5.27s\tremaining: 16.2s\n",
      "246:\tlearn: 0.1201785\ttotal: 5.3s\tremaining: 16.2s\n",
      "247:\tlearn: 0.1199122\ttotal: 5.33s\tremaining: 16.2s\n",
      "248:\tlearn: 0.1196777\ttotal: 5.35s\tremaining: 16.1s\n",
      "249:\tlearn: 0.1195142\ttotal: 5.38s\tremaining: 16.1s\n",
      "250:\tlearn: 0.1191378\ttotal: 5.41s\tremaining: 16.1s\n",
      "251:\tlearn: 0.1188878\ttotal: 5.44s\tremaining: 16.2s\n",
      "252:\tlearn: 0.1187062\ttotal: 5.48s\tremaining: 16.2s\n",
      "253:\tlearn: 0.1183994\ttotal: 5.52s\tremaining: 16.2s\n",
      "254:\tlearn: 0.1181482\ttotal: 5.56s\tremaining: 16.2s\n",
      "255:\tlearn: 0.1180174\ttotal: 5.59s\tremaining: 16.2s\n",
      "256:\tlearn: 0.1177753\ttotal: 5.62s\tremaining: 16.2s\n",
      "257:\tlearn: 0.1176106\ttotal: 5.65s\tremaining: 16.2s\n",
      "258:\tlearn: 0.1172357\ttotal: 5.7s\tremaining: 16.3s\n",
      "259:\tlearn: 0.1171004\ttotal: 5.73s\tremaining: 16.3s\n",
      "260:\tlearn: 0.1166466\ttotal: 5.76s\tremaining: 16.3s\n",
      "261:\tlearn: 0.1163510\ttotal: 5.79s\tremaining: 16.3s\n",
      "262:\tlearn: 0.1160222\ttotal: 5.81s\tremaining: 16.3s\n",
      "263:\tlearn: 0.1156373\ttotal: 5.84s\tremaining: 16.3s\n",
      "264:\tlearn: 0.1153176\ttotal: 5.88s\tremaining: 16.3s\n",
      "265:\tlearn: 0.1151698\ttotal: 5.92s\tremaining: 16.3s\n",
      "266:\tlearn: 0.1148412\ttotal: 5.96s\tremaining: 16.4s\n",
      "267:\tlearn: 0.1144957\ttotal: 5.99s\tremaining: 16.4s\n",
      "268:\tlearn: 0.1142867\ttotal: 6.02s\tremaining: 16.4s\n",
      "269:\tlearn: 0.1139677\ttotal: 6.05s\tremaining: 16.4s\n",
      "270:\tlearn: 0.1136483\ttotal: 6.08s\tremaining: 16.4s\n",
      "271:\tlearn: 0.1134710\ttotal: 6.12s\tremaining: 16.4s\n",
      "272:\tlearn: 0.1131199\ttotal: 6.16s\tremaining: 16.4s\n",
      "273:\tlearn: 0.1128108\ttotal: 6.18s\tremaining: 16.4s\n",
      "274:\tlearn: 0.1125281\ttotal: 6.22s\tremaining: 16.4s\n",
      "275:\tlearn: 0.1122525\ttotal: 6.25s\tremaining: 16.4s\n",
      "276:\tlearn: 0.1121309\ttotal: 6.28s\tremaining: 16.4s\n",
      "277:\tlearn: 0.1119645\ttotal: 6.31s\tremaining: 16.4s\n",
      "278:\tlearn: 0.1116346\ttotal: 6.35s\tremaining: 16.4s\n",
      "279:\tlearn: 0.1111975\ttotal: 6.38s\tremaining: 16.4s\n",
      "280:\tlearn: 0.1109975\ttotal: 6.42s\tremaining: 16.4s\n",
      "281:\tlearn: 0.1108633\ttotal: 6.45s\tremaining: 16.4s\n",
      "282:\tlearn: 0.1106534\ttotal: 6.48s\tremaining: 16.4s\n",
      "283:\tlearn: 0.1104184\ttotal: 6.51s\tremaining: 16.4s\n",
      "284:\tlearn: 0.1101508\ttotal: 6.54s\tremaining: 16.4s\n",
      "285:\tlearn: 0.1099004\ttotal: 6.57s\tremaining: 16.4s\n",
      "286:\tlearn: 0.1096890\ttotal: 6.6s\tremaining: 16.4s\n",
      "287:\tlearn: 0.1094122\ttotal: 6.62s\tremaining: 16.4s\n",
      "288:\tlearn: 0.1092390\ttotal: 6.65s\tremaining: 16.4s\n",
      "289:\tlearn: 0.1089785\ttotal: 6.68s\tremaining: 16.4s\n",
      "290:\tlearn: 0.1086938\ttotal: 6.71s\tremaining: 16.4s\n",
      "291:\tlearn: 0.1083942\ttotal: 6.75s\tremaining: 16.4s\n",
      "292:\tlearn: 0.1082053\ttotal: 6.78s\tremaining: 16.4s\n",
      "293:\tlearn: 0.1079881\ttotal: 6.81s\tremaining: 16.3s\n",
      "294:\tlearn: 0.1076699\ttotal: 6.85s\tremaining: 16.4s\n",
      "295:\tlearn: 0.1074860\ttotal: 6.89s\tremaining: 16.4s\n",
      "296:\tlearn: 0.1071846\ttotal: 6.92s\tremaining: 16.4s\n",
      "297:\tlearn: 0.1067748\ttotal: 6.95s\tremaining: 16.4s\n",
      "298:\tlearn: 0.1065374\ttotal: 6.99s\tremaining: 16.4s\n",
      "299:\tlearn: 0.1063917\ttotal: 7.02s\tremaining: 16.4s\n",
      "300:\tlearn: 0.1062375\ttotal: 7.05s\tremaining: 16.4s\n",
      "301:\tlearn: 0.1059652\ttotal: 7.09s\tremaining: 16.4s\n",
      "302:\tlearn: 0.1058107\ttotal: 7.13s\tremaining: 16.4s\n",
      "303:\tlearn: 0.1055092\ttotal: 7.17s\tremaining: 16.4s\n",
      "304:\tlearn: 0.1052763\ttotal: 7.21s\tremaining: 16.4s\n",
      "305:\tlearn: 0.1050630\ttotal: 7.24s\tremaining: 16.4s\n",
      "306:\tlearn: 0.1048423\ttotal: 7.28s\tremaining: 16.4s\n",
      "307:\tlearn: 0.1046702\ttotal: 7.31s\tremaining: 16.4s\n",
      "308:\tlearn: 0.1044356\ttotal: 7.34s\tremaining: 16.4s\n",
      "309:\tlearn: 0.1041679\ttotal: 7.37s\tremaining: 16.4s\n",
      "310:\tlearn: 0.1039956\ttotal: 7.4s\tremaining: 16.4s\n",
      "311:\tlearn: 0.1038098\ttotal: 7.44s\tremaining: 16.4s\n",
      "312:\tlearn: 0.1036505\ttotal: 7.48s\tremaining: 16.4s\n",
      "313:\tlearn: 0.1034878\ttotal: 7.51s\tremaining: 16.4s\n",
      "314:\tlearn: 0.1032641\ttotal: 7.53s\tremaining: 16.4s\n",
      "315:\tlearn: 0.1030448\ttotal: 7.55s\tremaining: 16.3s\n",
      "316:\tlearn: 0.1028482\ttotal: 7.57s\tremaining: 16.3s\n",
      "317:\tlearn: 0.1026598\ttotal: 7.59s\tremaining: 16.3s\n",
      "318:\tlearn: 0.1024196\ttotal: 7.62s\tremaining: 16.3s\n",
      "319:\tlearn: 0.1020721\ttotal: 7.66s\tremaining: 16.3s\n",
      "320:\tlearn: 0.1019252\ttotal: 7.7s\tremaining: 16.3s\n",
      "321:\tlearn: 0.1017101\ttotal: 7.72s\tremaining: 16.3s\n",
      "322:\tlearn: 0.1015507\ttotal: 7.75s\tremaining: 16.2s\n",
      "323:\tlearn: 0.1013267\ttotal: 7.77s\tremaining: 16.2s\n",
      "324:\tlearn: 0.1011780\ttotal: 7.79s\tremaining: 16.2s\n",
      "325:\tlearn: 0.1009862\ttotal: 7.81s\tremaining: 16.2s\n",
      "326:\tlearn: 0.1007987\ttotal: 7.83s\tremaining: 16.1s\n",
      "327:\tlearn: 0.1006645\ttotal: 7.86s\tremaining: 16.1s\n",
      "328:\tlearn: 0.1004548\ttotal: 7.88s\tremaining: 16.1s\n",
      "329:\tlearn: 0.1002944\ttotal: 7.9s\tremaining: 16s\n",
      "330:\tlearn: 0.1001288\ttotal: 7.92s\tremaining: 16s\n",
      "331:\tlearn: 0.0997957\ttotal: 7.95s\tremaining: 16s\n",
      "332:\tlearn: 0.0995901\ttotal: 7.96s\tremaining: 16s\n",
      "333:\tlearn: 0.0992104\ttotal: 7.99s\tremaining: 15.9s\n",
      "334:\tlearn: 0.0989366\ttotal: 8.02s\tremaining: 15.9s\n",
      "335:\tlearn: 0.0987827\ttotal: 8.04s\tremaining: 15.9s\n",
      "336:\tlearn: 0.0985205\ttotal: 8.06s\tremaining: 15.8s\n",
      "337:\tlearn: 0.0982972\ttotal: 8.08s\tremaining: 15.8s\n",
      "338:\tlearn: 0.0980069\ttotal: 8.1s\tremaining: 15.8s\n",
      "339:\tlearn: 0.0978375\ttotal: 8.13s\tremaining: 15.8s\n",
      "340:\tlearn: 0.0977690\ttotal: 8.15s\tremaining: 15.7s\n",
      "341:\tlearn: 0.0975058\ttotal: 8.17s\tremaining: 15.7s\n",
      "342:\tlearn: 0.0973097\ttotal: 8.19s\tremaining: 15.7s\n",
      "343:\tlearn: 0.0970743\ttotal: 8.21s\tremaining: 15.7s\n",
      "344:\tlearn: 0.0968746\ttotal: 8.23s\tremaining: 15.6s\n",
      "345:\tlearn: 0.0967622\ttotal: 8.25s\tremaining: 15.6s\n",
      "346:\tlearn: 0.0965892\ttotal: 8.27s\tremaining: 15.6s\n",
      "347:\tlearn: 0.0963964\ttotal: 8.29s\tremaining: 15.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348:\tlearn: 0.0961947\ttotal: 8.32s\tremaining: 15.5s\n",
      "349:\tlearn: 0.0960082\ttotal: 8.34s\tremaining: 15.5s\n",
      "350:\tlearn: 0.0958374\ttotal: 8.36s\tremaining: 15.5s\n",
      "351:\tlearn: 0.0956522\ttotal: 8.38s\tremaining: 15.4s\n",
      "352:\tlearn: 0.0954966\ttotal: 8.4s\tremaining: 15.4s\n",
      "353:\tlearn: 0.0953289\ttotal: 8.42s\tremaining: 15.4s\n",
      "354:\tlearn: 0.0951099\ttotal: 8.44s\tremaining: 15.3s\n",
      "355:\tlearn: 0.0949046\ttotal: 8.46s\tremaining: 15.3s\n",
      "356:\tlearn: 0.0946966\ttotal: 8.48s\tremaining: 15.3s\n",
      "357:\tlearn: 0.0946152\ttotal: 8.5s\tremaining: 15.2s\n",
      "358:\tlearn: 0.0945007\ttotal: 8.52s\tremaining: 15.2s\n",
      "359:\tlearn: 0.0943382\ttotal: 8.55s\tremaining: 15.2s\n",
      "360:\tlearn: 0.0942152\ttotal: 8.57s\tremaining: 15.2s\n",
      "361:\tlearn: 0.0940467\ttotal: 8.59s\tremaining: 15.1s\n",
      "362:\tlearn: 0.0938378\ttotal: 8.61s\tremaining: 15.1s\n",
      "363:\tlearn: 0.0936326\ttotal: 8.63s\tremaining: 15.1s\n",
      "364:\tlearn: 0.0934855\ttotal: 8.65s\tremaining: 15s\n",
      "365:\tlearn: 0.0933247\ttotal: 8.67s\tremaining: 15s\n",
      "366:\tlearn: 0.0932448\ttotal: 8.69s\tremaining: 15s\n",
      "367:\tlearn: 0.0931034\ttotal: 8.71s\tremaining: 15s\n",
      "368:\tlearn: 0.0928042\ttotal: 8.73s\tremaining: 14.9s\n",
      "369:\tlearn: 0.0926352\ttotal: 8.76s\tremaining: 14.9s\n",
      "370:\tlearn: 0.0924169\ttotal: 8.78s\tremaining: 14.9s\n",
      "371:\tlearn: 0.0923132\ttotal: 8.8s\tremaining: 14.9s\n",
      "372:\tlearn: 0.0922073\ttotal: 8.82s\tremaining: 14.8s\n",
      "373:\tlearn: 0.0920962\ttotal: 8.84s\tremaining: 14.8s\n",
      "374:\tlearn: 0.0919732\ttotal: 8.87s\tremaining: 14.8s\n",
      "375:\tlearn: 0.0917374\ttotal: 8.88s\tremaining: 14.7s\n",
      "376:\tlearn: 0.0916268\ttotal: 8.9s\tremaining: 14.7s\n",
      "377:\tlearn: 0.0916178\ttotal: 8.92s\tremaining: 14.7s\n",
      "378:\tlearn: 0.0914760\ttotal: 8.95s\tremaining: 14.7s\n",
      "379:\tlearn: 0.0912658\ttotal: 8.98s\tremaining: 14.6s\n",
      "380:\tlearn: 0.0910693\ttotal: 9.01s\tremaining: 14.6s\n",
      "381:\tlearn: 0.0909257\ttotal: 9.03s\tremaining: 14.6s\n",
      "382:\tlearn: 0.0909174\ttotal: 9.05s\tremaining: 14.6s\n",
      "383:\tlearn: 0.0907662\ttotal: 9.07s\tremaining: 14.6s\n",
      "384:\tlearn: 0.0905547\ttotal: 9.1s\tremaining: 14.5s\n",
      "385:\tlearn: 0.0904717\ttotal: 9.12s\tremaining: 14.5s\n",
      "386:\tlearn: 0.0904316\ttotal: 9.14s\tremaining: 14.5s\n",
      "387:\tlearn: 0.0902403\ttotal: 9.17s\tremaining: 14.5s\n",
      "388:\tlearn: 0.0900807\ttotal: 9.19s\tremaining: 14.4s\n",
      "389:\tlearn: 0.0899380\ttotal: 9.21s\tremaining: 14.4s\n",
      "390:\tlearn: 0.0897787\ttotal: 9.24s\tremaining: 14.4s\n",
      "391:\tlearn: 0.0896198\ttotal: 9.26s\tremaining: 14.4s\n",
      "392:\tlearn: 0.0893776\ttotal: 9.28s\tremaining: 14.3s\n",
      "393:\tlearn: 0.0891943\ttotal: 9.3s\tremaining: 14.3s\n",
      "394:\tlearn: 0.0890542\ttotal: 9.33s\tremaining: 14.3s\n",
      "395:\tlearn: 0.0888942\ttotal: 9.35s\tremaining: 14.3s\n",
      "396:\tlearn: 0.0887453\ttotal: 9.37s\tremaining: 14.2s\n",
      "397:\tlearn: 0.0885828\ttotal: 9.4s\tremaining: 14.2s\n",
      "398:\tlearn: 0.0884210\ttotal: 9.42s\tremaining: 14.2s\n",
      "399:\tlearn: 0.0882964\ttotal: 9.44s\tremaining: 14.2s\n",
      "400:\tlearn: 0.0881454\ttotal: 9.47s\tremaining: 14.1s\n",
      "401:\tlearn: 0.0880587\ttotal: 9.49s\tremaining: 14.1s\n",
      "402:\tlearn: 0.0878848\ttotal: 9.51s\tremaining: 14.1s\n",
      "403:\tlearn: 0.0877077\ttotal: 9.53s\tremaining: 14.1s\n",
      "404:\tlearn: 0.0875237\ttotal: 9.55s\tremaining: 14s\n",
      "405:\tlearn: 0.0874591\ttotal: 9.57s\tremaining: 14s\n",
      "406:\tlearn: 0.0873491\ttotal: 9.59s\tremaining: 14s\n",
      "407:\tlearn: 0.0872592\ttotal: 9.61s\tremaining: 13.9s\n",
      "408:\tlearn: 0.0871126\ttotal: 9.64s\tremaining: 13.9s\n",
      "409:\tlearn: 0.0869706\ttotal: 9.68s\tremaining: 13.9s\n",
      "410:\tlearn: 0.0867172\ttotal: 9.71s\tremaining: 13.9s\n",
      "411:\tlearn: 0.0864798\ttotal: 9.73s\tremaining: 13.9s\n",
      "412:\tlearn: 0.0863992\ttotal: 9.75s\tremaining: 13.9s\n",
      "413:\tlearn: 0.0861962\ttotal: 9.78s\tremaining: 13.8s\n",
      "414:\tlearn: 0.0860366\ttotal: 9.8s\tremaining: 13.8s\n",
      "415:\tlearn: 0.0858307\ttotal: 9.82s\tremaining: 13.8s\n",
      "416:\tlearn: 0.0856955\ttotal: 9.85s\tremaining: 13.8s\n",
      "417:\tlearn: 0.0855454\ttotal: 9.87s\tremaining: 13.7s\n",
      "418:\tlearn: 0.0852782\ttotal: 9.9s\tremaining: 13.7s\n",
      "419:\tlearn: 0.0851190\ttotal: 9.92s\tremaining: 13.7s\n",
      "420:\tlearn: 0.0849178\ttotal: 9.94s\tremaining: 13.7s\n",
      "421:\tlearn: 0.0847159\ttotal: 9.97s\tremaining: 13.7s\n",
      "422:\tlearn: 0.0845966\ttotal: 9.99s\tremaining: 13.6s\n",
      "423:\tlearn: 0.0844248\ttotal: 10s\tremaining: 13.6s\n",
      "424:\tlearn: 0.0841775\ttotal: 10s\tremaining: 13.6s\n",
      "425:\tlearn: 0.0840507\ttotal: 10.1s\tremaining: 13.6s\n",
      "426:\tlearn: 0.0838940\ttotal: 10.1s\tremaining: 13.5s\n",
      "427:\tlearn: 0.0837481\ttotal: 10.1s\tremaining: 13.5s\n",
      "428:\tlearn: 0.0836373\ttotal: 10.1s\tremaining: 13.5s\n",
      "429:\tlearn: 0.0834233\ttotal: 10.1s\tremaining: 13.5s\n",
      "430:\tlearn: 0.0834084\ttotal: 10.2s\tremaining: 13.4s\n",
      "431:\tlearn: 0.0833875\ttotal: 10.2s\tremaining: 13.4s\n",
      "432:\tlearn: 0.0832678\ttotal: 10.2s\tremaining: 13.4s\n",
      "433:\tlearn: 0.0831365\ttotal: 10.2s\tremaining: 13.3s\n",
      "434:\tlearn: 0.0830095\ttotal: 10.3s\tremaining: 13.3s\n",
      "435:\tlearn: 0.0828176\ttotal: 10.3s\tremaining: 13.3s\n",
      "436:\tlearn: 0.0827066\ttotal: 10.3s\tremaining: 13.3s\n",
      "437:\tlearn: 0.0825293\ttotal: 10.3s\tremaining: 13.3s\n",
      "438:\tlearn: 0.0823968\ttotal: 10.4s\tremaining: 13.2s\n",
      "439:\tlearn: 0.0823800\ttotal: 10.4s\tremaining: 13.2s\n",
      "440:\tlearn: 0.0821935\ttotal: 10.4s\tremaining: 13.2s\n",
      "441:\tlearn: 0.0819814\ttotal: 10.4s\tremaining: 13.2s\n",
      "442:\tlearn: 0.0818196\ttotal: 10.5s\tremaining: 13.1s\n",
      "443:\tlearn: 0.0816855\ttotal: 10.5s\tremaining: 13.1s\n",
      "444:\tlearn: 0.0816740\ttotal: 10.5s\tremaining: 13.1s\n",
      "445:\tlearn: 0.0814833\ttotal: 10.5s\tremaining: 13.1s\n",
      "446:\tlearn: 0.0813236\ttotal: 10.5s\tremaining: 13s\n",
      "447:\tlearn: 0.0811606\ttotal: 10.6s\tremaining: 13s\n",
      "448:\tlearn: 0.0809920\ttotal: 10.6s\tremaining: 13s\n",
      "449:\tlearn: 0.0808175\ttotal: 10.6s\tremaining: 13s\n",
      "450:\tlearn: 0.0807488\ttotal: 10.6s\tremaining: 12.9s\n",
      "451:\tlearn: 0.0806856\ttotal: 10.6s\tremaining: 12.9s\n",
      "452:\tlearn: 0.0806511\ttotal: 10.7s\tremaining: 12.9s\n",
      "453:\tlearn: 0.0804865\ttotal: 10.7s\tremaining: 12.9s\n",
      "454:\tlearn: 0.0802069\ttotal: 10.7s\tremaining: 12.9s\n",
      "455:\tlearn: 0.0800536\ttotal: 10.8s\tremaining: 12.8s\n",
      "456:\tlearn: 0.0799222\ttotal: 10.8s\tremaining: 12.8s\n",
      "457:\tlearn: 0.0797151\ttotal: 10.8s\tremaining: 12.8s\n",
      "458:\tlearn: 0.0795055\ttotal: 10.8s\tremaining: 12.8s\n",
      "459:\tlearn: 0.0792500\ttotal: 10.8s\tremaining: 12.7s\n",
      "460:\tlearn: 0.0790490\ttotal: 10.9s\tremaining: 12.7s\n",
      "461:\tlearn: 0.0788539\ttotal: 10.9s\tremaining: 12.7s\n",
      "462:\tlearn: 0.0786295\ttotal: 10.9s\tremaining: 12.7s\n",
      "463:\tlearn: 0.0785443\ttotal: 10.9s\tremaining: 12.6s\n",
      "464:\tlearn: 0.0783238\ttotal: 11s\tremaining: 12.6s\n",
      "465:\tlearn: 0.0782054\ttotal: 11s\tremaining: 12.6s\n",
      "466:\tlearn: 0.0780239\ttotal: 11s\tremaining: 12.6s\n",
      "467:\tlearn: 0.0778778\ttotal: 11s\tremaining: 12.5s\n",
      "468:\tlearn: 0.0778486\ttotal: 11.1s\tremaining: 12.5s\n",
      "469:\tlearn: 0.0777363\ttotal: 11.1s\tremaining: 12.5s\n",
      "470:\tlearn: 0.0776171\ttotal: 11.1s\tremaining: 12.5s\n",
      "471:\tlearn: 0.0774830\ttotal: 11.1s\tremaining: 12.4s\n",
      "472:\tlearn: 0.0773416\ttotal: 11.1s\tremaining: 12.4s\n",
      "473:\tlearn: 0.0771324\ttotal: 11.2s\tremaining: 12.4s\n",
      "474:\tlearn: 0.0771104\ttotal: 11.2s\tremaining: 12.4s\n",
      "475:\tlearn: 0.0770365\ttotal: 11.2s\tremaining: 12.3s\n",
      "476:\tlearn: 0.0768670\ttotal: 11.2s\tremaining: 12.3s\n",
      "477:\tlearn: 0.0767652\ttotal: 11.3s\tremaining: 12.3s\n",
      "478:\tlearn: 0.0765907\ttotal: 11.3s\tremaining: 12.3s\n",
      "479:\tlearn: 0.0764431\ttotal: 11.3s\tremaining: 12.3s\n",
      "480:\tlearn: 0.0764210\ttotal: 11.3s\tremaining: 12.2s\n",
      "481:\tlearn: 0.0763017\ttotal: 11.4s\tremaining: 12.2s\n",
      "482:\tlearn: 0.0762779\ttotal: 11.4s\tremaining: 12.2s\n",
      "483:\tlearn: 0.0762176\ttotal: 11.4s\tremaining: 12.2s\n",
      "484:\tlearn: 0.0761112\ttotal: 11.4s\tremaining: 12.1s\n",
      "485:\tlearn: 0.0760879\ttotal: 11.4s\tremaining: 12.1s\n",
      "486:\tlearn: 0.0759584\ttotal: 11.5s\tremaining: 12.1s\n",
      "487:\tlearn: 0.0758332\ttotal: 11.5s\tremaining: 12.1s\n",
      "488:\tlearn: 0.0756566\ttotal: 11.5s\tremaining: 12s\n",
      "489:\tlearn: 0.0756404\ttotal: 11.5s\tremaining: 12s\n",
      "490:\tlearn: 0.0753302\ttotal: 11.6s\tremaining: 12s\n",
      "491:\tlearn: 0.0752142\ttotal: 11.6s\tremaining: 11.9s\n",
      "492:\tlearn: 0.0750721\ttotal: 11.6s\tremaining: 11.9s\n",
      "493:\tlearn: 0.0749302\ttotal: 11.6s\tremaining: 11.9s\n",
      "494:\tlearn: 0.0747788\ttotal: 11.6s\tremaining: 11.9s\n",
      "495:\tlearn: 0.0747667\ttotal: 11.7s\tremaining: 11.8s\n",
      "496:\tlearn: 0.0746274\ttotal: 11.7s\tremaining: 11.8s\n",
      "497:\tlearn: 0.0743913\ttotal: 11.7s\tremaining: 11.8s\n",
      "498:\tlearn: 0.0742275\ttotal: 11.7s\tremaining: 11.8s\n",
      "499:\tlearn: 0.0742141\ttotal: 11.7s\tremaining: 11.7s\n",
      "500:\tlearn: 0.0740231\ttotal: 11.8s\tremaining: 11.7s\n",
      "501:\tlearn: 0.0738667\ttotal: 11.8s\tremaining: 11.7s\n",
      "502:\tlearn: 0.0737521\ttotal: 11.8s\tremaining: 11.7s\n",
      "503:\tlearn: 0.0737354\ttotal: 11.8s\tremaining: 11.6s\n",
      "504:\tlearn: 0.0737165\ttotal: 11.8s\tremaining: 11.6s\n",
      "505:\tlearn: 0.0736383\ttotal: 11.9s\tremaining: 11.6s\n",
      "506:\tlearn: 0.0735212\ttotal: 11.9s\tremaining: 11.6s\n",
      "507:\tlearn: 0.0733627\ttotal: 11.9s\tremaining: 11.5s\n",
      "508:\tlearn: 0.0732967\ttotal: 11.9s\tremaining: 11.5s\n",
      "509:\tlearn: 0.0732836\ttotal: 11.9s\tremaining: 11.5s\n",
      "510:\tlearn: 0.0731546\ttotal: 12s\tremaining: 11.4s\n",
      "511:\tlearn: 0.0729843\ttotal: 12s\tremaining: 11.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512:\tlearn: 0.0728641\ttotal: 12s\tremaining: 11.4s\n",
      "513:\tlearn: 0.0728539\ttotal: 12s\tremaining: 11.4s\n",
      "514:\tlearn: 0.0727970\ttotal: 12.1s\tremaining: 11.4s\n",
      "515:\tlearn: 0.0727674\ttotal: 12.1s\tremaining: 11.3s\n",
      "516:\tlearn: 0.0727526\ttotal: 12.1s\tremaining: 11.3s\n",
      "517:\tlearn: 0.0725834\ttotal: 12.1s\tremaining: 11.3s\n",
      "518:\tlearn: 0.0723769\ttotal: 12.2s\tremaining: 11.3s\n",
      "519:\tlearn: 0.0722329\ttotal: 12.2s\tremaining: 11.2s\n",
      "520:\tlearn: 0.0720518\ttotal: 12.2s\tremaining: 11.2s\n",
      "521:\tlearn: 0.0719321\ttotal: 12.2s\tremaining: 11.2s\n",
      "522:\tlearn: 0.0717245\ttotal: 12.2s\tremaining: 11.2s\n",
      "523:\tlearn: 0.0717105\ttotal: 12.3s\tremaining: 11.1s\n",
      "524:\tlearn: 0.0715764\ttotal: 12.3s\tremaining: 11.1s\n",
      "525:\tlearn: 0.0714986\ttotal: 12.3s\tremaining: 11.1s\n",
      "526:\tlearn: 0.0714168\ttotal: 12.3s\tremaining: 11.1s\n",
      "527:\tlearn: 0.0713081\ttotal: 12.3s\tremaining: 11s\n",
      "528:\tlearn: 0.0710377\ttotal: 12.4s\tremaining: 11s\n",
      "529:\tlearn: 0.0708677\ttotal: 12.4s\tremaining: 11s\n",
      "530:\tlearn: 0.0708246\ttotal: 12.4s\tremaining: 10.9s\n",
      "531:\tlearn: 0.0706739\ttotal: 12.4s\tremaining: 10.9s\n",
      "532:\tlearn: 0.0704929\ttotal: 12.5s\tremaining: 10.9s\n",
      "533:\tlearn: 0.0703427\ttotal: 12.5s\tremaining: 10.9s\n",
      "534:\tlearn: 0.0701487\ttotal: 12.5s\tremaining: 10.9s\n",
      "535:\tlearn: 0.0700023\ttotal: 12.5s\tremaining: 10.8s\n",
      "536:\tlearn: 0.0698671\ttotal: 12.5s\tremaining: 10.8s\n",
      "537:\tlearn: 0.0697211\ttotal: 12.6s\tremaining: 10.8s\n",
      "538:\tlearn: 0.0695898\ttotal: 12.6s\tremaining: 10.8s\n",
      "539:\tlearn: 0.0694194\ttotal: 12.6s\tremaining: 10.7s\n",
      "540:\tlearn: 0.0693503\ttotal: 12.6s\tremaining: 10.7s\n",
      "541:\tlearn: 0.0692727\ttotal: 12.7s\tremaining: 10.7s\n",
      "542:\tlearn: 0.0692496\ttotal: 12.7s\tremaining: 10.7s\n",
      "543:\tlearn: 0.0691436\ttotal: 12.7s\tremaining: 10.7s\n",
      "544:\tlearn: 0.0689881\ttotal: 12.7s\tremaining: 10.6s\n",
      "545:\tlearn: 0.0688280\ttotal: 12.8s\tremaining: 10.6s\n",
      "546:\tlearn: 0.0687685\ttotal: 12.8s\tremaining: 10.6s\n",
      "547:\tlearn: 0.0686508\ttotal: 12.8s\tremaining: 10.6s\n",
      "548:\tlearn: 0.0685230\ttotal: 12.8s\tremaining: 10.5s\n",
      "549:\tlearn: 0.0684001\ttotal: 12.8s\tremaining: 10.5s\n",
      "550:\tlearn: 0.0683726\ttotal: 12.9s\tremaining: 10.5s\n",
      "551:\tlearn: 0.0683608\ttotal: 12.9s\tremaining: 10.5s\n",
      "552:\tlearn: 0.0682326\ttotal: 12.9s\tremaining: 10.4s\n",
      "553:\tlearn: 0.0681058\ttotal: 12.9s\tremaining: 10.4s\n",
      "554:\tlearn: 0.0679648\ttotal: 13s\tremaining: 10.4s\n",
      "555:\tlearn: 0.0679526\ttotal: 13s\tremaining: 10.4s\n",
      "556:\tlearn: 0.0679440\ttotal: 13s\tremaining: 10.3s\n",
      "557:\tlearn: 0.0678553\ttotal: 13s\tremaining: 10.3s\n",
      "558:\tlearn: 0.0677043\ttotal: 13s\tremaining: 10.3s\n",
      "559:\tlearn: 0.0676689\ttotal: 13.1s\tremaining: 10.3s\n",
      "560:\tlearn: 0.0675742\ttotal: 13.1s\tremaining: 10.2s\n",
      "561:\tlearn: 0.0674030\ttotal: 13.1s\tremaining: 10.2s\n",
      "562:\tlearn: 0.0672725\ttotal: 13.1s\tremaining: 10.2s\n",
      "563:\tlearn: 0.0671567\ttotal: 13.2s\tremaining: 10.2s\n",
      "564:\tlearn: 0.0670275\ttotal: 13.2s\tremaining: 10.1s\n",
      "565:\tlearn: 0.0669124\ttotal: 13.2s\tremaining: 10.1s\n",
      "566:\tlearn: 0.0669033\ttotal: 13.2s\tremaining: 10.1s\n",
      "567:\tlearn: 0.0668109\ttotal: 13.2s\tremaining: 10.1s\n",
      "568:\tlearn: 0.0668016\ttotal: 13.2s\tremaining: 10s\n",
      "569:\tlearn: 0.0666643\ttotal: 13.3s\tremaining: 10s\n",
      "570:\tlearn: 0.0665225\ttotal: 13.3s\tremaining: 9.99s\n",
      "571:\tlearn: 0.0664141\ttotal: 13.3s\tremaining: 9.97s\n",
      "572:\tlearn: 0.0662521\ttotal: 13.3s\tremaining: 9.94s\n",
      "573:\tlearn: 0.0661115\ttotal: 13.4s\tremaining: 9.92s\n",
      "574:\tlearn: 0.0659657\ttotal: 13.4s\tremaining: 9.9s\n",
      "575:\tlearn: 0.0659443\ttotal: 13.4s\tremaining: 9.87s\n",
      "576:\tlearn: 0.0658420\ttotal: 13.4s\tremaining: 9.85s\n",
      "577:\tlearn: 0.0657332\ttotal: 13.5s\tremaining: 9.84s\n",
      "578:\tlearn: 0.0656457\ttotal: 13.5s\tremaining: 9.81s\n",
      "579:\tlearn: 0.0655164\ttotal: 13.5s\tremaining: 9.79s\n",
      "580:\tlearn: 0.0653796\ttotal: 13.5s\tremaining: 9.76s\n",
      "581:\tlearn: 0.0651928\ttotal: 13.6s\tremaining: 9.74s\n",
      "582:\tlearn: 0.0650972\ttotal: 13.6s\tremaining: 9.71s\n",
      "583:\tlearn: 0.0650843\ttotal: 13.6s\tremaining: 9.69s\n",
      "584:\tlearn: 0.0649410\ttotal: 13.6s\tremaining: 9.66s\n",
      "585:\tlearn: 0.0648327\ttotal: 13.6s\tremaining: 9.64s\n",
      "586:\tlearn: 0.0647398\ttotal: 13.7s\tremaining: 9.62s\n",
      "587:\tlearn: 0.0645955\ttotal: 13.7s\tremaining: 9.59s\n",
      "588:\tlearn: 0.0644791\ttotal: 13.7s\tremaining: 9.57s\n",
      "589:\tlearn: 0.0643293\ttotal: 13.7s\tremaining: 9.55s\n",
      "590:\tlearn: 0.0642322\ttotal: 13.8s\tremaining: 9.53s\n",
      "591:\tlearn: 0.0641608\ttotal: 13.8s\tremaining: 9.5s\n",
      "592:\tlearn: 0.0640282\ttotal: 13.8s\tremaining: 9.48s\n",
      "593:\tlearn: 0.0639601\ttotal: 13.8s\tremaining: 9.45s\n",
      "594:\tlearn: 0.0638123\ttotal: 13.9s\tremaining: 9.43s\n",
      "595:\tlearn: 0.0636743\ttotal: 13.9s\tremaining: 9.4s\n",
      "596:\tlearn: 0.0636665\ttotal: 13.9s\tremaining: 9.37s\n",
      "597:\tlearn: 0.0635182\ttotal: 13.9s\tremaining: 9.35s\n",
      "598:\tlearn: 0.0633823\ttotal: 13.9s\tremaining: 9.33s\n",
      "599:\tlearn: 0.0633649\ttotal: 14s\tremaining: 9.31s\n",
      "600:\tlearn: 0.0632711\ttotal: 14s\tremaining: 9.29s\n",
      "601:\tlearn: 0.0631389\ttotal: 14s\tremaining: 9.26s\n",
      "602:\tlearn: 0.0630289\ttotal: 14s\tremaining: 9.24s\n",
      "603:\tlearn: 0.0629047\ttotal: 14.1s\tremaining: 9.22s\n",
      "604:\tlearn: 0.0627526\ttotal: 14.1s\tremaining: 9.19s\n",
      "605:\tlearn: 0.0626778\ttotal: 14.1s\tremaining: 9.17s\n",
      "606:\tlearn: 0.0625395\ttotal: 14.1s\tremaining: 9.15s\n",
      "607:\tlearn: 0.0625315\ttotal: 14.2s\tremaining: 9.13s\n",
      "608:\tlearn: 0.0623556\ttotal: 14.2s\tremaining: 9.1s\n",
      "609:\tlearn: 0.0621614\ttotal: 14.2s\tremaining: 9.08s\n",
      "610:\tlearn: 0.0620779\ttotal: 14.2s\tremaining: 9.05s\n",
      "611:\tlearn: 0.0619137\ttotal: 14.2s\tremaining: 9.03s\n",
      "612:\tlearn: 0.0618973\ttotal: 14.3s\tremaining: 9.01s\n",
      "613:\tlearn: 0.0617795\ttotal: 14.3s\tremaining: 8.98s\n",
      "614:\tlearn: 0.0617276\ttotal: 14.3s\tremaining: 8.96s\n",
      "615:\tlearn: 0.0616427\ttotal: 14.3s\tremaining: 8.93s\n",
      "616:\tlearn: 0.0615342\ttotal: 14.4s\tremaining: 8.91s\n",
      "617:\tlearn: 0.0613355\ttotal: 14.4s\tremaining: 8.89s\n",
      "618:\tlearn: 0.0613186\ttotal: 14.4s\tremaining: 8.86s\n",
      "619:\tlearn: 0.0612381\ttotal: 14.4s\tremaining: 8.84s\n",
      "620:\tlearn: 0.0611475\ttotal: 14.4s\tremaining: 8.81s\n",
      "621:\tlearn: 0.0610609\ttotal: 14.5s\tremaining: 8.79s\n",
      "622:\tlearn: 0.0609778\ttotal: 14.5s\tremaining: 8.76s\n",
      "623:\tlearn: 0.0608959\ttotal: 14.5s\tremaining: 8.73s\n",
      "624:\tlearn: 0.0608029\ttotal: 14.5s\tremaining: 8.71s\n",
      "625:\tlearn: 0.0606778\ttotal: 14.5s\tremaining: 8.68s\n",
      "626:\tlearn: 0.0605631\ttotal: 14.6s\tremaining: 8.66s\n",
      "627:\tlearn: 0.0604519\ttotal: 14.6s\tremaining: 8.64s\n",
      "628:\tlearn: 0.0603598\ttotal: 14.6s\tremaining: 8.61s\n",
      "629:\tlearn: 0.0602693\ttotal: 14.6s\tremaining: 8.59s\n",
      "630:\tlearn: 0.0601849\ttotal: 14.6s\tremaining: 8.56s\n",
      "631:\tlearn: 0.0600762\ttotal: 14.7s\tremaining: 8.54s\n",
      "632:\tlearn: 0.0599681\ttotal: 14.7s\tremaining: 8.51s\n",
      "633:\tlearn: 0.0598503\ttotal: 14.7s\tremaining: 8.49s\n",
      "634:\tlearn: 0.0597690\ttotal: 14.7s\tremaining: 8.46s\n",
      "635:\tlearn: 0.0595959\ttotal: 14.7s\tremaining: 8.44s\n",
      "636:\tlearn: 0.0595886\ttotal: 14.8s\tremaining: 8.42s\n",
      "637:\tlearn: 0.0594672\ttotal: 14.8s\tremaining: 8.4s\n",
      "638:\tlearn: 0.0593482\ttotal: 14.8s\tremaining: 8.37s\n",
      "639:\tlearn: 0.0591587\ttotal: 14.8s\tremaining: 8.35s\n",
      "640:\tlearn: 0.0590473\ttotal: 14.9s\tremaining: 8.32s\n",
      "641:\tlearn: 0.0589535\ttotal: 14.9s\tremaining: 8.3s\n",
      "642:\tlearn: 0.0588698\ttotal: 14.9s\tremaining: 8.28s\n",
      "643:\tlearn: 0.0588613\ttotal: 14.9s\tremaining: 8.26s\n",
      "644:\tlearn: 0.0587014\ttotal: 15s\tremaining: 8.23s\n",
      "645:\tlearn: 0.0585935\ttotal: 15s\tremaining: 8.21s\n",
      "646:\tlearn: 0.0584460\ttotal: 15s\tremaining: 8.19s\n",
      "647:\tlearn: 0.0583700\ttotal: 15s\tremaining: 8.16s\n",
      "648:\tlearn: 0.0582355\ttotal: 15.1s\tremaining: 8.14s\n",
      "649:\tlearn: 0.0581767\ttotal: 15.1s\tremaining: 8.12s\n",
      "650:\tlearn: 0.0580892\ttotal: 15.1s\tremaining: 8.1s\n",
      "651:\tlearn: 0.0579988\ttotal: 15.1s\tremaining: 8.07s\n",
      "652:\tlearn: 0.0578902\ttotal: 15.1s\tremaining: 8.05s\n",
      "653:\tlearn: 0.0578832\ttotal: 15.2s\tremaining: 8.03s\n",
      "654:\tlearn: 0.0577695\ttotal: 15.2s\tremaining: 8s\n",
      "655:\tlearn: 0.0576342\ttotal: 15.2s\tremaining: 7.98s\n",
      "656:\tlearn: 0.0575297\ttotal: 15.2s\tremaining: 7.96s\n",
      "657:\tlearn: 0.0574518\ttotal: 15.3s\tremaining: 7.93s\n",
      "658:\tlearn: 0.0573709\ttotal: 15.3s\tremaining: 7.91s\n",
      "659:\tlearn: 0.0573475\ttotal: 15.3s\tremaining: 7.89s\n",
      "660:\tlearn: 0.0571440\ttotal: 15.3s\tremaining: 7.86s\n",
      "661:\tlearn: 0.0570310\ttotal: 15.4s\tremaining: 7.84s\n",
      "662:\tlearn: 0.0569586\ttotal: 15.4s\tremaining: 7.82s\n",
      "663:\tlearn: 0.0568222\ttotal: 15.4s\tremaining: 7.79s\n",
      "664:\tlearn: 0.0567735\ttotal: 15.4s\tremaining: 7.77s\n",
      "665:\tlearn: 0.0566904\ttotal: 15.4s\tremaining: 7.75s\n",
      "666:\tlearn: 0.0565774\ttotal: 15.5s\tremaining: 7.72s\n",
      "667:\tlearn: 0.0565635\ttotal: 15.5s\tremaining: 7.7s\n",
      "668:\tlearn: 0.0564480\ttotal: 15.5s\tremaining: 7.68s\n",
      "669:\tlearn: 0.0563254\ttotal: 15.5s\tremaining: 7.65s\n",
      "670:\tlearn: 0.0563101\ttotal: 15.6s\tremaining: 7.63s\n",
      "671:\tlearn: 0.0562328\ttotal: 15.6s\tremaining: 7.61s\n",
      "672:\tlearn: 0.0561448\ttotal: 15.6s\tremaining: 7.58s\n",
      "673:\tlearn: 0.0560763\ttotal: 15.6s\tremaining: 7.55s\n",
      "674:\tlearn: 0.0560110\ttotal: 15.6s\tremaining: 7.53s\n",
      "675:\tlearn: 0.0558559\ttotal: 15.7s\tremaining: 7.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "676:\tlearn: 0.0558463\ttotal: 15.7s\tremaining: 7.48s\n",
      "677:\tlearn: 0.0558138\ttotal: 15.7s\tremaining: 7.46s\n",
      "678:\tlearn: 0.0557142\ttotal: 15.7s\tremaining: 7.44s\n",
      "679:\tlearn: 0.0556450\ttotal: 15.8s\tremaining: 7.41s\n",
      "680:\tlearn: 0.0555824\ttotal: 15.8s\tremaining: 7.39s\n",
      "681:\tlearn: 0.0554975\ttotal: 15.8s\tremaining: 7.37s\n",
      "682:\tlearn: 0.0554911\ttotal: 15.8s\tremaining: 7.34s\n",
      "683:\tlearn: 0.0554848\ttotal: 15.8s\tremaining: 7.32s\n",
      "684:\tlearn: 0.0554531\ttotal: 15.9s\tremaining: 7.29s\n",
      "685:\tlearn: 0.0553580\ttotal: 15.9s\tremaining: 7.27s\n",
      "686:\tlearn: 0.0552674\ttotal: 15.9s\tremaining: 7.25s\n",
      "687:\tlearn: 0.0551684\ttotal: 15.9s\tremaining: 7.23s\n",
      "688:\tlearn: 0.0550581\ttotal: 16s\tremaining: 7.2s\n",
      "689:\tlearn: 0.0549679\ttotal: 16s\tremaining: 7.18s\n",
      "690:\tlearn: 0.0548761\ttotal: 16s\tremaining: 7.16s\n",
      "691:\tlearn: 0.0547826\ttotal: 16s\tremaining: 7.13s\n",
      "692:\tlearn: 0.0547116\ttotal: 16s\tremaining: 7.11s\n",
      "693:\tlearn: 0.0545871\ttotal: 16.1s\tremaining: 7.08s\n",
      "694:\tlearn: 0.0545506\ttotal: 16.1s\tremaining: 7.06s\n",
      "695:\tlearn: 0.0545043\ttotal: 16.1s\tremaining: 7.04s\n",
      "696:\tlearn: 0.0544343\ttotal: 16.1s\tremaining: 7.01s\n",
      "697:\tlearn: 0.0543396\ttotal: 16.2s\tremaining: 6.99s\n",
      "698:\tlearn: 0.0543239\ttotal: 16.2s\tremaining: 6.97s\n",
      "699:\tlearn: 0.0542425\ttotal: 16.2s\tremaining: 6.95s\n",
      "700:\tlearn: 0.0541768\ttotal: 16.2s\tremaining: 6.92s\n",
      "701:\tlearn: 0.0541005\ttotal: 16.3s\tremaining: 6.9s\n",
      "702:\tlearn: 0.0539840\ttotal: 16.3s\tremaining: 6.88s\n",
      "703:\tlearn: 0.0539412\ttotal: 16.3s\tremaining: 6.85s\n",
      "704:\tlearn: 0.0538458\ttotal: 16.3s\tremaining: 6.83s\n",
      "705:\tlearn: 0.0538105\ttotal: 16.3s\tremaining: 6.81s\n",
      "706:\tlearn: 0.0536975\ttotal: 16.4s\tremaining: 6.78s\n",
      "707:\tlearn: 0.0535843\ttotal: 16.4s\tremaining: 6.76s\n",
      "708:\tlearn: 0.0535173\ttotal: 16.4s\tremaining: 6.74s\n",
      "709:\tlearn: 0.0534057\ttotal: 16.4s\tremaining: 6.71s\n",
      "710:\tlearn: 0.0533025\ttotal: 16.5s\tremaining: 6.69s\n",
      "711:\tlearn: 0.0532075\ttotal: 16.5s\tremaining: 6.67s\n",
      "712:\tlearn: 0.0531918\ttotal: 16.5s\tremaining: 6.64s\n",
      "713:\tlearn: 0.0531441\ttotal: 16.5s\tremaining: 6.62s\n",
      "714:\tlearn: 0.0531044\ttotal: 16.6s\tremaining: 6.6s\n",
      "715:\tlearn: 0.0530036\ttotal: 16.6s\tremaining: 6.57s\n",
      "716:\tlearn: 0.0529376\ttotal: 16.6s\tremaining: 6.55s\n",
      "717:\tlearn: 0.0528494\ttotal: 16.6s\tremaining: 6.52s\n",
      "718:\tlearn: 0.0528344\ttotal: 16.6s\tremaining: 6.5s\n",
      "719:\tlearn: 0.0527449\ttotal: 16.7s\tremaining: 6.48s\n",
      "720:\tlearn: 0.0526537\ttotal: 16.7s\tremaining: 6.45s\n",
      "721:\tlearn: 0.0525460\ttotal: 16.7s\tremaining: 6.43s\n",
      "722:\tlearn: 0.0524820\ttotal: 16.7s\tremaining: 6.41s\n",
      "723:\tlearn: 0.0524124\ttotal: 16.7s\tremaining: 6.38s\n",
      "724:\tlearn: 0.0523522\ttotal: 16.8s\tremaining: 6.36s\n",
      "725:\tlearn: 0.0522492\ttotal: 16.8s\tremaining: 6.33s\n",
      "726:\tlearn: 0.0521747\ttotal: 16.8s\tremaining: 6.31s\n",
      "727:\tlearn: 0.0520745\ttotal: 16.8s\tremaining: 6.29s\n",
      "728:\tlearn: 0.0520688\ttotal: 16.9s\tremaining: 6.26s\n",
      "729:\tlearn: 0.0519774\ttotal: 16.9s\tremaining: 6.24s\n",
      "730:\tlearn: 0.0518949\ttotal: 16.9s\tremaining: 6.22s\n",
      "731:\tlearn: 0.0517921\ttotal: 16.9s\tremaining: 6.2s\n",
      "732:\tlearn: 0.0517016\ttotal: 16.9s\tremaining: 6.17s\n",
      "733:\tlearn: 0.0516012\ttotal: 17s\tremaining: 6.15s\n",
      "734:\tlearn: 0.0515956\ttotal: 17s\tremaining: 6.13s\n",
      "735:\tlearn: 0.0515107\ttotal: 17s\tremaining: 6.11s\n",
      "736:\tlearn: 0.0514316\ttotal: 17s\tremaining: 6.08s\n",
      "737:\tlearn: 0.0513593\ttotal: 17.1s\tremaining: 6.06s\n",
      "738:\tlearn: 0.0513538\ttotal: 17.1s\tremaining: 6.04s\n",
      "739:\tlearn: 0.0512938\ttotal: 17.1s\tremaining: 6.01s\n",
      "740:\tlearn: 0.0512028\ttotal: 17.1s\tremaining: 5.99s\n",
      "741:\tlearn: 0.0510707\ttotal: 17.2s\tremaining: 5.97s\n",
      "742:\tlearn: 0.0510092\ttotal: 17.2s\tremaining: 5.95s\n",
      "743:\tlearn: 0.0509071\ttotal: 17.2s\tremaining: 5.92s\n",
      "744:\tlearn: 0.0509003\ttotal: 17.2s\tremaining: 5.9s\n",
      "745:\tlearn: 0.0508601\ttotal: 17.3s\tremaining: 5.88s\n",
      "746:\tlearn: 0.0507866\ttotal: 17.3s\tremaining: 5.85s\n",
      "747:\tlearn: 0.0506763\ttotal: 17.3s\tremaining: 5.83s\n",
      "748:\tlearn: 0.0506264\ttotal: 17.3s\tremaining: 5.8s\n",
      "749:\tlearn: 0.0505030\ttotal: 17.3s\tremaining: 5.78s\n",
      "750:\tlearn: 0.0504110\ttotal: 17.4s\tremaining: 5.76s\n",
      "751:\tlearn: 0.0503338\ttotal: 17.4s\tremaining: 5.74s\n",
      "752:\tlearn: 0.0503204\ttotal: 17.4s\tremaining: 5.71s\n",
      "753:\tlearn: 0.0502536\ttotal: 17.4s\tremaining: 5.69s\n",
      "754:\tlearn: 0.0501089\ttotal: 17.5s\tremaining: 5.67s\n",
      "755:\tlearn: 0.0500133\ttotal: 17.5s\tremaining: 5.64s\n",
      "756:\tlearn: 0.0499240\ttotal: 17.5s\tremaining: 5.62s\n",
      "757:\tlearn: 0.0499173\ttotal: 17.5s\tremaining: 5.6s\n",
      "758:\tlearn: 0.0498360\ttotal: 17.5s\tremaining: 5.57s\n",
      "759:\tlearn: 0.0497016\ttotal: 17.6s\tremaining: 5.55s\n",
      "760:\tlearn: 0.0496686\ttotal: 17.6s\tremaining: 5.52s\n",
      "761:\tlearn: 0.0495707\ttotal: 17.6s\tremaining: 5.5s\n",
      "762:\tlearn: 0.0494780\ttotal: 17.6s\tremaining: 5.48s\n",
      "763:\tlearn: 0.0494722\ttotal: 17.7s\tremaining: 5.46s\n",
      "764:\tlearn: 0.0494407\ttotal: 17.7s\tremaining: 5.43s\n",
      "765:\tlearn: 0.0493726\ttotal: 17.7s\tremaining: 5.41s\n",
      "766:\tlearn: 0.0493656\ttotal: 17.7s\tremaining: 5.38s\n",
      "767:\tlearn: 0.0493091\ttotal: 17.7s\tremaining: 5.36s\n",
      "768:\tlearn: 0.0492011\ttotal: 17.8s\tremaining: 5.34s\n",
      "769:\tlearn: 0.0491092\ttotal: 17.8s\tremaining: 5.31s\n",
      "770:\tlearn: 0.0490162\ttotal: 17.8s\tremaining: 5.29s\n",
      "771:\tlearn: 0.0489388\ttotal: 17.8s\tremaining: 5.27s\n",
      "772:\tlearn: 0.0489000\ttotal: 17.9s\tremaining: 5.24s\n",
      "773:\tlearn: 0.0488684\ttotal: 17.9s\tremaining: 5.22s\n",
      "774:\tlearn: 0.0488006\ttotal: 17.9s\tremaining: 5.2s\n",
      "775:\tlearn: 0.0486961\ttotal: 17.9s\tremaining: 5.17s\n",
      "776:\tlearn: 0.0486911\ttotal: 18s\tremaining: 5.15s\n",
      "777:\tlearn: 0.0486338\ttotal: 18s\tremaining: 5.13s\n",
      "778:\tlearn: 0.0486289\ttotal: 18s\tremaining: 5.11s\n",
      "779:\tlearn: 0.0486046\ttotal: 18s\tremaining: 5.08s\n",
      "780:\tlearn: 0.0485656\ttotal: 18s\tremaining: 5.06s\n",
      "781:\tlearn: 0.0485074\ttotal: 18.1s\tremaining: 5.04s\n",
      "782:\tlearn: 0.0484435\ttotal: 18.1s\tremaining: 5.01s\n",
      "783:\tlearn: 0.0483658\ttotal: 18.1s\tremaining: 4.99s\n",
      "784:\tlearn: 0.0483112\ttotal: 18.1s\tremaining: 4.97s\n",
      "785:\tlearn: 0.0481732\ttotal: 18.2s\tremaining: 4.94s\n",
      "786:\tlearn: 0.0480888\ttotal: 18.2s\tremaining: 4.92s\n",
      "787:\tlearn: 0.0480217\ttotal: 18.2s\tremaining: 4.89s\n",
      "788:\tlearn: 0.0478957\ttotal: 18.2s\tremaining: 4.87s\n",
      "789:\tlearn: 0.0478522\ttotal: 18.2s\tremaining: 4.85s\n",
      "790:\tlearn: 0.0478474\ttotal: 18.3s\tremaining: 4.83s\n",
      "791:\tlearn: 0.0477804\ttotal: 18.3s\tremaining: 4.8s\n",
      "792:\tlearn: 0.0477205\ttotal: 18.3s\tremaining: 4.78s\n",
      "793:\tlearn: 0.0476619\ttotal: 18.3s\tremaining: 4.76s\n",
      "794:\tlearn: 0.0476412\ttotal: 18.4s\tremaining: 4.74s\n",
      "795:\tlearn: 0.0475681\ttotal: 18.4s\tremaining: 4.71s\n",
      "796:\tlearn: 0.0474977\ttotal: 18.4s\tremaining: 4.69s\n",
      "797:\tlearn: 0.0474929\ttotal: 18.4s\tremaining: 4.67s\n",
      "798:\tlearn: 0.0474815\ttotal: 18.5s\tremaining: 4.64s\n",
      "799:\tlearn: 0.0474211\ttotal: 18.5s\tremaining: 4.62s\n",
      "800:\tlearn: 0.0473337\ttotal: 18.5s\tremaining: 4.6s\n",
      "801:\tlearn: 0.0472374\ttotal: 18.5s\tremaining: 4.58s\n",
      "802:\tlearn: 0.0471557\ttotal: 18.6s\tremaining: 4.55s\n",
      "803:\tlearn: 0.0471167\ttotal: 18.6s\tremaining: 4.53s\n",
      "804:\tlearn: 0.0469944\ttotal: 18.6s\tremaining: 4.51s\n",
      "805:\tlearn: 0.0469225\ttotal: 18.6s\tremaining: 4.48s\n",
      "806:\tlearn: 0.0468196\ttotal: 18.6s\tremaining: 4.46s\n",
      "807:\tlearn: 0.0467238\ttotal: 18.7s\tremaining: 4.44s\n",
      "808:\tlearn: 0.0466339\ttotal: 18.7s\tremaining: 4.41s\n",
      "809:\tlearn: 0.0465607\ttotal: 18.7s\tremaining: 4.39s\n",
      "810:\tlearn: 0.0464917\ttotal: 18.7s\tremaining: 4.37s\n",
      "811:\tlearn: 0.0463869\ttotal: 18.8s\tremaining: 4.34s\n",
      "812:\tlearn: 0.0463094\ttotal: 18.8s\tremaining: 4.32s\n",
      "813:\tlearn: 0.0462167\ttotal: 18.8s\tremaining: 4.3s\n",
      "814:\tlearn: 0.0461540\ttotal: 18.8s\tremaining: 4.27s\n",
      "815:\tlearn: 0.0461406\ttotal: 18.9s\tremaining: 4.25s\n",
      "816:\tlearn: 0.0461359\ttotal: 18.9s\tremaining: 4.23s\n",
      "817:\tlearn: 0.0460862\ttotal: 18.9s\tremaining: 4.2s\n",
      "818:\tlearn: 0.0460352\ttotal: 18.9s\tremaining: 4.18s\n",
      "819:\tlearn: 0.0460272\ttotal: 18.9s\tremaining: 4.16s\n",
      "820:\tlearn: 0.0459503\ttotal: 19s\tremaining: 4.14s\n",
      "821:\tlearn: 0.0459149\ttotal: 19s\tremaining: 4.12s\n",
      "822:\tlearn: 0.0458755\ttotal: 19s\tremaining: 4.09s\n",
      "823:\tlearn: 0.0458233\ttotal: 19s\tremaining: 4.07s\n",
      "824:\tlearn: 0.0457616\ttotal: 19.1s\tremaining: 4.04s\n",
      "825:\tlearn: 0.0457043\ttotal: 19.1s\tremaining: 4.02s\n",
      "826:\tlearn: 0.0455668\ttotal: 19.1s\tremaining: 4s\n",
      "827:\tlearn: 0.0454933\ttotal: 19.1s\tremaining: 3.97s\n",
      "828:\tlearn: 0.0454885\ttotal: 19.2s\tremaining: 3.95s\n",
      "829:\tlearn: 0.0454320\ttotal: 19.2s\tremaining: 3.93s\n",
      "830:\tlearn: 0.0453416\ttotal: 19.2s\tremaining: 3.9s\n",
      "831:\tlearn: 0.0452512\ttotal: 19.2s\tremaining: 3.88s\n",
      "832:\tlearn: 0.0452318\ttotal: 19.3s\tremaining: 3.86s\n",
      "833:\tlearn: 0.0452270\ttotal: 19.3s\tremaining: 3.83s\n",
      "834:\tlearn: 0.0451426\ttotal: 19.3s\tremaining: 3.81s\n",
      "835:\tlearn: 0.0450973\ttotal: 19.3s\tremaining: 3.79s\n",
      "836:\tlearn: 0.0450933\ttotal: 19.3s\tremaining: 3.77s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "837:\tlearn: 0.0450892\ttotal: 19.4s\tremaining: 3.74s\n",
      "838:\tlearn: 0.0450352\ttotal: 19.4s\tremaining: 3.72s\n",
      "839:\tlearn: 0.0450239\ttotal: 19.4s\tremaining: 3.7s\n",
      "840:\tlearn: 0.0449482\ttotal: 19.4s\tremaining: 3.67s\n",
      "841:\tlearn: 0.0448576\ttotal: 19.4s\tremaining: 3.65s\n",
      "842:\tlearn: 0.0448476\ttotal: 19.5s\tremaining: 3.63s\n",
      "843:\tlearn: 0.0447832\ttotal: 19.5s\tremaining: 3.6s\n",
      "844:\tlearn: 0.0447780\ttotal: 19.5s\tremaining: 3.58s\n",
      "845:\tlearn: 0.0447200\ttotal: 19.5s\tremaining: 3.56s\n",
      "846:\tlearn: 0.0446283\ttotal: 19.6s\tremaining: 3.53s\n",
      "847:\tlearn: 0.0446090\ttotal: 19.6s\tremaining: 3.51s\n",
      "848:\tlearn: 0.0445754\ttotal: 19.6s\tremaining: 3.48s\n",
      "849:\tlearn: 0.0445310\ttotal: 19.6s\tremaining: 3.46s\n",
      "850:\tlearn: 0.0444602\ttotal: 19.6s\tremaining: 3.44s\n",
      "851:\tlearn: 0.0444158\ttotal: 19.7s\tremaining: 3.42s\n",
      "852:\tlearn: 0.0443311\ttotal: 19.7s\tremaining: 3.39s\n",
      "853:\tlearn: 0.0442592\ttotal: 19.7s\tremaining: 3.37s\n",
      "854:\tlearn: 0.0441910\ttotal: 19.7s\tremaining: 3.35s\n",
      "855:\tlearn: 0.0441381\ttotal: 19.8s\tremaining: 3.32s\n",
      "856:\tlearn: 0.0440825\ttotal: 19.8s\tremaining: 3.3s\n",
      "857:\tlearn: 0.0440283\ttotal: 19.8s\tremaining: 3.28s\n",
      "858:\tlearn: 0.0439846\ttotal: 19.8s\tremaining: 3.25s\n",
      "859:\tlearn: 0.0439212\ttotal: 19.8s\tremaining: 3.23s\n",
      "860:\tlearn: 0.0439174\ttotal: 19.9s\tremaining: 3.21s\n",
      "861:\tlearn: 0.0438841\ttotal: 19.9s\tremaining: 3.18s\n",
      "862:\tlearn: 0.0437962\ttotal: 19.9s\tremaining: 3.16s\n",
      "863:\tlearn: 0.0437718\ttotal: 19.9s\tremaining: 3.14s\n",
      "864:\tlearn: 0.0437082\ttotal: 20s\tremaining: 3.11s\n",
      "865:\tlearn: 0.0437033\ttotal: 20s\tremaining: 3.09s\n",
      "866:\tlearn: 0.0436335\ttotal: 20s\tremaining: 3.07s\n",
      "867:\tlearn: 0.0435775\ttotal: 20s\tremaining: 3.04s\n",
      "868:\tlearn: 0.0434929\ttotal: 20.1s\tremaining: 3.02s\n",
      "869:\tlearn: 0.0434319\ttotal: 20.1s\tremaining: 3s\n",
      "870:\tlearn: 0.0434274\ttotal: 20.1s\tremaining: 2.98s\n",
      "871:\tlearn: 0.0433703\ttotal: 20.1s\tremaining: 2.95s\n",
      "872:\tlearn: 0.0433453\ttotal: 20.1s\tremaining: 2.93s\n",
      "873:\tlearn: 0.0433062\ttotal: 20.2s\tremaining: 2.91s\n",
      "874:\tlearn: 0.0432233\ttotal: 20.2s\tremaining: 2.88s\n",
      "875:\tlearn: 0.0432184\ttotal: 20.2s\tremaining: 2.86s\n",
      "876:\tlearn: 0.0431935\ttotal: 20.2s\tremaining: 2.83s\n",
      "877:\tlearn: 0.0431619\ttotal: 20.2s\tremaining: 2.81s\n",
      "878:\tlearn: 0.0430667\ttotal: 20.3s\tremaining: 2.79s\n",
      "879:\tlearn: 0.0430501\ttotal: 20.3s\tremaining: 2.77s\n",
      "880:\tlearn: 0.0430461\ttotal: 20.3s\tremaining: 2.74s\n",
      "881:\tlearn: 0.0429868\ttotal: 20.3s\tremaining: 2.72s\n",
      "882:\tlearn: 0.0429236\ttotal: 20.3s\tremaining: 2.69s\n",
      "883:\tlearn: 0.0428619\ttotal: 20.4s\tremaining: 2.67s\n",
      "884:\tlearn: 0.0428144\ttotal: 20.4s\tremaining: 2.65s\n",
      "885:\tlearn: 0.0428075\ttotal: 20.4s\tremaining: 2.62s\n",
      "886:\tlearn: 0.0428034\ttotal: 20.4s\tremaining: 2.6s\n",
      "887:\tlearn: 0.0427492\ttotal: 20.4s\tremaining: 2.58s\n",
      "888:\tlearn: 0.0426907\ttotal: 20.5s\tremaining: 2.55s\n",
      "889:\tlearn: 0.0426438\ttotal: 20.5s\tremaining: 2.53s\n",
      "890:\tlearn: 0.0425509\ttotal: 20.5s\tremaining: 2.51s\n",
      "891:\tlearn: 0.0424951\ttotal: 20.5s\tremaining: 2.49s\n",
      "892:\tlearn: 0.0424410\ttotal: 20.6s\tremaining: 2.46s\n",
      "893:\tlearn: 0.0424027\ttotal: 20.6s\tremaining: 2.44s\n",
      "894:\tlearn: 0.0423569\ttotal: 20.6s\tremaining: 2.42s\n",
      "895:\tlearn: 0.0422972\ttotal: 20.6s\tremaining: 2.39s\n",
      "896:\tlearn: 0.0422331\ttotal: 20.6s\tremaining: 2.37s\n",
      "897:\tlearn: 0.0421438\ttotal: 20.7s\tremaining: 2.35s\n",
      "898:\tlearn: 0.0421402\ttotal: 20.7s\tremaining: 2.33s\n",
      "899:\tlearn: 0.0420733\ttotal: 20.8s\tremaining: 2.31s\n",
      "900:\tlearn: 0.0420698\ttotal: 20.8s\tremaining: 2.28s\n",
      "901:\tlearn: 0.0420476\ttotal: 20.8s\tremaining: 2.26s\n",
      "902:\tlearn: 0.0419966\ttotal: 20.9s\tremaining: 2.24s\n",
      "903:\tlearn: 0.0419933\ttotal: 20.9s\tremaining: 2.22s\n",
      "904:\tlearn: 0.0419443\ttotal: 20.9s\tremaining: 2.2s\n",
      "905:\tlearn: 0.0418983\ttotal: 21s\tremaining: 2.17s\n",
      "906:\tlearn: 0.0418228\ttotal: 21s\tremaining: 2.15s\n",
      "907:\tlearn: 0.0417503\ttotal: 21s\tremaining: 2.13s\n",
      "908:\tlearn: 0.0417318\ttotal: 21.1s\tremaining: 2.11s\n",
      "909:\tlearn: 0.0416485\ttotal: 21.1s\tremaining: 2.09s\n",
      "910:\tlearn: 0.0416204\ttotal: 21.1s\tremaining: 2.06s\n",
      "911:\tlearn: 0.0415565\ttotal: 21.2s\tremaining: 2.04s\n",
      "912:\tlearn: 0.0415173\ttotal: 21.2s\tremaining: 2.02s\n",
      "913:\tlearn: 0.0415138\ttotal: 21.2s\tremaining: 2s\n",
      "914:\tlearn: 0.0414698\ttotal: 21.3s\tremaining: 1.98s\n",
      "915:\tlearn: 0.0414135\ttotal: 21.3s\tremaining: 1.95s\n",
      "916:\tlearn: 0.0413801\ttotal: 21.3s\tremaining: 1.93s\n",
      "917:\tlearn: 0.0413376\ttotal: 21.4s\tremaining: 1.91s\n",
      "918:\tlearn: 0.0412955\ttotal: 21.4s\tremaining: 1.89s\n",
      "919:\tlearn: 0.0412391\ttotal: 21.4s\tremaining: 1.86s\n",
      "920:\tlearn: 0.0411938\ttotal: 21.5s\tremaining: 1.84s\n",
      "921:\tlearn: 0.0411452\ttotal: 21.5s\tremaining: 1.82s\n",
      "922:\tlearn: 0.0411414\ttotal: 21.5s\tremaining: 1.8s\n",
      "923:\tlearn: 0.0410158\ttotal: 21.6s\tremaining: 1.77s\n",
      "924:\tlearn: 0.0410014\ttotal: 21.6s\tremaining: 1.75s\n",
      "925:\tlearn: 0.0409237\ttotal: 21.6s\tremaining: 1.73s\n",
      "926:\tlearn: 0.0409204\ttotal: 21.7s\tremaining: 1.71s\n",
      "927:\tlearn: 0.0408940\ttotal: 21.7s\tremaining: 1.68s\n",
      "928:\tlearn: 0.0408256\ttotal: 21.7s\tremaining: 1.66s\n",
      "929:\tlearn: 0.0408169\ttotal: 21.8s\tremaining: 1.64s\n",
      "930:\tlearn: 0.0407946\ttotal: 21.8s\tremaining: 1.61s\n",
      "931:\tlearn: 0.0407334\ttotal: 21.8s\tremaining: 1.59s\n",
      "932:\tlearn: 0.0406313\ttotal: 21.9s\tremaining: 1.57s\n",
      "933:\tlearn: 0.0406217\ttotal: 21.9s\tremaining: 1.55s\n",
      "934:\tlearn: 0.0405483\ttotal: 21.9s\tremaining: 1.52s\n",
      "935:\tlearn: 0.0405006\ttotal: 21.9s\tremaining: 1.5s\n",
      "936:\tlearn: 0.0404409\ttotal: 22s\tremaining: 1.48s\n",
      "937:\tlearn: 0.0403923\ttotal: 22s\tremaining: 1.45s\n",
      "938:\tlearn: 0.0403412\ttotal: 22s\tremaining: 1.43s\n",
      "939:\tlearn: 0.0403066\ttotal: 22.1s\tremaining: 1.41s\n",
      "940:\tlearn: 0.0402427\ttotal: 22.1s\tremaining: 1.38s\n",
      "941:\tlearn: 0.0401762\ttotal: 22.1s\tremaining: 1.36s\n",
      "942:\tlearn: 0.0401090\ttotal: 22.1s\tremaining: 1.34s\n",
      "943:\tlearn: 0.0400417\ttotal: 22.2s\tremaining: 1.31s\n",
      "944:\tlearn: 0.0399935\ttotal: 22.2s\tremaining: 1.29s\n",
      "945:\tlearn: 0.0399864\ttotal: 22.2s\tremaining: 1.27s\n",
      "946:\tlearn: 0.0399833\ttotal: 22.3s\tremaining: 1.25s\n",
      "947:\tlearn: 0.0398974\ttotal: 22.3s\tremaining: 1.22s\n",
      "948:\tlearn: 0.0398354\ttotal: 22.3s\tremaining: 1.2s\n",
      "949:\tlearn: 0.0397855\ttotal: 22.3s\tremaining: 1.18s\n",
      "950:\tlearn: 0.0397516\ttotal: 22.4s\tremaining: 1.15s\n",
      "951:\tlearn: 0.0397485\ttotal: 22.4s\tremaining: 1.13s\n",
      "952:\tlearn: 0.0397181\ttotal: 22.4s\tremaining: 1.1s\n",
      "953:\tlearn: 0.0396536\ttotal: 22.4s\tremaining: 1.08s\n",
      "954:\tlearn: 0.0395975\ttotal: 22.5s\tremaining: 1.06s\n",
      "955:\tlearn: 0.0395944\ttotal: 22.5s\tremaining: 1.03s\n",
      "956:\tlearn: 0.0395277\ttotal: 22.5s\tremaining: 1.01s\n",
      "957:\tlearn: 0.0394864\ttotal: 22.6s\tremaining: 989ms\n",
      "958:\tlearn: 0.0394165\ttotal: 22.6s\tremaining: 966ms\n",
      "959:\tlearn: 0.0393779\ttotal: 22.6s\tremaining: 943ms\n",
      "960:\tlearn: 0.0393433\ttotal: 22.7s\tremaining: 920ms\n",
      "961:\tlearn: 0.0392814\ttotal: 22.7s\tremaining: 896ms\n",
      "962:\tlearn: 0.0392379\ttotal: 22.7s\tremaining: 873ms\n",
      "963:\tlearn: 0.0391579\ttotal: 22.8s\tremaining: 850ms\n",
      "964:\tlearn: 0.0390530\ttotal: 22.8s\tremaining: 827ms\n",
      "965:\tlearn: 0.0390143\ttotal: 22.8s\tremaining: 803ms\n",
      "966:\tlearn: 0.0389386\ttotal: 22.9s\tremaining: 780ms\n",
      "967:\tlearn: 0.0388654\ttotal: 22.9s\tremaining: 757ms\n",
      "968:\tlearn: 0.0388564\ttotal: 22.9s\tremaining: 734ms\n",
      "969:\tlearn: 0.0387758\ttotal: 23s\tremaining: 711ms\n",
      "970:\tlearn: 0.0387030\ttotal: 23s\tremaining: 687ms\n",
      "971:\tlearn: 0.0386823\ttotal: 23s\tremaining: 664ms\n",
      "972:\tlearn: 0.0386624\ttotal: 23.1s\tremaining: 640ms\n",
      "973:\tlearn: 0.0386220\ttotal: 23.1s\tremaining: 617ms\n",
      "974:\tlearn: 0.0386190\ttotal: 23.1s\tremaining: 594ms\n",
      "975:\tlearn: 0.0385699\ttotal: 23.2s\tremaining: 570ms\n",
      "976:\tlearn: 0.0385262\ttotal: 23.2s\tremaining: 546ms\n",
      "977:\tlearn: 0.0384912\ttotal: 23.2s\tremaining: 523ms\n",
      "978:\tlearn: 0.0384623\ttotal: 23.3s\tremaining: 499ms\n",
      "979:\tlearn: 0.0383744\ttotal: 23.3s\tremaining: 475ms\n",
      "980:\tlearn: 0.0383366\ttotal: 23.3s\tremaining: 452ms\n",
      "981:\tlearn: 0.0382876\ttotal: 23.4s\tremaining: 428ms\n",
      "982:\tlearn: 0.0382845\ttotal: 23.4s\tremaining: 405ms\n",
      "983:\tlearn: 0.0382230\ttotal: 23.4s\tremaining: 381ms\n",
      "984:\tlearn: 0.0381954\ttotal: 23.4s\tremaining: 357ms\n",
      "985:\tlearn: 0.0381073\ttotal: 23.5s\tremaining: 333ms\n",
      "986:\tlearn: 0.0380700\ttotal: 23.5s\tremaining: 309ms\n",
      "987:\tlearn: 0.0380572\ttotal: 23.5s\tremaining: 286ms\n",
      "988:\tlearn: 0.0380108\ttotal: 23.5s\tremaining: 262ms\n",
      "989:\tlearn: 0.0379538\ttotal: 23.6s\tremaining: 238ms\n",
      "990:\tlearn: 0.0379320\ttotal: 23.6s\tremaining: 214ms\n",
      "991:\tlearn: 0.0378886\ttotal: 23.6s\tremaining: 190ms\n",
      "992:\tlearn: 0.0377910\ttotal: 23.6s\tremaining: 167ms\n",
      "993:\tlearn: 0.0377760\ttotal: 23.6s\tremaining: 143ms\n",
      "994:\tlearn: 0.0377496\ttotal: 23.7s\tremaining: 119ms\n",
      "995:\tlearn: 0.0376982\ttotal: 23.7s\tremaining: 95.1ms\n",
      "996:\tlearn: 0.0376216\ttotal: 23.7s\tremaining: 71.3ms\n",
      "997:\tlearn: 0.0376049\ttotal: 23.7s\tremaining: 47.5ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "998:\tlearn: 0.0375420\ttotal: 23.7s\tremaining: 23.8ms\n",
      "999:\tlearn: 0.0375006\ttotal: 23.8s\tremaining: 0us\n",
      "Learning rate set to 0.018893\n",
      "0:\tlearn: 0.6675876\ttotal: 22.7ms\tremaining: 22.7s\n",
      "1:\tlearn: 0.6424392\ttotal: 43ms\tremaining: 21.5s\n",
      "2:\tlearn: 0.6222066\ttotal: 63.3ms\tremaining: 21s\n",
      "3:\tlearn: 0.6023577\ttotal: 83.6ms\tremaining: 20.8s\n",
      "4:\tlearn: 0.5854606\ttotal: 104ms\tremaining: 20.7s\n",
      "5:\tlearn: 0.5639603\ttotal: 124ms\tremaining: 20.6s\n",
      "6:\tlearn: 0.5482255\ttotal: 144ms\tremaining: 20.4s\n",
      "7:\tlearn: 0.5358321\ttotal: 165ms\tremaining: 20.4s\n",
      "8:\tlearn: 0.5193996\ttotal: 185ms\tremaining: 20.4s\n",
      "9:\tlearn: 0.5062073\ttotal: 205ms\tremaining: 20.3s\n",
      "10:\tlearn: 0.4989738\ttotal: 222ms\tremaining: 19.9s\n",
      "11:\tlearn: 0.4870253\ttotal: 242ms\tremaining: 19.9s\n",
      "12:\tlearn: 0.4750338\ttotal: 263ms\tremaining: 20s\n",
      "13:\tlearn: 0.4623075\ttotal: 284ms\tremaining: 20s\n",
      "14:\tlearn: 0.4528044\ttotal: 304ms\tremaining: 20s\n",
      "15:\tlearn: 0.4480425\ttotal: 325ms\tremaining: 20s\n",
      "16:\tlearn: 0.4380185\ttotal: 346ms\tremaining: 20s\n",
      "17:\tlearn: 0.4291668\ttotal: 366ms\tremaining: 20s\n",
      "18:\tlearn: 0.4186203\ttotal: 386ms\tremaining: 20s\n",
      "19:\tlearn: 0.4103539\ttotal: 409ms\tremaining: 20s\n",
      "20:\tlearn: 0.4016368\ttotal: 426ms\tremaining: 19.9s\n",
      "21:\tlearn: 0.3938512\ttotal: 445ms\tremaining: 19.8s\n",
      "22:\tlearn: 0.3879999\ttotal: 465ms\tremaining: 19.8s\n",
      "23:\tlearn: 0.3844783\ttotal: 486ms\tremaining: 19.8s\n",
      "24:\tlearn: 0.3781542\ttotal: 506ms\tremaining: 19.7s\n",
      "25:\tlearn: 0.3735345\ttotal: 526ms\tremaining: 19.7s\n",
      "26:\tlearn: 0.3677917\ttotal: 546ms\tremaining: 19.7s\n",
      "27:\tlearn: 0.3649653\ttotal: 566ms\tremaining: 19.7s\n",
      "28:\tlearn: 0.3584960\ttotal: 587ms\tremaining: 19.7s\n",
      "29:\tlearn: 0.3533299\ttotal: 608ms\tremaining: 19.7s\n",
      "30:\tlearn: 0.3503782\ttotal: 629ms\tremaining: 19.6s\n",
      "31:\tlearn: 0.3475654\ttotal: 662ms\tremaining: 20s\n",
      "32:\tlearn: 0.3413433\ttotal: 679ms\tremaining: 19.9s\n",
      "33:\tlearn: 0.3373884\ttotal: 700ms\tremaining: 19.9s\n",
      "34:\tlearn: 0.3352645\ttotal: 716ms\tremaining: 19.7s\n",
      "35:\tlearn: 0.3310620\ttotal: 733ms\tremaining: 19.6s\n",
      "36:\tlearn: 0.3291236\ttotal: 750ms\tremaining: 19.5s\n",
      "37:\tlearn: 0.3261429\ttotal: 766ms\tremaining: 19.4s\n",
      "38:\tlearn: 0.3220714\ttotal: 784ms\tremaining: 19.3s\n",
      "39:\tlearn: 0.3193186\ttotal: 802ms\tremaining: 19.2s\n",
      "40:\tlearn: 0.3165580\ttotal: 823ms\tremaining: 19.2s\n",
      "41:\tlearn: 0.3132869\ttotal: 843ms\tremaining: 19.2s\n",
      "42:\tlearn: 0.3102363\ttotal: 862ms\tremaining: 19.2s\n",
      "43:\tlearn: 0.3066945\ttotal: 880ms\tremaining: 19.1s\n",
      "44:\tlearn: 0.3022531\ttotal: 897ms\tremaining: 19s\n",
      "45:\tlearn: 0.2997273\ttotal: 918ms\tremaining: 19s\n",
      "46:\tlearn: 0.2958809\ttotal: 935ms\tremaining: 18.9s\n",
      "47:\tlearn: 0.2933859\ttotal: 952ms\tremaining: 18.9s\n",
      "48:\tlearn: 0.2915760\ttotal: 968ms\tremaining: 18.8s\n",
      "49:\tlearn: 0.2874505\ttotal: 985ms\tremaining: 18.7s\n",
      "50:\tlearn: 0.2846390\ttotal: 1s\tremaining: 18.6s\n",
      "51:\tlearn: 0.2822847\ttotal: 1.02s\tremaining: 18.6s\n",
      "52:\tlearn: 0.2787005\ttotal: 1.04s\tremaining: 18.6s\n",
      "53:\tlearn: 0.2757225\ttotal: 1.06s\tremaining: 18.6s\n",
      "54:\tlearn: 0.2729118\ttotal: 1.08s\tremaining: 18.6s\n",
      "55:\tlearn: 0.2694590\ttotal: 1.1s\tremaining: 18.6s\n",
      "56:\tlearn: 0.2677788\ttotal: 1.12s\tremaining: 18.6s\n",
      "57:\tlearn: 0.2653048\ttotal: 1.14s\tremaining: 18.6s\n",
      "58:\tlearn: 0.2623910\ttotal: 1.18s\tremaining: 18.8s\n",
      "59:\tlearn: 0.2606318\ttotal: 1.2s\tremaining: 18.8s\n",
      "60:\tlearn: 0.2581120\ttotal: 1.22s\tremaining: 18.8s\n",
      "61:\tlearn: 0.2567755\ttotal: 1.24s\tremaining: 18.8s\n",
      "62:\tlearn: 0.2550579\ttotal: 1.26s\tremaining: 18.7s\n",
      "63:\tlearn: 0.2520427\ttotal: 1.27s\tremaining: 18.7s\n",
      "64:\tlearn: 0.2502787\ttotal: 1.29s\tremaining: 18.6s\n",
      "65:\tlearn: 0.2477840\ttotal: 1.31s\tremaining: 18.6s\n",
      "66:\tlearn: 0.2464422\ttotal: 1.33s\tremaining: 18.6s\n",
      "67:\tlearn: 0.2441914\ttotal: 1.35s\tremaining: 18.5s\n",
      "68:\tlearn: 0.2420465\ttotal: 1.37s\tremaining: 18.4s\n",
      "69:\tlearn: 0.2409675\ttotal: 1.39s\tremaining: 18.4s\n",
      "70:\tlearn: 0.2391224\ttotal: 1.42s\tremaining: 18.6s\n",
      "71:\tlearn: 0.2371145\ttotal: 1.44s\tremaining: 18.5s\n",
      "72:\tlearn: 0.2355378\ttotal: 1.46s\tremaining: 18.5s\n",
      "73:\tlearn: 0.2344931\ttotal: 1.48s\tremaining: 18.5s\n",
      "74:\tlearn: 0.2332065\ttotal: 1.5s\tremaining: 18.5s\n",
      "75:\tlearn: 0.2316329\ttotal: 1.52s\tremaining: 18.4s\n",
      "76:\tlearn: 0.2303304\ttotal: 1.54s\tremaining: 18.4s\n",
      "77:\tlearn: 0.2292287\ttotal: 1.56s\tremaining: 18.4s\n",
      "78:\tlearn: 0.2283274\ttotal: 1.58s\tremaining: 18.4s\n",
      "79:\tlearn: 0.2267453\ttotal: 1.6s\tremaining: 18.4s\n",
      "80:\tlearn: 0.2260597\ttotal: 1.62s\tremaining: 18.4s\n",
      "81:\tlearn: 0.2242133\ttotal: 1.64s\tremaining: 18.3s\n",
      "82:\tlearn: 0.2226687\ttotal: 1.66s\tremaining: 18.3s\n",
      "83:\tlearn: 0.2216254\ttotal: 1.68s\tremaining: 18.4s\n",
      "84:\tlearn: 0.2205905\ttotal: 1.7s\tremaining: 18.4s\n",
      "85:\tlearn: 0.2187367\ttotal: 1.73s\tremaining: 18.3s\n",
      "86:\tlearn: 0.2173941\ttotal: 1.75s\tremaining: 18.3s\n",
      "87:\tlearn: 0.2165730\ttotal: 1.77s\tremaining: 18.3s\n",
      "88:\tlearn: 0.2153512\ttotal: 1.79s\tremaining: 18.3s\n",
      "89:\tlearn: 0.2144367\ttotal: 1.81s\tremaining: 18.3s\n",
      "90:\tlearn: 0.2133093\ttotal: 1.83s\tremaining: 18.3s\n",
      "91:\tlearn: 0.2120484\ttotal: 1.85s\tremaining: 18.2s\n",
      "92:\tlearn: 0.2109713\ttotal: 1.86s\tremaining: 18.2s\n",
      "93:\tlearn: 0.2096796\ttotal: 1.88s\tremaining: 18.1s\n",
      "94:\tlearn: 0.2080468\ttotal: 1.9s\tremaining: 18.1s\n",
      "95:\tlearn: 0.2071948\ttotal: 1.92s\tremaining: 18.1s\n",
      "96:\tlearn: 0.2064974\ttotal: 1.94s\tremaining: 18.1s\n",
      "97:\tlearn: 0.2056981\ttotal: 1.96s\tremaining: 18.1s\n",
      "98:\tlearn: 0.2047497\ttotal: 1.98s\tremaining: 18s\n",
      "99:\tlearn: 0.2037112\ttotal: 2s\tremaining: 18s\n",
      "100:\tlearn: 0.2023832\ttotal: 2.02s\tremaining: 18s\n",
      "101:\tlearn: 0.2014239\ttotal: 2.04s\tremaining: 17.9s\n",
      "102:\tlearn: 0.2002869\ttotal: 2.05s\tremaining: 17.9s\n",
      "103:\tlearn: 0.1992645\ttotal: 2.08s\tremaining: 17.9s\n",
      "104:\tlearn: 0.1976850\ttotal: 2.1s\tremaining: 17.9s\n",
      "105:\tlearn: 0.1966944\ttotal: 2.12s\tremaining: 17.9s\n",
      "106:\tlearn: 0.1958437\ttotal: 2.14s\tremaining: 17.9s\n",
      "107:\tlearn: 0.1950505\ttotal: 2.16s\tremaining: 17.9s\n",
      "108:\tlearn: 0.1942879\ttotal: 2.18s\tremaining: 17.9s\n",
      "109:\tlearn: 0.1930925\ttotal: 2.21s\tremaining: 17.8s\n",
      "110:\tlearn: 0.1923886\ttotal: 2.23s\tremaining: 17.8s\n",
      "111:\tlearn: 0.1917872\ttotal: 2.25s\tremaining: 17.8s\n",
      "112:\tlearn: 0.1907749\ttotal: 2.27s\tremaining: 17.8s\n",
      "113:\tlearn: 0.1901619\ttotal: 2.29s\tremaining: 17.8s\n",
      "114:\tlearn: 0.1894267\ttotal: 2.3s\tremaining: 17.7s\n",
      "115:\tlearn: 0.1884693\ttotal: 2.33s\tremaining: 17.8s\n",
      "116:\tlearn: 0.1877945\ttotal: 2.35s\tremaining: 17.8s\n",
      "117:\tlearn: 0.1865109\ttotal: 2.37s\tremaining: 17.7s\n",
      "118:\tlearn: 0.1860403\ttotal: 2.39s\tremaining: 17.7s\n",
      "119:\tlearn: 0.1852816\ttotal: 2.41s\tremaining: 17.7s\n",
      "120:\tlearn: 0.1845263\ttotal: 2.43s\tremaining: 17.7s\n",
      "121:\tlearn: 0.1832112\ttotal: 2.46s\tremaining: 17.7s\n",
      "122:\tlearn: 0.1827394\ttotal: 2.48s\tremaining: 17.7s\n",
      "123:\tlearn: 0.1821913\ttotal: 2.5s\tremaining: 17.7s\n",
      "124:\tlearn: 0.1815680\ttotal: 2.53s\tremaining: 17.7s\n",
      "125:\tlearn: 0.1811420\ttotal: 2.55s\tremaining: 17.7s\n",
      "126:\tlearn: 0.1800201\ttotal: 2.57s\tremaining: 17.7s\n",
      "127:\tlearn: 0.1789509\ttotal: 2.6s\tremaining: 17.7s\n",
      "128:\tlearn: 0.1775213\ttotal: 2.62s\tremaining: 17.7s\n",
      "129:\tlearn: 0.1768473\ttotal: 2.65s\tremaining: 17.7s\n",
      "130:\tlearn: 0.1759229\ttotal: 2.67s\tremaining: 17.7s\n",
      "131:\tlearn: 0.1755489\ttotal: 2.69s\tremaining: 17.7s\n",
      "132:\tlearn: 0.1745943\ttotal: 2.7s\tremaining: 17.6s\n",
      "133:\tlearn: 0.1736372\ttotal: 2.72s\tremaining: 17.6s\n",
      "134:\tlearn: 0.1727770\ttotal: 2.75s\tremaining: 17.6s\n",
      "135:\tlearn: 0.1720474\ttotal: 2.77s\tremaining: 17.6s\n",
      "136:\tlearn: 0.1711457\ttotal: 2.79s\tremaining: 17.6s\n",
      "137:\tlearn: 0.1704392\ttotal: 2.81s\tremaining: 17.5s\n",
      "138:\tlearn: 0.1699658\ttotal: 2.82s\tremaining: 17.5s\n",
      "139:\tlearn: 0.1693692\ttotal: 2.85s\tremaining: 17.5s\n",
      "140:\tlearn: 0.1688755\ttotal: 2.87s\tremaining: 17.5s\n",
      "141:\tlearn: 0.1681956\ttotal: 2.9s\tremaining: 17.5s\n",
      "142:\tlearn: 0.1676374\ttotal: 2.92s\tremaining: 17.5s\n",
      "143:\tlearn: 0.1671071\ttotal: 2.94s\tremaining: 17.5s\n",
      "144:\tlearn: 0.1663944\ttotal: 2.97s\tremaining: 17.5s\n",
      "145:\tlearn: 0.1658448\ttotal: 2.99s\tremaining: 17.5s\n",
      "146:\tlearn: 0.1652635\ttotal: 3.01s\tremaining: 17.5s\n",
      "147:\tlearn: 0.1648168\ttotal: 3.04s\tremaining: 17.5s\n",
      "148:\tlearn: 0.1641497\ttotal: 3.06s\tremaining: 17.5s\n",
      "149:\tlearn: 0.1634756\ttotal: 3.08s\tremaining: 17.5s\n",
      "150:\tlearn: 0.1628136\ttotal: 3.11s\tremaining: 17.5s\n",
      "151:\tlearn: 0.1623914\ttotal: 3.13s\tremaining: 17.5s\n",
      "152:\tlearn: 0.1618859\ttotal: 3.15s\tremaining: 17.5s\n",
      "153:\tlearn: 0.1614994\ttotal: 3.18s\tremaining: 17.5s\n",
      "154:\tlearn: 0.1605529\ttotal: 3.21s\tremaining: 17.5s\n",
      "155:\tlearn: 0.1598390\ttotal: 3.23s\tremaining: 17.5s\n",
      "156:\tlearn: 0.1592169\ttotal: 3.25s\tremaining: 17.5s\n",
      "157:\tlearn: 0.1589122\ttotal: 3.27s\tremaining: 17.4s\n",
      "158:\tlearn: 0.1580766\ttotal: 3.3s\tremaining: 17.4s\n",
      "159:\tlearn: 0.1576736\ttotal: 3.32s\tremaining: 17.4s\n",
      "160:\tlearn: 0.1571935\ttotal: 3.34s\tremaining: 17.4s\n",
      "161:\tlearn: 0.1567844\ttotal: 3.36s\tremaining: 17.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162:\tlearn: 0.1563796\ttotal: 3.38s\tremaining: 17.4s\n",
      "163:\tlearn: 0.1558112\ttotal: 3.41s\tremaining: 17.4s\n",
      "164:\tlearn: 0.1552061\ttotal: 3.43s\tremaining: 17.4s\n",
      "165:\tlearn: 0.1546323\ttotal: 3.45s\tremaining: 17.3s\n",
      "166:\tlearn: 0.1540046\ttotal: 3.47s\tremaining: 17.3s\n",
      "167:\tlearn: 0.1535666\ttotal: 3.49s\tremaining: 17.3s\n",
      "168:\tlearn: 0.1531194\ttotal: 3.5s\tremaining: 17.2s\n",
      "169:\tlearn: 0.1526140\ttotal: 3.53s\tremaining: 17.2s\n",
      "170:\tlearn: 0.1521123\ttotal: 3.56s\tremaining: 17.2s\n",
      "171:\tlearn: 0.1515226\ttotal: 3.58s\tremaining: 17.2s\n",
      "172:\tlearn: 0.1510213\ttotal: 3.61s\tremaining: 17.3s\n",
      "173:\tlearn: 0.1506652\ttotal: 3.64s\tremaining: 17.3s\n",
      "174:\tlearn: 0.1499605\ttotal: 3.67s\tremaining: 17.3s\n",
      "175:\tlearn: 0.1496320\ttotal: 3.69s\tremaining: 17.3s\n",
      "176:\tlearn: 0.1493217\ttotal: 3.71s\tremaining: 17.3s\n",
      "177:\tlearn: 0.1487362\ttotal: 3.73s\tremaining: 17.2s\n",
      "178:\tlearn: 0.1481049\ttotal: 3.75s\tremaining: 17.2s\n",
      "179:\tlearn: 0.1476097\ttotal: 3.77s\tremaining: 17.2s\n",
      "180:\tlearn: 0.1470096\ttotal: 3.8s\tremaining: 17.2s\n",
      "181:\tlearn: 0.1465761\ttotal: 3.82s\tremaining: 17.2s\n",
      "182:\tlearn: 0.1461189\ttotal: 3.85s\tremaining: 17.2s\n",
      "183:\tlearn: 0.1454008\ttotal: 3.87s\tremaining: 17.2s\n",
      "184:\tlearn: 0.1448306\ttotal: 3.89s\tremaining: 17.2s\n",
      "185:\tlearn: 0.1444413\ttotal: 3.91s\tremaining: 17.1s\n",
      "186:\tlearn: 0.1440678\ttotal: 3.93s\tremaining: 17.1s\n",
      "187:\tlearn: 0.1437375\ttotal: 3.95s\tremaining: 17.1s\n",
      "188:\tlearn: 0.1433244\ttotal: 3.97s\tremaining: 17s\n",
      "189:\tlearn: 0.1430053\ttotal: 3.99s\tremaining: 17s\n",
      "190:\tlearn: 0.1424646\ttotal: 4.01s\tremaining: 17s\n",
      "191:\tlearn: 0.1419718\ttotal: 4.03s\tremaining: 17s\n",
      "192:\tlearn: 0.1416118\ttotal: 4.05s\tremaining: 16.9s\n",
      "193:\tlearn: 0.1411409\ttotal: 4.08s\tremaining: 16.9s\n",
      "194:\tlearn: 0.1406975\ttotal: 4.1s\tremaining: 16.9s\n",
      "195:\tlearn: 0.1403040\ttotal: 4.13s\tremaining: 16.9s\n",
      "196:\tlearn: 0.1399405\ttotal: 4.15s\tremaining: 16.9s\n",
      "197:\tlearn: 0.1395660\ttotal: 4.17s\tremaining: 16.9s\n",
      "198:\tlearn: 0.1389338\ttotal: 4.19s\tremaining: 16.9s\n",
      "199:\tlearn: 0.1385802\ttotal: 4.21s\tremaining: 16.9s\n",
      "200:\tlearn: 0.1381184\ttotal: 4.24s\tremaining: 16.8s\n",
      "201:\tlearn: 0.1373885\ttotal: 4.26s\tremaining: 16.8s\n",
      "202:\tlearn: 0.1370132\ttotal: 4.28s\tremaining: 16.8s\n",
      "203:\tlearn: 0.1363628\ttotal: 4.31s\tremaining: 16.8s\n",
      "204:\tlearn: 0.1359037\ttotal: 4.33s\tremaining: 16.8s\n",
      "205:\tlearn: 0.1356687\ttotal: 4.35s\tremaining: 16.8s\n",
      "206:\tlearn: 0.1351653\ttotal: 4.37s\tremaining: 16.7s\n",
      "207:\tlearn: 0.1346839\ttotal: 4.38s\tremaining: 16.7s\n",
      "208:\tlearn: 0.1342997\ttotal: 4.41s\tremaining: 16.7s\n",
      "209:\tlearn: 0.1338781\ttotal: 4.43s\tremaining: 16.7s\n",
      "210:\tlearn: 0.1333585\ttotal: 4.45s\tremaining: 16.6s\n",
      "211:\tlearn: 0.1328799\ttotal: 4.46s\tremaining: 16.6s\n",
      "212:\tlearn: 0.1324001\ttotal: 4.48s\tremaining: 16.6s\n",
      "213:\tlearn: 0.1321020\ttotal: 4.51s\tremaining: 16.6s\n",
      "214:\tlearn: 0.1316608\ttotal: 4.54s\tremaining: 16.6s\n",
      "215:\tlearn: 0.1312219\ttotal: 4.56s\tremaining: 16.5s\n",
      "216:\tlearn: 0.1307803\ttotal: 4.58s\tremaining: 16.5s\n",
      "217:\tlearn: 0.1302535\ttotal: 4.61s\tremaining: 16.5s\n",
      "218:\tlearn: 0.1299565\ttotal: 4.63s\tremaining: 16.5s\n",
      "219:\tlearn: 0.1293729\ttotal: 4.66s\tremaining: 16.5s\n",
      "220:\tlearn: 0.1289499\ttotal: 4.68s\tremaining: 16.5s\n",
      "221:\tlearn: 0.1284756\ttotal: 4.71s\tremaining: 16.5s\n",
      "222:\tlearn: 0.1280965\ttotal: 4.73s\tremaining: 16.5s\n",
      "223:\tlearn: 0.1278001\ttotal: 4.76s\tremaining: 16.5s\n",
      "224:\tlearn: 0.1275351\ttotal: 4.78s\tremaining: 16.5s\n",
      "225:\tlearn: 0.1273157\ttotal: 4.8s\tremaining: 16.4s\n",
      "226:\tlearn: 0.1268804\ttotal: 4.82s\tremaining: 16.4s\n",
      "227:\tlearn: 0.1266606\ttotal: 4.85s\tremaining: 16.4s\n",
      "228:\tlearn: 0.1260960\ttotal: 4.87s\tremaining: 16.4s\n",
      "229:\tlearn: 0.1258581\ttotal: 4.89s\tremaining: 16.4s\n",
      "230:\tlearn: 0.1256688\ttotal: 4.91s\tremaining: 16.3s\n",
      "231:\tlearn: 0.1252299\ttotal: 4.93s\tremaining: 16.3s\n",
      "232:\tlearn: 0.1249553\ttotal: 4.95s\tremaining: 16.3s\n",
      "233:\tlearn: 0.1247022\ttotal: 4.98s\tremaining: 16.3s\n",
      "234:\tlearn: 0.1243941\ttotal: 5s\tremaining: 16.3s\n",
      "235:\tlearn: 0.1240401\ttotal: 5.03s\tremaining: 16.3s\n",
      "236:\tlearn: 0.1236229\ttotal: 5.05s\tremaining: 16.3s\n",
      "237:\tlearn: 0.1234487\ttotal: 5.07s\tremaining: 16.2s\n",
      "238:\tlearn: 0.1231849\ttotal: 5.09s\tremaining: 16.2s\n",
      "239:\tlearn: 0.1227959\ttotal: 5.1s\tremaining: 16.2s\n",
      "240:\tlearn: 0.1225144\ttotal: 5.12s\tremaining: 16.1s\n",
      "241:\tlearn: 0.1219922\ttotal: 5.14s\tremaining: 16.1s\n",
      "242:\tlearn: 0.1215584\ttotal: 5.16s\tremaining: 16.1s\n",
      "243:\tlearn: 0.1211502\ttotal: 5.21s\tremaining: 16.1s\n",
      "244:\tlearn: 0.1208685\ttotal: 5.24s\tremaining: 16.1s\n",
      "245:\tlearn: 0.1203970\ttotal: 5.26s\tremaining: 16.1s\n",
      "246:\tlearn: 0.1201785\ttotal: 5.28s\tremaining: 16.1s\n",
      "247:\tlearn: 0.1199122\ttotal: 5.31s\tremaining: 16.1s\n",
      "248:\tlearn: 0.1196777\ttotal: 5.33s\tremaining: 16.1s\n",
      "249:\tlearn: 0.1195142\ttotal: 5.35s\tremaining: 16.1s\n",
      "250:\tlearn: 0.1191378\ttotal: 5.38s\tremaining: 16s\n",
      "251:\tlearn: 0.1188878\ttotal: 5.4s\tremaining: 16s\n",
      "252:\tlearn: 0.1187062\ttotal: 5.43s\tremaining: 16s\n",
      "253:\tlearn: 0.1183994\ttotal: 5.45s\tremaining: 16s\n",
      "254:\tlearn: 0.1181482\ttotal: 5.48s\tremaining: 16s\n",
      "255:\tlearn: 0.1180174\ttotal: 5.5s\tremaining: 16s\n",
      "256:\tlearn: 0.1177753\ttotal: 5.52s\tremaining: 16s\n",
      "257:\tlearn: 0.1176106\ttotal: 5.54s\tremaining: 15.9s\n",
      "258:\tlearn: 0.1172357\ttotal: 5.57s\tremaining: 15.9s\n",
      "259:\tlearn: 0.1171004\ttotal: 5.59s\tremaining: 15.9s\n",
      "260:\tlearn: 0.1166466\ttotal: 5.61s\tremaining: 15.9s\n",
      "261:\tlearn: 0.1163510\ttotal: 5.63s\tremaining: 15.9s\n",
      "262:\tlearn: 0.1160222\ttotal: 5.66s\tremaining: 15.9s\n",
      "263:\tlearn: 0.1156373\ttotal: 5.68s\tremaining: 15.8s\n",
      "264:\tlearn: 0.1153176\ttotal: 5.7s\tremaining: 15.8s\n",
      "265:\tlearn: 0.1151698\ttotal: 5.72s\tremaining: 15.8s\n",
      "266:\tlearn: 0.1148412\ttotal: 5.74s\tremaining: 15.8s\n",
      "267:\tlearn: 0.1144957\ttotal: 5.76s\tremaining: 15.7s\n",
      "268:\tlearn: 0.1142867\ttotal: 5.78s\tremaining: 15.7s\n",
      "269:\tlearn: 0.1139677\ttotal: 5.8s\tremaining: 15.7s\n",
      "270:\tlearn: 0.1136483\ttotal: 5.82s\tremaining: 15.7s\n",
      "271:\tlearn: 0.1134710\ttotal: 5.85s\tremaining: 15.7s\n",
      "272:\tlearn: 0.1131199\ttotal: 5.88s\tremaining: 15.7s\n",
      "273:\tlearn: 0.1128108\ttotal: 5.91s\tremaining: 15.7s\n",
      "274:\tlearn: 0.1125281\ttotal: 5.93s\tremaining: 15.6s\n",
      "275:\tlearn: 0.1122525\ttotal: 5.96s\tremaining: 15.6s\n",
      "276:\tlearn: 0.1121309\ttotal: 5.98s\tremaining: 15.6s\n",
      "277:\tlearn: 0.1119645\ttotal: 6s\tremaining: 15.6s\n",
      "278:\tlearn: 0.1116346\ttotal: 6.03s\tremaining: 15.6s\n",
      "279:\tlearn: 0.1111975\ttotal: 6.05s\tremaining: 15.6s\n",
      "280:\tlearn: 0.1109975\ttotal: 6.08s\tremaining: 15.5s\n",
      "281:\tlearn: 0.1108633\ttotal: 6.1s\tremaining: 15.5s\n",
      "282:\tlearn: 0.1106534\ttotal: 6.12s\tremaining: 15.5s\n",
      "283:\tlearn: 0.1104184\ttotal: 6.14s\tremaining: 15.5s\n",
      "284:\tlearn: 0.1101508\ttotal: 6.16s\tremaining: 15.4s\n",
      "285:\tlearn: 0.1099004\ttotal: 6.18s\tremaining: 15.4s\n",
      "286:\tlearn: 0.1096890\ttotal: 6.2s\tremaining: 15.4s\n",
      "287:\tlearn: 0.1094122\ttotal: 6.22s\tremaining: 15.4s\n",
      "288:\tlearn: 0.1092390\ttotal: 6.24s\tremaining: 15.3s\n",
      "289:\tlearn: 0.1089785\ttotal: 6.26s\tremaining: 15.3s\n",
      "290:\tlearn: 0.1086938\ttotal: 6.28s\tremaining: 15.3s\n",
      "291:\tlearn: 0.1083942\ttotal: 6.3s\tremaining: 15.3s\n",
      "292:\tlearn: 0.1082053\ttotal: 6.33s\tremaining: 15.3s\n",
      "293:\tlearn: 0.1079881\ttotal: 6.34s\tremaining: 15.2s\n",
      "294:\tlearn: 0.1076699\ttotal: 6.37s\tremaining: 15.2s\n",
      "295:\tlearn: 0.1074860\ttotal: 6.39s\tremaining: 15.2s\n",
      "296:\tlearn: 0.1071846\ttotal: 6.41s\tremaining: 15.2s\n",
      "297:\tlearn: 0.1067748\ttotal: 6.44s\tremaining: 15.2s\n",
      "298:\tlearn: 0.1065374\ttotal: 6.46s\tremaining: 15.1s\n",
      "299:\tlearn: 0.1063917\ttotal: 6.48s\tremaining: 15.1s\n",
      "300:\tlearn: 0.1062375\ttotal: 6.5s\tremaining: 15.1s\n",
      "301:\tlearn: 0.1059652\ttotal: 6.53s\tremaining: 15.1s\n",
      "302:\tlearn: 0.1058107\ttotal: 6.56s\tremaining: 15.1s\n",
      "303:\tlearn: 0.1055092\ttotal: 6.58s\tremaining: 15.1s\n",
      "304:\tlearn: 0.1052763\ttotal: 6.61s\tremaining: 15.1s\n",
      "305:\tlearn: 0.1050630\ttotal: 6.63s\tremaining: 15s\n",
      "306:\tlearn: 0.1048423\ttotal: 6.65s\tremaining: 15s\n",
      "307:\tlearn: 0.1046702\ttotal: 6.67s\tremaining: 15s\n",
      "308:\tlearn: 0.1044356\ttotal: 6.69s\tremaining: 15s\n",
      "309:\tlearn: 0.1041679\ttotal: 6.72s\tremaining: 15s\n",
      "310:\tlearn: 0.1039956\ttotal: 6.74s\tremaining: 14.9s\n",
      "311:\tlearn: 0.1038098\ttotal: 6.76s\tremaining: 14.9s\n",
      "312:\tlearn: 0.1036505\ttotal: 6.79s\tremaining: 14.9s\n",
      "313:\tlearn: 0.1034878\ttotal: 6.81s\tremaining: 14.9s\n",
      "314:\tlearn: 0.1032641\ttotal: 6.83s\tremaining: 14.9s\n",
      "315:\tlearn: 0.1030448\ttotal: 6.86s\tremaining: 14.8s\n",
      "316:\tlearn: 0.1028482\ttotal: 6.88s\tremaining: 14.8s\n",
      "317:\tlearn: 0.1026598\ttotal: 6.9s\tremaining: 14.8s\n",
      "318:\tlearn: 0.1024196\ttotal: 6.92s\tremaining: 14.8s\n",
      "319:\tlearn: 0.1020721\ttotal: 6.94s\tremaining: 14.7s\n",
      "320:\tlearn: 0.1019252\ttotal: 6.96s\tremaining: 14.7s\n",
      "321:\tlearn: 0.1017101\ttotal: 6.98s\tremaining: 14.7s\n",
      "322:\tlearn: 0.1015507\ttotal: 7s\tremaining: 14.7s\n",
      "323:\tlearn: 0.1013267\ttotal: 7.02s\tremaining: 14.6s\n",
      "324:\tlearn: 0.1011780\ttotal: 7.04s\tremaining: 14.6s\n",
      "325:\tlearn: 0.1009862\ttotal: 7.06s\tremaining: 14.6s\n",
      "326:\tlearn: 0.1007987\ttotal: 7.08s\tremaining: 14.6s\n",
      "327:\tlearn: 0.1006645\ttotal: 7.1s\tremaining: 14.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328:\tlearn: 0.1004548\ttotal: 7.12s\tremaining: 14.5s\n",
      "329:\tlearn: 0.1002944\ttotal: 7.15s\tremaining: 14.5s\n",
      "330:\tlearn: 0.1001288\ttotal: 7.17s\tremaining: 14.5s\n",
      "331:\tlearn: 0.0997957\ttotal: 7.21s\tremaining: 14.5s\n",
      "332:\tlearn: 0.0995901\ttotal: 7.23s\tremaining: 14.5s\n",
      "333:\tlearn: 0.0992104\ttotal: 7.26s\tremaining: 14.5s\n",
      "334:\tlearn: 0.0989366\ttotal: 7.28s\tremaining: 14.5s\n",
      "335:\tlearn: 0.0987827\ttotal: 7.3s\tremaining: 14.4s\n",
      "336:\tlearn: 0.0985205\ttotal: 7.32s\tremaining: 14.4s\n",
      "337:\tlearn: 0.0982972\ttotal: 7.34s\tremaining: 14.4s\n",
      "338:\tlearn: 0.0980069\ttotal: 7.37s\tremaining: 14.4s\n",
      "339:\tlearn: 0.0978375\ttotal: 7.39s\tremaining: 14.3s\n",
      "340:\tlearn: 0.0977690\ttotal: 7.41s\tremaining: 14.3s\n",
      "341:\tlearn: 0.0975058\ttotal: 7.43s\tremaining: 14.3s\n",
      "342:\tlearn: 0.0973097\ttotal: 7.45s\tremaining: 14.3s\n",
      "343:\tlearn: 0.0970743\ttotal: 7.48s\tremaining: 14.3s\n",
      "344:\tlearn: 0.0968746\ttotal: 7.5s\tremaining: 14.2s\n",
      "345:\tlearn: 0.0967622\ttotal: 7.53s\tremaining: 14.2s\n",
      "346:\tlearn: 0.0965892\ttotal: 7.55s\tremaining: 14.2s\n",
      "347:\tlearn: 0.0963964\ttotal: 7.58s\tremaining: 14.2s\n",
      "348:\tlearn: 0.0961947\ttotal: 7.6s\tremaining: 14.2s\n",
      "349:\tlearn: 0.0960082\ttotal: 7.63s\tremaining: 14.2s\n",
      "350:\tlearn: 0.0958374\ttotal: 7.66s\tremaining: 14.2s\n",
      "351:\tlearn: 0.0956522\ttotal: 7.68s\tremaining: 14.1s\n",
      "352:\tlearn: 0.0954966\ttotal: 7.71s\tremaining: 14.1s\n",
      "353:\tlearn: 0.0953289\ttotal: 7.72s\tremaining: 14.1s\n",
      "354:\tlearn: 0.0951099\ttotal: 7.74s\tremaining: 14.1s\n",
      "355:\tlearn: 0.0949046\ttotal: 7.76s\tremaining: 14s\n",
      "356:\tlearn: 0.0946966\ttotal: 7.79s\tremaining: 14s\n",
      "357:\tlearn: 0.0946152\ttotal: 7.81s\tremaining: 14s\n",
      "358:\tlearn: 0.0945007\ttotal: 7.83s\tremaining: 14s\n",
      "359:\tlearn: 0.0943382\ttotal: 7.85s\tremaining: 14s\n",
      "360:\tlearn: 0.0942152\ttotal: 7.87s\tremaining: 13.9s\n",
      "361:\tlearn: 0.0940467\ttotal: 7.9s\tremaining: 13.9s\n",
      "362:\tlearn: 0.0938378\ttotal: 7.92s\tremaining: 13.9s\n",
      "363:\tlearn: 0.0936326\ttotal: 7.95s\tremaining: 13.9s\n",
      "364:\tlearn: 0.0934855\ttotal: 7.96s\tremaining: 13.9s\n",
      "365:\tlearn: 0.0933247\ttotal: 7.98s\tremaining: 13.8s\n",
      "366:\tlearn: 0.0932448\ttotal: 8.01s\tremaining: 13.8s\n",
      "367:\tlearn: 0.0931034\ttotal: 8.04s\tremaining: 13.8s\n",
      "368:\tlearn: 0.0928042\ttotal: 8.07s\tremaining: 13.8s\n",
      "369:\tlearn: 0.0926352\ttotal: 8.09s\tremaining: 13.8s\n",
      "370:\tlearn: 0.0924169\ttotal: 8.11s\tremaining: 13.8s\n",
      "371:\tlearn: 0.0923132\ttotal: 8.14s\tremaining: 13.7s\n",
      "372:\tlearn: 0.0922073\ttotal: 8.16s\tremaining: 13.7s\n",
      "373:\tlearn: 0.0920962\ttotal: 8.19s\tremaining: 13.7s\n",
      "374:\tlearn: 0.0919732\ttotal: 8.22s\tremaining: 13.7s\n",
      "375:\tlearn: 0.0917374\ttotal: 8.25s\tremaining: 13.7s\n",
      "376:\tlearn: 0.0916268\ttotal: 8.28s\tremaining: 13.7s\n",
      "377:\tlearn: 0.0916178\ttotal: 8.3s\tremaining: 13.7s\n",
      "378:\tlearn: 0.0914760\ttotal: 8.33s\tremaining: 13.6s\n",
      "379:\tlearn: 0.0912658\ttotal: 8.35s\tremaining: 13.6s\n",
      "380:\tlearn: 0.0910693\ttotal: 8.38s\tremaining: 13.6s\n",
      "381:\tlearn: 0.0909257\ttotal: 8.4s\tremaining: 13.6s\n",
      "382:\tlearn: 0.0909174\ttotal: 8.43s\tremaining: 13.6s\n",
      "383:\tlearn: 0.0907662\ttotal: 8.45s\tremaining: 13.6s\n",
      "384:\tlearn: 0.0905547\ttotal: 8.47s\tremaining: 13.5s\n",
      "385:\tlearn: 0.0904717\ttotal: 8.5s\tremaining: 13.5s\n",
      "386:\tlearn: 0.0904316\ttotal: 8.52s\tremaining: 13.5s\n",
      "387:\tlearn: 0.0902403\ttotal: 8.55s\tremaining: 13.5s\n",
      "388:\tlearn: 0.0900807\ttotal: 8.57s\tremaining: 13.5s\n",
      "389:\tlearn: 0.0899380\ttotal: 8.59s\tremaining: 13.4s\n",
      "390:\tlearn: 0.0897787\ttotal: 8.61s\tremaining: 13.4s\n",
      "391:\tlearn: 0.0896198\ttotal: 8.63s\tremaining: 13.4s\n",
      "392:\tlearn: 0.0893776\ttotal: 8.65s\tremaining: 13.4s\n",
      "393:\tlearn: 0.0891943\ttotal: 8.68s\tremaining: 13.3s\n",
      "394:\tlearn: 0.0890542\ttotal: 8.7s\tremaining: 13.3s\n",
      "395:\tlearn: 0.0888942\ttotal: 8.72s\tremaining: 13.3s\n",
      "396:\tlearn: 0.0887453\ttotal: 8.74s\tremaining: 13.3s\n",
      "397:\tlearn: 0.0885828\ttotal: 8.77s\tremaining: 13.3s\n",
      "398:\tlearn: 0.0884210\ttotal: 8.79s\tremaining: 13.2s\n",
      "399:\tlearn: 0.0882964\ttotal: 8.81s\tremaining: 13.2s\n",
      "400:\tlearn: 0.0881454\ttotal: 8.83s\tremaining: 13.2s\n",
      "401:\tlearn: 0.0880587\ttotal: 8.85s\tremaining: 13.2s\n",
      "402:\tlearn: 0.0878848\ttotal: 8.87s\tremaining: 13.1s\n",
      "403:\tlearn: 0.0877077\ttotal: 8.9s\tremaining: 13.1s\n",
      "404:\tlearn: 0.0875237\ttotal: 8.92s\tremaining: 13.1s\n",
      "405:\tlearn: 0.0874591\ttotal: 8.94s\tremaining: 13.1s\n",
      "406:\tlearn: 0.0873491\ttotal: 8.96s\tremaining: 13.1s\n",
      "407:\tlearn: 0.0872592\ttotal: 8.99s\tremaining: 13s\n",
      "408:\tlearn: 0.0871126\ttotal: 9.01s\tremaining: 13s\n",
      "409:\tlearn: 0.0869706\ttotal: 9.04s\tremaining: 13s\n",
      "410:\tlearn: 0.0867172\ttotal: 9.06s\tremaining: 13s\n",
      "411:\tlearn: 0.0864798\ttotal: 9.1s\tremaining: 13s\n",
      "412:\tlearn: 0.0863992\ttotal: 9.14s\tremaining: 13s\n",
      "413:\tlearn: 0.0861962\ttotal: 9.16s\tremaining: 13s\n",
      "414:\tlearn: 0.0860366\ttotal: 9.18s\tremaining: 12.9s\n",
      "415:\tlearn: 0.0858307\ttotal: 9.21s\tremaining: 12.9s\n",
      "416:\tlearn: 0.0856955\ttotal: 9.23s\tremaining: 12.9s\n",
      "417:\tlearn: 0.0855454\ttotal: 9.25s\tremaining: 12.9s\n",
      "418:\tlearn: 0.0852782\ttotal: 9.29s\tremaining: 12.9s\n",
      "419:\tlearn: 0.0851190\ttotal: 9.32s\tremaining: 12.9s\n",
      "420:\tlearn: 0.0849178\ttotal: 9.35s\tremaining: 12.9s\n",
      "421:\tlearn: 0.0847159\ttotal: 9.38s\tremaining: 12.8s\n",
      "422:\tlearn: 0.0845966\ttotal: 9.41s\tremaining: 12.8s\n",
      "423:\tlearn: 0.0844248\ttotal: 9.43s\tremaining: 12.8s\n",
      "424:\tlearn: 0.0841775\ttotal: 9.46s\tremaining: 12.8s\n",
      "425:\tlearn: 0.0840507\ttotal: 9.49s\tremaining: 12.8s\n",
      "426:\tlearn: 0.0838940\ttotal: 9.53s\tremaining: 12.8s\n",
      "427:\tlearn: 0.0837481\ttotal: 9.57s\tremaining: 12.8s\n",
      "428:\tlearn: 0.0836373\ttotal: 9.62s\tremaining: 12.8s\n",
      "429:\tlearn: 0.0834233\ttotal: 9.66s\tremaining: 12.8s\n",
      "430:\tlearn: 0.0834084\ttotal: 9.69s\tremaining: 12.8s\n",
      "431:\tlearn: 0.0833875\ttotal: 9.72s\tremaining: 12.8s\n",
      "432:\tlearn: 0.0832678\ttotal: 9.75s\tremaining: 12.8s\n",
      "433:\tlearn: 0.0831365\ttotal: 9.78s\tremaining: 12.7s\n",
      "434:\tlearn: 0.0830095\ttotal: 9.81s\tremaining: 12.7s\n",
      "435:\tlearn: 0.0828176\ttotal: 9.84s\tremaining: 12.7s\n",
      "436:\tlearn: 0.0827066\ttotal: 9.87s\tremaining: 12.7s\n",
      "437:\tlearn: 0.0825293\ttotal: 9.91s\tremaining: 12.7s\n",
      "438:\tlearn: 0.0823968\ttotal: 9.94s\tremaining: 12.7s\n",
      "439:\tlearn: 0.0823800\ttotal: 9.98s\tremaining: 12.7s\n",
      "440:\tlearn: 0.0821935\ttotal: 10s\tremaining: 12.7s\n",
      "441:\tlearn: 0.0819814\ttotal: 10s\tremaining: 12.7s\n",
      "442:\tlearn: 0.0818196\ttotal: 10.1s\tremaining: 12.7s\n",
      "443:\tlearn: 0.0816855\ttotal: 10.1s\tremaining: 12.7s\n",
      "444:\tlearn: 0.0816740\ttotal: 10.1s\tremaining: 12.7s\n",
      "445:\tlearn: 0.0814833\ttotal: 10.2s\tremaining: 12.6s\n",
      "446:\tlearn: 0.0813236\ttotal: 10.2s\tremaining: 12.6s\n",
      "447:\tlearn: 0.0811606\ttotal: 10.2s\tremaining: 12.6s\n",
      "448:\tlearn: 0.0809920\ttotal: 10.3s\tremaining: 12.6s\n",
      "449:\tlearn: 0.0808175\ttotal: 10.3s\tremaining: 12.6s\n",
      "450:\tlearn: 0.0807488\ttotal: 10.3s\tremaining: 12.6s\n",
      "451:\tlearn: 0.0806856\ttotal: 10.3s\tremaining: 12.5s\n",
      "452:\tlearn: 0.0806511\ttotal: 10.4s\tremaining: 12.5s\n",
      "453:\tlearn: 0.0804865\ttotal: 10.4s\tremaining: 12.5s\n",
      "454:\tlearn: 0.0802069\ttotal: 10.4s\tremaining: 12.5s\n",
      "455:\tlearn: 0.0800536\ttotal: 10.5s\tremaining: 12.5s\n",
      "456:\tlearn: 0.0799222\ttotal: 10.5s\tremaining: 12.5s\n",
      "457:\tlearn: 0.0797151\ttotal: 10.6s\tremaining: 12.5s\n",
      "458:\tlearn: 0.0795055\ttotal: 10.6s\tremaining: 12.5s\n",
      "459:\tlearn: 0.0792500\ttotal: 10.6s\tremaining: 12.5s\n",
      "460:\tlearn: 0.0790490\ttotal: 10.7s\tremaining: 12.5s\n",
      "461:\tlearn: 0.0788539\ttotal: 10.7s\tremaining: 12.4s\n",
      "462:\tlearn: 0.0786295\ttotal: 10.7s\tremaining: 12.4s\n",
      "463:\tlearn: 0.0785443\ttotal: 10.8s\tremaining: 12.4s\n",
      "464:\tlearn: 0.0783238\ttotal: 10.8s\tremaining: 12.4s\n",
      "465:\tlearn: 0.0782054\ttotal: 10.8s\tremaining: 12.4s\n",
      "466:\tlearn: 0.0780239\ttotal: 10.9s\tremaining: 12.4s\n",
      "467:\tlearn: 0.0778778\ttotal: 10.9s\tremaining: 12.4s\n",
      "468:\tlearn: 0.0778486\ttotal: 10.9s\tremaining: 12.3s\n",
      "469:\tlearn: 0.0777363\ttotal: 10.9s\tremaining: 12.3s\n",
      "470:\tlearn: 0.0776171\ttotal: 10.9s\tremaining: 12.3s\n",
      "471:\tlearn: 0.0774830\ttotal: 11s\tremaining: 12.3s\n",
      "472:\tlearn: 0.0773416\ttotal: 11s\tremaining: 12.2s\n",
      "473:\tlearn: 0.0771324\ttotal: 11s\tremaining: 12.2s\n",
      "474:\tlearn: 0.0771104\ttotal: 11s\tremaining: 12.2s\n",
      "475:\tlearn: 0.0770365\ttotal: 11s\tremaining: 12.2s\n",
      "476:\tlearn: 0.0768670\ttotal: 11.1s\tremaining: 12.1s\n",
      "477:\tlearn: 0.0767652\ttotal: 11.1s\tremaining: 12.1s\n",
      "478:\tlearn: 0.0765907\ttotal: 11.1s\tremaining: 12.1s\n",
      "479:\tlearn: 0.0764431\ttotal: 11.1s\tremaining: 12.1s\n",
      "480:\tlearn: 0.0764210\ttotal: 11.1s\tremaining: 12s\n",
      "481:\tlearn: 0.0763017\ttotal: 11.2s\tremaining: 12s\n",
      "482:\tlearn: 0.0762779\ttotal: 11.2s\tremaining: 12s\n",
      "483:\tlearn: 0.0762176\ttotal: 11.2s\tremaining: 12s\n",
      "484:\tlearn: 0.0761112\ttotal: 11.3s\tremaining: 12s\n",
      "485:\tlearn: 0.0760879\ttotal: 11.3s\tremaining: 12s\n",
      "486:\tlearn: 0.0759584\ttotal: 11.4s\tremaining: 12s\n",
      "487:\tlearn: 0.0758332\ttotal: 11.4s\tremaining: 11.9s\n",
      "488:\tlearn: 0.0756566\ttotal: 11.4s\tremaining: 11.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "489:\tlearn: 0.0756404\ttotal: 11.5s\tremaining: 11.9s\n",
      "490:\tlearn: 0.0753302\ttotal: 11.5s\tremaining: 11.9s\n",
      "491:\tlearn: 0.0752142\ttotal: 11.5s\tremaining: 11.9s\n",
      "492:\tlearn: 0.0750721\ttotal: 11.6s\tremaining: 11.9s\n",
      "493:\tlearn: 0.0749302\ttotal: 11.6s\tremaining: 11.9s\n",
      "494:\tlearn: 0.0747788\ttotal: 11.6s\tremaining: 11.9s\n",
      "495:\tlearn: 0.0747667\ttotal: 11.7s\tremaining: 11.9s\n",
      "496:\tlearn: 0.0746274\ttotal: 11.7s\tremaining: 11.8s\n",
      "497:\tlearn: 0.0743913\ttotal: 11.7s\tremaining: 11.8s\n",
      "498:\tlearn: 0.0742275\ttotal: 11.8s\tremaining: 11.8s\n",
      "499:\tlearn: 0.0742141\ttotal: 11.8s\tremaining: 11.8s\n",
      "500:\tlearn: 0.0740231\ttotal: 11.8s\tremaining: 11.8s\n",
      "501:\tlearn: 0.0738667\ttotal: 11.9s\tremaining: 11.8s\n",
      "502:\tlearn: 0.0737521\ttotal: 11.9s\tremaining: 11.8s\n",
      "503:\tlearn: 0.0737354\ttotal: 11.9s\tremaining: 11.7s\n",
      "504:\tlearn: 0.0737165\ttotal: 11.9s\tremaining: 11.7s\n",
      "505:\tlearn: 0.0736383\ttotal: 12s\tremaining: 11.7s\n",
      "506:\tlearn: 0.0735212\ttotal: 12s\tremaining: 11.7s\n",
      "507:\tlearn: 0.0733627\ttotal: 12s\tremaining: 11.7s\n",
      "508:\tlearn: 0.0732967\ttotal: 12.1s\tremaining: 11.7s\n",
      "509:\tlearn: 0.0732836\ttotal: 12.1s\tremaining: 11.6s\n",
      "510:\tlearn: 0.0731546\ttotal: 12.1s\tremaining: 11.6s\n",
      "511:\tlearn: 0.0729843\ttotal: 12.1s\tremaining: 11.6s\n",
      "512:\tlearn: 0.0728641\ttotal: 12.2s\tremaining: 11.6s\n",
      "513:\tlearn: 0.0728539\ttotal: 12.2s\tremaining: 11.5s\n",
      "514:\tlearn: 0.0727970\ttotal: 12.2s\tremaining: 11.5s\n",
      "515:\tlearn: 0.0727674\ttotal: 12.2s\tremaining: 11.5s\n",
      "516:\tlearn: 0.0727526\ttotal: 12.3s\tremaining: 11.5s\n",
      "517:\tlearn: 0.0725834\ttotal: 12.3s\tremaining: 11.4s\n",
      "518:\tlearn: 0.0723769\ttotal: 12.3s\tremaining: 11.4s\n",
      "519:\tlearn: 0.0722329\ttotal: 12.3s\tremaining: 11.4s\n",
      "520:\tlearn: 0.0720518\ttotal: 12.4s\tremaining: 11.4s\n",
      "521:\tlearn: 0.0719321\ttotal: 12.4s\tremaining: 11.3s\n",
      "522:\tlearn: 0.0717245\ttotal: 12.4s\tremaining: 11.3s\n",
      "523:\tlearn: 0.0717105\ttotal: 12.4s\tremaining: 11.3s\n",
      "524:\tlearn: 0.0715764\ttotal: 12.4s\tremaining: 11.3s\n",
      "525:\tlearn: 0.0714986\ttotal: 12.5s\tremaining: 11.2s\n",
      "526:\tlearn: 0.0714168\ttotal: 12.5s\tremaining: 11.2s\n",
      "527:\tlearn: 0.0713081\ttotal: 12.5s\tremaining: 11.2s\n",
      "528:\tlearn: 0.0710377\ttotal: 12.5s\tremaining: 11.2s\n",
      "529:\tlearn: 0.0708677\ttotal: 12.6s\tremaining: 11.1s\n",
      "530:\tlearn: 0.0708246\ttotal: 12.6s\tremaining: 11.1s\n",
      "531:\tlearn: 0.0706739\ttotal: 12.6s\tremaining: 11.1s\n",
      "532:\tlearn: 0.0704929\ttotal: 12.6s\tremaining: 11.1s\n",
      "533:\tlearn: 0.0703427\ttotal: 12.7s\tremaining: 11s\n",
      "534:\tlearn: 0.0701487\ttotal: 12.7s\tremaining: 11s\n",
      "535:\tlearn: 0.0700023\ttotal: 12.7s\tremaining: 11s\n",
      "536:\tlearn: 0.0698671\ttotal: 12.7s\tremaining: 11s\n",
      "537:\tlearn: 0.0697211\ttotal: 12.7s\tremaining: 10.9s\n",
      "538:\tlearn: 0.0695898\ttotal: 12.8s\tremaining: 10.9s\n",
      "539:\tlearn: 0.0694194\ttotal: 12.8s\tremaining: 10.9s\n",
      "540:\tlearn: 0.0693503\ttotal: 12.8s\tremaining: 10.9s\n",
      "541:\tlearn: 0.0692727\ttotal: 12.8s\tremaining: 10.8s\n",
      "542:\tlearn: 0.0692496\ttotal: 12.9s\tremaining: 10.8s\n",
      "543:\tlearn: 0.0691436\ttotal: 12.9s\tremaining: 10.8s\n",
      "544:\tlearn: 0.0689881\ttotal: 12.9s\tremaining: 10.8s\n",
      "545:\tlearn: 0.0688280\ttotal: 12.9s\tremaining: 10.7s\n",
      "546:\tlearn: 0.0687685\ttotal: 12.9s\tremaining: 10.7s\n",
      "547:\tlearn: 0.0686508\ttotal: 13s\tremaining: 10.7s\n",
      "548:\tlearn: 0.0685230\ttotal: 13s\tremaining: 10.7s\n",
      "549:\tlearn: 0.0684001\ttotal: 13s\tremaining: 10.7s\n",
      "550:\tlearn: 0.0683726\ttotal: 13s\tremaining: 10.6s\n",
      "551:\tlearn: 0.0683608\ttotal: 13.1s\tremaining: 10.6s\n",
      "552:\tlearn: 0.0682326\ttotal: 13.1s\tremaining: 10.6s\n",
      "553:\tlearn: 0.0681058\ttotal: 13.1s\tremaining: 10.6s\n",
      "554:\tlearn: 0.0679648\ttotal: 13.1s\tremaining: 10.5s\n",
      "555:\tlearn: 0.0679526\ttotal: 13.2s\tremaining: 10.5s\n",
      "556:\tlearn: 0.0679440\ttotal: 13.2s\tremaining: 10.5s\n",
      "557:\tlearn: 0.0678553\ttotal: 13.2s\tremaining: 10.5s\n",
      "558:\tlearn: 0.0677043\ttotal: 13.2s\tremaining: 10.4s\n",
      "559:\tlearn: 0.0676689\ttotal: 13.2s\tremaining: 10.4s\n",
      "560:\tlearn: 0.0675742\ttotal: 13.3s\tremaining: 10.4s\n",
      "561:\tlearn: 0.0674030\ttotal: 13.3s\tremaining: 10.4s\n",
      "562:\tlearn: 0.0672725\ttotal: 13.3s\tremaining: 10.3s\n",
      "563:\tlearn: 0.0671567\ttotal: 13.3s\tremaining: 10.3s\n",
      "564:\tlearn: 0.0670275\ttotal: 13.4s\tremaining: 10.3s\n",
      "565:\tlearn: 0.0669124\ttotal: 13.4s\tremaining: 10.3s\n",
      "566:\tlearn: 0.0669033\ttotal: 13.4s\tremaining: 10.2s\n",
      "567:\tlearn: 0.0668109\ttotal: 13.4s\tremaining: 10.2s\n",
      "568:\tlearn: 0.0668016\ttotal: 13.4s\tremaining: 10.2s\n",
      "569:\tlearn: 0.0666643\ttotal: 13.5s\tremaining: 10.2s\n",
      "570:\tlearn: 0.0665225\ttotal: 13.5s\tremaining: 10.1s\n",
      "571:\tlearn: 0.0664141\ttotal: 13.5s\tremaining: 10.1s\n",
      "572:\tlearn: 0.0662521\ttotal: 13.5s\tremaining: 10.1s\n",
      "573:\tlearn: 0.0661115\ttotal: 13.5s\tremaining: 10.1s\n",
      "574:\tlearn: 0.0659657\ttotal: 13.6s\tremaining: 10s\n",
      "575:\tlearn: 0.0659443\ttotal: 13.6s\tremaining: 10s\n",
      "576:\tlearn: 0.0658420\ttotal: 13.6s\tremaining: 9.99s\n",
      "577:\tlearn: 0.0657332\ttotal: 13.6s\tremaining: 9.96s\n",
      "578:\tlearn: 0.0656457\ttotal: 13.7s\tremaining: 9.94s\n",
      "579:\tlearn: 0.0655164\ttotal: 13.7s\tremaining: 9.91s\n",
      "580:\tlearn: 0.0653796\ttotal: 13.7s\tremaining: 9.89s\n",
      "581:\tlearn: 0.0651928\ttotal: 13.7s\tremaining: 9.86s\n",
      "582:\tlearn: 0.0650972\ttotal: 13.8s\tremaining: 9.84s\n",
      "583:\tlearn: 0.0650843\ttotal: 13.8s\tremaining: 9.82s\n",
      "584:\tlearn: 0.0649410\ttotal: 13.8s\tremaining: 9.79s\n",
      "585:\tlearn: 0.0648327\ttotal: 13.8s\tremaining: 9.77s\n",
      "586:\tlearn: 0.0647398\ttotal: 13.9s\tremaining: 9.75s\n",
      "587:\tlearn: 0.0645955\ttotal: 13.9s\tremaining: 9.72s\n",
      "588:\tlearn: 0.0644791\ttotal: 13.9s\tremaining: 9.7s\n",
      "589:\tlearn: 0.0643293\ttotal: 13.9s\tremaining: 9.68s\n",
      "590:\tlearn: 0.0642322\ttotal: 13.9s\tremaining: 9.65s\n",
      "591:\tlearn: 0.0641608\ttotal: 14s\tremaining: 9.63s\n",
      "592:\tlearn: 0.0640282\ttotal: 14s\tremaining: 9.6s\n",
      "593:\tlearn: 0.0639601\ttotal: 14s\tremaining: 9.59s\n",
      "594:\tlearn: 0.0638123\ttotal: 14s\tremaining: 9.56s\n",
      "595:\tlearn: 0.0636743\ttotal: 14.1s\tremaining: 9.54s\n",
      "596:\tlearn: 0.0636665\ttotal: 14.1s\tremaining: 9.51s\n",
      "597:\tlearn: 0.0635182\ttotal: 14.1s\tremaining: 9.48s\n",
      "598:\tlearn: 0.0633823\ttotal: 14.1s\tremaining: 9.46s\n",
      "599:\tlearn: 0.0633649\ttotal: 14.2s\tremaining: 9.43s\n",
      "600:\tlearn: 0.0632711\ttotal: 14.2s\tremaining: 9.41s\n",
      "601:\tlearn: 0.0631389\ttotal: 14.2s\tremaining: 9.38s\n",
      "602:\tlearn: 0.0630289\ttotal: 14.2s\tremaining: 9.36s\n",
      "603:\tlearn: 0.0629047\ttotal: 14.2s\tremaining: 9.33s\n",
      "604:\tlearn: 0.0627526\ttotal: 14.3s\tremaining: 9.3s\n",
      "605:\tlearn: 0.0626778\ttotal: 14.3s\tremaining: 9.29s\n",
      "606:\tlearn: 0.0625395\ttotal: 14.3s\tremaining: 9.26s\n",
      "607:\tlearn: 0.0625315\ttotal: 14.3s\tremaining: 9.23s\n",
      "608:\tlearn: 0.0623556\ttotal: 14.3s\tremaining: 9.21s\n",
      "609:\tlearn: 0.0621614\ttotal: 14.4s\tremaining: 9.19s\n",
      "610:\tlearn: 0.0620779\ttotal: 14.4s\tremaining: 9.17s\n",
      "611:\tlearn: 0.0619137\ttotal: 14.4s\tremaining: 9.14s\n",
      "612:\tlearn: 0.0618973\ttotal: 14.5s\tremaining: 9.12s\n",
      "613:\tlearn: 0.0617795\ttotal: 14.5s\tremaining: 9.1s\n",
      "614:\tlearn: 0.0617276\ttotal: 14.5s\tremaining: 9.08s\n",
      "615:\tlearn: 0.0616427\ttotal: 14.5s\tremaining: 9.05s\n",
      "616:\tlearn: 0.0615342\ttotal: 14.5s\tremaining: 9.03s\n",
      "617:\tlearn: 0.0613355\ttotal: 14.6s\tremaining: 9s\n",
      "618:\tlearn: 0.0613186\ttotal: 14.6s\tremaining: 8.97s\n",
      "619:\tlearn: 0.0612381\ttotal: 14.6s\tremaining: 8.95s\n",
      "620:\tlearn: 0.0611475\ttotal: 14.6s\tremaining: 8.92s\n",
      "621:\tlearn: 0.0610609\ttotal: 14.6s\tremaining: 8.89s\n",
      "622:\tlearn: 0.0609778\ttotal: 14.7s\tremaining: 8.87s\n",
      "623:\tlearn: 0.0608959\ttotal: 14.7s\tremaining: 8.85s\n",
      "624:\tlearn: 0.0608029\ttotal: 14.7s\tremaining: 8.82s\n",
      "625:\tlearn: 0.0606778\ttotal: 14.7s\tremaining: 8.8s\n",
      "626:\tlearn: 0.0605631\ttotal: 14.8s\tremaining: 8.78s\n",
      "627:\tlearn: 0.0604519\ttotal: 14.8s\tremaining: 8.76s\n",
      "628:\tlearn: 0.0603598\ttotal: 14.8s\tremaining: 8.73s\n",
      "629:\tlearn: 0.0602693\ttotal: 14.8s\tremaining: 8.71s\n",
      "630:\tlearn: 0.0601849\ttotal: 14.9s\tremaining: 8.69s\n",
      "631:\tlearn: 0.0600762\ttotal: 14.9s\tremaining: 8.66s\n",
      "632:\tlearn: 0.0599681\ttotal: 14.9s\tremaining: 8.64s\n",
      "633:\tlearn: 0.0598503\ttotal: 14.9s\tremaining: 8.62s\n",
      "634:\tlearn: 0.0597690\ttotal: 14.9s\tremaining: 8.59s\n",
      "635:\tlearn: 0.0595959\ttotal: 15s\tremaining: 8.57s\n",
      "636:\tlearn: 0.0595886\ttotal: 15s\tremaining: 8.54s\n",
      "637:\tlearn: 0.0594672\ttotal: 15s\tremaining: 8.52s\n",
      "638:\tlearn: 0.0593482\ttotal: 15s\tremaining: 8.5s\n",
      "639:\tlearn: 0.0591587\ttotal: 15.1s\tremaining: 8.47s\n",
      "640:\tlearn: 0.0590473\ttotal: 15.1s\tremaining: 8.45s\n",
      "641:\tlearn: 0.0589535\ttotal: 15.1s\tremaining: 8.43s\n",
      "642:\tlearn: 0.0588698\ttotal: 15.1s\tremaining: 8.4s\n",
      "643:\tlearn: 0.0588613\ttotal: 15.2s\tremaining: 8.38s\n",
      "644:\tlearn: 0.0587014\ttotal: 15.2s\tremaining: 8.35s\n",
      "645:\tlearn: 0.0585935\ttotal: 15.2s\tremaining: 8.33s\n",
      "646:\tlearn: 0.0584460\ttotal: 15.2s\tremaining: 8.3s\n",
      "647:\tlearn: 0.0583700\ttotal: 15.2s\tremaining: 8.28s\n",
      "648:\tlearn: 0.0582355\ttotal: 15.3s\tremaining: 8.25s\n",
      "649:\tlearn: 0.0581767\ttotal: 15.3s\tremaining: 8.23s\n",
      "650:\tlearn: 0.0580892\ttotal: 15.3s\tremaining: 8.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "651:\tlearn: 0.0579988\ttotal: 15.3s\tremaining: 8.18s\n",
      "652:\tlearn: 0.0578902\ttotal: 15.3s\tremaining: 8.16s\n",
      "653:\tlearn: 0.0578832\ttotal: 15.4s\tremaining: 8.13s\n",
      "654:\tlearn: 0.0577695\ttotal: 15.4s\tremaining: 8.11s\n",
      "655:\tlearn: 0.0576342\ttotal: 15.4s\tremaining: 8.09s\n",
      "656:\tlearn: 0.0575297\ttotal: 15.4s\tremaining: 8.06s\n",
      "657:\tlearn: 0.0574518\ttotal: 15.5s\tremaining: 8.04s\n",
      "658:\tlearn: 0.0573709\ttotal: 15.5s\tremaining: 8.01s\n",
      "659:\tlearn: 0.0573475\ttotal: 15.5s\tremaining: 7.99s\n",
      "660:\tlearn: 0.0571440\ttotal: 15.5s\tremaining: 7.96s\n",
      "661:\tlearn: 0.0570310\ttotal: 15.5s\tremaining: 7.94s\n",
      "662:\tlearn: 0.0569586\ttotal: 15.6s\tremaining: 7.91s\n",
      "663:\tlearn: 0.0568222\ttotal: 15.6s\tremaining: 7.89s\n",
      "664:\tlearn: 0.0567735\ttotal: 15.6s\tremaining: 7.86s\n",
      "665:\tlearn: 0.0566904\ttotal: 15.6s\tremaining: 7.84s\n",
      "666:\tlearn: 0.0565774\ttotal: 15.6s\tremaining: 7.81s\n",
      "667:\tlearn: 0.0565635\ttotal: 15.7s\tremaining: 7.79s\n",
      "668:\tlearn: 0.0564480\ttotal: 15.7s\tremaining: 7.76s\n",
      "669:\tlearn: 0.0563254\ttotal: 15.7s\tremaining: 7.74s\n",
      "670:\tlearn: 0.0563101\ttotal: 15.7s\tremaining: 7.71s\n",
      "671:\tlearn: 0.0562328\ttotal: 15.7s\tremaining: 7.69s\n",
      "672:\tlearn: 0.0561448\ttotal: 15.8s\tremaining: 7.67s\n",
      "673:\tlearn: 0.0560763\ttotal: 15.8s\tremaining: 7.64s\n",
      "674:\tlearn: 0.0560110\ttotal: 15.8s\tremaining: 7.62s\n",
      "675:\tlearn: 0.0558559\ttotal: 15.8s\tremaining: 7.6s\n",
      "676:\tlearn: 0.0558463\ttotal: 15.9s\tremaining: 7.57s\n",
      "677:\tlearn: 0.0558138\ttotal: 15.9s\tremaining: 7.55s\n",
      "678:\tlearn: 0.0557142\ttotal: 15.9s\tremaining: 7.52s\n",
      "679:\tlearn: 0.0556450\ttotal: 15.9s\tremaining: 7.5s\n",
      "680:\tlearn: 0.0555824\ttotal: 16s\tremaining: 7.47s\n",
      "681:\tlearn: 0.0554975\ttotal: 16s\tremaining: 7.45s\n",
      "682:\tlearn: 0.0554911\ttotal: 16s\tremaining: 7.43s\n",
      "683:\tlearn: 0.0554848\ttotal: 16s\tremaining: 7.4s\n",
      "684:\tlearn: 0.0554531\ttotal: 16s\tremaining: 7.38s\n",
      "685:\tlearn: 0.0553580\ttotal: 16.1s\tremaining: 7.35s\n",
      "686:\tlearn: 0.0552674\ttotal: 16.1s\tremaining: 7.33s\n",
      "687:\tlearn: 0.0551684\ttotal: 16.1s\tremaining: 7.3s\n",
      "688:\tlearn: 0.0550581\ttotal: 16.1s\tremaining: 7.28s\n",
      "689:\tlearn: 0.0549679\ttotal: 16.1s\tremaining: 7.25s\n",
      "690:\tlearn: 0.0548761\ttotal: 16.2s\tremaining: 7.23s\n",
      "691:\tlearn: 0.0547826\ttotal: 16.2s\tremaining: 7.21s\n",
      "692:\tlearn: 0.0547116\ttotal: 16.2s\tremaining: 7.18s\n",
      "693:\tlearn: 0.0545871\ttotal: 16.2s\tremaining: 7.16s\n",
      "694:\tlearn: 0.0545506\ttotal: 16.3s\tremaining: 7.14s\n",
      "695:\tlearn: 0.0545043\ttotal: 16.3s\tremaining: 7.11s\n",
      "696:\tlearn: 0.0544343\ttotal: 16.3s\tremaining: 7.09s\n",
      "697:\tlearn: 0.0543396\ttotal: 16.3s\tremaining: 7.07s\n",
      "698:\tlearn: 0.0543239\ttotal: 16.3s\tremaining: 7.04s\n",
      "699:\tlearn: 0.0542425\ttotal: 16.4s\tremaining: 7.01s\n",
      "700:\tlearn: 0.0541768\ttotal: 16.4s\tremaining: 6.99s\n",
      "701:\tlearn: 0.0541005\ttotal: 16.4s\tremaining: 6.97s\n",
      "702:\tlearn: 0.0539840\ttotal: 16.4s\tremaining: 6.95s\n",
      "703:\tlearn: 0.0539412\ttotal: 16.5s\tremaining: 6.92s\n",
      "704:\tlearn: 0.0538458\ttotal: 16.5s\tremaining: 6.9s\n",
      "705:\tlearn: 0.0538105\ttotal: 16.5s\tremaining: 6.87s\n",
      "706:\tlearn: 0.0536975\ttotal: 16.5s\tremaining: 6.85s\n",
      "707:\tlearn: 0.0535843\ttotal: 16.6s\tremaining: 6.83s\n",
      "708:\tlearn: 0.0535173\ttotal: 16.6s\tremaining: 6.8s\n",
      "709:\tlearn: 0.0534057\ttotal: 16.6s\tremaining: 6.78s\n",
      "710:\tlearn: 0.0533025\ttotal: 16.6s\tremaining: 6.75s\n",
      "711:\tlearn: 0.0532075\ttotal: 16.6s\tremaining: 6.72s\n",
      "712:\tlearn: 0.0531918\ttotal: 16.6s\tremaining: 6.7s\n",
      "713:\tlearn: 0.0531441\ttotal: 16.7s\tremaining: 6.68s\n",
      "714:\tlearn: 0.0531044\ttotal: 16.7s\tremaining: 6.65s\n",
      "715:\tlearn: 0.0530036\ttotal: 16.7s\tremaining: 6.63s\n",
      "716:\tlearn: 0.0529376\ttotal: 16.7s\tremaining: 6.61s\n",
      "717:\tlearn: 0.0528494\ttotal: 16.8s\tremaining: 6.58s\n",
      "718:\tlearn: 0.0528344\ttotal: 16.8s\tremaining: 6.56s\n",
      "719:\tlearn: 0.0527449\ttotal: 16.8s\tremaining: 6.54s\n",
      "720:\tlearn: 0.0526537\ttotal: 16.8s\tremaining: 6.51s\n",
      "721:\tlearn: 0.0525460\ttotal: 16.9s\tremaining: 6.49s\n",
      "722:\tlearn: 0.0524820\ttotal: 16.9s\tremaining: 6.47s\n",
      "723:\tlearn: 0.0524124\ttotal: 16.9s\tremaining: 6.45s\n",
      "724:\tlearn: 0.0523522\ttotal: 16.9s\tremaining: 6.42s\n",
      "725:\tlearn: 0.0522492\ttotal: 17s\tremaining: 6.4s\n",
      "726:\tlearn: 0.0521747\ttotal: 17s\tremaining: 6.37s\n",
      "727:\tlearn: 0.0520745\ttotal: 17s\tremaining: 6.35s\n",
      "728:\tlearn: 0.0520688\ttotal: 17s\tremaining: 6.32s\n",
      "729:\tlearn: 0.0519774\ttotal: 17s\tremaining: 6.3s\n",
      "730:\tlearn: 0.0518949\ttotal: 17.1s\tremaining: 6.28s\n",
      "731:\tlearn: 0.0517921\ttotal: 17.1s\tremaining: 6.25s\n",
      "732:\tlearn: 0.0517016\ttotal: 17.1s\tremaining: 6.23s\n",
      "733:\tlearn: 0.0516012\ttotal: 17.1s\tremaining: 6.21s\n",
      "734:\tlearn: 0.0515956\ttotal: 17.2s\tremaining: 6.18s\n",
      "735:\tlearn: 0.0515107\ttotal: 17.2s\tremaining: 6.16s\n",
      "736:\tlearn: 0.0514316\ttotal: 17.2s\tremaining: 6.13s\n",
      "737:\tlearn: 0.0513593\ttotal: 17.2s\tremaining: 6.11s\n",
      "738:\tlearn: 0.0513538\ttotal: 17.2s\tremaining: 6.08s\n",
      "739:\tlearn: 0.0512938\ttotal: 17.2s\tremaining: 6.06s\n",
      "740:\tlearn: 0.0512028\ttotal: 17.3s\tremaining: 6.03s\n",
      "741:\tlearn: 0.0510707\ttotal: 17.3s\tremaining: 6.01s\n",
      "742:\tlearn: 0.0510092\ttotal: 17.3s\tremaining: 5.99s\n",
      "743:\tlearn: 0.0509071\ttotal: 17.3s\tremaining: 5.96s\n",
      "744:\tlearn: 0.0509003\ttotal: 17.4s\tremaining: 5.94s\n",
      "745:\tlearn: 0.0508601\ttotal: 17.4s\tremaining: 5.92s\n",
      "746:\tlearn: 0.0507866\ttotal: 17.4s\tremaining: 5.89s\n",
      "747:\tlearn: 0.0506763\ttotal: 17.4s\tremaining: 5.87s\n",
      "748:\tlearn: 0.0506264\ttotal: 17.4s\tremaining: 5.84s\n",
      "749:\tlearn: 0.0505030\ttotal: 17.5s\tremaining: 5.82s\n",
      "750:\tlearn: 0.0504110\ttotal: 17.5s\tremaining: 5.8s\n",
      "751:\tlearn: 0.0503338\ttotal: 17.5s\tremaining: 5.77s\n",
      "752:\tlearn: 0.0503204\ttotal: 17.5s\tremaining: 5.75s\n",
      "753:\tlearn: 0.0502536\ttotal: 17.6s\tremaining: 5.73s\n",
      "754:\tlearn: 0.0501089\ttotal: 17.6s\tremaining: 5.7s\n",
      "755:\tlearn: 0.0500133\ttotal: 17.6s\tremaining: 5.68s\n",
      "756:\tlearn: 0.0499240\ttotal: 17.6s\tremaining: 5.65s\n",
      "757:\tlearn: 0.0499173\ttotal: 17.6s\tremaining: 5.63s\n",
      "758:\tlearn: 0.0498360\ttotal: 17.7s\tremaining: 5.61s\n",
      "759:\tlearn: 0.0497016\ttotal: 17.7s\tremaining: 5.58s\n",
      "760:\tlearn: 0.0496686\ttotal: 17.7s\tremaining: 5.55s\n",
      "761:\tlearn: 0.0495707\ttotal: 17.7s\tremaining: 5.53s\n",
      "762:\tlearn: 0.0494780\ttotal: 17.7s\tremaining: 5.51s\n",
      "763:\tlearn: 0.0494722\ttotal: 17.8s\tremaining: 5.49s\n",
      "764:\tlearn: 0.0494407\ttotal: 17.8s\tremaining: 5.46s\n",
      "765:\tlearn: 0.0493726\ttotal: 17.8s\tremaining: 5.44s\n",
      "766:\tlearn: 0.0493656\ttotal: 17.8s\tremaining: 5.42s\n",
      "767:\tlearn: 0.0493091\ttotal: 17.9s\tremaining: 5.39s\n",
      "768:\tlearn: 0.0492011\ttotal: 17.9s\tremaining: 5.37s\n",
      "769:\tlearn: 0.0491092\ttotal: 17.9s\tremaining: 5.34s\n",
      "770:\tlearn: 0.0490162\ttotal: 17.9s\tremaining: 5.32s\n",
      "771:\tlearn: 0.0489388\ttotal: 17.9s\tremaining: 5.3s\n",
      "772:\tlearn: 0.0489000\ttotal: 18s\tremaining: 5.28s\n",
      "773:\tlearn: 0.0488684\ttotal: 18s\tremaining: 5.25s\n",
      "774:\tlearn: 0.0488006\ttotal: 18s\tremaining: 5.23s\n",
      "775:\tlearn: 0.0486961\ttotal: 18s\tremaining: 5.2s\n",
      "776:\tlearn: 0.0486911\ttotal: 18s\tremaining: 5.18s\n",
      "777:\tlearn: 0.0486338\ttotal: 18.1s\tremaining: 5.16s\n",
      "778:\tlearn: 0.0486289\ttotal: 18.1s\tremaining: 5.13s\n",
      "779:\tlearn: 0.0486046\ttotal: 18.1s\tremaining: 5.11s\n",
      "780:\tlearn: 0.0485656\ttotal: 18.1s\tremaining: 5.08s\n",
      "781:\tlearn: 0.0485074\ttotal: 18.2s\tremaining: 5.06s\n",
      "782:\tlearn: 0.0484435\ttotal: 18.2s\tremaining: 5.04s\n",
      "783:\tlearn: 0.0483658\ttotal: 18.2s\tremaining: 5.02s\n",
      "784:\tlearn: 0.0483112\ttotal: 18.2s\tremaining: 4.99s\n",
      "785:\tlearn: 0.0481732\ttotal: 18.3s\tremaining: 4.97s\n",
      "786:\tlearn: 0.0480888\ttotal: 18.3s\tremaining: 4.95s\n",
      "787:\tlearn: 0.0480217\ttotal: 18.3s\tremaining: 4.92s\n",
      "788:\tlearn: 0.0478957\ttotal: 18.3s\tremaining: 4.9s\n",
      "789:\tlearn: 0.0478522\ttotal: 18.3s\tremaining: 4.87s\n",
      "790:\tlearn: 0.0478474\ttotal: 18.4s\tremaining: 4.85s\n",
      "791:\tlearn: 0.0477804\ttotal: 18.4s\tremaining: 4.83s\n",
      "792:\tlearn: 0.0477205\ttotal: 18.4s\tremaining: 4.8s\n",
      "793:\tlearn: 0.0476619\ttotal: 18.4s\tremaining: 4.78s\n",
      "794:\tlearn: 0.0476412\ttotal: 18.4s\tremaining: 4.75s\n",
      "795:\tlearn: 0.0475681\ttotal: 18.5s\tremaining: 4.73s\n",
      "796:\tlearn: 0.0474977\ttotal: 18.5s\tremaining: 4.71s\n",
      "797:\tlearn: 0.0474929\ttotal: 18.5s\tremaining: 4.68s\n",
      "798:\tlearn: 0.0474815\ttotal: 18.5s\tremaining: 4.66s\n",
      "799:\tlearn: 0.0474211\ttotal: 18.5s\tremaining: 4.63s\n",
      "800:\tlearn: 0.0473337\ttotal: 18.6s\tremaining: 4.61s\n",
      "801:\tlearn: 0.0472374\ttotal: 18.6s\tremaining: 4.59s\n",
      "802:\tlearn: 0.0471557\ttotal: 18.6s\tremaining: 4.57s\n",
      "803:\tlearn: 0.0471167\ttotal: 18.6s\tremaining: 4.54s\n",
      "804:\tlearn: 0.0469944\ttotal: 18.7s\tremaining: 4.52s\n",
      "805:\tlearn: 0.0469225\ttotal: 18.7s\tremaining: 4.5s\n",
      "806:\tlearn: 0.0468196\ttotal: 18.7s\tremaining: 4.47s\n",
      "807:\tlearn: 0.0467238\ttotal: 18.7s\tremaining: 4.45s\n",
      "808:\tlearn: 0.0466339\ttotal: 18.7s\tremaining: 4.43s\n",
      "809:\tlearn: 0.0465607\ttotal: 18.8s\tremaining: 4.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "810:\tlearn: 0.0464917\ttotal: 18.8s\tremaining: 4.38s\n",
      "811:\tlearn: 0.0463869\ttotal: 18.8s\tremaining: 4.36s\n",
      "812:\tlearn: 0.0463094\ttotal: 18.8s\tremaining: 4.33s\n",
      "813:\tlearn: 0.0462167\ttotal: 18.9s\tremaining: 4.31s\n",
      "814:\tlearn: 0.0461540\ttotal: 18.9s\tremaining: 4.28s\n",
      "815:\tlearn: 0.0461406\ttotal: 18.9s\tremaining: 4.26s\n",
      "816:\tlearn: 0.0461359\ttotal: 18.9s\tremaining: 4.24s\n",
      "817:\tlearn: 0.0460862\ttotal: 18.9s\tremaining: 4.21s\n",
      "818:\tlearn: 0.0460352\ttotal: 19s\tremaining: 4.19s\n",
      "819:\tlearn: 0.0460272\ttotal: 19s\tremaining: 4.17s\n",
      "820:\tlearn: 0.0459503\ttotal: 19s\tremaining: 4.14s\n",
      "821:\tlearn: 0.0459149\ttotal: 19s\tremaining: 4.12s\n",
      "822:\tlearn: 0.0458755\ttotal: 19s\tremaining: 4.09s\n",
      "823:\tlearn: 0.0458233\ttotal: 19.1s\tremaining: 4.07s\n",
      "824:\tlearn: 0.0457616\ttotal: 19.1s\tremaining: 4.04s\n",
      "825:\tlearn: 0.0457043\ttotal: 19.1s\tremaining: 4.02s\n",
      "826:\tlearn: 0.0455668\ttotal: 19.1s\tremaining: 4s\n",
      "827:\tlearn: 0.0454933\ttotal: 19.1s\tremaining: 3.97s\n",
      "828:\tlearn: 0.0454885\ttotal: 19.1s\tremaining: 3.95s\n",
      "829:\tlearn: 0.0454320\ttotal: 19.2s\tremaining: 3.93s\n",
      "830:\tlearn: 0.0453416\ttotal: 19.2s\tremaining: 3.9s\n",
      "831:\tlearn: 0.0452512\ttotal: 19.2s\tremaining: 3.88s\n",
      "832:\tlearn: 0.0452318\ttotal: 19.2s\tremaining: 3.85s\n",
      "833:\tlearn: 0.0452270\ttotal: 19.3s\tremaining: 3.83s\n",
      "834:\tlearn: 0.0451426\ttotal: 19.3s\tremaining: 3.81s\n",
      "835:\tlearn: 0.0450973\ttotal: 19.3s\tremaining: 3.79s\n",
      "836:\tlearn: 0.0450933\ttotal: 19.3s\tremaining: 3.76s\n",
      "837:\tlearn: 0.0450892\ttotal: 19.3s\tremaining: 3.74s\n",
      "838:\tlearn: 0.0450352\ttotal: 19.4s\tremaining: 3.72s\n",
      "839:\tlearn: 0.0450239\ttotal: 19.4s\tremaining: 3.69s\n",
      "840:\tlearn: 0.0449482\ttotal: 19.4s\tremaining: 3.67s\n",
      "841:\tlearn: 0.0448576\ttotal: 19.4s\tremaining: 3.65s\n",
      "842:\tlearn: 0.0448476\ttotal: 19.4s\tremaining: 3.62s\n",
      "843:\tlearn: 0.0447832\ttotal: 19.5s\tremaining: 3.6s\n",
      "844:\tlearn: 0.0447780\ttotal: 19.5s\tremaining: 3.58s\n",
      "845:\tlearn: 0.0447200\ttotal: 19.5s\tremaining: 3.55s\n",
      "846:\tlearn: 0.0446283\ttotal: 19.5s\tremaining: 3.53s\n",
      "847:\tlearn: 0.0446090\ttotal: 19.6s\tremaining: 3.51s\n",
      "848:\tlearn: 0.0445754\ttotal: 19.6s\tremaining: 3.48s\n",
      "849:\tlearn: 0.0445310\ttotal: 19.6s\tremaining: 3.46s\n",
      "850:\tlearn: 0.0444602\ttotal: 19.6s\tremaining: 3.44s\n",
      "851:\tlearn: 0.0444158\ttotal: 19.7s\tremaining: 3.41s\n",
      "852:\tlearn: 0.0443311\ttotal: 19.7s\tremaining: 3.39s\n",
      "853:\tlearn: 0.0442592\ttotal: 19.7s\tremaining: 3.37s\n",
      "854:\tlearn: 0.0441910\ttotal: 19.7s\tremaining: 3.34s\n",
      "855:\tlearn: 0.0441381\ttotal: 19.7s\tremaining: 3.32s\n",
      "856:\tlearn: 0.0440825\ttotal: 19.8s\tremaining: 3.3s\n",
      "857:\tlearn: 0.0440283\ttotal: 19.8s\tremaining: 3.27s\n",
      "858:\tlearn: 0.0439846\ttotal: 19.8s\tremaining: 3.25s\n",
      "859:\tlearn: 0.0439212\ttotal: 19.8s\tremaining: 3.23s\n",
      "860:\tlearn: 0.0439174\ttotal: 19.9s\tremaining: 3.21s\n",
      "861:\tlearn: 0.0438841\ttotal: 19.9s\tremaining: 3.18s\n",
      "862:\tlearn: 0.0437962\ttotal: 19.9s\tremaining: 3.16s\n",
      "863:\tlearn: 0.0437718\ttotal: 19.9s\tremaining: 3.13s\n",
      "864:\tlearn: 0.0437082\ttotal: 19.9s\tremaining: 3.11s\n",
      "865:\tlearn: 0.0437033\ttotal: 20s\tremaining: 3.09s\n",
      "866:\tlearn: 0.0436335\ttotal: 20s\tremaining: 3.06s\n",
      "867:\tlearn: 0.0435775\ttotal: 20s\tremaining: 3.04s\n",
      "868:\tlearn: 0.0434929\ttotal: 20s\tremaining: 3.02s\n",
      "869:\tlearn: 0.0434319\ttotal: 20.1s\tremaining: 3s\n",
      "870:\tlearn: 0.0434274\ttotal: 20.1s\tremaining: 2.97s\n",
      "871:\tlearn: 0.0433703\ttotal: 20.1s\tremaining: 2.95s\n",
      "872:\tlearn: 0.0433453\ttotal: 20.1s\tremaining: 2.93s\n",
      "873:\tlearn: 0.0433062\ttotal: 20.1s\tremaining: 2.9s\n",
      "874:\tlearn: 0.0432233\ttotal: 20.2s\tremaining: 2.88s\n",
      "875:\tlearn: 0.0432184\ttotal: 20.2s\tremaining: 2.85s\n",
      "876:\tlearn: 0.0431935\ttotal: 20.2s\tremaining: 2.83s\n",
      "877:\tlearn: 0.0431619\ttotal: 20.2s\tremaining: 2.81s\n",
      "878:\tlearn: 0.0430667\ttotal: 20.3s\tremaining: 2.79s\n",
      "879:\tlearn: 0.0430501\ttotal: 20.3s\tremaining: 2.77s\n",
      "880:\tlearn: 0.0430461\ttotal: 20.3s\tremaining: 2.74s\n",
      "881:\tlearn: 0.0429868\ttotal: 20.3s\tremaining: 2.72s\n",
      "882:\tlearn: 0.0429236\ttotal: 20.3s\tremaining: 2.69s\n",
      "883:\tlearn: 0.0428619\ttotal: 20.4s\tremaining: 2.67s\n",
      "884:\tlearn: 0.0428144\ttotal: 20.4s\tremaining: 2.65s\n",
      "885:\tlearn: 0.0428075\ttotal: 20.4s\tremaining: 2.62s\n",
      "886:\tlearn: 0.0428034\ttotal: 20.4s\tremaining: 2.6s\n",
      "887:\tlearn: 0.0427492\ttotal: 20.4s\tremaining: 2.58s\n",
      "888:\tlearn: 0.0426907\ttotal: 20.5s\tremaining: 2.56s\n",
      "889:\tlearn: 0.0426438\ttotal: 20.5s\tremaining: 2.53s\n",
      "890:\tlearn: 0.0425509\ttotal: 20.5s\tremaining: 2.51s\n",
      "891:\tlearn: 0.0424951\ttotal: 20.5s\tremaining: 2.49s\n",
      "892:\tlearn: 0.0424410\ttotal: 20.6s\tremaining: 2.46s\n",
      "893:\tlearn: 0.0424027\ttotal: 20.6s\tremaining: 2.44s\n",
      "894:\tlearn: 0.0423569\ttotal: 20.6s\tremaining: 2.42s\n",
      "895:\tlearn: 0.0422972\ttotal: 20.6s\tremaining: 2.39s\n",
      "896:\tlearn: 0.0422331\ttotal: 20.6s\tremaining: 2.37s\n",
      "897:\tlearn: 0.0421438\ttotal: 20.7s\tremaining: 2.35s\n",
      "898:\tlearn: 0.0421402\ttotal: 20.7s\tremaining: 2.32s\n",
      "899:\tlearn: 0.0420733\ttotal: 20.7s\tremaining: 2.3s\n",
      "900:\tlearn: 0.0420698\ttotal: 20.7s\tremaining: 2.28s\n",
      "901:\tlearn: 0.0420476\ttotal: 20.8s\tremaining: 2.25s\n",
      "902:\tlearn: 0.0419966\ttotal: 20.8s\tremaining: 2.23s\n",
      "903:\tlearn: 0.0419933\ttotal: 20.8s\tremaining: 2.21s\n",
      "904:\tlearn: 0.0419443\ttotal: 20.8s\tremaining: 2.19s\n",
      "905:\tlearn: 0.0418983\ttotal: 20.9s\tremaining: 2.16s\n",
      "906:\tlearn: 0.0418228\ttotal: 20.9s\tremaining: 2.14s\n",
      "907:\tlearn: 0.0417503\ttotal: 20.9s\tremaining: 2.12s\n",
      "908:\tlearn: 0.0417318\ttotal: 20.9s\tremaining: 2.1s\n",
      "909:\tlearn: 0.0416485\ttotal: 20.9s\tremaining: 2.07s\n",
      "910:\tlearn: 0.0416204\ttotal: 21s\tremaining: 2.05s\n",
      "911:\tlearn: 0.0415565\ttotal: 21s\tremaining: 2.02s\n",
      "912:\tlearn: 0.0415173\ttotal: 21s\tremaining: 2s\n",
      "913:\tlearn: 0.0415138\ttotal: 21s\tremaining: 1.98s\n",
      "914:\tlearn: 0.0414698\ttotal: 21.1s\tremaining: 1.96s\n",
      "915:\tlearn: 0.0414135\ttotal: 21.1s\tremaining: 1.93s\n",
      "916:\tlearn: 0.0413801\ttotal: 21.1s\tremaining: 1.91s\n",
      "917:\tlearn: 0.0413376\ttotal: 21.1s\tremaining: 1.89s\n",
      "918:\tlearn: 0.0412955\ttotal: 21.1s\tremaining: 1.86s\n",
      "919:\tlearn: 0.0412391\ttotal: 21.2s\tremaining: 1.84s\n",
      "920:\tlearn: 0.0411938\ttotal: 21.2s\tremaining: 1.82s\n",
      "921:\tlearn: 0.0411452\ttotal: 21.2s\tremaining: 1.79s\n",
      "922:\tlearn: 0.0411414\ttotal: 21.2s\tremaining: 1.77s\n",
      "923:\tlearn: 0.0410158\ttotal: 21.2s\tremaining: 1.75s\n",
      "924:\tlearn: 0.0410014\ttotal: 21.3s\tremaining: 1.72s\n",
      "925:\tlearn: 0.0409237\ttotal: 21.3s\tremaining: 1.7s\n",
      "926:\tlearn: 0.0409204\ttotal: 21.3s\tremaining: 1.68s\n",
      "927:\tlearn: 0.0408940\ttotal: 21.3s\tremaining: 1.66s\n",
      "928:\tlearn: 0.0408256\ttotal: 21.4s\tremaining: 1.63s\n",
      "929:\tlearn: 0.0408169\ttotal: 21.4s\tremaining: 1.61s\n",
      "930:\tlearn: 0.0407946\ttotal: 21.4s\tremaining: 1.58s\n",
      "931:\tlearn: 0.0407334\ttotal: 21.4s\tremaining: 1.56s\n",
      "932:\tlearn: 0.0406313\ttotal: 21.4s\tremaining: 1.54s\n",
      "933:\tlearn: 0.0406217\ttotal: 21.5s\tremaining: 1.52s\n",
      "934:\tlearn: 0.0405483\ttotal: 21.5s\tremaining: 1.49s\n",
      "935:\tlearn: 0.0405006\ttotal: 21.5s\tremaining: 1.47s\n",
      "936:\tlearn: 0.0404409\ttotal: 21.5s\tremaining: 1.45s\n",
      "937:\tlearn: 0.0403923\ttotal: 21.5s\tremaining: 1.42s\n",
      "938:\tlearn: 0.0403412\ttotal: 21.6s\tremaining: 1.4s\n",
      "939:\tlearn: 0.0403066\ttotal: 21.6s\tremaining: 1.38s\n",
      "940:\tlearn: 0.0402427\ttotal: 21.6s\tremaining: 1.35s\n",
      "941:\tlearn: 0.0401762\ttotal: 21.6s\tremaining: 1.33s\n",
      "942:\tlearn: 0.0401090\ttotal: 21.7s\tremaining: 1.31s\n",
      "943:\tlearn: 0.0400417\ttotal: 21.7s\tremaining: 1.28s\n",
      "944:\tlearn: 0.0399935\ttotal: 21.7s\tremaining: 1.26s\n",
      "945:\tlearn: 0.0399864\ttotal: 21.7s\tremaining: 1.24s\n",
      "946:\tlearn: 0.0399833\ttotal: 21.7s\tremaining: 1.22s\n",
      "947:\tlearn: 0.0398974\ttotal: 21.8s\tremaining: 1.19s\n",
      "948:\tlearn: 0.0398354\ttotal: 21.8s\tremaining: 1.17s\n",
      "949:\tlearn: 0.0397855\ttotal: 21.8s\tremaining: 1.15s\n",
      "950:\tlearn: 0.0397516\ttotal: 21.8s\tremaining: 1.12s\n",
      "951:\tlearn: 0.0397485\ttotal: 21.9s\tremaining: 1.1s\n",
      "952:\tlearn: 0.0397181\ttotal: 21.9s\tremaining: 1.08s\n",
      "953:\tlearn: 0.0396536\ttotal: 21.9s\tremaining: 1.05s\n",
      "954:\tlearn: 0.0395975\ttotal: 21.9s\tremaining: 1.03s\n",
      "955:\tlearn: 0.0395944\ttotal: 21.9s\tremaining: 1.01s\n",
      "956:\tlearn: 0.0395277\ttotal: 21.9s\tremaining: 986ms\n",
      "957:\tlearn: 0.0394864\ttotal: 22s\tremaining: 963ms\n",
      "958:\tlearn: 0.0394165\ttotal: 22s\tremaining: 940ms\n",
      "959:\tlearn: 0.0393779\ttotal: 22s\tremaining: 918ms\n",
      "960:\tlearn: 0.0393433\ttotal: 22s\tremaining: 895ms\n",
      "961:\tlearn: 0.0392814\ttotal: 22.1s\tremaining: 872ms\n",
      "962:\tlearn: 0.0392379\ttotal: 22.1s\tremaining: 849ms\n",
      "963:\tlearn: 0.0391579\ttotal: 22.1s\tremaining: 826ms\n",
      "964:\tlearn: 0.0390530\ttotal: 22.1s\tremaining: 803ms\n",
      "965:\tlearn: 0.0390143\ttotal: 22.2s\tremaining: 780ms\n",
      "966:\tlearn: 0.0389386\ttotal: 22.2s\tremaining: 757ms\n",
      "967:\tlearn: 0.0388654\ttotal: 22.2s\tremaining: 734ms\n",
      "968:\tlearn: 0.0388564\ttotal: 22.2s\tremaining: 710ms\n",
      "969:\tlearn: 0.0387758\ttotal: 22.2s\tremaining: 688ms\n",
      "970:\tlearn: 0.0387030\ttotal: 22.3s\tremaining: 665ms\n",
      "971:\tlearn: 0.0386823\ttotal: 22.3s\tremaining: 642ms\n",
      "972:\tlearn: 0.0386624\ttotal: 22.3s\tremaining: 619ms\n",
      "973:\tlearn: 0.0386220\ttotal: 22.3s\tremaining: 596ms\n",
      "974:\tlearn: 0.0386190\ttotal: 22.3s\tremaining: 573ms\n",
      "975:\tlearn: 0.0385699\ttotal: 22.4s\tremaining: 550ms\n",
      "976:\tlearn: 0.0385262\ttotal: 22.4s\tremaining: 527ms\n",
      "977:\tlearn: 0.0384912\ttotal: 22.4s\tremaining: 504ms\n",
      "978:\tlearn: 0.0384623\ttotal: 22.4s\tremaining: 481ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "979:\tlearn: 0.0383744\ttotal: 22.4s\tremaining: 458ms\n",
      "980:\tlearn: 0.0383366\ttotal: 22.5s\tremaining: 435ms\n",
      "981:\tlearn: 0.0382876\ttotal: 22.5s\tremaining: 412ms\n",
      "982:\tlearn: 0.0382845\ttotal: 22.5s\tremaining: 389ms\n",
      "983:\tlearn: 0.0382230\ttotal: 22.5s\tremaining: 366ms\n",
      "984:\tlearn: 0.0381954\ttotal: 22.6s\tremaining: 344ms\n",
      "985:\tlearn: 0.0381073\ttotal: 22.6s\tremaining: 321ms\n",
      "986:\tlearn: 0.0380700\ttotal: 22.6s\tremaining: 298ms\n",
      "987:\tlearn: 0.0380572\ttotal: 22.6s\tremaining: 275ms\n",
      "988:\tlearn: 0.0380108\ttotal: 22.6s\tremaining: 252ms\n",
      "989:\tlearn: 0.0379538\ttotal: 22.7s\tremaining: 229ms\n",
      "990:\tlearn: 0.0379320\ttotal: 22.7s\tremaining: 206ms\n",
      "991:\tlearn: 0.0378886\ttotal: 22.7s\tremaining: 183ms\n",
      "992:\tlearn: 0.0377910\ttotal: 22.7s\tremaining: 160ms\n",
      "993:\tlearn: 0.0377760\ttotal: 22.8s\tremaining: 137ms\n",
      "994:\tlearn: 0.0377496\ttotal: 22.8s\tremaining: 114ms\n",
      "995:\tlearn: 0.0376982\ttotal: 22.8s\tremaining: 91.6ms\n",
      "996:\tlearn: 0.0376216\ttotal: 22.8s\tremaining: 68.7ms\n",
      "997:\tlearn: 0.0376049\ttotal: 22.9s\tremaining: 45.8ms\n",
      "998:\tlearn: 0.0375420\ttotal: 22.9s\tremaining: 22.9ms\n",
      "999:\tlearn: 0.0375006\ttotal: 22.9s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "scores1 = {\n",
    "    4 : {None : None},\n",
    "    10 : {None : None},\n",
    "    104 : {None : None},\n",
    "}\n",
    "\n",
    "res_dfs1 = {\n",
    "    4 : {None : None},\n",
    "    10 : {None : None},\n",
    "    104 : {None : None},\n",
    "}\n",
    "    \n",
    "for c_name, classifier in top_classes.items():\n",
    "    for split_method in ['tt','skf']:\n",
    "        for rs in scores1.keys():\n",
    "            a1, d1 = sc_pca_class_test(X, y, MinMaxScaler(), None, 50, 0.2, classifier, split_method, 11)\n",
    "            key = c_name + '_' + split_method\n",
    "            scores1[rs].update({key:a1})\n",
    "            res_dfs1[rs].update({key:d1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "6231286f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CatBoost_skf</th>\n",
       "      <td>0.985493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBM_skf</th>\n",
       "      <td>0.983559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBM_tt</th>\n",
       "      <td>0.981643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADABoost200_skf</th>\n",
       "      <td>0.981625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatBoost_tt</th>\n",
       "      <td>0.978744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest100_skf</th>\n",
       "      <td>0.977756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest200_skf</th>\n",
       "      <td>0.977756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADABoost200_tt</th>\n",
       "      <td>0.974879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest100_tt</th>\n",
       "      <td>0.973913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest200_tt</th>\n",
       "      <td>0.971981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVMLinear_skf</th>\n",
       "      <td>0.970986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVMLinear_tt</th>\n",
       "      <td>0.969082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADABoost100_tt</th>\n",
       "      <td>0.968116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADABoost100_skf</th>\n",
       "      <td>0.967118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GrdBst_skf</th>\n",
       "      <td>0.965184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GrdBst_tt</th>\n",
       "      <td>0.964251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression_skf</th>\n",
       "      <td>0.964217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression_tt</th>\n",
       "      <td>0.963285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVMSigmoid_tt</th>\n",
       "      <td>0.848309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVMSigmoid_skf</th>\n",
       "      <td>0.834623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>None</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        accuracy\n",
       "CatBoost_skf            0.985493\n",
       "LGBM_skf                0.983559\n",
       "LGBM_tt                 0.981643\n",
       "ADABoost200_skf         0.981625\n",
       "CatBoost_tt             0.978744\n",
       "RandomForest100_skf     0.977756\n",
       "RandomForest200_skf     0.977756\n",
       "ADABoost200_tt          0.974879\n",
       "RandomForest100_tt      0.973913\n",
       "RandomForest200_tt      0.971981\n",
       "SVMLinear_skf           0.970986\n",
       "SVMLinear_tt            0.969082\n",
       "ADABoost100_tt          0.968116\n",
       "ADABoost100_skf         0.967118\n",
       "GrdBst_skf              0.965184\n",
       "GrdBst_tt               0.964251\n",
       "LogisticRegression_skf  0.964217\n",
       "LogisticRegression_tt   0.963285\n",
       "SVMSigmoid_tt           0.848309\n",
       "SVMSigmoid_skf          0.834623\n",
       "None                         NaN"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(scores1[10], orient='index', columns=['accuracy']).sort_values(by='accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "bb5d523f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfls = []\n",
    "\n",
    "for rs in scores1.keys():\n",
    "    dfls.append(pd.DataFrame.from_dict(scores1[rs], orient='index', columns=['accuracy']).sort_values(by='accuracy', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "e8053cd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['accuracy', 'accuracy', 'accuracy'], dtype='object')"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1_df = pd.concat(dfls, axis=1)\n",
    "#s1_df['avg_acc'] = \n",
    "s1_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "6b2bf632",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_df['Accuracy'] = s1_df[[col for col in s1_df.columns if col.startswith('a')]].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "d5ec97a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CatBoost_skf</th>\n",
       "      <td>0.985493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBM_skf</th>\n",
       "      <td>0.983559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBM_tt</th>\n",
       "      <td>0.981643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADABoost200_skf</th>\n",
       "      <td>0.981625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatBoost_tt</th>\n",
       "      <td>0.978744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest200_skf</th>\n",
       "      <td>0.977756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest200_tt</th>\n",
       "      <td>0.975845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADABoost200_tt</th>\n",
       "      <td>0.974879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest100_skf</th>\n",
       "      <td>0.974855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVMLinear_skf</th>\n",
       "      <td>0.970986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVMLinear_tt</th>\n",
       "      <td>0.969082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADABoost100_tt</th>\n",
       "      <td>0.968116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest100_tt</th>\n",
       "      <td>0.971014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADABoost100_skf</th>\n",
       "      <td>0.967118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GrdBst_tt</th>\n",
       "      <td>0.964251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression_skf</th>\n",
       "      <td>0.964217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression_tt</th>\n",
       "      <td>0.963285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GrdBst_skf</th>\n",
       "      <td>0.962605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVMSigmoid_tt</th>\n",
       "      <td>0.848309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVMSigmoid_skf</th>\n",
       "      <td>0.834623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>None</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Accuracy\n",
       "CatBoost_skf            0.985493\n",
       "LGBM_skf                0.983559\n",
       "LGBM_tt                 0.981643\n",
       "ADABoost200_skf         0.981625\n",
       "CatBoost_tt             0.978744\n",
       "RandomForest200_skf     0.977756\n",
       "RandomForest200_tt      0.975845\n",
       "ADABoost200_tt          0.974879\n",
       "RandomForest100_skf     0.974855\n",
       "SVMLinear_skf           0.970986\n",
       "SVMLinear_tt            0.969082\n",
       "ADABoost100_tt          0.968116\n",
       "RandomForest100_tt      0.971014\n",
       "ADABoost100_skf         0.967118\n",
       "GrdBst_tt               0.964251\n",
       "LogisticRegression_skf  0.964217\n",
       "LogisticRegression_tt   0.963285\n",
       "GrdBst_skf              0.962605\n",
       "SVMSigmoid_tt           0.848309\n",
       "SVMSigmoid_skf          0.834623\n",
       "None                         NaN"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1_df[['Accuracy']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6dd0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_graph(df):\n",
    "\n",
    "    df.plot(x=df.index, y='y', kind='line', marker='o', title='Simple Line Graph')\n",
    "\n",
    "    # Adding labels\n",
    "    plt.xlabel('X Axis')\n",
    "    plt.ylabel('Y Axis')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "6a75bde0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CatBoost_skf</th>\n",
       "      <td>0.985493</td>\n",
       "      <td>0.985493</td>\n",
       "      <td>0.985493</td>\n",
       "      <td>0.985493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBM_skf</th>\n",
       "      <td>0.983559</td>\n",
       "      <td>0.983559</td>\n",
       "      <td>0.983559</td>\n",
       "      <td>0.983559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBM_tt</th>\n",
       "      <td>0.981643</td>\n",
       "      <td>0.981643</td>\n",
       "      <td>0.981643</td>\n",
       "      <td>0.981643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADABoost200_skf</th>\n",
       "      <td>0.981625</td>\n",
       "      <td>0.981625</td>\n",
       "      <td>0.981625</td>\n",
       "      <td>0.981625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatBoost_tt</th>\n",
       "      <td>0.978744</td>\n",
       "      <td>0.978744</td>\n",
       "      <td>0.978744</td>\n",
       "      <td>0.978744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest200_skf</th>\n",
       "      <td>0.978723</td>\n",
       "      <td>0.977756</td>\n",
       "      <td>0.976789</td>\n",
       "      <td>0.977756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest200_tt</th>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.971981</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.975845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADABoost200_tt</th>\n",
       "      <td>0.974879</td>\n",
       "      <td>0.974879</td>\n",
       "      <td>0.974879</td>\n",
       "      <td>0.974879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest100_skf</th>\n",
       "      <td>0.972921</td>\n",
       "      <td>0.977756</td>\n",
       "      <td>0.973888</td>\n",
       "      <td>0.974855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVMLinear_skf</th>\n",
       "      <td>0.970986</td>\n",
       "      <td>0.970986</td>\n",
       "      <td>0.970986</td>\n",
       "      <td>0.970986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVMLinear_tt</th>\n",
       "      <td>0.969082</td>\n",
       "      <td>0.969082</td>\n",
       "      <td>0.969082</td>\n",
       "      <td>0.969082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADABoost100_tt</th>\n",
       "      <td>0.968116</td>\n",
       "      <td>0.968116</td>\n",
       "      <td>0.968116</td>\n",
       "      <td>0.968116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest100_tt</th>\n",
       "      <td>0.967150</td>\n",
       "      <td>0.973913</td>\n",
       "      <td>0.971981</td>\n",
       "      <td>0.971014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADABoost100_skf</th>\n",
       "      <td>0.967118</td>\n",
       "      <td>0.967118</td>\n",
       "      <td>0.967118</td>\n",
       "      <td>0.967118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GrdBst_tt</th>\n",
       "      <td>0.964251</td>\n",
       "      <td>0.964251</td>\n",
       "      <td>0.964251</td>\n",
       "      <td>0.964251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression_skf</th>\n",
       "      <td>0.964217</td>\n",
       "      <td>0.964217</td>\n",
       "      <td>0.964217</td>\n",
       "      <td>0.964217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression_tt</th>\n",
       "      <td>0.963285</td>\n",
       "      <td>0.963285</td>\n",
       "      <td>0.963285</td>\n",
       "      <td>0.963285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GrdBst_skf</th>\n",
       "      <td>0.961315</td>\n",
       "      <td>0.965184</td>\n",
       "      <td>0.961315</td>\n",
       "      <td>0.962605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVMSigmoid_tt</th>\n",
       "      <td>0.848309</td>\n",
       "      <td>0.848309</td>\n",
       "      <td>0.848309</td>\n",
       "      <td>0.848309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVMSigmoid_skf</th>\n",
       "      <td>0.834623</td>\n",
       "      <td>0.834623</td>\n",
       "      <td>0.834623</td>\n",
       "      <td>0.834623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>None</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        accuracy  accuracy  accuracy  Accuracy\n",
       "CatBoost_skf            0.985493  0.985493  0.985493  0.985493\n",
       "LGBM_skf                0.983559  0.983559  0.983559  0.983559\n",
       "LGBM_tt                 0.981643  0.981643  0.981643  0.981643\n",
       "ADABoost200_skf         0.981625  0.981625  0.981625  0.981625\n",
       "CatBoost_tt             0.978744  0.978744  0.978744  0.978744\n",
       "RandomForest200_skf     0.978723  0.977756  0.976789  0.977756\n",
       "RandomForest200_tt      0.977778  0.971981  0.977778  0.975845\n",
       "ADABoost200_tt          0.974879  0.974879  0.974879  0.974879\n",
       "RandomForest100_skf     0.972921  0.977756  0.973888  0.974855\n",
       "SVMLinear_skf           0.970986  0.970986  0.970986  0.970986\n",
       "SVMLinear_tt            0.969082  0.969082  0.969082  0.969082\n",
       "ADABoost100_tt          0.968116  0.968116  0.968116  0.968116\n",
       "RandomForest100_tt      0.967150  0.973913  0.971981  0.971014\n",
       "ADABoost100_skf         0.967118  0.967118  0.967118  0.967118\n",
       "GrdBst_tt               0.964251  0.964251  0.964251  0.964251\n",
       "LogisticRegression_skf  0.964217  0.964217  0.964217  0.964217\n",
       "LogisticRegression_tt   0.963285  0.963285  0.963285  0.963285\n",
       "GrdBst_skf              0.961315  0.965184  0.961315  0.962605\n",
       "SVMSigmoid_tt           0.848309  0.848309  0.848309  0.848309\n",
       "SVMSigmoid_skf          0.834623  0.834623  0.834623  0.834623\n",
       "None                         NaN       NaN       NaN       NaN"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "9bba8831",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_df = s1_df.iloc[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "b062ae94",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_std = np.std(s1_df.Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "9a7e2a5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7945047075237757, 1.0256113466348316)"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = s1_df[['Accuracy']].sort_values(by='Accuracy',ascending=False).plot(kind='barh', y='Accuracy', title='Accuracy', legend=False)\n",
    "\n",
    "plt.xlim(min(s1_df.Accuracy) - acc_std, max(s1_df.Accuracy) + acc_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "34c29840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['accuracy', 'accuracy', 'accuracy']"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[col for col in s1_df.columns if col.startswith('a')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "40a0f3a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CatBoost_skf</th>\n",
       "      <td>0.985493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBM_skf</th>\n",
       "      <td>0.983559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBM_tt</th>\n",
       "      <td>0.981643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADABoost200_skf</th>\n",
       "      <td>0.981625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest200_skf</th>\n",
       "      <td>0.979691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatBoost_tt</th>\n",
       "      <td>0.978744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest200_tt</th>\n",
       "      <td>0.975845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest100_tt</th>\n",
       "      <td>0.974879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADABoost200_tt</th>\n",
       "      <td>0.974879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest100_skf</th>\n",
       "      <td>0.974855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVMLinear_skf</th>\n",
       "      <td>0.970986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVMLinear_tt</th>\n",
       "      <td>0.969082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADABoost100_tt</th>\n",
       "      <td>0.968116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADABoost100_skf</th>\n",
       "      <td>0.967118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GrdBst_tt</th>\n",
       "      <td>0.964251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression_skf</th>\n",
       "      <td>0.964217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression_tt</th>\n",
       "      <td>0.963285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GrdBst_skf</th>\n",
       "      <td>0.961315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN5n_tt</th>\n",
       "      <td>0.878261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN5n_skf</th>\n",
       "      <td>0.863636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVMSigmoid_tt</th>\n",
       "      <td>0.848309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVMSigmoid_skf</th>\n",
       "      <td>0.834623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN15n_tt</th>\n",
       "      <td>0.788406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN15n_skf</th>\n",
       "      <td>0.779497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN25n_tt</th>\n",
       "      <td>0.740097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN25n_skf</th>\n",
       "      <td>0.723404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        accuracy\n",
       "CatBoost_skf            0.985493\n",
       "LGBM_skf                0.983559\n",
       "LGBM_tt                 0.981643\n",
       "ADABoost200_skf         0.981625\n",
       "RandomForest200_skf     0.979691\n",
       "CatBoost_tt             0.978744\n",
       "RandomForest200_tt      0.975845\n",
       "RandomForest100_tt      0.974879\n",
       "ADABoost200_tt          0.974879\n",
       "RandomForest100_skf     0.974855\n",
       "SVMLinear_skf           0.970986\n",
       "SVMLinear_tt            0.969082\n",
       "ADABoost100_tt          0.968116\n",
       "ADABoost100_skf         0.967118\n",
       "GrdBst_tt               0.964251\n",
       "LogisticRegression_skf  0.964217\n",
       "LogisticRegression_tt   0.963285\n",
       "GrdBst_skf              0.961315\n",
       "KNN5n_tt                0.878261\n",
       "KNN5n_skf               0.863636\n",
       "SVMSigmoid_tt           0.848309\n",
       "SVMSigmoid_skf          0.834623\n",
       "KNN15n_tt               0.788406\n",
       "KNN15n_skf              0.779497\n",
       "KNN25n_tt               0.740097\n",
       "KNN25n_skf              0.723404"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(scores, orient='index', columns=['accuracy']).sort_values(by='accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a33444",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9eafbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for pc in ['pca', 'svd', ]\n",
    "score, ddf = sc_pca_class_test(X, y, MinMaxScaler(),None, 50, 0.2, LGBMClassifier(n_estimators=200), 'kf', 52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "5e79f5fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LGBM_skf</th>\n",
       "      <td>0.978723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVMLinear_tt</th>\n",
       "      <td>0.976812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADABoost200_tt</th>\n",
       "      <td>0.975845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBM_tt</th>\n",
       "      <td>0.975845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADABoost200_skf</th>\n",
       "      <td>0.972921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADABoost100_tt</th>\n",
       "      <td>0.971981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression_tt</th>\n",
       "      <td>0.971014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest200_tt</th>\n",
       "      <td>0.969082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADABoost100_skf</th>\n",
       "      <td>0.968085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest200_skf</th>\n",
       "      <td>0.968085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest100_tt</th>\n",
       "      <td>0.967150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVMLinear_skf</th>\n",
       "      <td>0.966151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression_skf</th>\n",
       "      <td>0.965184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GrdBst_skf</th>\n",
       "      <td>0.965184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest100_skf</th>\n",
       "      <td>0.963250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GrdBst_tt</th>\n",
       "      <td>0.955556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN5n_tt</th>\n",
       "      <td>0.878261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN5n_skf</th>\n",
       "      <td>0.863636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVMSigmoid_tt</th>\n",
       "      <td>0.845411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVMSigmoid_skf</th>\n",
       "      <td>0.844294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN15n_tt</th>\n",
       "      <td>0.788406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN15n_skf</th>\n",
       "      <td>0.779497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN25n_tt</th>\n",
       "      <td>0.740097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN25n_skf</th>\n",
       "      <td>0.723404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        accuracy\n",
       "LGBM_skf                0.978723\n",
       "SVMLinear_tt            0.976812\n",
       "ADABoost200_tt          0.975845\n",
       "LGBM_tt                 0.975845\n",
       "ADABoost200_skf         0.972921\n",
       "ADABoost100_tt          0.971981\n",
       "LogisticRegression_tt   0.971014\n",
       "RandomForest200_tt      0.969082\n",
       "ADABoost100_skf         0.968085\n",
       "RandomForest200_skf     0.968085\n",
       "RandomForest100_tt      0.967150\n",
       "SVMLinear_skf           0.966151\n",
       "LogisticRegression_skf  0.965184\n",
       "GrdBst_skf              0.965184\n",
       "RandomForest100_skf     0.963250\n",
       "GrdBst_tt               0.955556\n",
       "KNN5n_tt                0.878261\n",
       "KNN5n_skf               0.863636\n",
       "SVMSigmoid_tt           0.845411\n",
       "SVMSigmoid_skf          0.844294\n",
       "KNN15n_tt               0.788406\n",
       "KNN15n_skf              0.779497\n",
       "KNN25n_tt               0.740097\n",
       "KNN25n_skf              0.723404"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(scores, orient='index', columns=['accuracy']).sort_values(by='accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "2d960d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "model = CatBoostClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "3a44a1f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.018891\n",
      "0:\tlearn: 0.6674408\ttotal: 202ms\tremaining: 3m 22s\n",
      "1:\tlearn: 0.6418175\ttotal: 238ms\tremaining: 1m 58s\n",
      "2:\tlearn: 0.6190177\ttotal: 265ms\tremaining: 1m 27s\n",
      "3:\tlearn: 0.5981246\ttotal: 290ms\tremaining: 1m 12s\n",
      "4:\tlearn: 0.5784861\ttotal: 318ms\tremaining: 1m 3s\n",
      "5:\tlearn: 0.5602460\ttotal: 343ms\tremaining: 56.9s\n",
      "6:\tlearn: 0.5434723\ttotal: 364ms\tremaining: 51.7s\n",
      "7:\tlearn: 0.5268864\ttotal: 382ms\tremaining: 47.4s\n",
      "8:\tlearn: 0.5125066\ttotal: 402ms\tremaining: 44.2s\n",
      "9:\tlearn: 0.5060472\ttotal: 424ms\tremaining: 42s\n",
      "10:\tlearn: 0.4939413\ttotal: 446ms\tremaining: 40.1s\n",
      "11:\tlearn: 0.4854633\ttotal: 464ms\tremaining: 38.2s\n",
      "12:\tlearn: 0.4725927\ttotal: 482ms\tremaining: 36.6s\n",
      "13:\tlearn: 0.4606820\ttotal: 501ms\tremaining: 35.3s\n",
      "14:\tlearn: 0.4500795\ttotal: 523ms\tremaining: 34.3s\n",
      "15:\tlearn: 0.4375371\ttotal: 543ms\tremaining: 33.4s\n",
      "16:\tlearn: 0.4283709\ttotal: 564ms\tremaining: 32.6s\n",
      "17:\tlearn: 0.4191348\ttotal: 585ms\tremaining: 31.9s\n",
      "18:\tlearn: 0.4111556\ttotal: 606ms\tremaining: 31.3s\n",
      "19:\tlearn: 0.4031859\ttotal: 626ms\tremaining: 30.7s\n",
      "20:\tlearn: 0.3976901\ttotal: 650ms\tremaining: 30.3s\n",
      "21:\tlearn: 0.3931334\ttotal: 671ms\tremaining: 29.8s\n",
      "22:\tlearn: 0.3858197\ttotal: 692ms\tremaining: 29.4s\n",
      "23:\tlearn: 0.3780784\ttotal: 710ms\tremaining: 28.9s\n",
      "24:\tlearn: 0.3739442\ttotal: 730ms\tremaining: 28.5s\n",
      "25:\tlearn: 0.3691954\ttotal: 749ms\tremaining: 28s\n",
      "26:\tlearn: 0.3662559\ttotal: 768ms\tremaining: 27.7s\n",
      "27:\tlearn: 0.3604369\ttotal: 790ms\tremaining: 27.4s\n",
      "28:\tlearn: 0.3554286\ttotal: 812ms\tremaining: 27.2s\n",
      "29:\tlearn: 0.3521639\ttotal: 834ms\tremaining: 27s\n",
      "30:\tlearn: 0.3467371\ttotal: 859ms\tremaining: 26.8s\n",
      "31:\tlearn: 0.3405302\ttotal: 878ms\tremaining: 26.6s\n",
      "32:\tlearn: 0.3361433\ttotal: 897ms\tremaining: 26.3s\n",
      "33:\tlearn: 0.3298932\ttotal: 917ms\tremaining: 26s\n",
      "34:\tlearn: 0.3264470\ttotal: 939ms\tremaining: 25.9s\n",
      "35:\tlearn: 0.3223103\ttotal: 961ms\tremaining: 25.7s\n",
      "36:\tlearn: 0.3174088\ttotal: 983ms\tremaining: 25.6s\n",
      "37:\tlearn: 0.3147492\ttotal: 1s\tremaining: 25.4s\n",
      "38:\tlearn: 0.3106609\ttotal: 1.02s\tremaining: 25.2s\n",
      "39:\tlearn: 0.3072086\ttotal: 1.04s\tremaining: 25.1s\n",
      "40:\tlearn: 0.3043587\ttotal: 1.06s\tremaining: 24.9s\n",
      "41:\tlearn: 0.3025812\ttotal: 1.09s\tremaining: 24.8s\n",
      "42:\tlearn: 0.2996034\ttotal: 1.11s\tremaining: 24.6s\n",
      "43:\tlearn: 0.2978142\ttotal: 1.13s\tremaining: 24.5s\n",
      "44:\tlearn: 0.2958666\ttotal: 1.15s\tremaining: 24.4s\n",
      "45:\tlearn: 0.2936473\ttotal: 1.17s\tremaining: 24.3s\n",
      "46:\tlearn: 0.2900181\ttotal: 1.19s\tremaining: 24.2s\n",
      "47:\tlearn: 0.2879882\ttotal: 1.21s\tremaining: 24s\n",
      "48:\tlearn: 0.2850777\ttotal: 1.23s\tremaining: 23.9s\n",
      "49:\tlearn: 0.2831363\ttotal: 1.25s\tremaining: 23.8s\n",
      "50:\tlearn: 0.2810366\ttotal: 1.28s\tremaining: 23.8s\n",
      "51:\tlearn: 0.2790600\ttotal: 1.3s\tremaining: 23.7s\n",
      "52:\tlearn: 0.2757457\ttotal: 1.32s\tremaining: 23.7s\n",
      "53:\tlearn: 0.2738738\ttotal: 1.35s\tremaining: 23.6s\n",
      "54:\tlearn: 0.2711449\ttotal: 1.37s\tremaining: 23.6s\n",
      "55:\tlearn: 0.2686483\ttotal: 1.4s\tremaining: 23.5s\n",
      "56:\tlearn: 0.2670055\ttotal: 1.42s\tremaining: 23.4s\n",
      "57:\tlearn: 0.2655642\ttotal: 1.44s\tremaining: 23.4s\n",
      "58:\tlearn: 0.2639553\ttotal: 1.46s\tremaining: 23.3s\n",
      "59:\tlearn: 0.2614937\ttotal: 1.48s\tremaining: 23.2s\n",
      "60:\tlearn: 0.2595575\ttotal: 1.5s\tremaining: 23.2s\n",
      "61:\tlearn: 0.2579701\ttotal: 1.53s\tremaining: 23.1s\n",
      "62:\tlearn: 0.2568104\ttotal: 1.55s\tremaining: 23s\n",
      "63:\tlearn: 0.2547003\ttotal: 1.57s\tremaining: 23s\n",
      "64:\tlearn: 0.2524513\ttotal: 1.59s\tremaining: 22.9s\n",
      "65:\tlearn: 0.2510875\ttotal: 1.61s\tremaining: 22.8s\n",
      "66:\tlearn: 0.2484602\ttotal: 1.63s\tremaining: 22.7s\n",
      "67:\tlearn: 0.2469312\ttotal: 1.65s\tremaining: 22.6s\n",
      "68:\tlearn: 0.2453721\ttotal: 1.67s\tremaining: 22.5s\n",
      "69:\tlearn: 0.2436276\ttotal: 1.69s\tremaining: 22.5s\n",
      "70:\tlearn: 0.2425215\ttotal: 1.71s\tremaining: 22.4s\n",
      "71:\tlearn: 0.2413058\ttotal: 1.74s\tremaining: 22.4s\n",
      "72:\tlearn: 0.2397747\ttotal: 1.76s\tremaining: 22.4s\n",
      "73:\tlearn: 0.2378914\ttotal: 1.79s\tremaining: 22.4s\n",
      "74:\tlearn: 0.2366564\ttotal: 1.81s\tremaining: 22.3s\n",
      "75:\tlearn: 0.2354525\ttotal: 1.83s\tremaining: 22.3s\n",
      "76:\tlearn: 0.2342050\ttotal: 1.85s\tremaining: 22.2s\n",
      "77:\tlearn: 0.2327193\ttotal: 1.87s\tremaining: 22.1s\n",
      "78:\tlearn: 0.2317158\ttotal: 1.89s\tremaining: 22.1s\n",
      "79:\tlearn: 0.2304492\ttotal: 1.92s\tremaining: 22s\n",
      "80:\tlearn: 0.2287806\ttotal: 1.94s\tremaining: 22s\n",
      "81:\tlearn: 0.2278512\ttotal: 1.96s\tremaining: 22s\n",
      "82:\tlearn: 0.2261253\ttotal: 1.99s\tremaining: 22s\n",
      "83:\tlearn: 0.2241534\ttotal: 2.01s\tremaining: 22s\n",
      "84:\tlearn: 0.2232591\ttotal: 2.04s\tremaining: 22s\n",
      "85:\tlearn: 0.2209216\ttotal: 2.06s\tremaining: 21.9s\n",
      "86:\tlearn: 0.2200421\ttotal: 2.08s\tremaining: 21.8s\n",
      "87:\tlearn: 0.2186367\ttotal: 2.1s\tremaining: 21.8s\n",
      "88:\tlearn: 0.2173139\ttotal: 2.12s\tremaining: 21.7s\n",
      "89:\tlearn: 0.2156978\ttotal: 2.14s\tremaining: 21.7s\n",
      "90:\tlearn: 0.2146468\ttotal: 2.16s\tremaining: 21.6s\n",
      "91:\tlearn: 0.2135490\ttotal: 2.19s\tremaining: 21.6s\n",
      "92:\tlearn: 0.2125211\ttotal: 2.21s\tremaining: 21.6s\n",
      "93:\tlearn: 0.2115286\ttotal: 2.24s\tremaining: 21.6s\n",
      "94:\tlearn: 0.2101075\ttotal: 2.26s\tremaining: 21.5s\n",
      "95:\tlearn: 0.2093564\ttotal: 2.29s\tremaining: 21.6s\n",
      "96:\tlearn: 0.2081524\ttotal: 2.31s\tremaining: 21.5s\n",
      "97:\tlearn: 0.2064406\ttotal: 2.34s\tremaining: 21.5s\n",
      "98:\tlearn: 0.2055775\ttotal: 2.36s\tremaining: 21.5s\n",
      "99:\tlearn: 0.2045904\ttotal: 2.38s\tremaining: 21.4s\n",
      "100:\tlearn: 0.2032417\ttotal: 2.4s\tremaining: 21.4s\n",
      "101:\tlearn: 0.2024014\ttotal: 2.43s\tremaining: 21.4s\n",
      "102:\tlearn: 0.2012763\ttotal: 2.47s\tremaining: 21.6s\n",
      "103:\tlearn: 0.1996054\ttotal: 2.5s\tremaining: 21.6s\n",
      "104:\tlearn: 0.1985837\ttotal: 2.54s\tremaining: 21.6s\n",
      "105:\tlearn: 0.1972716\ttotal: 2.56s\tremaining: 21.6s\n",
      "106:\tlearn: 0.1963287\ttotal: 2.58s\tremaining: 21.5s\n",
      "107:\tlearn: 0.1953404\ttotal: 2.6s\tremaining: 21.5s\n",
      "108:\tlearn: 0.1945222\ttotal: 2.62s\tremaining: 21.4s\n",
      "109:\tlearn: 0.1938969\ttotal: 2.65s\tremaining: 21.4s\n",
      "110:\tlearn: 0.1927696\ttotal: 2.66s\tremaining: 21.3s\n",
      "111:\tlearn: 0.1918708\ttotal: 2.68s\tremaining: 21.3s\n",
      "112:\tlearn: 0.1909304\ttotal: 2.7s\tremaining: 21.2s\n",
      "113:\tlearn: 0.1900273\ttotal: 2.74s\tremaining: 21.3s\n",
      "114:\tlearn: 0.1889825\ttotal: 2.76s\tremaining: 21.2s\n",
      "115:\tlearn: 0.1883097\ttotal: 2.78s\tremaining: 21.2s\n",
      "116:\tlearn: 0.1871341\ttotal: 2.8s\tremaining: 21.1s\n",
      "117:\tlearn: 0.1865985\ttotal: 2.83s\tremaining: 21.2s\n",
      "118:\tlearn: 0.1851861\ttotal: 2.86s\tremaining: 21.2s\n",
      "119:\tlearn: 0.1845700\ttotal: 2.88s\tremaining: 21.1s\n",
      "120:\tlearn: 0.1836908\ttotal: 2.9s\tremaining: 21s\n",
      "121:\tlearn: 0.1826957\ttotal: 2.92s\tremaining: 21s\n",
      "122:\tlearn: 0.1817790\ttotal: 2.94s\tremaining: 21s\n",
      "123:\tlearn: 0.1808772\ttotal: 2.96s\tremaining: 20.9s\n",
      "124:\tlearn: 0.1798614\ttotal: 2.98s\tremaining: 20.9s\n",
      "125:\tlearn: 0.1793590\ttotal: 3s\tremaining: 20.8s\n",
      "126:\tlearn: 0.1783983\ttotal: 3.03s\tremaining: 20.8s\n",
      "127:\tlearn: 0.1775584\ttotal: 3.05s\tremaining: 20.8s\n",
      "128:\tlearn: 0.1769265\ttotal: 3.07s\tremaining: 20.7s\n",
      "129:\tlearn: 0.1762086\ttotal: 3.09s\tremaining: 20.7s\n",
      "130:\tlearn: 0.1752775\ttotal: 3.12s\tremaining: 20.7s\n",
      "131:\tlearn: 0.1747331\ttotal: 3.14s\tremaining: 20.7s\n",
      "132:\tlearn: 0.1742609\ttotal: 3.17s\tremaining: 20.7s\n",
      "133:\tlearn: 0.1733347\ttotal: 3.2s\tremaining: 20.7s\n",
      "134:\tlearn: 0.1729428\ttotal: 3.22s\tremaining: 20.6s\n",
      "135:\tlearn: 0.1721076\ttotal: 3.24s\tremaining: 20.6s\n",
      "136:\tlearn: 0.1709267\ttotal: 3.26s\tremaining: 20.6s\n",
      "137:\tlearn: 0.1704310\ttotal: 3.29s\tremaining: 20.5s\n",
      "138:\tlearn: 0.1698272\ttotal: 3.31s\tremaining: 20.5s\n",
      "139:\tlearn: 0.1693042\ttotal: 3.33s\tremaining: 20.5s\n",
      "140:\tlearn: 0.1687954\ttotal: 3.35s\tremaining: 20.4s\n",
      "141:\tlearn: 0.1680660\ttotal: 3.38s\tremaining: 20.5s\n",
      "142:\tlearn: 0.1676642\ttotal: 3.4s\tremaining: 20.4s\n",
      "143:\tlearn: 0.1671663\ttotal: 3.42s\tremaining: 20.4s\n",
      "144:\tlearn: 0.1665885\ttotal: 3.45s\tremaining: 20.4s\n",
      "145:\tlearn: 0.1662471\ttotal: 3.47s\tremaining: 20.3s\n",
      "146:\tlearn: 0.1657662\ttotal: 3.5s\tremaining: 20.3s\n",
      "147:\tlearn: 0.1649034\ttotal: 3.52s\tremaining: 20.2s\n",
      "148:\tlearn: 0.1643861\ttotal: 3.54s\tremaining: 20.2s\n",
      "149:\tlearn: 0.1633691\ttotal: 3.56s\tremaining: 20.2s\n",
      "150:\tlearn: 0.1628898\ttotal: 3.58s\tremaining: 20.1s\n",
      "151:\tlearn: 0.1621605\ttotal: 3.6s\tremaining: 20.1s\n",
      "152:\tlearn: 0.1614691\ttotal: 3.62s\tremaining: 20.1s\n",
      "153:\tlearn: 0.1607957\ttotal: 3.64s\tremaining: 20s\n",
      "154:\tlearn: 0.1604565\ttotal: 3.66s\tremaining: 20s\n",
      "155:\tlearn: 0.1600228\ttotal: 3.69s\tremaining: 19.9s\n",
      "156:\tlearn: 0.1595167\ttotal: 3.71s\tremaining: 19.9s\n",
      "157:\tlearn: 0.1590113\ttotal: 3.73s\tremaining: 19.9s\n",
      "158:\tlearn: 0.1586787\ttotal: 3.75s\tremaining: 19.8s\n",
      "159:\tlearn: 0.1582252\ttotal: 3.77s\tremaining: 19.8s\n",
      "160:\tlearn: 0.1576371\ttotal: 3.79s\tremaining: 19.8s\n",
      "161:\tlearn: 0.1571948\ttotal: 3.81s\tremaining: 19.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162:\tlearn: 0.1568060\ttotal: 3.84s\tremaining: 19.7s\n",
      "163:\tlearn: 0.1564570\ttotal: 3.87s\tremaining: 19.7s\n",
      "164:\tlearn: 0.1557501\ttotal: 3.89s\tremaining: 19.7s\n",
      "165:\tlearn: 0.1551128\ttotal: 3.92s\tremaining: 19.7s\n",
      "166:\tlearn: 0.1546226\ttotal: 3.94s\tremaining: 19.6s\n",
      "167:\tlearn: 0.1541589\ttotal: 3.96s\tremaining: 19.6s\n",
      "168:\tlearn: 0.1536502\ttotal: 3.98s\tremaining: 19.6s\n",
      "169:\tlearn: 0.1530493\ttotal: 4.01s\tremaining: 19.6s\n",
      "170:\tlearn: 0.1528098\ttotal: 4.03s\tremaining: 19.5s\n",
      "171:\tlearn: 0.1523601\ttotal: 4.05s\tremaining: 19.5s\n",
      "172:\tlearn: 0.1519702\ttotal: 4.08s\tremaining: 19.5s\n",
      "173:\tlearn: 0.1515071\ttotal: 4.1s\tremaining: 19.5s\n",
      "174:\tlearn: 0.1509713\ttotal: 4.12s\tremaining: 19.4s\n",
      "175:\tlearn: 0.1503854\ttotal: 4.14s\tremaining: 19.4s\n",
      "176:\tlearn: 0.1500256\ttotal: 4.17s\tremaining: 19.4s\n",
      "177:\tlearn: 0.1496172\ttotal: 4.19s\tremaining: 19.3s\n",
      "178:\tlearn: 0.1490256\ttotal: 4.21s\tremaining: 19.3s\n",
      "179:\tlearn: 0.1484535\ttotal: 4.24s\tremaining: 19.3s\n",
      "180:\tlearn: 0.1480863\ttotal: 4.26s\tremaining: 19.3s\n",
      "181:\tlearn: 0.1477644\ttotal: 4.28s\tremaining: 19.2s\n",
      "182:\tlearn: 0.1472284\ttotal: 4.3s\tremaining: 19.2s\n",
      "183:\tlearn: 0.1468052\ttotal: 4.34s\tremaining: 19.2s\n",
      "184:\tlearn: 0.1461513\ttotal: 4.36s\tremaining: 19.2s\n",
      "185:\tlearn: 0.1457289\ttotal: 4.38s\tremaining: 19.2s\n",
      "186:\tlearn: 0.1453451\ttotal: 4.41s\tremaining: 19.2s\n",
      "187:\tlearn: 0.1448617\ttotal: 4.43s\tremaining: 19.1s\n",
      "188:\tlearn: 0.1444459\ttotal: 4.45s\tremaining: 19.1s\n",
      "189:\tlearn: 0.1441255\ttotal: 4.47s\tremaining: 19.1s\n",
      "190:\tlearn: 0.1436981\ttotal: 4.5s\tremaining: 19s\n",
      "191:\tlearn: 0.1433687\ttotal: 4.52s\tremaining: 19s\n",
      "192:\tlearn: 0.1428974\ttotal: 4.54s\tremaining: 19s\n",
      "193:\tlearn: 0.1425664\ttotal: 4.56s\tremaining: 18.9s\n",
      "194:\tlearn: 0.1416337\ttotal: 4.58s\tremaining: 18.9s\n",
      "195:\tlearn: 0.1411565\ttotal: 4.6s\tremaining: 18.9s\n",
      "196:\tlearn: 0.1407510\ttotal: 4.62s\tremaining: 18.8s\n",
      "197:\tlearn: 0.1403957\ttotal: 4.64s\tremaining: 18.8s\n",
      "198:\tlearn: 0.1400068\ttotal: 4.66s\tremaining: 18.8s\n",
      "199:\tlearn: 0.1397074\ttotal: 4.68s\tremaining: 18.7s\n",
      "200:\tlearn: 0.1393848\ttotal: 4.71s\tremaining: 18.7s\n",
      "201:\tlearn: 0.1389764\ttotal: 4.74s\tremaining: 18.7s\n",
      "202:\tlearn: 0.1382948\ttotal: 4.76s\tremaining: 18.7s\n",
      "203:\tlearn: 0.1379237\ttotal: 4.79s\tremaining: 18.7s\n",
      "204:\tlearn: 0.1377093\ttotal: 4.8s\tremaining: 18.6s\n",
      "205:\tlearn: 0.1371637\ttotal: 4.83s\tremaining: 18.6s\n",
      "206:\tlearn: 0.1368239\ttotal: 4.84s\tremaining: 18.6s\n",
      "207:\tlearn: 0.1363785\ttotal: 4.87s\tremaining: 18.5s\n",
      "208:\tlearn: 0.1359826\ttotal: 4.89s\tremaining: 18.5s\n",
      "209:\tlearn: 0.1355457\ttotal: 4.91s\tremaining: 18.5s\n",
      "210:\tlearn: 0.1352393\ttotal: 4.93s\tremaining: 18.5s\n",
      "211:\tlearn: 0.1348646\ttotal: 4.96s\tremaining: 18.4s\n",
      "212:\tlearn: 0.1345145\ttotal: 4.98s\tremaining: 18.4s\n",
      "213:\tlearn: 0.1342411\ttotal: 5s\tremaining: 18.4s\n",
      "214:\tlearn: 0.1339006\ttotal: 5.03s\tremaining: 18.4s\n",
      "215:\tlearn: 0.1336712\ttotal: 5.05s\tremaining: 18.3s\n",
      "216:\tlearn: 0.1333397\ttotal: 5.07s\tremaining: 18.3s\n",
      "217:\tlearn: 0.1330608\ttotal: 5.1s\tremaining: 18.3s\n",
      "218:\tlearn: 0.1324937\ttotal: 5.12s\tremaining: 18.3s\n",
      "219:\tlearn: 0.1322666\ttotal: 5.14s\tremaining: 18.2s\n",
      "220:\tlearn: 0.1318005\ttotal: 5.17s\tremaining: 18.2s\n",
      "221:\tlearn: 0.1314761\ttotal: 5.19s\tremaining: 18.2s\n",
      "222:\tlearn: 0.1312138\ttotal: 5.22s\tremaining: 18.2s\n",
      "223:\tlearn: 0.1308355\ttotal: 5.25s\tremaining: 18.2s\n",
      "224:\tlearn: 0.1304982\ttotal: 5.27s\tremaining: 18.2s\n",
      "225:\tlearn: 0.1302598\ttotal: 5.29s\tremaining: 18.1s\n",
      "226:\tlearn: 0.1300772\ttotal: 5.32s\tremaining: 18.1s\n",
      "227:\tlearn: 0.1297519\ttotal: 5.34s\tremaining: 18.1s\n",
      "228:\tlearn: 0.1292001\ttotal: 5.36s\tremaining: 18s\n",
      "229:\tlearn: 0.1285417\ttotal: 5.38s\tremaining: 18s\n",
      "230:\tlearn: 0.1281670\ttotal: 5.41s\tremaining: 18s\n",
      "231:\tlearn: 0.1280056\ttotal: 5.43s\tremaining: 18s\n",
      "232:\tlearn: 0.1274867\ttotal: 5.47s\tremaining: 18s\n",
      "233:\tlearn: 0.1270031\ttotal: 5.49s\tremaining: 18s\n",
      "234:\tlearn: 0.1267233\ttotal: 5.52s\tremaining: 18s\n",
      "235:\tlearn: 0.1265013\ttotal: 5.54s\tremaining: 17.9s\n",
      "236:\tlearn: 0.1261998\ttotal: 5.57s\tremaining: 17.9s\n",
      "237:\tlearn: 0.1259316\ttotal: 5.59s\tremaining: 17.9s\n",
      "238:\tlearn: 0.1256884\ttotal: 5.62s\tremaining: 17.9s\n",
      "239:\tlearn: 0.1255202\ttotal: 5.64s\tremaining: 17.9s\n",
      "240:\tlearn: 0.1252870\ttotal: 5.67s\tremaining: 17.8s\n",
      "241:\tlearn: 0.1247411\ttotal: 5.69s\tremaining: 17.8s\n",
      "242:\tlearn: 0.1245300\ttotal: 5.72s\tremaining: 17.8s\n",
      "243:\tlearn: 0.1242033\ttotal: 5.75s\tremaining: 17.8s\n",
      "244:\tlearn: 0.1237843\ttotal: 5.78s\tremaining: 17.8s\n",
      "245:\tlearn: 0.1231625\ttotal: 5.8s\tremaining: 17.8s\n",
      "246:\tlearn: 0.1228610\ttotal: 5.83s\tremaining: 17.8s\n",
      "247:\tlearn: 0.1226726\ttotal: 5.85s\tremaining: 17.7s\n",
      "248:\tlearn: 0.1224956\ttotal: 5.88s\tremaining: 17.7s\n",
      "249:\tlearn: 0.1221127\ttotal: 5.9s\tremaining: 17.7s\n",
      "250:\tlearn: 0.1219657\ttotal: 5.93s\tremaining: 17.7s\n",
      "251:\tlearn: 0.1216306\ttotal: 5.95s\tremaining: 17.7s\n",
      "252:\tlearn: 0.1212850\ttotal: 5.97s\tremaining: 17.6s\n",
      "253:\tlearn: 0.1210128\ttotal: 6s\tremaining: 17.6s\n",
      "254:\tlearn: 0.1208533\ttotal: 6.02s\tremaining: 17.6s\n",
      "255:\tlearn: 0.1205377\ttotal: 6.04s\tremaining: 17.6s\n",
      "256:\tlearn: 0.1200613\ttotal: 6.06s\tremaining: 17.5s\n",
      "257:\tlearn: 0.1196371\ttotal: 6.09s\tremaining: 17.5s\n",
      "258:\tlearn: 0.1195391\ttotal: 6.11s\tremaining: 17.5s\n",
      "259:\tlearn: 0.1192710\ttotal: 6.13s\tremaining: 17.4s\n",
      "260:\tlearn: 0.1190761\ttotal: 6.15s\tremaining: 17.4s\n",
      "261:\tlearn: 0.1187439\ttotal: 6.17s\tremaining: 17.4s\n",
      "262:\tlearn: 0.1184335\ttotal: 6.2s\tremaining: 17.4s\n",
      "263:\tlearn: 0.1181011\ttotal: 6.22s\tremaining: 17.4s\n",
      "264:\tlearn: 0.1178563\ttotal: 6.25s\tremaining: 17.3s\n",
      "265:\tlearn: 0.1175758\ttotal: 6.28s\tremaining: 17.3s\n",
      "266:\tlearn: 0.1171734\ttotal: 6.31s\tremaining: 17.3s\n",
      "267:\tlearn: 0.1169679\ttotal: 6.33s\tremaining: 17.3s\n",
      "268:\tlearn: 0.1166614\ttotal: 6.36s\tremaining: 17.3s\n",
      "269:\tlearn: 0.1163311\ttotal: 6.38s\tremaining: 17.3s\n",
      "270:\tlearn: 0.1161154\ttotal: 6.42s\tremaining: 17.3s\n",
      "271:\tlearn: 0.1158364\ttotal: 6.45s\tremaining: 17.3s\n",
      "272:\tlearn: 0.1155990\ttotal: 6.47s\tremaining: 17.2s\n",
      "273:\tlearn: 0.1151788\ttotal: 6.5s\tremaining: 17.2s\n",
      "274:\tlearn: 0.1149755\ttotal: 6.53s\tremaining: 17.2s\n",
      "275:\tlearn: 0.1147092\ttotal: 6.55s\tremaining: 17.2s\n",
      "276:\tlearn: 0.1145389\ttotal: 6.58s\tremaining: 17.2s\n",
      "277:\tlearn: 0.1143517\ttotal: 6.61s\tremaining: 17.2s\n",
      "278:\tlearn: 0.1142178\ttotal: 6.63s\tremaining: 17.1s\n",
      "279:\tlearn: 0.1138454\ttotal: 6.66s\tremaining: 17.1s\n",
      "280:\tlearn: 0.1137119\ttotal: 6.68s\tremaining: 17.1s\n",
      "281:\tlearn: 0.1134197\ttotal: 6.7s\tremaining: 17.1s\n",
      "282:\tlearn: 0.1131719\ttotal: 6.73s\tremaining: 17s\n",
      "283:\tlearn: 0.1128555\ttotal: 6.75s\tremaining: 17s\n",
      "284:\tlearn: 0.1125375\ttotal: 6.77s\tremaining: 17s\n",
      "285:\tlearn: 0.1123558\ttotal: 6.79s\tremaining: 17s\n",
      "286:\tlearn: 0.1120845\ttotal: 6.82s\tremaining: 16.9s\n",
      "287:\tlearn: 0.1119461\ttotal: 6.84s\tremaining: 16.9s\n",
      "288:\tlearn: 0.1116442\ttotal: 6.86s\tremaining: 16.9s\n",
      "289:\tlearn: 0.1113184\ttotal: 6.89s\tremaining: 16.9s\n",
      "290:\tlearn: 0.1110215\ttotal: 6.91s\tremaining: 16.8s\n",
      "291:\tlearn: 0.1107822\ttotal: 6.93s\tremaining: 16.8s\n",
      "292:\tlearn: 0.1104719\ttotal: 6.96s\tremaining: 16.8s\n",
      "293:\tlearn: 0.1102395\ttotal: 6.98s\tremaining: 16.8s\n",
      "294:\tlearn: 0.1100573\ttotal: 7s\tremaining: 16.7s\n",
      "295:\tlearn: 0.1098711\ttotal: 7.03s\tremaining: 16.7s\n",
      "296:\tlearn: 0.1096028\ttotal: 7.05s\tremaining: 16.7s\n",
      "297:\tlearn: 0.1094669\ttotal: 7.07s\tremaining: 16.7s\n",
      "298:\tlearn: 0.1092455\ttotal: 7.09s\tremaining: 16.6s\n",
      "299:\tlearn: 0.1090601\ttotal: 7.12s\tremaining: 16.6s\n",
      "300:\tlearn: 0.1088807\ttotal: 7.14s\tremaining: 16.6s\n",
      "301:\tlearn: 0.1086148\ttotal: 7.16s\tremaining: 16.6s\n",
      "302:\tlearn: 0.1084240\ttotal: 7.18s\tremaining: 16.5s\n",
      "303:\tlearn: 0.1080818\ttotal: 7.21s\tremaining: 16.5s\n",
      "304:\tlearn: 0.1077222\ttotal: 7.23s\tremaining: 16.5s\n",
      "305:\tlearn: 0.1075270\ttotal: 7.26s\tremaining: 16.5s\n",
      "306:\tlearn: 0.1073040\ttotal: 7.28s\tremaining: 16.4s\n",
      "307:\tlearn: 0.1070895\ttotal: 7.3s\tremaining: 16.4s\n",
      "308:\tlearn: 0.1068692\ttotal: 7.33s\tremaining: 16.4s\n",
      "309:\tlearn: 0.1065637\ttotal: 7.35s\tremaining: 16.4s\n",
      "310:\tlearn: 0.1062768\ttotal: 7.39s\tremaining: 16.4s\n",
      "311:\tlearn: 0.1061050\ttotal: 7.41s\tremaining: 16.3s\n",
      "312:\tlearn: 0.1059388\ttotal: 7.43s\tremaining: 16.3s\n",
      "313:\tlearn: 0.1056732\ttotal: 7.46s\tremaining: 16.3s\n",
      "314:\tlearn: 0.1054430\ttotal: 7.48s\tremaining: 16.3s\n",
      "315:\tlearn: 0.1053028\ttotal: 7.5s\tremaining: 16.2s\n",
      "316:\tlearn: 0.1051329\ttotal: 7.52s\tremaining: 16.2s\n",
      "317:\tlearn: 0.1049422\ttotal: 7.54s\tremaining: 16.2s\n",
      "318:\tlearn: 0.1047179\ttotal: 7.58s\tremaining: 16.2s\n",
      "319:\tlearn: 0.1045782\ttotal: 7.61s\tremaining: 16.2s\n",
      "320:\tlearn: 0.1043551\ttotal: 7.63s\tremaining: 16.1s\n",
      "321:\tlearn: 0.1041212\ttotal: 7.65s\tremaining: 16.1s\n",
      "322:\tlearn: 0.1039306\ttotal: 7.67s\tremaining: 16.1s\n",
      "323:\tlearn: 0.1036971\ttotal: 7.69s\tremaining: 16s\n",
      "324:\tlearn: 0.1034825\ttotal: 7.71s\tremaining: 16s\n",
      "325:\tlearn: 0.1032147\ttotal: 7.74s\tremaining: 16s\n",
      "326:\tlearn: 0.1030536\ttotal: 7.76s\tremaining: 16s\n",
      "327:\tlearn: 0.1029502\ttotal: 7.78s\tremaining: 15.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328:\tlearn: 0.1027659\ttotal: 7.8s\tremaining: 15.9s\n",
      "329:\tlearn: 0.1026058\ttotal: 7.83s\tremaining: 15.9s\n",
      "330:\tlearn: 0.1024970\ttotal: 7.85s\tremaining: 15.9s\n",
      "331:\tlearn: 0.1023996\ttotal: 7.88s\tremaining: 15.9s\n",
      "332:\tlearn: 0.1021604\ttotal: 7.9s\tremaining: 15.8s\n",
      "333:\tlearn: 0.1019881\ttotal: 7.93s\tremaining: 15.8s\n",
      "334:\tlearn: 0.1017336\ttotal: 7.95s\tremaining: 15.8s\n",
      "335:\tlearn: 0.1015101\ttotal: 7.98s\tremaining: 15.8s\n",
      "336:\tlearn: 0.1012244\ttotal: 8.01s\tremaining: 15.8s\n",
      "337:\tlearn: 0.1011046\ttotal: 8.03s\tremaining: 15.7s\n",
      "338:\tlearn: 0.1008996\ttotal: 8.06s\tremaining: 15.7s\n",
      "339:\tlearn: 0.1007496\ttotal: 8.08s\tremaining: 15.7s\n",
      "340:\tlearn: 0.1006210\ttotal: 8.1s\tremaining: 15.7s\n",
      "341:\tlearn: 0.1004524\ttotal: 8.13s\tremaining: 15.6s\n",
      "342:\tlearn: 0.1001944\ttotal: 8.15s\tremaining: 15.6s\n",
      "343:\tlearn: 0.0999958\ttotal: 8.17s\tremaining: 15.6s\n",
      "344:\tlearn: 0.0999002\ttotal: 8.2s\tremaining: 15.6s\n",
      "345:\tlearn: 0.0996889\ttotal: 8.22s\tremaining: 15.5s\n",
      "346:\tlearn: 0.0995191\ttotal: 8.24s\tremaining: 15.5s\n",
      "347:\tlearn: 0.0992950\ttotal: 8.27s\tremaining: 15.5s\n",
      "348:\tlearn: 0.0991223\ttotal: 8.29s\tremaining: 15.5s\n",
      "349:\tlearn: 0.0989630\ttotal: 8.31s\tremaining: 15.4s\n",
      "350:\tlearn: 0.0987572\ttotal: 8.33s\tremaining: 15.4s\n",
      "351:\tlearn: 0.0985892\ttotal: 8.36s\tremaining: 15.4s\n",
      "352:\tlearn: 0.0982885\ttotal: 8.38s\tremaining: 15.4s\n",
      "353:\tlearn: 0.0979680\ttotal: 8.42s\tremaining: 15.4s\n",
      "354:\tlearn: 0.0977622\ttotal: 8.44s\tremaining: 15.3s\n",
      "355:\tlearn: 0.0976406\ttotal: 8.47s\tremaining: 15.3s\n",
      "356:\tlearn: 0.0974412\ttotal: 8.49s\tremaining: 15.3s\n",
      "357:\tlearn: 0.0972144\ttotal: 8.52s\tremaining: 15.3s\n",
      "358:\tlearn: 0.0969310\ttotal: 8.54s\tremaining: 15.3s\n",
      "359:\tlearn: 0.0967426\ttotal: 8.57s\tremaining: 15.2s\n",
      "360:\tlearn: 0.0965133\ttotal: 8.59s\tremaining: 15.2s\n",
      "361:\tlearn: 0.0963339\ttotal: 8.61s\tremaining: 15.2s\n",
      "362:\tlearn: 0.0961247\ttotal: 8.63s\tremaining: 15.1s\n",
      "363:\tlearn: 0.0958990\ttotal: 8.66s\tremaining: 15.1s\n",
      "364:\tlearn: 0.0956598\ttotal: 8.68s\tremaining: 15.1s\n",
      "365:\tlearn: 0.0954546\ttotal: 8.71s\tremaining: 15.1s\n",
      "366:\tlearn: 0.0952983\ttotal: 8.73s\tremaining: 15.1s\n",
      "367:\tlearn: 0.0950457\ttotal: 8.76s\tremaining: 15s\n",
      "368:\tlearn: 0.0948445\ttotal: 8.78s\tremaining: 15s\n",
      "369:\tlearn: 0.0946300\ttotal: 8.8s\tremaining: 15s\n",
      "370:\tlearn: 0.0944107\ttotal: 8.82s\tremaining: 15s\n",
      "371:\tlearn: 0.0942521\ttotal: 8.85s\tremaining: 14.9s\n",
      "372:\tlearn: 0.0940285\ttotal: 8.87s\tremaining: 14.9s\n",
      "373:\tlearn: 0.0938246\ttotal: 8.89s\tremaining: 14.9s\n",
      "374:\tlearn: 0.0935842\ttotal: 8.92s\tremaining: 14.9s\n",
      "375:\tlearn: 0.0933554\ttotal: 8.95s\tremaining: 14.8s\n",
      "376:\tlearn: 0.0932283\ttotal: 8.97s\tremaining: 14.8s\n",
      "377:\tlearn: 0.0930283\ttotal: 8.99s\tremaining: 14.8s\n",
      "378:\tlearn: 0.0929146\ttotal: 9.02s\tremaining: 14.8s\n",
      "379:\tlearn: 0.0928064\ttotal: 9.04s\tremaining: 14.7s\n",
      "380:\tlearn: 0.0926335\ttotal: 9.06s\tremaining: 14.7s\n",
      "381:\tlearn: 0.0924009\ttotal: 9.09s\tremaining: 14.7s\n",
      "382:\tlearn: 0.0921965\ttotal: 9.11s\tremaining: 14.7s\n",
      "383:\tlearn: 0.0920146\ttotal: 9.13s\tremaining: 14.7s\n",
      "384:\tlearn: 0.0918302\ttotal: 9.16s\tremaining: 14.6s\n",
      "385:\tlearn: 0.0915894\ttotal: 9.18s\tremaining: 14.6s\n",
      "386:\tlearn: 0.0913816\ttotal: 9.21s\tremaining: 14.6s\n",
      "387:\tlearn: 0.0912633\ttotal: 9.22s\tremaining: 14.6s\n",
      "388:\tlearn: 0.0912122\ttotal: 9.24s\tremaining: 14.5s\n",
      "389:\tlearn: 0.0910621\ttotal: 9.26s\tremaining: 14.5s\n",
      "390:\tlearn: 0.0909166\ttotal: 9.28s\tremaining: 14.5s\n",
      "391:\tlearn: 0.0908419\ttotal: 9.3s\tremaining: 14.4s\n",
      "392:\tlearn: 0.0905111\ttotal: 9.33s\tremaining: 14.4s\n",
      "393:\tlearn: 0.0903955\ttotal: 9.34s\tremaining: 14.4s\n",
      "394:\tlearn: 0.0901290\ttotal: 9.36s\tremaining: 14.3s\n",
      "395:\tlearn: 0.0899366\ttotal: 9.38s\tremaining: 14.3s\n",
      "396:\tlearn: 0.0897320\ttotal: 9.41s\tremaining: 14.3s\n",
      "397:\tlearn: 0.0895855\ttotal: 9.43s\tremaining: 14.3s\n",
      "398:\tlearn: 0.0893542\ttotal: 9.45s\tremaining: 14.2s\n",
      "399:\tlearn: 0.0891912\ttotal: 9.47s\tremaining: 14.2s\n",
      "400:\tlearn: 0.0890922\ttotal: 9.49s\tremaining: 14.2s\n",
      "401:\tlearn: 0.0889010\ttotal: 9.52s\tremaining: 14.2s\n",
      "402:\tlearn: 0.0887229\ttotal: 9.55s\tremaining: 14.2s\n",
      "403:\tlearn: 0.0885561\ttotal: 9.57s\tremaining: 14.1s\n",
      "404:\tlearn: 0.0883308\ttotal: 9.6s\tremaining: 14.1s\n",
      "405:\tlearn: 0.0881761\ttotal: 9.62s\tremaining: 14.1s\n",
      "406:\tlearn: 0.0878912\ttotal: 9.64s\tremaining: 14s\n",
      "407:\tlearn: 0.0876506\ttotal: 9.66s\tremaining: 14s\n",
      "408:\tlearn: 0.0874431\ttotal: 9.68s\tremaining: 14s\n",
      "409:\tlearn: 0.0873249\ttotal: 9.7s\tremaining: 14s\n",
      "410:\tlearn: 0.0871048\ttotal: 9.72s\tremaining: 13.9s\n",
      "411:\tlearn: 0.0868100\ttotal: 9.75s\tremaining: 13.9s\n",
      "412:\tlearn: 0.0866526\ttotal: 9.77s\tremaining: 13.9s\n",
      "413:\tlearn: 0.0864147\ttotal: 9.8s\tremaining: 13.9s\n",
      "414:\tlearn: 0.0862073\ttotal: 9.82s\tremaining: 13.8s\n",
      "415:\tlearn: 0.0858798\ttotal: 9.84s\tremaining: 13.8s\n",
      "416:\tlearn: 0.0856549\ttotal: 9.87s\tremaining: 13.8s\n",
      "417:\tlearn: 0.0855468\ttotal: 9.89s\tremaining: 13.8s\n",
      "418:\tlearn: 0.0854290\ttotal: 9.91s\tremaining: 13.7s\n",
      "419:\tlearn: 0.0852653\ttotal: 9.93s\tremaining: 13.7s\n",
      "420:\tlearn: 0.0850283\ttotal: 9.95s\tremaining: 13.7s\n",
      "421:\tlearn: 0.0848014\ttotal: 9.98s\tremaining: 13.7s\n",
      "422:\tlearn: 0.0847798\ttotal: 9.99s\tremaining: 13.6s\n",
      "423:\tlearn: 0.0845639\ttotal: 10s\tremaining: 13.6s\n",
      "424:\tlearn: 0.0842489\ttotal: 10s\tremaining: 13.6s\n",
      "425:\tlearn: 0.0841466\ttotal: 10.1s\tremaining: 13.6s\n",
      "426:\tlearn: 0.0839698\ttotal: 10.1s\tremaining: 13.6s\n",
      "427:\tlearn: 0.0838036\ttotal: 10.1s\tremaining: 13.5s\n",
      "428:\tlearn: 0.0836412\ttotal: 10.1s\tremaining: 13.5s\n",
      "429:\tlearn: 0.0834447\ttotal: 10.2s\tremaining: 13.5s\n",
      "430:\tlearn: 0.0832560\ttotal: 10.2s\tremaining: 13.5s\n",
      "431:\tlearn: 0.0831055\ttotal: 10.2s\tremaining: 13.4s\n",
      "432:\tlearn: 0.0829922\ttotal: 10.2s\tremaining: 13.4s\n",
      "433:\tlearn: 0.0829689\ttotal: 10.3s\tremaining: 13.4s\n",
      "434:\tlearn: 0.0828095\ttotal: 10.3s\tremaining: 13.4s\n",
      "435:\tlearn: 0.0826372\ttotal: 10.3s\tremaining: 13.3s\n",
      "436:\tlearn: 0.0824843\ttotal: 10.3s\tremaining: 13.3s\n",
      "437:\tlearn: 0.0823486\ttotal: 10.3s\tremaining: 13.3s\n",
      "438:\tlearn: 0.0822192\ttotal: 10.4s\tremaining: 13.2s\n",
      "439:\tlearn: 0.0819938\ttotal: 10.4s\tremaining: 13.2s\n",
      "440:\tlearn: 0.0818536\ttotal: 10.4s\tremaining: 13.2s\n",
      "441:\tlearn: 0.0816911\ttotal: 10.4s\tremaining: 13.2s\n",
      "442:\tlearn: 0.0815569\ttotal: 10.4s\tremaining: 13.1s\n",
      "443:\tlearn: 0.0814254\ttotal: 10.5s\tremaining: 13.1s\n",
      "444:\tlearn: 0.0812721\ttotal: 10.5s\tremaining: 13.1s\n",
      "445:\tlearn: 0.0811094\ttotal: 10.5s\tremaining: 13.1s\n",
      "446:\tlearn: 0.0810212\ttotal: 10.5s\tremaining: 13s\n",
      "447:\tlearn: 0.0807763\ttotal: 10.6s\tremaining: 13s\n",
      "448:\tlearn: 0.0805169\ttotal: 10.6s\tremaining: 13s\n",
      "449:\tlearn: 0.0803862\ttotal: 10.6s\tremaining: 13s\n",
      "450:\tlearn: 0.0801887\ttotal: 10.6s\tremaining: 12.9s\n",
      "451:\tlearn: 0.0800313\ttotal: 10.6s\tremaining: 12.9s\n",
      "452:\tlearn: 0.0798653\ttotal: 10.7s\tremaining: 12.9s\n",
      "453:\tlearn: 0.0796688\ttotal: 10.7s\tremaining: 12.9s\n",
      "454:\tlearn: 0.0795023\ttotal: 10.7s\tremaining: 12.8s\n",
      "455:\tlearn: 0.0792591\ttotal: 10.7s\tremaining: 12.8s\n",
      "456:\tlearn: 0.0791126\ttotal: 10.8s\tremaining: 12.8s\n",
      "457:\tlearn: 0.0789923\ttotal: 10.8s\tremaining: 12.8s\n",
      "458:\tlearn: 0.0787807\ttotal: 10.8s\tremaining: 12.8s\n",
      "459:\tlearn: 0.0786596\ttotal: 10.8s\tremaining: 12.7s\n",
      "460:\tlearn: 0.0784879\ttotal: 10.9s\tremaining: 12.7s\n",
      "461:\tlearn: 0.0783644\ttotal: 10.9s\tremaining: 12.7s\n",
      "462:\tlearn: 0.0781472\ttotal: 10.9s\tremaining: 12.7s\n",
      "463:\tlearn: 0.0780101\ttotal: 10.9s\tremaining: 12.6s\n",
      "464:\tlearn: 0.0778954\ttotal: 10.9s\tremaining: 12.6s\n",
      "465:\tlearn: 0.0776831\ttotal: 11s\tremaining: 12.6s\n",
      "466:\tlearn: 0.0775397\ttotal: 11s\tremaining: 12.5s\n",
      "467:\tlearn: 0.0773280\ttotal: 11s\tremaining: 12.5s\n",
      "468:\tlearn: 0.0771456\ttotal: 11s\tremaining: 12.5s\n",
      "469:\tlearn: 0.0769361\ttotal: 11.1s\tremaining: 12.5s\n",
      "470:\tlearn: 0.0767860\ttotal: 11.1s\tremaining: 12.4s\n",
      "471:\tlearn: 0.0767633\ttotal: 11.1s\tremaining: 12.4s\n",
      "472:\tlearn: 0.0766224\ttotal: 11.1s\tremaining: 12.4s\n",
      "473:\tlearn: 0.0764574\ttotal: 11.2s\tremaining: 12.4s\n",
      "474:\tlearn: 0.0763614\ttotal: 11.2s\tremaining: 12.4s\n",
      "475:\tlearn: 0.0763449\ttotal: 11.2s\tremaining: 12.3s\n",
      "476:\tlearn: 0.0762715\ttotal: 11.2s\tremaining: 12.3s\n",
      "477:\tlearn: 0.0761460\ttotal: 11.2s\tremaining: 12.3s\n",
      "478:\tlearn: 0.0759998\ttotal: 11.3s\tremaining: 12.3s\n",
      "479:\tlearn: 0.0757887\ttotal: 11.3s\tremaining: 12.2s\n",
      "480:\tlearn: 0.0756403\ttotal: 11.3s\tremaining: 12.2s\n",
      "481:\tlearn: 0.0754399\ttotal: 11.3s\tremaining: 12.2s\n",
      "482:\tlearn: 0.0753312\ttotal: 11.3s\tremaining: 12.2s\n",
      "483:\tlearn: 0.0751477\ttotal: 11.4s\tremaining: 12.1s\n",
      "484:\tlearn: 0.0751177\ttotal: 11.4s\tremaining: 12.1s\n",
      "485:\tlearn: 0.0749498\ttotal: 11.4s\tremaining: 12.1s\n",
      "486:\tlearn: 0.0747690\ttotal: 11.4s\tremaining: 12s\n",
      "487:\tlearn: 0.0746495\ttotal: 11.5s\tremaining: 12s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "488:\tlearn: 0.0744437\ttotal: 11.5s\tremaining: 12s\n",
      "489:\tlearn: 0.0742331\ttotal: 11.5s\tremaining: 12s\n",
      "490:\tlearn: 0.0741108\ttotal: 11.5s\tremaining: 11.9s\n",
      "491:\tlearn: 0.0739823\ttotal: 11.5s\tremaining: 11.9s\n",
      "492:\tlearn: 0.0737846\ttotal: 11.6s\tremaining: 11.9s\n",
      "493:\tlearn: 0.0737738\ttotal: 11.6s\tremaining: 11.9s\n",
      "494:\tlearn: 0.0736770\ttotal: 11.6s\tremaining: 11.8s\n",
      "495:\tlearn: 0.0735525\ttotal: 11.6s\tremaining: 11.8s\n",
      "496:\tlearn: 0.0734534\ttotal: 11.7s\tremaining: 11.8s\n",
      "497:\tlearn: 0.0732863\ttotal: 11.7s\tremaining: 11.8s\n",
      "498:\tlearn: 0.0731695\ttotal: 11.7s\tremaining: 11.8s\n",
      "499:\tlearn: 0.0729750\ttotal: 11.7s\tremaining: 11.7s\n",
      "500:\tlearn: 0.0728713\ttotal: 11.8s\tremaining: 11.7s\n",
      "501:\tlearn: 0.0728389\ttotal: 11.8s\tremaining: 11.7s\n",
      "502:\tlearn: 0.0726864\ttotal: 11.8s\tremaining: 11.6s\n",
      "503:\tlearn: 0.0725758\ttotal: 11.8s\tremaining: 11.6s\n",
      "504:\tlearn: 0.0723610\ttotal: 11.8s\tremaining: 11.6s\n",
      "505:\tlearn: 0.0722327\ttotal: 11.8s\tremaining: 11.6s\n",
      "506:\tlearn: 0.0721231\ttotal: 11.9s\tremaining: 11.5s\n",
      "507:\tlearn: 0.0719992\ttotal: 11.9s\tremaining: 11.5s\n",
      "508:\tlearn: 0.0718176\ttotal: 11.9s\tremaining: 11.5s\n",
      "509:\tlearn: 0.0716629\ttotal: 11.9s\tremaining: 11.5s\n",
      "510:\tlearn: 0.0715578\ttotal: 12s\tremaining: 11.4s\n",
      "511:\tlearn: 0.0714311\ttotal: 12s\tremaining: 11.4s\n",
      "512:\tlearn: 0.0712650\ttotal: 12s\tremaining: 11.4s\n",
      "513:\tlearn: 0.0712016\ttotal: 12s\tremaining: 11.4s\n",
      "514:\tlearn: 0.0711343\ttotal: 12s\tremaining: 11.3s\n",
      "515:\tlearn: 0.0710213\ttotal: 12.1s\tremaining: 11.3s\n",
      "516:\tlearn: 0.0708949\ttotal: 12.1s\tremaining: 11.3s\n",
      "517:\tlearn: 0.0708492\ttotal: 12.1s\tremaining: 11.3s\n",
      "518:\tlearn: 0.0708372\ttotal: 12.1s\tremaining: 11.3s\n",
      "519:\tlearn: 0.0707298\ttotal: 12.2s\tremaining: 11.2s\n",
      "520:\tlearn: 0.0705234\ttotal: 12.2s\tremaining: 11.2s\n",
      "521:\tlearn: 0.0704919\ttotal: 12.2s\tremaining: 11.2s\n",
      "522:\tlearn: 0.0703835\ttotal: 12.2s\tremaining: 11.2s\n",
      "523:\tlearn: 0.0702701\ttotal: 12.3s\tremaining: 11.1s\n",
      "524:\tlearn: 0.0700650\ttotal: 12.3s\tremaining: 11.1s\n",
      "525:\tlearn: 0.0698776\ttotal: 12.3s\tremaining: 11.1s\n",
      "526:\tlearn: 0.0697361\ttotal: 12.3s\tremaining: 11.1s\n",
      "527:\tlearn: 0.0697112\ttotal: 12.3s\tremaining: 11s\n",
      "528:\tlearn: 0.0695825\ttotal: 12.4s\tremaining: 11s\n",
      "529:\tlearn: 0.0695445\ttotal: 12.4s\tremaining: 11s\n",
      "530:\tlearn: 0.0693748\ttotal: 12.4s\tremaining: 10.9s\n",
      "531:\tlearn: 0.0692421\ttotal: 12.4s\tremaining: 10.9s\n",
      "532:\tlearn: 0.0690850\ttotal: 12.4s\tremaining: 10.9s\n",
      "533:\tlearn: 0.0688631\ttotal: 12.5s\tremaining: 10.9s\n",
      "534:\tlearn: 0.0687727\ttotal: 12.5s\tremaining: 10.8s\n",
      "535:\tlearn: 0.0686423\ttotal: 12.5s\tremaining: 10.8s\n",
      "536:\tlearn: 0.0686316\ttotal: 12.5s\tremaining: 10.8s\n",
      "537:\tlearn: 0.0685859\ttotal: 12.5s\tremaining: 10.8s\n",
      "538:\tlearn: 0.0684621\ttotal: 12.6s\tremaining: 10.8s\n",
      "539:\tlearn: 0.0683396\ttotal: 12.6s\tremaining: 10.7s\n",
      "540:\tlearn: 0.0683221\ttotal: 12.6s\tremaining: 10.7s\n",
      "541:\tlearn: 0.0682954\ttotal: 12.6s\tremaining: 10.7s\n",
      "542:\tlearn: 0.0681800\ttotal: 12.7s\tremaining: 10.7s\n",
      "543:\tlearn: 0.0680578\ttotal: 12.7s\tremaining: 10.6s\n",
      "544:\tlearn: 0.0679572\ttotal: 12.7s\tremaining: 10.6s\n",
      "545:\tlearn: 0.0677857\ttotal: 12.7s\tremaining: 10.6s\n",
      "546:\tlearn: 0.0676370\ttotal: 12.8s\tremaining: 10.6s\n",
      "547:\tlearn: 0.0674053\ttotal: 12.8s\tremaining: 10.5s\n",
      "548:\tlearn: 0.0672378\ttotal: 12.8s\tremaining: 10.5s\n",
      "549:\tlearn: 0.0670608\ttotal: 12.8s\tremaining: 10.5s\n",
      "550:\tlearn: 0.0670482\ttotal: 12.8s\tremaining: 10.5s\n",
      "551:\tlearn: 0.0669005\ttotal: 12.9s\tremaining: 10.4s\n",
      "552:\tlearn: 0.0668238\ttotal: 12.9s\tremaining: 10.4s\n",
      "553:\tlearn: 0.0666765\ttotal: 12.9s\tremaining: 10.4s\n",
      "554:\tlearn: 0.0665253\ttotal: 12.9s\tremaining: 10.4s\n",
      "555:\tlearn: 0.0665134\ttotal: 13s\tremaining: 10.3s\n",
      "556:\tlearn: 0.0664036\ttotal: 13s\tremaining: 10.3s\n",
      "557:\tlearn: 0.0662068\ttotal: 13s\tremaining: 10.3s\n",
      "558:\tlearn: 0.0660655\ttotal: 13s\tremaining: 10.3s\n",
      "559:\tlearn: 0.0660547\ttotal: 13s\tremaining: 10.2s\n",
      "560:\tlearn: 0.0659000\ttotal: 13.1s\tremaining: 10.2s\n",
      "561:\tlearn: 0.0657677\ttotal: 13.1s\tremaining: 10.2s\n",
      "562:\tlearn: 0.0657600\ttotal: 13.1s\tremaining: 10.2s\n",
      "563:\tlearn: 0.0657517\ttotal: 13.1s\tremaining: 10.1s\n",
      "564:\tlearn: 0.0656075\ttotal: 13.1s\tremaining: 10.1s\n",
      "565:\tlearn: 0.0654731\ttotal: 13.2s\tremaining: 10.1s\n",
      "566:\tlearn: 0.0653652\ttotal: 13.2s\tremaining: 10.1s\n",
      "567:\tlearn: 0.0653570\ttotal: 13.2s\tremaining: 10s\n",
      "568:\tlearn: 0.0651047\ttotal: 13.2s\tremaining: 10s\n",
      "569:\tlearn: 0.0648786\ttotal: 13.3s\tremaining: 10s\n",
      "570:\tlearn: 0.0647947\ttotal: 13.3s\tremaining: 9.97s\n",
      "571:\tlearn: 0.0646980\ttotal: 13.3s\tremaining: 9.95s\n",
      "572:\tlearn: 0.0645462\ttotal: 13.3s\tremaining: 9.93s\n",
      "573:\tlearn: 0.0644555\ttotal: 13.3s\tremaining: 9.9s\n",
      "574:\tlearn: 0.0643321\ttotal: 13.4s\tremaining: 9.88s\n",
      "575:\tlearn: 0.0641501\ttotal: 13.4s\tremaining: 9.85s\n",
      "576:\tlearn: 0.0640043\ttotal: 13.4s\tremaining: 9.83s\n",
      "577:\tlearn: 0.0639863\ttotal: 13.4s\tremaining: 9.81s\n",
      "578:\tlearn: 0.0638857\ttotal: 13.5s\tremaining: 9.78s\n",
      "579:\tlearn: 0.0638779\ttotal: 13.5s\tremaining: 9.76s\n",
      "580:\tlearn: 0.0637825\ttotal: 13.5s\tremaining: 9.73s\n",
      "581:\tlearn: 0.0637680\ttotal: 13.5s\tremaining: 9.7s\n",
      "582:\tlearn: 0.0636115\ttotal: 13.5s\tremaining: 9.69s\n",
      "583:\tlearn: 0.0635919\ttotal: 13.6s\tremaining: 9.66s\n",
      "584:\tlearn: 0.0634465\ttotal: 13.6s\tremaining: 9.63s\n",
      "585:\tlearn: 0.0632917\ttotal: 13.6s\tremaining: 9.61s\n",
      "586:\tlearn: 0.0632751\ttotal: 13.6s\tremaining: 9.58s\n",
      "587:\tlearn: 0.0631867\ttotal: 13.6s\tremaining: 9.56s\n",
      "588:\tlearn: 0.0630352\ttotal: 13.7s\tremaining: 9.54s\n",
      "589:\tlearn: 0.0628573\ttotal: 13.7s\tremaining: 9.51s\n",
      "590:\tlearn: 0.0627168\ttotal: 13.7s\tremaining: 9.49s\n",
      "591:\tlearn: 0.0625706\ttotal: 13.7s\tremaining: 9.46s\n",
      "592:\tlearn: 0.0624564\ttotal: 13.8s\tremaining: 9.44s\n",
      "593:\tlearn: 0.0623184\ttotal: 13.8s\tremaining: 9.42s\n",
      "594:\tlearn: 0.0623112\ttotal: 13.8s\tremaining: 9.39s\n",
      "595:\tlearn: 0.0621227\ttotal: 13.8s\tremaining: 9.38s\n",
      "596:\tlearn: 0.0620412\ttotal: 13.9s\tremaining: 9.36s\n",
      "597:\tlearn: 0.0619427\ttotal: 13.9s\tremaining: 9.34s\n",
      "598:\tlearn: 0.0618316\ttotal: 13.9s\tremaining: 9.31s\n",
      "599:\tlearn: 0.0615894\ttotal: 13.9s\tremaining: 9.29s\n",
      "600:\tlearn: 0.0615385\ttotal: 14s\tremaining: 9.26s\n",
      "601:\tlearn: 0.0615315\ttotal: 14s\tremaining: 9.24s\n",
      "602:\tlearn: 0.0613995\ttotal: 14s\tremaining: 9.21s\n",
      "603:\tlearn: 0.0612259\ttotal: 14s\tremaining: 9.19s\n",
      "604:\tlearn: 0.0611127\ttotal: 14s\tremaining: 9.17s\n",
      "605:\tlearn: 0.0609801\ttotal: 14.1s\tremaining: 9.14s\n",
      "606:\tlearn: 0.0608769\ttotal: 14.1s\tremaining: 9.12s\n",
      "607:\tlearn: 0.0607392\ttotal: 14.1s\tremaining: 9.09s\n",
      "608:\tlearn: 0.0607323\ttotal: 14.1s\tremaining: 9.07s\n",
      "609:\tlearn: 0.0607073\ttotal: 14.2s\tremaining: 9.05s\n",
      "610:\tlearn: 0.0605817\ttotal: 14.2s\tremaining: 9.03s\n",
      "611:\tlearn: 0.0605751\ttotal: 14.2s\tremaining: 9s\n",
      "612:\tlearn: 0.0604754\ttotal: 14.2s\tremaining: 8.98s\n",
      "613:\tlearn: 0.0604645\ttotal: 14.2s\tremaining: 8.95s\n",
      "614:\tlearn: 0.0604579\ttotal: 14.3s\tremaining: 8.93s\n",
      "615:\tlearn: 0.0603533\ttotal: 14.3s\tremaining: 8.9s\n",
      "616:\tlearn: 0.0602558\ttotal: 14.3s\tremaining: 8.88s\n",
      "617:\tlearn: 0.0601616\ttotal: 14.3s\tremaining: 8.86s\n",
      "618:\tlearn: 0.0601429\ttotal: 14.3s\tremaining: 8.83s\n",
      "619:\tlearn: 0.0600705\ttotal: 14.4s\tremaining: 8.81s\n",
      "620:\tlearn: 0.0599664\ttotal: 14.4s\tremaining: 8.78s\n",
      "621:\tlearn: 0.0598463\ttotal: 14.4s\tremaining: 8.76s\n",
      "622:\tlearn: 0.0597484\ttotal: 14.4s\tremaining: 8.73s\n",
      "623:\tlearn: 0.0596128\ttotal: 14.5s\tremaining: 8.71s\n",
      "624:\tlearn: 0.0595692\ttotal: 14.5s\tremaining: 8.68s\n",
      "625:\tlearn: 0.0594728\ttotal: 14.5s\tremaining: 8.66s\n",
      "626:\tlearn: 0.0593652\ttotal: 14.5s\tremaining: 8.63s\n",
      "627:\tlearn: 0.0591829\ttotal: 14.5s\tremaining: 8.61s\n",
      "628:\tlearn: 0.0590668\ttotal: 14.6s\tremaining: 8.58s\n",
      "629:\tlearn: 0.0589584\ttotal: 14.6s\tremaining: 8.56s\n",
      "630:\tlearn: 0.0588605\ttotal: 14.6s\tremaining: 8.54s\n",
      "631:\tlearn: 0.0587344\ttotal: 14.6s\tremaining: 8.51s\n",
      "632:\tlearn: 0.0586359\ttotal: 14.6s\tremaining: 8.49s\n",
      "633:\tlearn: 0.0586105\ttotal: 14.7s\tremaining: 8.46s\n",
      "634:\tlearn: 0.0584847\ttotal: 14.7s\tremaining: 8.45s\n",
      "635:\tlearn: 0.0584736\ttotal: 14.7s\tremaining: 8.42s\n",
      "636:\tlearn: 0.0583825\ttotal: 14.7s\tremaining: 8.4s\n",
      "637:\tlearn: 0.0583029\ttotal: 14.8s\tremaining: 8.38s\n",
      "638:\tlearn: 0.0582403\ttotal: 14.8s\tremaining: 8.35s\n",
      "639:\tlearn: 0.0581201\ttotal: 14.8s\tremaining: 8.33s\n",
      "640:\tlearn: 0.0580393\ttotal: 14.8s\tremaining: 8.3s\n",
      "641:\tlearn: 0.0579161\ttotal: 14.8s\tremaining: 8.28s\n",
      "642:\tlearn: 0.0578433\ttotal: 14.9s\tremaining: 8.25s\n",
      "643:\tlearn: 0.0578173\ttotal: 14.9s\tremaining: 8.23s\n",
      "644:\tlearn: 0.0576884\ttotal: 14.9s\tremaining: 8.2s\n",
      "645:\tlearn: 0.0576756\ttotal: 14.9s\tremaining: 8.18s\n",
      "646:\tlearn: 0.0574957\ttotal: 14.9s\tremaining: 8.16s\n",
      "647:\tlearn: 0.0574840\ttotal: 15s\tremaining: 8.13s\n",
      "648:\tlearn: 0.0574709\ttotal: 15s\tremaining: 8.11s\n",
      "649:\tlearn: 0.0573400\ttotal: 15s\tremaining: 8.09s\n",
      "650:\tlearn: 0.0572510\ttotal: 15.1s\tremaining: 8.07s\n",
      "651:\tlearn: 0.0571479\ttotal: 15.1s\tremaining: 8.04s\n",
      "652:\tlearn: 0.0571381\ttotal: 15.1s\tremaining: 8.02s\n",
      "653:\tlearn: 0.0570040\ttotal: 15.1s\tremaining: 8s\n",
      "654:\tlearn: 0.0569177\ttotal: 15.1s\tremaining: 7.97s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "655:\tlearn: 0.0568734\ttotal: 15.2s\tremaining: 7.95s\n",
      "656:\tlearn: 0.0568037\ttotal: 15.2s\tremaining: 7.93s\n",
      "657:\tlearn: 0.0567043\ttotal: 15.2s\tremaining: 7.91s\n",
      "658:\tlearn: 0.0565850\ttotal: 15.2s\tremaining: 7.88s\n",
      "659:\tlearn: 0.0565790\ttotal: 15.3s\tremaining: 7.86s\n",
      "660:\tlearn: 0.0564483\ttotal: 15.3s\tremaining: 7.83s\n",
      "661:\tlearn: 0.0563428\ttotal: 15.3s\tremaining: 7.81s\n",
      "662:\tlearn: 0.0562396\ttotal: 15.3s\tremaining: 7.79s\n",
      "663:\tlearn: 0.0561313\ttotal: 15.3s\tremaining: 7.76s\n",
      "664:\tlearn: 0.0560465\ttotal: 15.4s\tremaining: 7.74s\n",
      "665:\tlearn: 0.0559411\ttotal: 15.4s\tremaining: 7.72s\n",
      "666:\tlearn: 0.0558250\ttotal: 15.4s\tremaining: 7.7s\n",
      "667:\tlearn: 0.0558192\ttotal: 15.4s\tremaining: 7.67s\n",
      "668:\tlearn: 0.0557161\ttotal: 15.5s\tremaining: 7.65s\n",
      "669:\tlearn: 0.0556496\ttotal: 15.5s\tremaining: 7.63s\n",
      "670:\tlearn: 0.0556368\ttotal: 15.5s\tremaining: 7.6s\n",
      "671:\tlearn: 0.0555534\ttotal: 15.5s\tremaining: 7.58s\n",
      "672:\tlearn: 0.0554498\ttotal: 15.6s\tremaining: 7.56s\n",
      "673:\tlearn: 0.0553259\ttotal: 15.6s\tremaining: 7.53s\n",
      "674:\tlearn: 0.0553203\ttotal: 15.6s\tremaining: 7.51s\n",
      "675:\tlearn: 0.0553147\ttotal: 15.6s\tremaining: 7.49s\n",
      "676:\tlearn: 0.0553082\ttotal: 15.6s\tremaining: 7.46s\n",
      "677:\tlearn: 0.0551995\ttotal: 15.7s\tremaining: 7.44s\n",
      "678:\tlearn: 0.0550921\ttotal: 15.7s\tremaining: 7.41s\n",
      "679:\tlearn: 0.0549707\ttotal: 15.7s\tremaining: 7.39s\n",
      "680:\tlearn: 0.0548975\ttotal: 15.7s\tremaining: 7.37s\n",
      "681:\tlearn: 0.0548899\ttotal: 15.8s\tremaining: 7.35s\n",
      "682:\tlearn: 0.0548641\ttotal: 15.8s\tremaining: 7.32s\n",
      "683:\tlearn: 0.0547678\ttotal: 15.8s\tremaining: 7.3s\n",
      "684:\tlearn: 0.0546415\ttotal: 15.8s\tremaining: 7.27s\n",
      "685:\tlearn: 0.0545023\ttotal: 15.8s\tremaining: 7.25s\n",
      "686:\tlearn: 0.0544345\ttotal: 15.9s\tremaining: 7.23s\n",
      "687:\tlearn: 0.0544127\ttotal: 15.9s\tremaining: 7.2s\n",
      "688:\tlearn: 0.0542809\ttotal: 15.9s\tremaining: 7.18s\n",
      "689:\tlearn: 0.0542565\ttotal: 15.9s\tremaining: 7.15s\n",
      "690:\tlearn: 0.0542512\ttotal: 15.9s\tremaining: 7.13s\n",
      "691:\tlearn: 0.0541690\ttotal: 16s\tremaining: 7.11s\n",
      "692:\tlearn: 0.0540950\ttotal: 16s\tremaining: 7.08s\n",
      "693:\tlearn: 0.0540707\ttotal: 16s\tremaining: 7.06s\n",
      "694:\tlearn: 0.0539668\ttotal: 16s\tremaining: 7.03s\n",
      "695:\tlearn: 0.0538604\ttotal: 16.1s\tremaining: 7.01s\n",
      "696:\tlearn: 0.0538552\ttotal: 16.1s\tremaining: 6.99s\n",
      "697:\tlearn: 0.0537677\ttotal: 16.1s\tremaining: 6.96s\n",
      "698:\tlearn: 0.0536578\ttotal: 16.1s\tremaining: 6.94s\n",
      "699:\tlearn: 0.0536094\ttotal: 16.1s\tremaining: 6.91s\n",
      "700:\tlearn: 0.0536042\ttotal: 16.2s\tremaining: 6.89s\n",
      "701:\tlearn: 0.0535228\ttotal: 16.2s\tremaining: 6.86s\n",
      "702:\tlearn: 0.0534527\ttotal: 16.2s\tremaining: 6.84s\n",
      "703:\tlearn: 0.0533750\ttotal: 16.2s\tremaining: 6.82s\n",
      "704:\tlearn: 0.0532499\ttotal: 16.2s\tremaining: 6.79s\n",
      "705:\tlearn: 0.0532100\ttotal: 16.3s\tremaining: 6.78s\n",
      "706:\tlearn: 0.0531138\ttotal: 16.3s\tremaining: 6.75s\n",
      "707:\tlearn: 0.0529708\ttotal: 16.3s\tremaining: 6.73s\n",
      "708:\tlearn: 0.0528770\ttotal: 16.3s\tremaining: 6.7s\n",
      "709:\tlearn: 0.0527947\ttotal: 16.4s\tremaining: 6.68s\n",
      "710:\tlearn: 0.0527365\ttotal: 16.4s\tremaining: 6.66s\n",
      "711:\tlearn: 0.0527302\ttotal: 16.4s\tremaining: 6.63s\n",
      "712:\tlearn: 0.0526329\ttotal: 16.4s\tremaining: 6.61s\n",
      "713:\tlearn: 0.0525024\ttotal: 16.4s\tremaining: 6.59s\n",
      "714:\tlearn: 0.0524148\ttotal: 16.5s\tremaining: 6.56s\n",
      "715:\tlearn: 0.0523546\ttotal: 16.5s\tremaining: 6.54s\n",
      "716:\tlearn: 0.0522901\ttotal: 16.5s\tremaining: 6.52s\n",
      "717:\tlearn: 0.0521889\ttotal: 16.5s\tremaining: 6.5s\n",
      "718:\tlearn: 0.0521279\ttotal: 16.6s\tremaining: 6.47s\n",
      "719:\tlearn: 0.0520357\ttotal: 16.6s\tremaining: 6.45s\n",
      "720:\tlearn: 0.0519755\ttotal: 16.6s\tremaining: 6.42s\n",
      "721:\tlearn: 0.0519706\ttotal: 16.6s\tremaining: 6.4s\n",
      "722:\tlearn: 0.0518812\ttotal: 16.6s\tremaining: 6.37s\n",
      "723:\tlearn: 0.0517739\ttotal: 16.7s\tremaining: 6.35s\n",
      "724:\tlearn: 0.0516640\ttotal: 16.7s\tremaining: 6.32s\n",
      "725:\tlearn: 0.0515667\ttotal: 16.7s\tremaining: 6.3s\n",
      "726:\tlearn: 0.0515121\ttotal: 16.7s\tremaining: 6.28s\n",
      "727:\tlearn: 0.0513927\ttotal: 16.7s\tremaining: 6.25s\n",
      "728:\tlearn: 0.0513045\ttotal: 16.8s\tremaining: 6.23s\n",
      "729:\tlearn: 0.0512920\ttotal: 16.8s\tremaining: 6.21s\n",
      "730:\tlearn: 0.0512161\ttotal: 16.8s\tremaining: 6.18s\n",
      "731:\tlearn: 0.0512113\ttotal: 16.8s\tremaining: 6.16s\n",
      "732:\tlearn: 0.0510979\ttotal: 16.8s\tremaining: 6.13s\n",
      "733:\tlearn: 0.0510698\ttotal: 16.9s\tremaining: 6.11s\n",
      "734:\tlearn: 0.0509811\ttotal: 16.9s\tremaining: 6.09s\n",
      "735:\tlearn: 0.0509689\ttotal: 16.9s\tremaining: 6.07s\n",
      "736:\tlearn: 0.0508508\ttotal: 16.9s\tremaining: 6.04s\n",
      "737:\tlearn: 0.0507333\ttotal: 17s\tremaining: 6.02s\n",
      "738:\tlearn: 0.0506412\ttotal: 17s\tremaining: 6s\n",
      "739:\tlearn: 0.0505583\ttotal: 17s\tremaining: 5.97s\n",
      "740:\tlearn: 0.0505536\ttotal: 17s\tremaining: 5.95s\n",
      "741:\tlearn: 0.0504807\ttotal: 17s\tremaining: 5.93s\n",
      "742:\tlearn: 0.0504594\ttotal: 17.1s\tremaining: 5.9s\n",
      "743:\tlearn: 0.0504436\ttotal: 17.1s\tremaining: 5.88s\n",
      "744:\tlearn: 0.0503715\ttotal: 17.1s\tremaining: 5.85s\n",
      "745:\tlearn: 0.0502938\ttotal: 17.1s\tremaining: 5.83s\n",
      "746:\tlearn: 0.0501981\ttotal: 17.1s\tremaining: 5.81s\n",
      "747:\tlearn: 0.0501068\ttotal: 17.2s\tremaining: 5.79s\n",
      "748:\tlearn: 0.0500221\ttotal: 17.2s\tremaining: 5.76s\n",
      "749:\tlearn: 0.0499569\ttotal: 17.2s\tremaining: 5.74s\n",
      "750:\tlearn: 0.0499452\ttotal: 17.2s\tremaining: 5.71s\n",
      "751:\tlearn: 0.0499383\ttotal: 17.3s\tremaining: 5.69s\n",
      "752:\tlearn: 0.0498516\ttotal: 17.3s\tremaining: 5.67s\n",
      "753:\tlearn: 0.0498337\ttotal: 17.3s\tremaining: 5.64s\n",
      "754:\tlearn: 0.0497310\ttotal: 17.3s\tremaining: 5.62s\n",
      "755:\tlearn: 0.0496523\ttotal: 17.3s\tremaining: 5.59s\n",
      "756:\tlearn: 0.0496433\ttotal: 17.4s\tremaining: 5.57s\n",
      "757:\tlearn: 0.0496265\ttotal: 17.4s\tremaining: 5.55s\n",
      "758:\tlearn: 0.0495407\ttotal: 17.4s\tremaining: 5.53s\n",
      "759:\tlearn: 0.0494854\ttotal: 17.4s\tremaining: 5.51s\n",
      "760:\tlearn: 0.0494810\ttotal: 17.5s\tremaining: 5.48s\n",
      "761:\tlearn: 0.0494178\ttotal: 17.5s\tremaining: 5.46s\n",
      "762:\tlearn: 0.0493472\ttotal: 17.5s\tremaining: 5.43s\n",
      "763:\tlearn: 0.0493006\ttotal: 17.5s\tremaining: 5.41s\n",
      "764:\tlearn: 0.0492961\ttotal: 17.5s\tremaining: 5.39s\n",
      "765:\tlearn: 0.0492299\ttotal: 17.6s\tremaining: 5.36s\n",
      "766:\tlearn: 0.0491428\ttotal: 17.6s\tremaining: 5.34s\n",
      "767:\tlearn: 0.0491368\ttotal: 17.6s\tremaining: 5.32s\n",
      "768:\tlearn: 0.0490453\ttotal: 17.6s\tremaining: 5.29s\n",
      "769:\tlearn: 0.0490166\ttotal: 17.6s\tremaining: 5.27s\n",
      "770:\tlearn: 0.0489340\ttotal: 17.7s\tremaining: 5.25s\n",
      "771:\tlearn: 0.0488540\ttotal: 17.7s\tremaining: 5.22s\n",
      "772:\tlearn: 0.0487684\ttotal: 17.7s\tremaining: 5.2s\n",
      "773:\tlearn: 0.0487113\ttotal: 17.7s\tremaining: 5.17s\n",
      "774:\tlearn: 0.0487070\ttotal: 17.7s\tremaining: 5.15s\n",
      "775:\tlearn: 0.0486230\ttotal: 17.8s\tremaining: 5.13s\n",
      "776:\tlearn: 0.0485440\ttotal: 17.8s\tremaining: 5.1s\n",
      "777:\tlearn: 0.0484619\ttotal: 17.8s\tremaining: 5.08s\n",
      "778:\tlearn: 0.0483822\ttotal: 17.8s\tremaining: 5.06s\n",
      "779:\tlearn: 0.0482950\ttotal: 17.8s\tremaining: 5.03s\n",
      "780:\tlearn: 0.0482856\ttotal: 17.9s\tremaining: 5.01s\n",
      "781:\tlearn: 0.0482445\ttotal: 17.9s\tremaining: 4.99s\n",
      "782:\tlearn: 0.0481810\ttotal: 17.9s\tremaining: 4.96s\n",
      "783:\tlearn: 0.0481754\ttotal: 17.9s\tremaining: 4.94s\n",
      "784:\tlearn: 0.0480484\ttotal: 17.9s\tremaining: 4.91s\n",
      "785:\tlearn: 0.0479804\ttotal: 18s\tremaining: 4.89s\n",
      "786:\tlearn: 0.0479217\ttotal: 18s\tremaining: 4.86s\n",
      "787:\tlearn: 0.0478658\ttotal: 18s\tremaining: 4.84s\n",
      "788:\tlearn: 0.0477576\ttotal: 18s\tremaining: 4.82s\n",
      "789:\tlearn: 0.0476912\ttotal: 18s\tremaining: 4.79s\n",
      "790:\tlearn: 0.0476091\ttotal: 18.1s\tremaining: 4.77s\n",
      "791:\tlearn: 0.0475463\ttotal: 18.1s\tremaining: 4.75s\n",
      "792:\tlearn: 0.0474850\ttotal: 18.1s\tremaining: 4.72s\n",
      "793:\tlearn: 0.0474013\ttotal: 18.1s\tremaining: 4.7s\n",
      "794:\tlearn: 0.0473971\ttotal: 18.1s\tremaining: 4.68s\n",
      "795:\tlearn: 0.0472880\ttotal: 18.2s\tremaining: 4.65s\n",
      "796:\tlearn: 0.0472120\ttotal: 18.2s\tremaining: 4.63s\n",
      "797:\tlearn: 0.0471330\ttotal: 18.2s\tremaining: 4.61s\n",
      "798:\tlearn: 0.0470623\ttotal: 18.2s\tremaining: 4.58s\n",
      "799:\tlearn: 0.0469965\ttotal: 18.2s\tremaining: 4.56s\n",
      "800:\tlearn: 0.0469040\ttotal: 18.3s\tremaining: 4.54s\n",
      "801:\tlearn: 0.0468973\ttotal: 18.3s\tremaining: 4.51s\n",
      "802:\tlearn: 0.0468225\ttotal: 18.3s\tremaining: 4.49s\n",
      "803:\tlearn: 0.0468184\ttotal: 18.3s\tremaining: 4.47s\n",
      "804:\tlearn: 0.0467368\ttotal: 18.3s\tremaining: 4.44s\n",
      "805:\tlearn: 0.0466582\ttotal: 18.4s\tremaining: 4.42s\n",
      "806:\tlearn: 0.0466529\ttotal: 18.4s\tremaining: 4.4s\n",
      "807:\tlearn: 0.0465632\ttotal: 18.4s\tremaining: 4.37s\n",
      "808:\tlearn: 0.0464924\ttotal: 18.4s\tremaining: 4.35s\n",
      "809:\tlearn: 0.0464441\ttotal: 18.4s\tremaining: 4.33s\n",
      "810:\tlearn: 0.0463600\ttotal: 18.5s\tremaining: 4.3s\n",
      "811:\tlearn: 0.0463529\ttotal: 18.5s\tremaining: 4.28s\n",
      "812:\tlearn: 0.0463062\ttotal: 18.5s\tremaining: 4.26s\n",
      "813:\tlearn: 0.0462574\ttotal: 18.5s\tremaining: 4.24s\n",
      "814:\tlearn: 0.0462094\ttotal: 18.6s\tremaining: 4.21s\n",
      "815:\tlearn: 0.0461437\ttotal: 18.6s\tremaining: 4.19s\n",
      "816:\tlearn: 0.0460724\ttotal: 18.6s\tremaining: 4.17s\n",
      "817:\tlearn: 0.0460027\ttotal: 18.6s\tremaining: 4.14s\n",
      "818:\tlearn: 0.0459496\ttotal: 18.6s\tremaining: 4.12s\n",
      "819:\tlearn: 0.0458717\ttotal: 18.7s\tremaining: 4.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "820:\tlearn: 0.0457946\ttotal: 18.7s\tremaining: 4.08s\n",
      "821:\tlearn: 0.0457397\ttotal: 18.7s\tremaining: 4.05s\n",
      "822:\tlearn: 0.0457354\ttotal: 18.7s\tremaining: 4.03s\n",
      "823:\tlearn: 0.0457305\ttotal: 18.8s\tremaining: 4.01s\n",
      "824:\tlearn: 0.0457026\ttotal: 18.8s\tremaining: 3.99s\n",
      "825:\tlearn: 0.0456175\ttotal: 18.8s\tremaining: 3.97s\n",
      "826:\tlearn: 0.0455352\ttotal: 18.9s\tremaining: 3.94s\n",
      "827:\tlearn: 0.0454512\ttotal: 18.9s\tremaining: 3.92s\n",
      "828:\tlearn: 0.0454439\ttotal: 18.9s\tremaining: 3.9s\n",
      "829:\tlearn: 0.0453202\ttotal: 18.9s\tremaining: 3.88s\n",
      "830:\tlearn: 0.0452880\ttotal: 18.9s\tremaining: 3.85s\n",
      "831:\tlearn: 0.0451963\ttotal: 19s\tremaining: 3.83s\n",
      "832:\tlearn: 0.0451023\ttotal: 19s\tremaining: 3.81s\n",
      "833:\tlearn: 0.0450252\ttotal: 19s\tremaining: 3.78s\n",
      "834:\tlearn: 0.0449682\ttotal: 19s\tremaining: 3.76s\n",
      "835:\tlearn: 0.0449103\ttotal: 19.1s\tremaining: 3.74s\n",
      "836:\tlearn: 0.0448449\ttotal: 19.1s\tremaining: 3.72s\n",
      "837:\tlearn: 0.0447993\ttotal: 19.1s\tremaining: 3.69s\n",
      "838:\tlearn: 0.0446949\ttotal: 19.1s\tremaining: 3.67s\n",
      "839:\tlearn: 0.0446215\ttotal: 19.1s\tremaining: 3.65s\n",
      "840:\tlearn: 0.0445054\ttotal: 19.2s\tremaining: 3.62s\n",
      "841:\tlearn: 0.0444726\ttotal: 19.2s\tremaining: 3.6s\n",
      "842:\tlearn: 0.0444624\ttotal: 19.2s\tremaining: 3.58s\n",
      "843:\tlearn: 0.0443900\ttotal: 19.2s\tremaining: 3.55s\n",
      "844:\tlearn: 0.0443555\ttotal: 19.3s\tremaining: 3.53s\n",
      "845:\tlearn: 0.0442839\ttotal: 19.3s\tremaining: 3.51s\n",
      "846:\tlearn: 0.0442404\ttotal: 19.3s\tremaining: 3.48s\n",
      "847:\tlearn: 0.0441824\ttotal: 19.3s\tremaining: 3.46s\n",
      "848:\tlearn: 0.0441275\ttotal: 19.3s\tremaining: 3.44s\n",
      "849:\tlearn: 0.0440429\ttotal: 19.4s\tremaining: 3.42s\n",
      "850:\tlearn: 0.0440301\ttotal: 19.4s\tremaining: 3.4s\n",
      "851:\tlearn: 0.0439521\ttotal: 19.4s\tremaining: 3.37s\n",
      "852:\tlearn: 0.0438550\ttotal: 19.4s\tremaining: 3.35s\n",
      "853:\tlearn: 0.0438007\ttotal: 19.5s\tremaining: 3.33s\n",
      "854:\tlearn: 0.0437077\ttotal: 19.5s\tremaining: 3.3s\n",
      "855:\tlearn: 0.0436294\ttotal: 19.5s\tremaining: 3.28s\n",
      "856:\tlearn: 0.0436255\ttotal: 19.5s\tremaining: 3.26s\n",
      "857:\tlearn: 0.0435357\ttotal: 19.5s\tremaining: 3.23s\n",
      "858:\tlearn: 0.0434604\ttotal: 19.6s\tremaining: 3.21s\n",
      "859:\tlearn: 0.0433876\ttotal: 19.6s\tremaining: 3.19s\n",
      "860:\tlearn: 0.0433240\ttotal: 19.6s\tremaining: 3.16s\n",
      "861:\tlearn: 0.0432314\ttotal: 19.6s\tremaining: 3.14s\n",
      "862:\tlearn: 0.0431796\ttotal: 19.6s\tremaining: 3.12s\n",
      "863:\tlearn: 0.0431756\ttotal: 19.7s\tremaining: 3.09s\n",
      "864:\tlearn: 0.0430790\ttotal: 19.7s\tremaining: 3.07s\n",
      "865:\tlearn: 0.0430093\ttotal: 19.7s\tremaining: 3.05s\n",
      "866:\tlearn: 0.0429420\ttotal: 19.7s\tremaining: 3.02s\n",
      "867:\tlearn: 0.0428665\ttotal: 19.7s\tremaining: 3s\n",
      "868:\tlearn: 0.0428404\ttotal: 19.8s\tremaining: 2.98s\n",
      "869:\tlearn: 0.0427610\ttotal: 19.8s\tremaining: 2.95s\n",
      "870:\tlearn: 0.0426717\ttotal: 19.8s\tremaining: 2.93s\n",
      "871:\tlearn: 0.0426123\ttotal: 19.8s\tremaining: 2.91s\n",
      "872:\tlearn: 0.0426084\ttotal: 19.8s\tremaining: 2.89s\n",
      "873:\tlearn: 0.0425380\ttotal: 19.9s\tremaining: 2.86s\n",
      "874:\tlearn: 0.0425005\ttotal: 19.9s\tremaining: 2.84s\n",
      "875:\tlearn: 0.0424709\ttotal: 19.9s\tremaining: 2.82s\n",
      "876:\tlearn: 0.0424675\ttotal: 19.9s\tremaining: 2.79s\n",
      "877:\tlearn: 0.0423716\ttotal: 19.9s\tremaining: 2.77s\n",
      "878:\tlearn: 0.0423026\ttotal: 20s\tremaining: 2.75s\n",
      "879:\tlearn: 0.0422662\ttotal: 20s\tremaining: 2.73s\n",
      "880:\tlearn: 0.0421876\ttotal: 20s\tremaining: 2.7s\n",
      "881:\tlearn: 0.0421175\ttotal: 20s\tremaining: 2.68s\n",
      "882:\tlearn: 0.0420448\ttotal: 20.1s\tremaining: 2.66s\n",
      "883:\tlearn: 0.0419771\ttotal: 20.1s\tremaining: 2.63s\n",
      "884:\tlearn: 0.0419057\ttotal: 20.1s\tremaining: 2.61s\n",
      "885:\tlearn: 0.0418545\ttotal: 20.1s\tremaining: 2.59s\n",
      "886:\tlearn: 0.0417866\ttotal: 20.1s\tremaining: 2.56s\n",
      "887:\tlearn: 0.0417203\ttotal: 20.2s\tremaining: 2.54s\n",
      "888:\tlearn: 0.0416875\ttotal: 20.2s\tremaining: 2.52s\n",
      "889:\tlearn: 0.0416388\ttotal: 20.2s\tremaining: 2.5s\n",
      "890:\tlearn: 0.0415694\ttotal: 20.2s\tremaining: 2.47s\n",
      "891:\tlearn: 0.0415584\ttotal: 20.2s\tremaining: 2.45s\n",
      "892:\tlearn: 0.0415523\ttotal: 20.2s\tremaining: 2.43s\n",
      "893:\tlearn: 0.0415053\ttotal: 20.3s\tremaining: 2.4s\n",
      "894:\tlearn: 0.0414262\ttotal: 20.3s\tremaining: 2.38s\n",
      "895:\tlearn: 0.0413877\ttotal: 20.3s\tremaining: 2.36s\n",
      "896:\tlearn: 0.0413293\ttotal: 20.3s\tremaining: 2.33s\n",
      "897:\tlearn: 0.0412673\ttotal: 20.3s\tremaining: 2.31s\n",
      "898:\tlearn: 0.0412044\ttotal: 20.4s\tremaining: 2.29s\n",
      "899:\tlearn: 0.0411364\ttotal: 20.4s\tremaining: 2.27s\n",
      "900:\tlearn: 0.0410674\ttotal: 20.4s\tremaining: 2.24s\n",
      "901:\tlearn: 0.0410050\ttotal: 20.4s\tremaining: 2.22s\n",
      "902:\tlearn: 0.0409388\ttotal: 20.5s\tremaining: 2.2s\n",
      "903:\tlearn: 0.0409297\ttotal: 20.5s\tremaining: 2.17s\n",
      "904:\tlearn: 0.0408542\ttotal: 20.5s\tremaining: 2.15s\n",
      "905:\tlearn: 0.0408420\ttotal: 20.5s\tremaining: 2.13s\n",
      "906:\tlearn: 0.0408077\ttotal: 20.5s\tremaining: 2.11s\n",
      "907:\tlearn: 0.0407392\ttotal: 20.6s\tremaining: 2.08s\n",
      "908:\tlearn: 0.0406685\ttotal: 20.6s\tremaining: 2.06s\n",
      "909:\tlearn: 0.0406602\ttotal: 20.6s\tremaining: 2.04s\n",
      "910:\tlearn: 0.0406008\ttotal: 20.6s\tremaining: 2.02s\n",
      "911:\tlearn: 0.0405559\ttotal: 20.7s\tremaining: 1.99s\n",
      "912:\tlearn: 0.0405474\ttotal: 20.7s\tremaining: 1.97s\n",
      "913:\tlearn: 0.0405435\ttotal: 20.7s\tremaining: 1.95s\n",
      "914:\tlearn: 0.0404789\ttotal: 20.7s\tremaining: 1.93s\n",
      "915:\tlearn: 0.0404458\ttotal: 20.7s\tremaining: 1.9s\n",
      "916:\tlearn: 0.0403726\ttotal: 20.8s\tremaining: 1.88s\n",
      "917:\tlearn: 0.0403192\ttotal: 20.8s\tremaining: 1.86s\n",
      "918:\tlearn: 0.0402518\ttotal: 20.8s\tremaining: 1.83s\n",
      "919:\tlearn: 0.0401925\ttotal: 20.8s\tremaining: 1.81s\n",
      "920:\tlearn: 0.0401840\ttotal: 20.9s\tremaining: 1.79s\n",
      "921:\tlearn: 0.0401154\ttotal: 20.9s\tremaining: 1.77s\n",
      "922:\tlearn: 0.0400395\ttotal: 20.9s\tremaining: 1.74s\n",
      "923:\tlearn: 0.0399820\ttotal: 20.9s\tremaining: 1.72s\n",
      "924:\tlearn: 0.0399757\ttotal: 20.9s\tremaining: 1.7s\n",
      "925:\tlearn: 0.0398903\ttotal: 20.9s\tremaining: 1.67s\n",
      "926:\tlearn: 0.0398543\ttotal: 21s\tremaining: 1.65s\n",
      "927:\tlearn: 0.0398261\ttotal: 21s\tremaining: 1.63s\n",
      "928:\tlearn: 0.0397650\ttotal: 21s\tremaining: 1.6s\n",
      "929:\tlearn: 0.0397138\ttotal: 21s\tremaining: 1.58s\n",
      "930:\tlearn: 0.0396507\ttotal: 21s\tremaining: 1.56s\n",
      "931:\tlearn: 0.0395901\ttotal: 21.1s\tremaining: 1.54s\n",
      "932:\tlearn: 0.0395404\ttotal: 21.1s\tremaining: 1.51s\n",
      "933:\tlearn: 0.0394639\ttotal: 21.1s\tremaining: 1.49s\n",
      "934:\tlearn: 0.0394609\ttotal: 21.1s\tremaining: 1.47s\n",
      "935:\tlearn: 0.0394355\ttotal: 21.1s\tremaining: 1.44s\n",
      "936:\tlearn: 0.0393545\ttotal: 21.1s\tremaining: 1.42s\n",
      "937:\tlearn: 0.0392893\ttotal: 21.2s\tremaining: 1.4s\n",
      "938:\tlearn: 0.0392369\ttotal: 21.2s\tremaining: 1.38s\n",
      "939:\tlearn: 0.0391931\ttotal: 21.2s\tremaining: 1.35s\n",
      "940:\tlearn: 0.0391375\ttotal: 21.2s\tremaining: 1.33s\n",
      "941:\tlearn: 0.0390868\ttotal: 21.2s\tremaining: 1.31s\n",
      "942:\tlearn: 0.0390402\ttotal: 21.3s\tremaining: 1.29s\n",
      "943:\tlearn: 0.0389856\ttotal: 21.3s\tremaining: 1.26s\n",
      "944:\tlearn: 0.0389222\ttotal: 21.3s\tremaining: 1.24s\n",
      "945:\tlearn: 0.0388482\ttotal: 21.4s\tremaining: 1.22s\n",
      "946:\tlearn: 0.0387818\ttotal: 21.4s\tremaining: 1.2s\n",
      "947:\tlearn: 0.0387719\ttotal: 21.4s\tremaining: 1.17s\n",
      "948:\tlearn: 0.0386888\ttotal: 21.4s\tremaining: 1.15s\n",
      "949:\tlearn: 0.0386580\ttotal: 21.4s\tremaining: 1.13s\n",
      "950:\tlearn: 0.0385914\ttotal: 21.5s\tremaining: 1.1s\n",
      "951:\tlearn: 0.0385237\ttotal: 21.5s\tremaining: 1.08s\n",
      "952:\tlearn: 0.0384779\ttotal: 21.5s\tremaining: 1.06s\n",
      "953:\tlearn: 0.0384242\ttotal: 21.5s\tremaining: 1.04s\n",
      "954:\tlearn: 0.0382776\ttotal: 21.6s\tremaining: 1.01s\n",
      "955:\tlearn: 0.0382440\ttotal: 21.6s\tremaining: 993ms\n",
      "956:\tlearn: 0.0382411\ttotal: 21.6s\tremaining: 970ms\n",
      "957:\tlearn: 0.0381852\ttotal: 21.6s\tremaining: 948ms\n",
      "958:\tlearn: 0.0381121\ttotal: 21.6s\tremaining: 925ms\n",
      "959:\tlearn: 0.0380460\ttotal: 21.7s\tremaining: 903ms\n",
      "960:\tlearn: 0.0379919\ttotal: 21.7s\tremaining: 880ms\n",
      "961:\tlearn: 0.0379560\ttotal: 21.7s\tremaining: 857ms\n",
      "962:\tlearn: 0.0379532\ttotal: 21.7s\tremaining: 835ms\n",
      "963:\tlearn: 0.0379504\ttotal: 21.8s\tremaining: 812ms\n",
      "964:\tlearn: 0.0379470\ttotal: 21.8s\tremaining: 790ms\n",
      "965:\tlearn: 0.0379443\ttotal: 21.8s\tremaining: 767ms\n",
      "966:\tlearn: 0.0378860\ttotal: 21.8s\tremaining: 744ms\n",
      "967:\tlearn: 0.0378599\ttotal: 21.8s\tremaining: 722ms\n",
      "968:\tlearn: 0.0378105\ttotal: 21.9s\tremaining: 699ms\n",
      "969:\tlearn: 0.0377519\ttotal: 21.9s\tremaining: 677ms\n",
      "970:\tlearn: 0.0376949\ttotal: 21.9s\tremaining: 654ms\n",
      "971:\tlearn: 0.0376622\ttotal: 21.9s\tremaining: 632ms\n",
      "972:\tlearn: 0.0376217\ttotal: 22s\tremaining: 609ms\n",
      "973:\tlearn: 0.0375603\ttotal: 22s\tremaining: 587ms\n",
      "974:\tlearn: 0.0375577\ttotal: 22s\tremaining: 564ms\n",
      "975:\tlearn: 0.0375100\ttotal: 22s\tremaining: 541ms\n",
      "976:\tlearn: 0.0374584\ttotal: 22s\tremaining: 519ms\n",
      "977:\tlearn: 0.0373852\ttotal: 22.1s\tremaining: 496ms\n",
      "978:\tlearn: 0.0373159\ttotal: 22.1s\tremaining: 474ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "979:\tlearn: 0.0373133\ttotal: 22.1s\tremaining: 451ms\n",
      "980:\tlearn: 0.0372577\ttotal: 22.1s\tremaining: 429ms\n",
      "981:\tlearn: 0.0372542\ttotal: 22.2s\tremaining: 406ms\n",
      "982:\tlearn: 0.0371723\ttotal: 22.2s\tremaining: 384ms\n",
      "983:\tlearn: 0.0370950\ttotal: 22.2s\tremaining: 361ms\n",
      "984:\tlearn: 0.0370381\ttotal: 22.2s\tremaining: 338ms\n",
      "985:\tlearn: 0.0370165\ttotal: 22.2s\tremaining: 316ms\n",
      "986:\tlearn: 0.0369708\ttotal: 22.3s\tremaining: 293ms\n",
      "987:\tlearn: 0.0369623\ttotal: 22.3s\tremaining: 271ms\n",
      "988:\tlearn: 0.0369349\ttotal: 22.3s\tremaining: 248ms\n",
      "989:\tlearn: 0.0368595\ttotal: 22.3s\tremaining: 226ms\n",
      "990:\tlearn: 0.0368081\ttotal: 22.4s\tremaining: 203ms\n",
      "991:\tlearn: 0.0367728\ttotal: 22.4s\tremaining: 180ms\n",
      "992:\tlearn: 0.0367194\ttotal: 22.4s\tremaining: 158ms\n",
      "993:\tlearn: 0.0366426\ttotal: 22.4s\tremaining: 135ms\n",
      "994:\tlearn: 0.0366153\ttotal: 22.4s\tremaining: 113ms\n",
      "995:\tlearn: 0.0365447\ttotal: 22.5s\tremaining: 90.3ms\n",
      "996:\tlearn: 0.0365092\ttotal: 22.5s\tremaining: 67.7ms\n",
      "997:\tlearn: 0.0364302\ttotal: 22.5s\tremaining: 45.1ms\n",
      "998:\tlearn: 0.0363475\ttotal: 22.5s\tremaining: 22.6ms\n",
      "999:\tlearn: 0.0363399\ttotal: 22.6s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x27e32b85ed0>"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "6ba6d7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "a33c81e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9797101449275363\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318267fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "631b51a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1164, number of negative: 2973\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.199342 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21023\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2581\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.281363 -> initscore=-0.937709\n",
      "[LightGBM] [Info] Start training from score -0.937709\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.259453 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21041\n",
      "[LightGBM] [Info] Number of data points in the train set: 4138, number of used features: 2583\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289995 -> initscore=-0.895408\n",
      "[LightGBM] [Info] Start training from score -0.895408\n"
     ]
    }
   ],
   "source": [
    "scores = {}\n",
    "res_dfs = {}\n",
    "\n",
    "for c_name, classifier in classifiers.items():\n",
    "    for split_method in ['tt','skf']:\n",
    "        a1, d1 = sc_pca_class_test(X, y, MinMaxScaler(), None, 50, 0.2, classifier, split_method, 12)\n",
    "        key = c_name + '_' + split_method\n",
    "        scores[key] = a1\n",
    "        res_dfs[key] = d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "cc33b8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_acc_df(classifies, sp_ls, pcs, n_components, rs_ls):\n",
    "    \n",
    "    n_results_acc = {}\n",
    "    n_results_rep = {}\n",
    "\n",
    "    for cl_name, cl_func in classifies.items():\n",
    "        for p in pcs:\n",
    "            for sp in sp_ls:\n",
    "                for n in n_components:\n",
    "                    for rs in rs_ls:\n",
    "                        acc, rep = sc_pca_class_test(X, y, StandardScaler(), p, n, 0.2, cl_func, sp, rs) \n",
    "                        key_name = cl_name + '_' + sp + '_' + str(p) + '_' + str(n) + '_' + str(rs)\n",
    "                        n_results_acc[key_name] = acc\n",
    "                        n_results_rep[key_name] = rep\n",
    "                        \n",
    "    acc = pd.DataFrame.from_dict(n_results_acc, orient='index')\n",
    "    acc.reset_index(inplace=True)\n",
    "    acc.rename(columns={'index': 'model', 0 : 'accuracy'}, inplace=True)\n",
    "\n",
    "    split_columns = acc['model'].str.split('_', expand=True)\n",
    "\n",
    "    split_columns.columns = ['model_name', 'split_method', 'pca', 'n_components', 'random_state']\n",
    "\n",
    "    acc2 = acc.join(split_columns)\n",
    "    acc2.drop(columns=['model'], inplace=True) \n",
    "    \n",
    "\n",
    "    \n",
    "    return acc2.sort_values(by='accuracy', ascending=False), rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "fa58a45d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.983784</td>\n",
       "      <td>0.982456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.959044</td>\n",
       "      <td>0.952542</td>\n",
       "      <td>0.955782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   precision    recall  f1-score\n",
       "0   0.981132  0.983784  0.982456\n",
       "1   0.959044  0.952542  0.955782"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_dc = {}\n",
    "\n",
    "for k in n_results_rep.keys():\n",
    "    n_results_rep[k].loc[['0','1'], ['precision', 'recall', 'f1-score']]\n",
    "    \n",
    "    \n",
    "    ['accuracy', 'weighted avg'], ['precision', 'recall', 'f1-score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6761884",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = pd.DataFrame.from_dict(n_results_rep, orient='index')\n",
    "acc.reset_index(inplace=True)\n",
    "acc.rename(columns={'index': 'model', 0 : 'accuracy'}, inplace=True)\n",
    "\n",
    "split_columns = acc['model'].str.split('_', expand=True)\n",
    "\n",
    "split_columns.columns = ['model_name', 'split_method', 'pca', 'n_components', 'random_state']\n",
    "\n",
    "acc2 = acc.join(split_columns)\n",
    "acc2.drop(columns=['model'], inplace=True) \n",
    "\n",
    "\n",
    "\n",
    "return acc2.sort_values(by='accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "e9bf74eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(n_results_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ddd3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_results_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "5f0b9319",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "\n",
    "for model,df in n_results_rep.items():\n",
    "    row = df.loc[['weighted avg'], ['precision', 'recall', 'f1-score']].T.to_dict()\n",
    "    row = row['weighted avg']\n",
    "    row['model'] = model\n",
    "    rows.append(row)\n",
    "\n",
    "result_df = pd.DataFrame(rows)\n",
    "\n",
    "result_df = result_df[['model', 'precision', 'recall', 'f1-score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "78ad6ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "\n",
    "for model,df in pca_results_rep.items():\n",
    "    row = df.loc[['weighted avg'], ['precision', 'recall', 'f1-score']].T.to_dict()\n",
    "    row = row['weighted avg']\n",
    "    row['model'] = model\n",
    "    rows.append(row)\n",
    "\n",
    "p_result_df = pd.DataFrame(rows)\n",
    "\n",
    "#p_result_df = p_result_df[['model', 'precision', 'recall', 'f1-score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "33c70927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "864"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(p_result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "b1a2b919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.975776</td>\n",
       "      <td>0.975845</td>\n",
       "      <td>0.975783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score\n",
       "weighted avg   0.975776  0.975845  0.975783"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_results_rep['RandomForest200_StandardScaler_tt_2'].loc[['weighted avg'], ['precision', 'recall', 'f1-score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "e3d27eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = create_acc_df({key:value for (key,value) in classifiers.items() if key in ['RandomForest200']}, ['tt'], ['pca'], [25,50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "62c6db6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>model_name</th>\n",
       "      <th>split_method</th>\n",
       "      <th>pca</th>\n",
       "      <th>n_components</th>\n",
       "      <th>random_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.972947</td>\n",
       "      <td>RandomForest200</td>\n",
       "      <td>tt</td>\n",
       "      <td>pca</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.971014</td>\n",
       "      <td>RandomForest200</td>\n",
       "      <td>tt</td>\n",
       "      <td>pca</td>\n",
       "      <td>50</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.969082</td>\n",
       "      <td>RandomForest200</td>\n",
       "      <td>tt</td>\n",
       "      <td>pca</td>\n",
       "      <td>50</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.968116</td>\n",
       "      <td>RandomForest200</td>\n",
       "      <td>tt</td>\n",
       "      <td>pca</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.968116</td>\n",
       "      <td>RandomForest200</td>\n",
       "      <td>tt</td>\n",
       "      <td>pca</td>\n",
       "      <td>25</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.967150</td>\n",
       "      <td>RandomForest200</td>\n",
       "      <td>tt</td>\n",
       "      <td>pca</td>\n",
       "      <td>50</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy       model_name split_method  pca n_components random_state\n",
       "1  0.972947  RandomForest200           tt  pca           25            9\n",
       "3  0.971014  RandomForest200           tt  pca           50           25\n",
       "4  0.969082  RandomForest200           tt  pca           50            9\n",
       "0  0.968116  RandomForest200           tt  pca           25           25\n",
       "2  0.968116  RandomForest200           tt  pca           25          210\n",
       "5  0.967150  RandomForest200           tt  pca           50          210"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524c05c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "a6ab0cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_classifiers = {key:value for (key,value) in classifiers.items() if key in ['RandomForest200', 'RandomForest100','LGBM']}\n",
    "sp_ls_2 = ['tt', 'sss']\n",
    "pcs = ['pca','svd', 'None']\n",
    "n_components = [100, 75, 125]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "1a06613d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RandomForest100': RandomForestClassifier(),\n",
       " 'RandomForest200': RandomForestClassifier(n_estimators=200),\n",
       " 'LGBM': LGBMClassifier()}"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6654f600",
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in [0,1]:\n",
    "    df.loc[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "f5586066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1205, number of negative: 2932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021694 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23809\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2610\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.291274 -> initscore=-0.889205\n",
      "[LightGBM] [Info] Start training from score -0.889205\n",
      "[LightGBM] [Info] Number of positive: 1213, number of negative: 2924\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020869 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23679\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2585\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.293208 -> initscore=-0.879856\n",
      "[LightGBM] [Info] Start training from score -0.879856\n",
      "[LightGBM] [Info] Number of positive: 1203, number of negative: 2934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021413 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23660\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2580\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290790 -> initscore=-0.891548\n",
      "[LightGBM] [Info] Start training from score -0.891548\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023117 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23415\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2564\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021393 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23523\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2564\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021393 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23380\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2577\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n"
     ]
    }
   ],
   "source": [
    "n_results_acc = {}\n",
    "n_results_rep = {}\n",
    "\n",
    "for cl_name, cl_func in top_classifiers.items():\n",
    "    for p in pcs:\n",
    "        for sp in sp_ls_2:\n",
    "            for n in n_components:\n",
    "                for rs in [25, 9, 210]:\n",
    "                    acc, rep = sc_pca_class_test(X, y, StandardScaler(), p, n, 0.2, cl_func, sp, rs) \n",
    "                    key_name = cl_name + '_' + sp + '_' + str(p) + '_' + str(n_components) + '_' + str(rs)\n",
    "                    n_results_acc[key_name] = acc\n",
    "                    n_results_rep[key_name] = rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "1119a79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = pd.DataFrame.from_dict(n_results_acc, orient='index')\n",
    "acc.reset_index(inplace=True)\n",
    "acc.rename(columns={'index': 'model', 0 : 'accuracy'}, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f244adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(p_result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "296ff0e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.950304</td>\n",
       "      <td>0.949758</td>\n",
       "      <td>0.948884</td>\n",
       "      <td>LogisticRegression_StandardScaler_tt_25_25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.947511</td>\n",
       "      <td>0.947826</td>\n",
       "      <td>0.947459</td>\n",
       "      <td>LogisticRegression_StandardScaler_tt_25_105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.930364</td>\n",
       "      <td>0.930435</td>\n",
       "      <td>0.929140</td>\n",
       "      <td>LogisticRegression_StandardScaler_tt_25_94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.964107</td>\n",
       "      <td>0.964251</td>\n",
       "      <td>0.964126</td>\n",
       "      <td>LogisticRegression_StandardScaler_tt_50_25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.963568</td>\n",
       "      <td>0.963285</td>\n",
       "      <td>0.963389</td>\n",
       "      <td>LogisticRegression_StandardScaler_tt_50_105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>0.956357</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.956413</td>\n",
       "      <td>ADABoost_200_MinMaxScaler_sss_75_105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>0.948063</td>\n",
       "      <td>0.947826</td>\n",
       "      <td>0.947928</td>\n",
       "      <td>ADABoost_200_MinMaxScaler_sss_75_94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>0.952535</td>\n",
       "      <td>0.952657</td>\n",
       "      <td>0.952586</td>\n",
       "      <td>ADABoost_200_MinMaxScaler_sss_100_25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>0.954415</td>\n",
       "      <td>0.954589</td>\n",
       "      <td>0.954476</td>\n",
       "      <td>ADABoost_200_MinMaxScaler_sss_100_105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>0.944875</td>\n",
       "      <td>0.944928</td>\n",
       "      <td>0.944900</td>\n",
       "      <td>ADABoost_200_MinMaxScaler_sss_100_94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>864 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     precision    recall  f1-score  \\\n",
       "0     0.950304  0.949758  0.948884   \n",
       "1     0.947511  0.947826  0.947459   \n",
       "2     0.930364  0.930435  0.929140   \n",
       "3     0.964107  0.964251  0.964126   \n",
       "4     0.963568  0.963285  0.963389   \n",
       "..         ...       ...       ...   \n",
       "859   0.956357  0.956522  0.956413   \n",
       "860   0.948063  0.947826  0.947928   \n",
       "861   0.952535  0.952657  0.952586   \n",
       "862   0.954415  0.954589  0.954476   \n",
       "863   0.944875  0.944928  0.944900   \n",
       "\n",
       "                                           model  \n",
       "0     LogisticRegression_StandardScaler_tt_25_25  \n",
       "1    LogisticRegression_StandardScaler_tt_25_105  \n",
       "2     LogisticRegression_StandardScaler_tt_25_94  \n",
       "3     LogisticRegression_StandardScaler_tt_50_25  \n",
       "4    LogisticRegression_StandardScaler_tt_50_105  \n",
       "..                                           ...  \n",
       "859         ADABoost_200_MinMaxScaler_sss_75_105  \n",
       "860          ADABoost_200_MinMaxScaler_sss_75_94  \n",
       "861         ADABoost_200_MinMaxScaler_sss_100_25  \n",
       "862        ADABoost_200_MinMaxScaler_sss_100_105  \n",
       "863         ADABoost_200_MinMaxScaler_sss_100_94  \n",
       "\n",
       "[864 rows x 4 columns]"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "f7b64e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_res_5 = p_result_df[p_result_df.underscore_count == 5]\n",
    "p_res_4 = p_result_df[p_result_df.underscore_count == 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "04ec8a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mitch\\AppData\\Local\\Temp\\ipykernel_25184\\3063789221.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  p_res_5['model'] = p_res_5['model'].apply(lambda x: x.replace('_', '', 1))\n"
     ]
    }
   ],
   "source": [
    "p_res_5['model'] = p_res_5['model'].apply(lambda x: x.replace('_', '', 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "fbb8a9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_res_5['underscore_count'] = p_res_5['model'].str.count('_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "0cfd2435",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp['underscore_count'] = pp['model'].str.count('_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "d49d7d56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "underscore_count\n",
       "4    864\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp.underscore_count.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "bbf19d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = pd.concat([p_res_4, p_res_5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "aa35a4a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>model</th>\n",
       "      <th>underscore_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.950304</td>\n",
       "      <td>0.949758</td>\n",
       "      <td>0.948884</td>\n",
       "      <td>LogisticRegression_StandardScaler_tt_25_25</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.947511</td>\n",
       "      <td>0.947826</td>\n",
       "      <td>0.947459</td>\n",
       "      <td>LogisticRegression_StandardScaler_tt_25_105</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.930364</td>\n",
       "      <td>0.930435</td>\n",
       "      <td>0.929140</td>\n",
       "      <td>LogisticRegression_StandardScaler_tt_25_94</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.964107</td>\n",
       "      <td>0.964251</td>\n",
       "      <td>0.964126</td>\n",
       "      <td>LogisticRegression_StandardScaler_tt_50_25</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.963568</td>\n",
       "      <td>0.963285</td>\n",
       "      <td>0.963389</td>\n",
       "      <td>LogisticRegression_StandardScaler_tt_50_105</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>0.956357</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.956413</td>\n",
       "      <td>ADABoost200_MinMaxScaler_sss_75_105</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>0.948063</td>\n",
       "      <td>0.947826</td>\n",
       "      <td>0.947928</td>\n",
       "      <td>ADABoost200_MinMaxScaler_sss_75_94</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>0.952535</td>\n",
       "      <td>0.952657</td>\n",
       "      <td>0.952586</td>\n",
       "      <td>ADABoost200_MinMaxScaler_sss_100_25</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>0.954415</td>\n",
       "      <td>0.954589</td>\n",
       "      <td>0.954476</td>\n",
       "      <td>ADABoost200_MinMaxScaler_sss_100_105</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>0.944875</td>\n",
       "      <td>0.944928</td>\n",
       "      <td>0.944900</td>\n",
       "      <td>ADABoost200_MinMaxScaler_sss_100_94</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>864 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     precision    recall  f1-score  \\\n",
       "0     0.950304  0.949758  0.948884   \n",
       "1     0.947511  0.947826  0.947459   \n",
       "2     0.930364  0.930435  0.929140   \n",
       "3     0.964107  0.964251  0.964126   \n",
       "4     0.963568  0.963285  0.963389   \n",
       "..         ...       ...       ...   \n",
       "859   0.956357  0.956522  0.956413   \n",
       "860   0.948063  0.947826  0.947928   \n",
       "861   0.952535  0.952657  0.952586   \n",
       "862   0.954415  0.954589  0.954476   \n",
       "863   0.944875  0.944928  0.944900   \n",
       "\n",
       "                                           model  underscore_count  \n",
       "0     LogisticRegression_StandardScaler_tt_25_25                 4  \n",
       "1    LogisticRegression_StandardScaler_tt_25_105                 4  \n",
       "2     LogisticRegression_StandardScaler_tt_25_94                 4  \n",
       "3     LogisticRegression_StandardScaler_tt_50_25                 4  \n",
       "4    LogisticRegression_StandardScaler_tt_50_105                 4  \n",
       "..                                           ...               ...  \n",
       "859          ADABoost200_MinMaxScaler_sss_75_105                 4  \n",
       "860           ADABoost200_MinMaxScaler_sss_75_94                 4  \n",
       "861          ADABoost200_MinMaxScaler_sss_100_25                 4  \n",
       "862         ADABoost200_MinMaxScaler_sss_100_105                 4  \n",
       "863          ADABoost200_MinMaxScaler_sss_100_94                 4  \n",
       "\n",
       "[864 rows x 5 columns]"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "3ab625c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp2 = dfc(pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "c95a340e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>model_name</th>\n",
       "      <th>scaler</th>\n",
       "      <th>split_method</th>\n",
       "      <th>random_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.950304</td>\n",
       "      <td>0.949758</td>\n",
       "      <td>0.948884</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>tt</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.947511</td>\n",
       "      <td>0.947826</td>\n",
       "      <td>0.947459</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>tt</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.930364</td>\n",
       "      <td>0.930435</td>\n",
       "      <td>0.929140</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>tt</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.964107</td>\n",
       "      <td>0.964251</td>\n",
       "      <td>0.964126</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>tt</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.963568</td>\n",
       "      <td>0.963285</td>\n",
       "      <td>0.963389</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>tt</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>0.956357</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.956413</td>\n",
       "      <td>ADABoost200</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>sss</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>0.948063</td>\n",
       "      <td>0.947826</td>\n",
       "      <td>0.947928</td>\n",
       "      <td>ADABoost200</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>sss</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>0.952535</td>\n",
       "      <td>0.952657</td>\n",
       "      <td>0.952586</td>\n",
       "      <td>ADABoost200</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>sss</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>0.954415</td>\n",
       "      <td>0.954589</td>\n",
       "      <td>0.954476</td>\n",
       "      <td>ADABoost200</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>sss</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>0.944875</td>\n",
       "      <td>0.944928</td>\n",
       "      <td>0.944900</td>\n",
       "      <td>ADABoost200</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>sss</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>864 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     precision    recall  f1-score          model_name          scaler  \\\n",
       "0     0.950304  0.949758  0.948884  LogisticRegression  StandardScaler   \n",
       "1     0.947511  0.947826  0.947459  LogisticRegression  StandardScaler   \n",
       "2     0.930364  0.930435  0.929140  LogisticRegression  StandardScaler   \n",
       "3     0.964107  0.964251  0.964126  LogisticRegression  StandardScaler   \n",
       "4     0.963568  0.963285  0.963389  LogisticRegression  StandardScaler   \n",
       "..         ...       ...       ...                 ...             ...   \n",
       "859   0.956357  0.956522  0.956413         ADABoost200    MinMaxScaler   \n",
       "860   0.948063  0.947826  0.947928         ADABoost200    MinMaxScaler   \n",
       "861   0.952535  0.952657  0.952586         ADABoost200    MinMaxScaler   \n",
       "862   0.954415  0.954589  0.954476         ADABoost200    MinMaxScaler   \n",
       "863   0.944875  0.944928  0.944900         ADABoost200    MinMaxScaler   \n",
       "\n",
       "    split_method random_state  \n",
       "0             tt           25  \n",
       "1             tt          105  \n",
       "2             tt           94  \n",
       "3             tt           25  \n",
       "4             tt          105  \n",
       "..           ...          ...  \n",
       "859          sss          105  \n",
       "860          sss           94  \n",
       "861          sss           25  \n",
       "862          sss          105  \n",
       "863          sss           94  \n",
       "\n",
       "[864 rows x 7 columns]"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp2.drop(columns=['n_components', 'underscore_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "5ec3f3a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['LogisticRegression', 'SVMLinear', 'SVMSigmoid', 'LGBM', 'GrdBst',\n",
       "       'RandomForest100', 'RandomForest200', 'KNN5n', 'KNN15n', 'KNN25n',\n",
       "       'ADABoost100', 'ADABoost200'], dtype=object)"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp2.model_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "1dc5a6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_pp2 = pp2[['model_name','scaler','precision','recall','f1-score']].groupby(['model_name', 'scaler']).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "e2cb019a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_pp2['combination'] = mean_pp2['model_name'] + '_' + mean_pp2['scaler']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "e5b917aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "57f26bd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Plot lines for precision, recall, and f1-score\n",
    "for metric in ['precision', 'recall', 'f1-score']:\n",
    "    ax.plot(mean_pp2['combination'], mean_pp2[metric], marker='o', label=metric)\n",
    "\n",
    "# Add labels and title\n",
    "ax.set_xlabel('Model and Scaler Combination')\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('Precision, Recall, and F1-Score by Model and Scaler Combination')\n",
    "ax.legend(title='Metrics', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Rotate x-axis labels for better readability\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce9ec52",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size = 0.1, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a96813",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0523e1be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4736f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Unique model and scaler combinations\n",
    "combinations = mean_df.groupby(['model_name', 'scaler'])\n",
    "\n",
    "# Plot lines for each combination\n",
    "for (model_name, scaler), group in combinations:\n",
    "    ax.plot(group['scaler'], group['precision'], marker='o', label=f'{model_name} - Precision')\n",
    "    ax.plot(group['scaler'], group['recall'], marker='o', label=f'{model_name} - Recall')\n",
    "    ax.plot(group['scaler'], group['f1-score'], marker='o', label=f'{model_name} - F1-Score')\n",
    "\n",
    "# Add labels and title\n",
    "ax.set_xlabel('Scaler')\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('Precision, Recall, and F1-Score by Model and Scaler')\n",
    "ax.legend(title='Legend', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280fc136",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "56bd503b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfc(df):\n",
    "    \n",
    "    split_columns = df['model'].str.split('_', expand=True)\n",
    "\n",
    "    split_columns.columns = ['model_name', 'scaler', 'split_method', 'n_components', 'random_state']\n",
    "\n",
    "    df2 = df.join(split_columns)\n",
    "\n",
    "    # Optionally, drop the original 'model' column\n",
    "    df2.drop(columns=['model'], inplace=True)\n",
    "    \n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "40a66e6b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 6 elements, new values have 4 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[263], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m split_columns \u001b[38;5;241m=\u001b[39m p_result_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m, expand\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 3\u001b[0m split_columns\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_name\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscaler\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msplit_method\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom_state\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      5\u001b[0m p_res_df \u001b[38;5;241m=\u001b[39m p_result_df\u001b[38;5;241m.\u001b[39mjoin(split_columns)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Optionally, drop the original 'model' column\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:6218\u001b[0m, in \u001b[0;36mNDFrame.__setattr__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m   6216\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   6217\u001b[0m     \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name)\n\u001b[1;32m-> 6218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, value)\n\u001b[0;32m   6219\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[0;32m   6220\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32mproperties.pyx:69\u001b[0m, in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:767\u001b[0m, in \u001b[0;36mNDFrame._set_axis\u001b[1;34m(self, axis, labels)\u001b[0m\n\u001b[0;32m    762\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    763\u001b[0m \u001b[38;5;124;03mThis is called from the cython code when we set the `index` attribute\u001b[39;00m\n\u001b[0;32m    764\u001b[0m \u001b[38;5;124;03mdirectly, e.g. `series.index = [1, 2, 3]`.\u001b[39;00m\n\u001b[0;32m    765\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    766\u001b[0m labels \u001b[38;5;241m=\u001b[39m ensure_index(labels)\n\u001b[1;32m--> 767\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mset_axis(axis, labels)\n\u001b[0;32m    768\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:227\u001b[0m, in \u001b[0;36mBaseBlockManager.set_axis\u001b[1;34m(self, axis, new_labels)\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_axis\u001b[39m(\u001b[38;5;28mself\u001b[39m, axis: AxisInt, new_labels: Index) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    226\u001b[0m     \u001b[38;5;66;03m# Caller is responsible for ensuring we have an Index object.\u001b[39;00m\n\u001b[1;32m--> 227\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_set_axis(axis, new_labels)\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis] \u001b[38;5;241m=\u001b[39m new_labels\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\base.py:85\u001b[0m, in \u001b[0;36mDataManager._validate_set_axis\u001b[1;34m(self, axis, new_labels)\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m new_len \u001b[38;5;241m!=\u001b[39m old_len:\n\u001b[1;32m---> 85\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     86\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength mismatch: Expected axis has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mold_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements, new \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     87\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m elements\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     88\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Length mismatch: Expected axis has 6 elements, new values have 4 elements"
     ]
    }
   ],
   "source": [
    "split_columns = p_result_df['model'].str.split('_', expand=True)\n",
    "\n",
    "split_columns.columns = ['model_name', 'scaler', 'split_method', 'random_state']\n",
    "\n",
    "p_res_df = p_result_df.join(split_columns)\n",
    "\n",
    "# Optionally, drop the original 'model' column\n",
    "p_res_df.drop(columns=['model'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "76df006a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>model_name</th>\n",
       "      <th>scaler</th>\n",
       "      <th>split_method</th>\n",
       "      <th>random_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.981643</td>\n",
       "      <td>RandomForest200</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>tt</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.980676</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>tt</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.979710</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>sss</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.976812</td>\n",
       "      <td>RandomForest100</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>sss</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.976812</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>sss</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.975845</td>\n",
       "      <td>RandomForest200</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>tt</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.975845</td>\n",
       "      <td>RandomForest200</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>sss</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.975845</td>\n",
       "      <td>RandomForest100</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>tt</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.974879</td>\n",
       "      <td>RandomForest100</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>tt</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.974879</td>\n",
       "      <td>RandomForest200</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>sss</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.974879</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>tt</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.972947</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>sss</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.972947</td>\n",
       "      <td>RandomForest200</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>tt</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.971981</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>tt</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.971014</td>\n",
       "      <td>RandomForest100</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>sss</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.971014</td>\n",
       "      <td>RandomForest100</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>tt</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.970048</td>\n",
       "      <td>RandomForest200</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>sss</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.969082</td>\n",
       "      <td>RandomForest100</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>sss</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.955556</td>\n",
       "      <td>SVMLinear</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>sss</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.951691</td>\n",
       "      <td>SVMLinear</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>tt</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.944928</td>\n",
       "      <td>SVMLinear</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>tt</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.944928</td>\n",
       "      <td>SVMLinear</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>sss</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.941063</td>\n",
       "      <td>SVMLinear</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>sss</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.937198</td>\n",
       "      <td>SVMLinear</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>tt</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    accuracy       model_name          scaler split_method random_state\n",
       "8   0.981643  RandomForest200  StandardScaler           tt          410\n",
       "19  0.980676             LGBM  StandardScaler           tt           52\n",
       "22  0.979710             LGBM  StandardScaler          sss           52\n",
       "3   0.976812  RandomForest100  StandardScaler          sss            2\n",
       "21  0.976812             LGBM  StandardScaler          sss            2\n",
       "6   0.975845  RandomForest200  StandardScaler           tt            2\n",
       "9   0.975845  RandomForest200  StandardScaler          sss            2\n",
       "1   0.975845  RandomForest100  StandardScaler           tt           52\n",
       "0   0.974879  RandomForest100  StandardScaler           tt            2\n",
       "11  0.974879  RandomForest200  StandardScaler          sss          410\n",
       "20  0.974879             LGBM  StandardScaler           tt          410\n",
       "23  0.972947             LGBM  StandardScaler          sss          410\n",
       "7   0.972947  RandomForest200  StandardScaler           tt           52\n",
       "18  0.971981             LGBM  StandardScaler           tt            2\n",
       "4   0.971014  RandomForest100  StandardScaler          sss           52\n",
       "2   0.971014  RandomForest100  StandardScaler           tt          410\n",
       "10  0.970048  RandomForest200  StandardScaler          sss           52\n",
       "5   0.969082  RandomForest100  StandardScaler          sss          410\n",
       "15  0.955556        SVMLinear  StandardScaler          sss            2\n",
       "13  0.951691        SVMLinear  StandardScaler           tt           52\n",
       "14  0.944928        SVMLinear  StandardScaler           tt          410\n",
       "17  0.944928        SVMLinear  StandardScaler          sss          410\n",
       "16  0.941063        SVMLinear  StandardScaler          sss           52\n",
       "12  0.937198        SVMLinear  StandardScaler           tt            2"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc2.sort_values(by='accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "a127ca0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lda'"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'lda_svd'[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "9870d679",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "91f222a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "08a19700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LogisticRegression': LogisticRegression(max_iter=500),\n",
       " 'RandomForest100': RandomForestClassifier(),\n",
       " 'RandomForest200': RandomForestClassifier(n_estimators=200),\n",
       " 'SVMLinear': SVC(kernel='linear'),\n",
       " 'SVMSigmoid': SVC(kernel='sigmoid'),\n",
       " 'KNN5n': KNeighborsClassifier(),\n",
       " 'KNN15n': KNeighborsClassifier(n_neighbors=15),\n",
       " 'KNN25n': KNeighborsClassifier(n_neighbors=25),\n",
       " 'LGBM': LGBMClassifier(),\n",
       " 'GrdBst': GradientBoostingClassifier(),\n",
       " 'ADABoost100': AdaBoostClassifier(n_estimators=100),\n",
       " 'ADABoost200': AdaBoostClassifier(n_estimators=200)}"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "53abe46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for pc in ['pca', 'svd', ]\n",
    "score, ddf = sc_pca_class_test(X, y, MinMaxScaler(),None, 50, 0.2, LGBMClassifier(n_estimators=200), 'kf', 52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "cb9aa55a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9806576402321083"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "f4f5723d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sc_pca_class_test(X, y, scaler, reduce, components, ts, classifier, split_method, rs):\n",
    "\n",
    "    if scaler:\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "    else:\n",
    "        X_scaled = None\n",
    "        \n",
    "    r_params = {'n_components': components, 'random_state': rs}\n",
    "    \n",
    "    r_dc = {'pca': PCA(**r_params),\n",
    "             'svd' : TruncatedSVD(**r_params),\n",
    "             'tsne': TSNE(method='exact', n_components= components, random_state= rs),\n",
    "             'lda_svd' : LDA(n_components= 2, solver= 'svd')}\n",
    "    \n",
    "    if reduce in r_dc.keys():\n",
    "        if reduce[:3].lower() == 'lda':\n",
    "            X_reduced = r_dc[reduce].fit_transform(X_scaled, y)\n",
    "        else:\n",
    "            X_reduced = r_dc[reduce].fit_transform(X_scaled)\n",
    "    else: \n",
    "        X_reduced = X_scaled.copy()   \n",
    "        \n",
    "    n_splits=int((1/ts))\n",
    "    \n",
    "    split_dc = {\n",
    "           'skf' : StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=rs),\n",
    "            'sss' : StratifiedShuffleSplit(n_splits=n_splits, test_size=ts, random_state=rs),    \n",
    "            'kf': KFold(n_splits=n_splits, shuffle=True, random_state=rs)\n",
    "    }\n",
    "    \n",
    "\n",
    "    if split_method == 'tt':\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_reduced, y, test_size=ts, random_state=rs)\n",
    "        \n",
    "    elif split_method in split_dc.keys():\n",
    "        \n",
    "        for train_index, test_index in split_dc[split_method].split(X_reduced, y):\n",
    "            X_train, X_test = X_reduced[train_index], X_reduced[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "    else:\n",
    "        print(split_method + ' not allowed')\n",
    "        return 'FAILURE'\n",
    "    \n",
    "    classifier.fit(X_train, y_train)    \n",
    "    \n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report_dc = classification_report(y_test, y_pred, output_dict=True)\n",
    "    report_df = pd.DataFrame(report_dc).transpose()\n",
    "    \n",
    "    return accuracy, report_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "c1953c05",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "n_components cannot be larger than min(n_features, n_classes - 1).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[324], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m bac, brep \u001b[38;5;241m=\u001b[39m sc_pca_class_test(X, y, StandardScaler(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlda_svd\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m0.2\u001b[39m, RandomForestClassifier(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m42\u001b[39m)\n",
      "Cell \u001b[1;32mIn[319], line 14\u001b[0m, in \u001b[0;36msc_pca_class_test\u001b[1;34m(X, y, scaler, reduce, components, ts, classifier, split_method, rs)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reduce \u001b[38;5;129;01min\u001b[39;00m r_dc\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m reduce[:\u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlda\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m---> 14\u001b[0m         X_reduced \u001b[38;5;241m=\u001b[39m r_dc[reduce]\u001b[38;5;241m.\u001b[39mfit_transform(X_scaled, y)\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     16\u001b[0m         X_reduced \u001b[38;5;241m=\u001b[39m r_dc[reduce]\u001b[38;5;241m.\u001b[39mfit_transform(X_scaled)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:870\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    867\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m--> 870\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:582\u001b[0m, in \u001b[0;36mLinearDiscriminantAnalysis.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    580\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    581\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components \u001b[38;5;241m>\u001b[39m max_components:\n\u001b[1;32m--> 582\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    583\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_components cannot be larger than min(n_features, n_classes - 1).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    584\u001b[0m         )\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_components \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components\n\u001b[0;32m    587\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msolver \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msvd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;31mValueError\u001b[0m: n_components cannot be larger than min(n_features, n_classes - 1)."
     ]
    }
   ],
   "source": [
    "bac, brep = sc_pca_class_test(X, y, StandardScaler(), 'lda_svd', 5, 0.2, RandomForestClassifier(), 'tt', 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cf5272",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819b831f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bc940c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ab4da4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78918d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Fetch data (we use newsgroups data for demonstration; replace with actual email spam dataset)\n",
    "newsgroups = fetch_20newsgroups(subset='all', categories=['alt.atheism', 'soc.religion.christian'])\n",
    "X = newsgroups.data\n",
    "y = newsgroups.target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86efdc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text data to TF-IDF features\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X_tfidf = vectorizer.fit_transform(X)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d3dcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LDA model using SVD solver\n",
    "lda_svd = LinearDiscriminantAnalysis(solver='svd')\n",
    "lda_svd.fit(X_train.toarray(), y_train)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "y_pred_svd = lda_svd.predict(X_test.toarray())\n",
    "print(\"SVD Solver\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_svd))\n",
    "print(classification_report(y_test, y_pred_svd))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6455e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ad2c2989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale\n",
      "pca\n"
     ]
    }
   ],
   "source": [
    "c1, c2 = sc_pca_class_test(X, y, mm_sc, 50, 0.2, LogisticRegression(), 'skf', 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7892e665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.962060</td>\n",
       "      <td>0.967302</td>\n",
       "      <td>0.964674</td>\n",
       "      <td>734.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.918919</td>\n",
       "      <td>0.906667</td>\n",
       "      <td>0.912752</td>\n",
       "      <td>300.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.949710</td>\n",
       "      <td>0.949710</td>\n",
       "      <td>0.949710</td>\n",
       "      <td>0.94971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.940489</td>\n",
       "      <td>0.936985</td>\n",
       "      <td>0.938713</td>\n",
       "      <td>1034.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.949543</td>\n",
       "      <td>0.949710</td>\n",
       "      <td>0.949609</td>\n",
       "      <td>1034.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "0              0.962060  0.967302  0.964674   734.00000\n",
       "1              0.918919  0.906667  0.912752   300.00000\n",
       "accuracy       0.949710  0.949710  0.949710     0.94971\n",
       "macro avg      0.940489  0.936985  0.938713  1034.00000\n",
       "weighted avg   0.949543  0.949710  0.949609  1034.00000"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "582a5db7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9497098646034816"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fa990e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(int((1/0.2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ff21317",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Prediction']\n",
    "X = df.drop(columns=['Prediction'])\n",
    "\n",
    "\n",
    "mm_sc = MinMaxScaler()\n",
    "sc_sc = StandardScaler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab1578c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data\n",
    "X_scaled = mm_sc.fit_transform(X)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=25)\n",
    "X_pca = pca.fit_transform(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f694eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56eb042e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "34dab51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, test_index in sss.split(X_pca, y):\n",
    "    X_train, X_test = X_pca[train_index], X_pca[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "69d4413d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "329d21c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4c182bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd02cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "        sss = StratifiedShuffleSplit(n_splits=int((1/ts)), test_size=ts, random_state=rs)\n",
    "        \n",
    "        for train_index, test_index in sss.split(X_pca, y):\n",
    "            X_train, X_test = X_pca[train_index], X_pca[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f72edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_test, rep_test = sc_pca_class_test(X, y, mm_sc, 0.2, 25, LogisticRegression(), 'sss', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690236f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a5526562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1199, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001616 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6375\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289824 -> initscore=-0.896241\n",
      "[LightGBM] [Info] Start training from score -0.896241\n",
      "[LightGBM] [Info] Number of positive: 1196, number of negative: 2941\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000485 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6375\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289098 -> initscore=-0.899767\n",
      "[LightGBM] [Info] Start training from score -0.899767\n",
      "[LightGBM] [Info] Number of positive: 1199, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000827 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6375\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289824 -> initscore=-0.896241\n",
      "[LightGBM] [Info] Start training from score -0.896241\n",
      "[LightGBM] [Info] Number of positive: 1199, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001194 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12750\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 50\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289824 -> initscore=-0.896241\n",
      "[LightGBM] [Info] Start training from score -0.896241\n",
      "[LightGBM] [Info] Number of positive: 1196, number of negative: 2941\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001149 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12750\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 50\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289098 -> initscore=-0.899767\n",
      "[LightGBM] [Info] Start training from score -0.899767\n",
      "[LightGBM] [Info] Number of positive: 1199, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001148 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12750\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 50\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289824 -> initscore=-0.896241\n",
      "[LightGBM] [Info] Start training from score -0.896241\n",
      "[LightGBM] [Info] Number of positive: 1199, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001715 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19125\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289824 -> initscore=-0.896241\n",
      "[LightGBM] [Info] Start training from score -0.896241\n",
      "[LightGBM] [Info] Number of positive: 1196, number of negative: 2941\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001738 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19125\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289098 -> initscore=-0.899767\n",
      "[LightGBM] [Info] Start training from score -0.899767\n",
      "[LightGBM] [Info] Number of positive: 1199, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001707 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19125\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289824 -> initscore=-0.896241\n",
      "[LightGBM] [Info] Start training from score -0.896241\n",
      "[LightGBM] [Info] Number of positive: 1199, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002161 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 25500\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289824 -> initscore=-0.896241\n",
      "[LightGBM] [Info] Start training from score -0.896241\n",
      "[LightGBM] [Info] Number of positive: 1196, number of negative: 2941\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002634 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 25500\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289098 -> initscore=-0.899767\n",
      "[LightGBM] [Info] Start training from score -0.899767\n",
      "[LightGBM] [Info] Number of positive: 1199, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002466 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 25500\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289824 -> initscore=-0.896241\n",
      "[LightGBM] [Info] Start training from score -0.896241\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000991 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6375\n",
      "[LightGBM] [Info] Number of data points in the train set: 4138, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289995 -> initscore=-0.895408\n",
      "[LightGBM] [Info] Start training from score -0.895408\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000480 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6375\n",
      "[LightGBM] [Info] Number of data points in the train set: 4138, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289995 -> initscore=-0.895408\n",
      "[LightGBM] [Info] Start training from score -0.895408\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000492 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6375\n",
      "[LightGBM] [Info] Number of data points in the train set: 4138, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289995 -> initscore=-0.895408\n",
      "[LightGBM] [Info] Start training from score -0.895408\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001138 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12750\n",
      "[LightGBM] [Info] Number of data points in the train set: 4138, number of used features: 50\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289995 -> initscore=-0.895408\n",
      "[LightGBM] [Info] Start training from score -0.895408\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001223 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12750\n",
      "[LightGBM] [Info] Number of data points in the train set: 4138, number of used features: 50\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289995 -> initscore=-0.895408\n",
      "[LightGBM] [Info] Start training from score -0.895408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001198 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12750\n",
      "[LightGBM] [Info] Number of data points in the train set: 4138, number of used features: 50\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289995 -> initscore=-0.895408\n",
      "[LightGBM] [Info] Start training from score -0.895408\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001637 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19125\n",
      "[LightGBM] [Info] Number of data points in the train set: 4138, number of used features: 75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289995 -> initscore=-0.895408\n",
      "[LightGBM] [Info] Start training from score -0.895408\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001653 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19125\n",
      "[LightGBM] [Info] Number of data points in the train set: 4138, number of used features: 75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289995 -> initscore=-0.895408\n",
      "[LightGBM] [Info] Start training from score -0.895408\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001663 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19125\n",
      "[LightGBM] [Info] Number of data points in the train set: 4138, number of used features: 75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289995 -> initscore=-0.895408\n",
      "[LightGBM] [Info] Start training from score -0.895408\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002125 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 25500\n",
      "[LightGBM] [Info] Number of data points in the train set: 4138, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289995 -> initscore=-0.895408\n",
      "[LightGBM] [Info] Start training from score -0.895408\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002145 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 25500\n",
      "[LightGBM] [Info] Number of data points in the train set: 4138, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289995 -> initscore=-0.895408\n",
      "[LightGBM] [Info] Start training from score -0.895408\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002232 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 25500\n",
      "[LightGBM] [Info] Number of data points in the train set: 4138, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289995 -> initscore=-0.895408\n",
      "[LightGBM] [Info] Start training from score -0.895408\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000614 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6375\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000748 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6375\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000491 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6375\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001427 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12750\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 50\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001494 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12750\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 50\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001306 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12750\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 50\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001730 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19125\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001698 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19125\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001811 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19125\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002057 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 25500\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002278 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 25500\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002247 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 25500\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1199, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000941 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6375\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289824 -> initscore=-0.896241\n",
      "[LightGBM] [Info] Start training from score -0.896241\n",
      "[LightGBM] [Info] Number of positive: 1196, number of negative: 2941\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000518 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6375\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289098 -> initscore=-0.899767\n",
      "[LightGBM] [Info] Start training from score -0.899767\n",
      "[LightGBM] [Info] Number of positive: 1199, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000547 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6375\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289824 -> initscore=-0.896241\n",
      "[LightGBM] [Info] Start training from score -0.896241\n",
      "[LightGBM] [Info] Number of positive: 1199, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001252 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12750\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 50\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289824 -> initscore=-0.896241\n",
      "[LightGBM] [Info] Start training from score -0.896241\n",
      "[LightGBM] [Info] Number of positive: 1196, number of negative: 2941\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001240 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12750\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 50\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289098 -> initscore=-0.899767\n",
      "[LightGBM] [Info] Start training from score -0.899767\n",
      "[LightGBM] [Info] Number of positive: 1199, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001246 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12750\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 50\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289824 -> initscore=-0.896241\n",
      "[LightGBM] [Info] Start training from score -0.896241\n",
      "[LightGBM] [Info] Number of positive: 1199, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001775 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19125\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289824 -> initscore=-0.896241\n",
      "[LightGBM] [Info] Start training from score -0.896241\n",
      "[LightGBM] [Info] Number of positive: 1196, number of negative: 2941\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002181 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19125\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289098 -> initscore=-0.899767\n",
      "[LightGBM] [Info] Start training from score -0.899767\n",
      "[LightGBM] [Info] Number of positive: 1199, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002092 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19125\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289824 -> initscore=-0.896241\n",
      "[LightGBM] [Info] Start training from score -0.896241\n",
      "[LightGBM] [Info] Number of positive: 1199, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002605 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 25500\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289824 -> initscore=-0.896241\n",
      "[LightGBM] [Info] Start training from score -0.896241\n",
      "[LightGBM] [Info] Number of positive: 1196, number of negative: 2941\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002373 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 25500\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289098 -> initscore=-0.899767\n",
      "[LightGBM] [Info] Start training from score -0.899767\n",
      "[LightGBM] [Info] Number of positive: 1199, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002265 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 25500\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289824 -> initscore=-0.896241\n",
      "[LightGBM] [Info] Start training from score -0.896241\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000691 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6375\n",
      "[LightGBM] [Info] Number of data points in the train set: 4138, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289995 -> initscore=-0.895408\n",
      "[LightGBM] [Info] Start training from score -0.895408\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000971 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6375\n",
      "[LightGBM] [Info] Number of data points in the train set: 4138, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289995 -> initscore=-0.895408\n",
      "[LightGBM] [Info] Start training from score -0.895408\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000460 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6375\n",
      "[LightGBM] [Info] Number of data points in the train set: 4138, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289995 -> initscore=-0.895408\n",
      "[LightGBM] [Info] Start training from score -0.895408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001261 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12750\n",
      "[LightGBM] [Info] Number of data points in the train set: 4138, number of used features: 50\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289995 -> initscore=-0.895408\n",
      "[LightGBM] [Info] Start training from score -0.895408\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001276 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12750\n",
      "[LightGBM] [Info] Number of data points in the train set: 4138, number of used features: 50\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289995 -> initscore=-0.895408\n",
      "[LightGBM] [Info] Start training from score -0.895408\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001196 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12750\n",
      "[LightGBM] [Info] Number of data points in the train set: 4138, number of used features: 50\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289995 -> initscore=-0.895408\n",
      "[LightGBM] [Info] Start training from score -0.895408\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001946 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19125\n",
      "[LightGBM] [Info] Number of data points in the train set: 4138, number of used features: 75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289995 -> initscore=-0.895408\n",
      "[LightGBM] [Info] Start training from score -0.895408\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001602 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19125\n",
      "[LightGBM] [Info] Number of data points in the train set: 4138, number of used features: 75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289995 -> initscore=-0.895408\n",
      "[LightGBM] [Info] Start training from score -0.895408\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001720 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19125\n",
      "[LightGBM] [Info] Number of data points in the train set: 4138, number of used features: 75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289995 -> initscore=-0.895408\n",
      "[LightGBM] [Info] Start training from score -0.895408\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002290 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 25500\n",
      "[LightGBM] [Info] Number of data points in the train set: 4138, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289995 -> initscore=-0.895408\n",
      "[LightGBM] [Info] Start training from score -0.895408\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002288 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 25500\n",
      "[LightGBM] [Info] Number of data points in the train set: 4138, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289995 -> initscore=-0.895408\n",
      "[LightGBM] [Info] Start training from score -0.895408\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002274 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 25500\n",
      "[LightGBM] [Info] Number of data points in the train set: 4138, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289995 -> initscore=-0.895408\n",
      "[LightGBM] [Info] Start training from score -0.895408\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000847 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6375\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000632 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6375\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000520 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6375\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001234 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12750\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 50\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001274 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12750\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 50\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001316 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12750\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 50\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001820 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19125\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001936 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19125\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002006 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19125\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 75\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002262 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 25500\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002417 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 25500\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002277 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 25500\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "sc_dc = {'StandardScaler' : StandardScaler(), 'MinMaxScaler' : MinMaxScaler()}\n",
    "\n",
    "sp_ls = ['tt', 'skf', 'sss']\n",
    "\n",
    "pca_comp = [25, 50, 75, 100]\n",
    "\n",
    "SV_lin = SVC(kernel='linear')\n",
    "SV_log = SVC(kernel='sigmoid')\n",
    "\n",
    "classifiers = {\n",
    "    'LogisticRegression': LogisticRegression(max_iter=500),\n",
    "    'RandomForest100': RandomForestClassifier(n_estimators=100),\n",
    "    'RandomForest200': RandomForestClassifier(n_estimators=200),\n",
    "    'SVMLinear': SV_lin,\n",
    "    'SVMSigmoid': SV_log,\n",
    "    'KNN5n' : KNeighborsClassifier(n_neighbors=5),\n",
    "    'KNN15n' : KNeighborsClassifier(n_neighbors=15),\n",
    "    'KNN25n' : KNeighborsClassifier(n_neighbors=25),    \n",
    "    'LGBM' : lgb.LGBMClassifier(),\n",
    "    'GrdBst': GradientBoostingClassifier(),\n",
    "    'ADABoost100': AdaBoostClassifier(n_estimators=100),\n",
    "    'ADABoost200': AdaBoostClassifier(n_estimators=200),    \n",
    "}\n",
    "\n",
    "pca_results_acc = {}\n",
    "pca_results_rep = {}\n",
    "\n",
    "for cl_name, cl_func in classifiers.items():\n",
    "    for sc_name, sc_func in sc_dc.items():\n",
    "        for sp in sp_ls:\n",
    "            for n_comp in pca_comp:\n",
    "                for rs in [25, 105, 94]:\n",
    "                    acc, rep = sc_pca_class_test(X, y, sc_func, n_comp, 0.2, cl_func, sp, rs) \n",
    "                    key_name = cl_name + '_' + sc_name + '_' + sp + '_' + str(n_comp) + '_' + str(rs)\n",
    "                    pca_results_acc[key_name] = acc\n",
    "                    pca_results_rep[key_name] = rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "bf4ed7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_classifiers = {key:value for (key,value) in classifiers.items() if key in ['RandomForest200', 'RandomForest100','LGBM','GrdBost','AdaBoost200','SVMLinear']}\n",
    "sp_ls_2 = ['tt', 'sss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f152e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "eae9157b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1205, number of negative: 2932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021694 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23809\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2610\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.291274 -> initscore=-0.889205\n",
      "[LightGBM] [Info] Start training from score -0.889205\n",
      "[LightGBM] [Info] Number of positive: 1213, number of negative: 2924\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020869 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23679\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2585\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.293208 -> initscore=-0.879856\n",
      "[LightGBM] [Info] Start training from score -0.879856\n",
      "[LightGBM] [Info] Number of positive: 1203, number of negative: 2934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021413 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23660\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2580\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290790 -> initscore=-0.891548\n",
      "[LightGBM] [Info] Start training from score -0.891548\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023117 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23415\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2564\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021393 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23523\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2564\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021393 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23380\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2577\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n"
     ]
    }
   ],
   "source": [
    "n_results_acc = {}\n",
    "n_results_rep = {}\n",
    "\n",
    "for cl_name, cl_func in top_classifiers.items():\n",
    "    for sp in sp_ls_2:\n",
    "        for rs in [2, 52, 410]:\n",
    "            acc, rep = sc_pca_class_test(X, y, StandardScaler(), False, 0.2, cl_func, sp, rs) \n",
    "            key_name = cl_name + '_' + 'StandardScaler' + '_' + sp + '_' + str(rs)\n",
    "            n_results_acc[key_name] = acc\n",
    "            n_results_rep[key_name] = rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "e9f49842",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = pd.DataFrame.from_dict(n_results_acc, orient='index')\n",
    "acc.reset_index(inplace=True)\n",
    "acc.rename(columns={'index': 'model', 0 : 'accuracy'}, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "0e637bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_columns = acc['model'].str.split('_', expand=True)\n",
    "\n",
    "split_columns.columns = ['model_name', 'scaler', 'split_method', 'random_state']\n",
    "\n",
    "acc2 = acc.join(split_columns)\n",
    "\n",
    "# Optionally, drop the original 'model' column\n",
    "acc2.drop(columns=['model'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "136bf9c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>model_name</th>\n",
       "      <th>scaler</th>\n",
       "      <th>split_method</th>\n",
       "      <th>random_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.981643</td>\n",
       "      <td>RandomForest200</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>tt</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.980676</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>tt</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.979710</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>sss</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.976812</td>\n",
       "      <td>RandomForest100</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>sss</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.976812</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>sss</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.975845</td>\n",
       "      <td>RandomForest200</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>tt</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.975845</td>\n",
       "      <td>RandomForest200</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>sss</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.975845</td>\n",
       "      <td>RandomForest100</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>tt</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.974879</td>\n",
       "      <td>RandomForest100</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>tt</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.974879</td>\n",
       "      <td>RandomForest200</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>sss</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.974879</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>tt</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.972947</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>sss</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.972947</td>\n",
       "      <td>RandomForest200</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>tt</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.971981</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>tt</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.971014</td>\n",
       "      <td>RandomForest100</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>sss</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.971014</td>\n",
       "      <td>RandomForest100</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>tt</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.970048</td>\n",
       "      <td>RandomForest200</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>sss</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.969082</td>\n",
       "      <td>RandomForest100</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>sss</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.955556</td>\n",
       "      <td>SVMLinear</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>sss</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.951691</td>\n",
       "      <td>SVMLinear</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>tt</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.944928</td>\n",
       "      <td>SVMLinear</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>tt</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.944928</td>\n",
       "      <td>SVMLinear</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>sss</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.941063</td>\n",
       "      <td>SVMLinear</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>sss</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.937198</td>\n",
       "      <td>SVMLinear</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>tt</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    accuracy       model_name          scaler split_method random_state\n",
       "8   0.981643  RandomForest200  StandardScaler           tt          410\n",
       "19  0.980676             LGBM  StandardScaler           tt           52\n",
       "22  0.979710             LGBM  StandardScaler          sss           52\n",
       "3   0.976812  RandomForest100  StandardScaler          sss            2\n",
       "21  0.976812             LGBM  StandardScaler          sss            2\n",
       "6   0.975845  RandomForest200  StandardScaler           tt            2\n",
       "9   0.975845  RandomForest200  StandardScaler          sss            2\n",
       "1   0.975845  RandomForest100  StandardScaler           tt           52\n",
       "0   0.974879  RandomForest100  StandardScaler           tt            2\n",
       "11  0.974879  RandomForest200  StandardScaler          sss          410\n",
       "20  0.974879             LGBM  StandardScaler           tt          410\n",
       "23  0.972947             LGBM  StandardScaler          sss          410\n",
       "7   0.972947  RandomForest200  StandardScaler           tt           52\n",
       "18  0.971981             LGBM  StandardScaler           tt            2\n",
       "4   0.971014  RandomForest100  StandardScaler          sss           52\n",
       "2   0.971014  RandomForest100  StandardScaler           tt          410\n",
       "10  0.970048  RandomForest200  StandardScaler          sss           52\n",
       "5   0.969082  RandomForest100  StandardScaler          sss          410\n",
       "15  0.955556        SVMLinear  StandardScaler          sss            2\n",
       "13  0.951691        SVMLinear  StandardScaler           tt           52\n",
       "14  0.944928        SVMLinear  StandardScaler           tt          410\n",
       "17  0.944928        SVMLinear  StandardScaler          sss          410\n",
       "16  0.941063        SVMLinear  StandardScaler          sss           52\n",
       "12  0.937198        SVMLinear  StandardScaler           tt            2"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc2.sort_values(by='accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f92b15d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f6b9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    ", StandardScaler(), tt or sss, pca=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1274a8af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ec10c8c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LogisticRegression_StandardScaler_tt_25_25': 0.9497584541062802,\n",
       " 'LogisticRegression_StandardScaler_tt_25_105': 0.9478260869565217,\n",
       " 'LogisticRegression_StandardScaler_tt_25_94': 0.9304347826086956,\n",
       " 'LogisticRegression_StandardScaler_tt_50_25': 0.9642512077294686,\n",
       " 'LogisticRegression_StandardScaler_tt_50_105': 0.9632850241545894,\n",
       " 'LogisticRegression_StandardScaler_tt_50_94': 0.9603864734299516,\n",
       " 'LogisticRegression_StandardScaler_tt_75_25': 0.9632850241545894,\n",
       " 'LogisticRegression_StandardScaler_tt_75_105': 0.9671497584541063,\n",
       " 'LogisticRegression_StandardScaler_tt_75_94': 0.9584541062801932,\n",
       " 'LogisticRegression_StandardScaler_tt_100_25': 0.9594202898550724,\n",
       " 'LogisticRegression_StandardScaler_tt_100_105': 0.9719806763285024,\n",
       " 'LogisticRegression_StandardScaler_tt_100_94': 0.9632850241545894,\n",
       " 'LogisticRegression_StandardScaler_skf_25_25': 0.9429400386847195,\n",
       " 'LogisticRegression_StandardScaler_skf_25_105': 0.9487427466150871,\n",
       " 'LogisticRegression_StandardScaler_skf_25_94': 0.9458413926499033,\n",
       " 'LogisticRegression_StandardScaler_skf_50_25': 0.9477756286266924,\n",
       " 'LogisticRegression_StandardScaler_skf_50_105': 0.9555125725338491,\n",
       " 'LogisticRegression_StandardScaler_skf_50_94': 0.9555125725338491,\n",
       " 'LogisticRegression_StandardScaler_skf_75_25': 0.9564796905222437,\n",
       " 'LogisticRegression_StandardScaler_skf_75_105': 0.9545454545454546,\n",
       " 'LogisticRegression_StandardScaler_skf_75_94': 0.9535783365570599,\n",
       " 'LogisticRegression_StandardScaler_skf_100_25': 0.9545454545454546,\n",
       " 'LogisticRegression_StandardScaler_skf_100_105': 0.9622823984526112,\n",
       " 'LogisticRegression_StandardScaler_skf_100_94': 0.9564796905222437,\n",
       " 'LogisticRegression_StandardScaler_sss_25_25': 0.9429951690821256,\n",
       " 'LogisticRegression_StandardScaler_sss_25_105': 0.9323671497584541,\n",
       " 'LogisticRegression_StandardScaler_sss_25_94': 0.9420289855072463,\n",
       " 'LogisticRegression_StandardScaler_sss_50_25': 0.9603864734299516,\n",
       " 'LogisticRegression_StandardScaler_sss_50_105': 0.9652173913043478,\n",
       " 'LogisticRegression_StandardScaler_sss_50_94': 0.9594202898550724,\n",
       " 'LogisticRegression_StandardScaler_sss_75_25': 0.9710144927536232,\n",
       " 'LogisticRegression_StandardScaler_sss_75_105': 0.9632850241545894,\n",
       " 'LogisticRegression_StandardScaler_sss_75_94': 0.9603864734299516,\n",
       " 'LogisticRegression_StandardScaler_sss_100_25': 0.970048309178744,\n",
       " 'LogisticRegression_StandardScaler_sss_100_105': 0.9594202898550724,\n",
       " 'LogisticRegression_StandardScaler_sss_100_94': 0.9545893719806763,\n",
       " 'LogisticRegression_MinMaxScaler_tt_25_25': 0.9400966183574879,\n",
       " 'LogisticRegression_MinMaxScaler_tt_25_105': 0.9429951690821256,\n",
       " 'LogisticRegression_MinMaxScaler_tt_25_94': 0.9314009661835749,\n",
       " 'LogisticRegression_MinMaxScaler_tt_50_25': 0.9536231884057971,\n",
       " 'LogisticRegression_MinMaxScaler_tt_50_105': 0.9555555555555556,\n",
       " 'LogisticRegression_MinMaxScaler_tt_50_94': 0.9439613526570049,\n",
       " 'LogisticRegression_MinMaxScaler_tt_75_25': 0.9516908212560387,\n",
       " 'LogisticRegression_MinMaxScaler_tt_75_105': 0.9507246376811594,\n",
       " 'LogisticRegression_MinMaxScaler_tt_75_94': 0.9478260869565217,\n",
       " 'LogisticRegression_MinMaxScaler_tt_100_25': 0.9468599033816425,\n",
       " 'LogisticRegression_MinMaxScaler_tt_100_105': 0.9642512077294686,\n",
       " 'LogisticRegression_MinMaxScaler_tt_100_94': 0.9497584541062802,\n",
       " 'LogisticRegression_MinMaxScaler_skf_25_25': 0.9410058027079303,\n",
       " 'LogisticRegression_MinMaxScaler_skf_25_105': 0.9313346228239845,\n",
       " 'LogisticRegression_MinMaxScaler_skf_25_94': 0.9332688588007737,\n",
       " 'LogisticRegression_MinMaxScaler_skf_50_25': 0.9535783365570599,\n",
       " 'LogisticRegression_MinMaxScaler_skf_50_105': 0.9487427466150871,\n",
       " 'LogisticRegression_MinMaxScaler_skf_50_94': 0.9439071566731141,\n",
       " 'LogisticRegression_MinMaxScaler_skf_75_25': 0.9593810444874274,\n",
       " 'LogisticRegression_MinMaxScaler_skf_75_105': 0.9468085106382979,\n",
       " 'LogisticRegression_MinMaxScaler_skf_75_94': 0.9448742746615088,\n",
       " 'LogisticRegression_MinMaxScaler_skf_100_25': 0.960348162475822,\n",
       " 'LogisticRegression_MinMaxScaler_skf_100_105': 0.9497098646034816,\n",
       " 'LogisticRegression_MinMaxScaler_skf_100_94': 0.9468085106382979,\n",
       " 'LogisticRegression_MinMaxScaler_sss_25_25': 0.9285024154589372,\n",
       " 'LogisticRegression_MinMaxScaler_sss_25_105': 0.9420289855072463,\n",
       " 'LogisticRegression_MinMaxScaler_sss_25_94': 0.9323671497584541,\n",
       " 'LogisticRegression_MinMaxScaler_sss_50_25': 0.9478260869565217,\n",
       " 'LogisticRegression_MinMaxScaler_sss_50_105': 0.9545893719806763,\n",
       " 'LogisticRegression_MinMaxScaler_sss_50_94': 0.9478260869565217,\n",
       " 'LogisticRegression_MinMaxScaler_sss_75_25': 0.9507246376811594,\n",
       " 'LogisticRegression_MinMaxScaler_sss_75_105': 0.9497584541062802,\n",
       " 'LogisticRegression_MinMaxScaler_sss_75_94': 0.9507246376811594,\n",
       " 'LogisticRegression_MinMaxScaler_sss_100_25': 0.9497584541062802,\n",
       " 'LogisticRegression_MinMaxScaler_sss_100_105': 0.9594202898550724,\n",
       " 'LogisticRegression_MinMaxScaler_sss_100_94': 0.9536231884057971,\n",
       " 'RandomForest_100_StandardScaler_tt_25_25': 0.9681159420289855,\n",
       " 'RandomForest_100_StandardScaler_tt_25_105': 0.970048309178744,\n",
       " 'RandomForest_100_StandardScaler_tt_25_94': 0.9642512077294686,\n",
       " 'RandomForest_100_StandardScaler_tt_50_25': 0.9690821256038648,\n",
       " 'RandomForest_100_StandardScaler_tt_50_105': 0.970048309178744,\n",
       " 'RandomForest_100_StandardScaler_tt_50_94': 0.9671497584541063,\n",
       " 'RandomForest_100_StandardScaler_tt_75_25': 0.9739130434782609,\n",
       " 'RandomForest_100_StandardScaler_tt_75_105': 0.9690821256038648,\n",
       " 'RandomForest_100_StandardScaler_tt_75_94': 0.9710144927536232,\n",
       " 'RandomForest_100_StandardScaler_tt_100_25': 0.9690821256038648,\n",
       " 'RandomForest_100_StandardScaler_tt_100_105': 0.9710144927536232,\n",
       " 'RandomForest_100_StandardScaler_tt_100_94': 0.9690821256038648,\n",
       " 'RandomForest_100_StandardScaler_skf_25_25': 0.9680851063829787,\n",
       " 'RandomForest_100_StandardScaler_skf_25_105': 0.9593810444874274,\n",
       " 'RandomForest_100_StandardScaler_skf_25_94': 0.9574468085106383,\n",
       " 'RandomForest_100_StandardScaler_skf_50_25': 0.9690522243713733,\n",
       " 'RandomForest_100_StandardScaler_skf_50_105': 0.9642166344294004,\n",
       " 'RandomForest_100_StandardScaler_skf_50_94': 0.965183752417795,\n",
       " 'RandomForest_100_StandardScaler_skf_75_25': 0.9680851063829787,\n",
       " 'RandomForest_100_StandardScaler_skf_75_105': 0.9690522243713733,\n",
       " 'RandomForest_100_StandardScaler_skf_75_94': 0.9671179883945842,\n",
       " 'RandomForest_100_StandardScaler_skf_100_25': 0.9700193423597679,\n",
       " 'RandomForest_100_StandardScaler_skf_100_105': 0.9671179883945842,\n",
       " 'RandomForest_100_StandardScaler_skf_100_94': 0.9661508704061895,\n",
       " 'RandomForest_100_StandardScaler_sss_25_25': 0.9681159420289855,\n",
       " 'RandomForest_100_StandardScaler_sss_25_105': 0.9671497584541063,\n",
       " 'RandomForest_100_StandardScaler_sss_25_94': 0.9584541062801932,\n",
       " 'RandomForest_100_StandardScaler_sss_50_25': 0.970048309178744,\n",
       " 'RandomForest_100_StandardScaler_sss_50_105': 0.970048309178744,\n",
       " 'RandomForest_100_StandardScaler_sss_50_94': 0.9632850241545894,\n",
       " 'RandomForest_100_StandardScaler_sss_75_25': 0.9719806763285024,\n",
       " 'RandomForest_100_StandardScaler_sss_75_105': 0.978743961352657,\n",
       " 'RandomForest_100_StandardScaler_sss_75_94': 0.9603864734299516,\n",
       " 'RandomForest_100_StandardScaler_sss_100_25': 0.9690821256038648,\n",
       " 'RandomForest_100_StandardScaler_sss_100_105': 0.9729468599033816,\n",
       " 'RandomForest_100_StandardScaler_sss_100_94': 0.9642512077294686,\n",
       " 'RandomForest_100_MinMaxScaler_tt_25_25': 0.9681159420289855,\n",
       " 'RandomForest_100_MinMaxScaler_tt_25_105': 0.970048309178744,\n",
       " 'RandomForest_100_MinMaxScaler_tt_25_94': 0.9652173913043478,\n",
       " 'RandomForest_100_MinMaxScaler_tt_50_25': 0.9632850241545894,\n",
       " 'RandomForest_100_MinMaxScaler_tt_50_105': 0.9719806763285024,\n",
       " 'RandomForest_100_MinMaxScaler_tt_50_94': 0.9671497584541063,\n",
       " 'RandomForest_100_MinMaxScaler_tt_75_25': 0.9632850241545894,\n",
       " 'RandomForest_100_MinMaxScaler_tt_75_105': 0.9729468599033816,\n",
       " 'RandomForest_100_MinMaxScaler_tt_75_94': 0.9652173913043478,\n",
       " 'RandomForest_100_MinMaxScaler_tt_100_25': 0.9632850241545894,\n",
       " 'RandomForest_100_MinMaxScaler_tt_100_105': 0.9768115942028985,\n",
       " 'RandomForest_100_MinMaxScaler_tt_100_94': 0.9690821256038648,\n",
       " 'RandomForest_100_MinMaxScaler_skf_25_25': 0.9700193423597679,\n",
       " 'RandomForest_100_MinMaxScaler_skf_25_105': 0.9700193423597679,\n",
       " 'RandomForest_100_MinMaxScaler_skf_25_94': 0.9526112185686654,\n",
       " 'RandomForest_100_MinMaxScaler_skf_50_25': 0.9671179883945842,\n",
       " 'RandomForest_100_MinMaxScaler_skf_50_105': 0.965183752417795,\n",
       " 'RandomForest_100_MinMaxScaler_skf_50_94': 0.9535783365570599,\n",
       " 'RandomForest_100_MinMaxScaler_skf_75_25': 0.9622823984526112,\n",
       " 'RandomForest_100_MinMaxScaler_skf_75_105': 0.960348162475822,\n",
       " 'RandomForest_100_MinMaxScaler_skf_75_94': 0.9564796905222437,\n",
       " 'RandomForest_100_MinMaxScaler_skf_100_25': 0.965183752417795,\n",
       " 'RandomForest_100_MinMaxScaler_skf_100_105': 0.9622823984526112,\n",
       " 'RandomForest_100_MinMaxScaler_skf_100_94': 0.9477756286266924,\n",
       " 'RandomForest_100_MinMaxScaler_sss_25_25': 0.9652173913043478,\n",
       " 'RandomForest_100_MinMaxScaler_sss_25_105': 0.9710144927536232,\n",
       " 'RandomForest_100_MinMaxScaler_sss_25_94': 0.9671497584541063,\n",
       " 'RandomForest_100_MinMaxScaler_sss_50_25': 0.9671497584541063,\n",
       " 'RandomForest_100_MinMaxScaler_sss_50_105': 0.9623188405797102,\n",
       " 'RandomForest_100_MinMaxScaler_sss_50_94': 0.9671497584541063,\n",
       " 'RandomForest_100_MinMaxScaler_sss_75_25': 0.966183574879227,\n",
       " 'RandomForest_100_MinMaxScaler_sss_75_105': 0.966183574879227,\n",
       " 'RandomForest_100_MinMaxScaler_sss_75_94': 0.9642512077294686,\n",
       " 'RandomForest_100_MinMaxScaler_sss_100_25': 0.966183574879227,\n",
       " 'RandomForest_100_MinMaxScaler_sss_100_105': 0.9681159420289855,\n",
       " 'RandomForest_100_MinMaxScaler_sss_100_94': 0.9632850241545894,\n",
       " 'RandomForest_200_StandardScaler_tt_25_25': 0.9671497584541063,\n",
       " 'RandomForest_200_StandardScaler_tt_25_105': 0.9652173913043478,\n",
       " 'RandomForest_200_StandardScaler_tt_25_94': 0.9690821256038648,\n",
       " 'RandomForest_200_StandardScaler_tt_50_25': 0.9739130434782609,\n",
       " 'RandomForest_200_StandardScaler_tt_50_105': 0.9690821256038648,\n",
       " 'RandomForest_200_StandardScaler_tt_50_94': 0.9671497584541063,\n",
       " 'RandomForest_200_StandardScaler_tt_75_25': 0.9758454106280193,\n",
       " 'RandomForest_200_StandardScaler_tt_75_105': 0.9671497584541063,\n",
       " 'RandomForest_200_StandardScaler_tt_75_94': 0.9710144927536232,\n",
       " 'RandomForest_200_StandardScaler_tt_100_25': 0.9710144927536232,\n",
       " 'RandomForest_200_StandardScaler_tt_100_105': 0.9690821256038648,\n",
       " 'RandomForest_200_StandardScaler_tt_100_94': 0.966183574879227,\n",
       " 'RandomForest_200_StandardScaler_skf_25_25': 0.9671179883945842,\n",
       " 'RandomForest_200_StandardScaler_skf_25_105': 0.9613152804642167,\n",
       " 'RandomForest_200_StandardScaler_skf_25_94': 0.9545454545454546,\n",
       " 'RandomForest_200_StandardScaler_skf_50_25': 0.9680851063829787,\n",
       " 'RandomForest_200_StandardScaler_skf_50_105': 0.9661508704061895,\n",
       " 'RandomForest_200_StandardScaler_skf_50_94': 0.965183752417795,\n",
       " 'RandomForest_200_StandardScaler_skf_75_25': 0.9700193423597679,\n",
       " 'RandomForest_200_StandardScaler_skf_75_105': 0.9661508704061895,\n",
       " 'RandomForest_200_StandardScaler_skf_75_94': 0.9632495164410058,\n",
       " 'RandomForest_200_StandardScaler_skf_100_25': 0.9709864603481625,\n",
       " 'RandomForest_200_StandardScaler_skf_100_105': 0.9700193423597679,\n",
       " 'RandomForest_200_StandardScaler_skf_100_94': 0.9642166344294004,\n",
       " 'RandomForest_200_StandardScaler_sss_25_25': 0.966183574879227,\n",
       " 'RandomForest_200_StandardScaler_sss_25_105': 0.9681159420289855,\n",
       " 'RandomForest_200_StandardScaler_sss_25_94': 0.9584541062801932,\n",
       " 'RandomForest_200_StandardScaler_sss_50_25': 0.9671497584541063,\n",
       " 'RandomForest_200_StandardScaler_sss_50_105': 0.9719806763285024,\n",
       " 'RandomForest_200_StandardScaler_sss_50_94': 0.9603864734299516,\n",
       " 'RandomForest_200_StandardScaler_sss_75_25': 0.9710144927536232,\n",
       " 'RandomForest_200_StandardScaler_sss_75_105': 0.9710144927536232,\n",
       " 'RandomForest_200_StandardScaler_sss_75_94': 0.961352657004831,\n",
       " 'RandomForest_200_StandardScaler_sss_100_25': 0.9710144927536232,\n",
       " 'RandomForest_200_StandardScaler_sss_100_105': 0.970048309178744,\n",
       " 'RandomForest_200_StandardScaler_sss_100_94': 0.9623188405797102,\n",
       " 'RandomForest_200_MinMaxScaler_tt_25_25': 0.9690821256038648,\n",
       " 'RandomForest_200_MinMaxScaler_tt_25_105': 0.9671497584541063,\n",
       " 'RandomForest_200_MinMaxScaler_tt_25_94': 0.970048309178744,\n",
       " 'RandomForest_200_MinMaxScaler_tt_50_25': 0.9690821256038648,\n",
       " 'RandomForest_200_MinMaxScaler_tt_50_105': 0.9719806763285024,\n",
       " 'RandomForest_200_MinMaxScaler_tt_50_94': 0.9681159420289855,\n",
       " 'RandomForest_200_MinMaxScaler_tt_75_25': 0.9632850241545894,\n",
       " 'RandomForest_200_MinMaxScaler_tt_75_105': 0.9777777777777777,\n",
       " 'RandomForest_200_MinMaxScaler_tt_75_94': 0.9632850241545894,\n",
       " 'RandomForest_200_MinMaxScaler_tt_100_25': 0.9681159420289855,\n",
       " 'RandomForest_200_MinMaxScaler_tt_100_105': 0.978743961352657,\n",
       " 'RandomForest_200_MinMaxScaler_tt_100_94': 0.9642512077294686,\n",
       " 'RandomForest_200_MinMaxScaler_skf_25_25': 0.9690522243713733,\n",
       " 'RandomForest_200_MinMaxScaler_skf_25_105': 0.965183752417795,\n",
       " 'RandomForest_200_MinMaxScaler_skf_25_94': 0.9516441005802708,\n",
       " 'RandomForest_200_MinMaxScaler_skf_50_25': 0.9680851063829787,\n",
       " 'RandomForest_200_MinMaxScaler_skf_50_105': 0.9671179883945842,\n",
       " 'RandomForest_200_MinMaxScaler_skf_50_94': 0.9535783365570599,\n",
       " 'RandomForest_200_MinMaxScaler_skf_75_25': 0.9680851063829787,\n",
       " 'RandomForest_200_MinMaxScaler_skf_75_105': 0.960348162475822,\n",
       " 'RandomForest_200_MinMaxScaler_skf_75_94': 0.9545454545454546,\n",
       " 'RandomForest_200_MinMaxScaler_skf_100_25': 0.9671179883945842,\n",
       " 'RandomForest_200_MinMaxScaler_skf_100_105': 0.9555125725338491,\n",
       " 'RandomForest_200_MinMaxScaler_skf_100_94': 0.9555125725338491,\n",
       " 'RandomForest_200_MinMaxScaler_sss_25_25': 0.970048309178744,\n",
       " 'RandomForest_200_MinMaxScaler_sss_25_105': 0.9681159420289855,\n",
       " 'RandomForest_200_MinMaxScaler_sss_25_94': 0.9642512077294686,\n",
       " 'RandomForest_200_MinMaxScaler_sss_50_25': 0.9710144927536232,\n",
       " 'RandomForest_200_MinMaxScaler_sss_50_105': 0.9719806763285024,\n",
       " 'RandomForest_200_MinMaxScaler_sss_50_94': 0.9642512077294686,\n",
       " 'RandomForest_200_MinMaxScaler_sss_75_25': 0.9710144927536232,\n",
       " 'RandomForest_200_MinMaxScaler_sss_75_105': 0.9671497584541063,\n",
       " 'RandomForest_200_MinMaxScaler_sss_75_94': 0.966183574879227,\n",
       " 'RandomForest_200_MinMaxScaler_sss_100_25': 0.9690821256038648,\n",
       " 'RandomForest_200_MinMaxScaler_sss_100_105': 0.9710144927536232,\n",
       " 'RandomForest_200_MinMaxScaler_sss_100_94': 0.9671497584541063,\n",
       " 'SVMLinear_StandardScaler_tt_25_25': 0.9487922705314009,\n",
       " 'SVMLinear_StandardScaler_tt_25_105': 0.9487922705314009,\n",
       " 'SVMLinear_StandardScaler_tt_25_94': 0.9449275362318841,\n",
       " 'SVMLinear_StandardScaler_tt_50_25': 0.9594202898550724,\n",
       " 'SVMLinear_StandardScaler_tt_50_105': 0.970048309178744,\n",
       " 'SVMLinear_StandardScaler_tt_50_94': 0.9603864734299516,\n",
       " 'SVMLinear_StandardScaler_tt_75_25': 0.9652173913043478,\n",
       " 'SVMLinear_StandardScaler_tt_75_105': 0.9690821256038648,\n",
       " 'SVMLinear_StandardScaler_tt_75_94': 0.961352657004831,\n",
       " 'SVMLinear_StandardScaler_tt_100_25': 0.957487922705314,\n",
       " 'SVMLinear_StandardScaler_tt_100_105': 0.9681159420289855,\n",
       " 'SVMLinear_StandardScaler_tt_100_94': 0.9584541062801932,\n",
       " 'SVMLinear_StandardScaler_skf_25_25': 0.9506769825918762,\n",
       " 'SVMLinear_StandardScaler_skf_25_105': 0.937137330754352,\n",
       " 'SVMLinear_StandardScaler_skf_25_94': 0.937137330754352,\n",
       " 'SVMLinear_StandardScaler_skf_50_25': 0.9526112185686654,\n",
       " 'SVMLinear_StandardScaler_skf_50_105': 0.9506769825918762,\n",
       " 'SVMLinear_StandardScaler_skf_50_94': 0.9526112185686654,\n",
       " 'SVMLinear_StandardScaler_skf_75_25': 0.9613152804642167,\n",
       " 'SVMLinear_StandardScaler_skf_75_105': 0.9584139264990329,\n",
       " 'SVMLinear_StandardScaler_skf_75_94': 0.9506769825918762,\n",
       " 'SVMLinear_StandardScaler_skf_100_25': 0.9526112185686654,\n",
       " 'SVMLinear_StandardScaler_skf_100_105': 0.9613152804642167,\n",
       " 'SVMLinear_StandardScaler_skf_100_94': 0.9584139264990329,\n",
       " 'SVMLinear_StandardScaler_sss_25_25': 0.9449275362318841,\n",
       " 'SVMLinear_StandardScaler_sss_25_105': 0.9429951690821256,\n",
       " 'SVMLinear_StandardScaler_sss_25_94': 0.9487922705314009,\n",
       " 'SVMLinear_StandardScaler_sss_50_25': 0.961352657004831,\n",
       " 'SVMLinear_StandardScaler_sss_50_105': 0.961352657004831,\n",
       " 'SVMLinear_StandardScaler_sss_50_94': 0.9555555555555556,\n",
       " 'SVMLinear_StandardScaler_sss_75_25': 0.9652173913043478,\n",
       " 'SVMLinear_StandardScaler_sss_75_105': 0.9603864734299516,\n",
       " 'SVMLinear_StandardScaler_sss_75_94': 0.9555555555555556,\n",
       " 'SVMLinear_StandardScaler_sss_100_25': 0.9671497584541063,\n",
       " 'SVMLinear_StandardScaler_sss_100_105': 0.966183574879227,\n",
       " 'SVMLinear_StandardScaler_sss_100_94': 0.957487922705314,\n",
       " 'SVMLinear_MinMaxScaler_tt_25_25': 0.9478260869565217,\n",
       " 'SVMLinear_MinMaxScaler_tt_25_105': 0.9545893719806763,\n",
       " 'SVMLinear_MinMaxScaler_tt_25_94': 0.9449275362318841,\n",
       " 'SVMLinear_MinMaxScaler_tt_50_25': 0.9555555555555556,\n",
       " 'SVMLinear_MinMaxScaler_tt_50_105': 0.9565217391304348,\n",
       " 'SVMLinear_MinMaxScaler_tt_50_94': 0.9497584541062802,\n",
       " 'SVMLinear_MinMaxScaler_tt_75_25': 0.9555555555555556,\n",
       " 'SVMLinear_MinMaxScaler_tt_75_105': 0.957487922705314,\n",
       " 'SVMLinear_MinMaxScaler_tt_75_94': 0.9439613526570049,\n",
       " 'SVMLinear_MinMaxScaler_tt_100_25': 0.961352657004831,\n",
       " 'SVMLinear_MinMaxScaler_tt_100_105': 0.9652173913043478,\n",
       " 'SVMLinear_MinMaxScaler_tt_100_94': 0.9545893719806763,\n",
       " 'SVMLinear_MinMaxScaler_skf_25_25': 0.9477756286266924,\n",
       " 'SVMLinear_MinMaxScaler_skf_25_105': 0.9458413926499033,\n",
       " 'SVMLinear_MinMaxScaler_skf_25_94': 0.9352030947775629,\n",
       " 'SVMLinear_MinMaxScaler_skf_50_25': 0.9584139264990329,\n",
       " 'SVMLinear_MinMaxScaler_skf_50_105': 0.9555125725338491,\n",
       " 'SVMLinear_MinMaxScaler_skf_50_94': 0.9487427466150871,\n",
       " 'SVMLinear_MinMaxScaler_skf_75_25': 0.9574468085106383,\n",
       " 'SVMLinear_MinMaxScaler_skf_75_105': 0.9593810444874274,\n",
       " 'SVMLinear_MinMaxScaler_skf_75_94': 0.9390715667311412,\n",
       " 'SVMLinear_MinMaxScaler_skf_100_25': 0.9613152804642167,\n",
       " 'SVMLinear_MinMaxScaler_skf_100_105': 0.9516441005802708,\n",
       " 'SVMLinear_MinMaxScaler_skf_100_94': 0.9429400386847195,\n",
       " 'SVMLinear_MinMaxScaler_sss_25_25': 0.957487922705314,\n",
       " 'SVMLinear_MinMaxScaler_sss_25_105': 0.9458937198067633,\n",
       " 'SVMLinear_MinMaxScaler_sss_25_94': 0.9439613526570049,\n",
       " 'SVMLinear_MinMaxScaler_sss_50_25': 0.9632850241545894,\n",
       " 'SVMLinear_MinMaxScaler_sss_50_105': 0.9468599033816425,\n",
       " 'SVMLinear_MinMaxScaler_sss_50_94': 0.9507246376811594,\n",
       " 'SVMLinear_MinMaxScaler_sss_75_25': 0.9623188405797102,\n",
       " 'SVMLinear_MinMaxScaler_sss_75_105': 0.9487922705314009,\n",
       " 'SVMLinear_MinMaxScaler_sss_75_94': 0.9449275362318841,\n",
       " 'SVMLinear_MinMaxScaler_sss_100_25': 0.9710144927536232,\n",
       " 'SVMLinear_MinMaxScaler_sss_100_105': 0.9565217391304348,\n",
       " 'SVMLinear_MinMaxScaler_sss_100_94': 0.9526570048309179,\n",
       " 'SVMSigmoid_StandardScaler_tt_25_25': 0.8840579710144928,\n",
       " 'SVMSigmoid_StandardScaler_tt_25_105': 0.8183574879227054,\n",
       " 'SVMSigmoid_StandardScaler_tt_25_94': 0.8164251207729468,\n",
       " 'SVMSigmoid_StandardScaler_tt_50_25': 0.8966183574879227,\n",
       " 'SVMSigmoid_StandardScaler_tt_50_105': 0.8309178743961353,\n",
       " 'SVMSigmoid_StandardScaler_tt_50_94': 0.8309178743961353,\n",
       " 'SVMSigmoid_StandardScaler_tt_75_25': 0.855072463768116,\n",
       " 'SVMSigmoid_StandardScaler_tt_75_105': 0.8367149758454107,\n",
       " 'SVMSigmoid_StandardScaler_tt_75_94': 0.842512077294686,\n",
       " 'SVMSigmoid_StandardScaler_tt_100_25': 0.9053140096618357,\n",
       " 'SVMSigmoid_StandardScaler_tt_100_105': 0.8483091787439614,\n",
       " 'SVMSigmoid_StandardScaler_tt_100_94': 0.855072463768116,\n",
       " 'SVMSigmoid_StandardScaler_skf_25_25': 0.8404255319148937,\n",
       " 'SVMSigmoid_StandardScaler_skf_25_105': 0.8462282398452611,\n",
       " 'SVMSigmoid_StandardScaler_skf_25_94': 0.8201160541586073,\n",
       " 'SVMSigmoid_StandardScaler_skf_50_25': 0.8462282398452611,\n",
       " 'SVMSigmoid_StandardScaler_skf_50_105': 0.8539651837524178,\n",
       " 'SVMSigmoid_StandardScaler_skf_50_94': 0.8278529980657641,\n",
       " 'SVMSigmoid_StandardScaler_skf_75_25': 0.8568665377176016,\n",
       " 'SVMSigmoid_StandardScaler_skf_75_105': 0.851063829787234,\n",
       " 'SVMSigmoid_StandardScaler_skf_75_94': 0.8500967117988395,\n",
       " 'SVMSigmoid_StandardScaler_skf_100_25': 0.8588007736943907,\n",
       " 'SVMSigmoid_StandardScaler_skf_100_105': 0.8568665377176016,\n",
       " 'SVMSigmoid_StandardScaler_skf_100_94': 0.8529980657640233,\n",
       " 'SVMSigmoid_StandardScaler_sss_25_25': 0.8241545893719807,\n",
       " 'SVMSigmoid_StandardScaler_sss_25_105': 0.8135265700483092,\n",
       " 'SVMSigmoid_StandardScaler_sss_25_94': 0.8280193236714976,\n",
       " 'SVMSigmoid_StandardScaler_sss_50_25': 0.8309178743961353,\n",
       " 'SVMSigmoid_StandardScaler_sss_50_105': 0.8164251207729468,\n",
       " 'SVMSigmoid_StandardScaler_sss_50_94': 0.8338164251207729,\n",
       " 'SVMSigmoid_StandardScaler_sss_75_25': 0.8347826086956521,\n",
       " 'SVMSigmoid_StandardScaler_sss_75_105': 0.8376811594202899,\n",
       " 'SVMSigmoid_StandardScaler_sss_75_94': 0.8434782608695652,\n",
       " 'SVMSigmoid_StandardScaler_sss_100_25': 0.8483091787439614,\n",
       " 'SVMSigmoid_StandardScaler_sss_100_105': 0.842512077294686,\n",
       " 'SVMSigmoid_StandardScaler_sss_100_94': 0.8502415458937198,\n",
       " 'SVMSigmoid_MinMaxScaler_tt_25_25': 0.8560386473429952,\n",
       " 'SVMSigmoid_MinMaxScaler_tt_25_105': 0.8028985507246377,\n",
       " 'SVMSigmoid_MinMaxScaler_tt_25_94': 0.8231884057971014,\n",
       " 'SVMSigmoid_MinMaxScaler_tt_50_25': 0.8347826086956521,\n",
       " 'SVMSigmoid_MinMaxScaler_tt_50_105': 0.8144927536231884,\n",
       " 'SVMSigmoid_MinMaxScaler_tt_50_94': 0.8289855072463768,\n",
       " 'SVMSigmoid_MinMaxScaler_tt_75_25': 0.8357487922705314,\n",
       " 'SVMSigmoid_MinMaxScaler_tt_75_105': 0.8222222222222222,\n",
       " 'SVMSigmoid_MinMaxScaler_tt_75_94': 0.881159420289855,\n",
       " 'SVMSigmoid_MinMaxScaler_tt_100_25': 0.8347826086956521,\n",
       " 'SVMSigmoid_MinMaxScaler_tt_100_105': 0.8241545893719807,\n",
       " 'SVMSigmoid_MinMaxScaler_tt_100_94': 0.8879227053140096,\n",
       " 'SVMSigmoid_MinMaxScaler_skf_25_25': 0.8239845261121856,\n",
       " 'SVMSigmoid_MinMaxScaler_skf_25_105': 0.8317214700193424,\n",
       " 'SVMSigmoid_MinMaxScaler_skf_25_94': 0.8133462282398453,\n",
       " 'SVMSigmoid_MinMaxScaler_skf_50_25': 0.8230174081237911,\n",
       " 'SVMSigmoid_MinMaxScaler_skf_50_105': 0.8346228239845261,\n",
       " 'SVMSigmoid_MinMaxScaler_skf_50_94': 0.8220502901353965,\n",
       " 'SVMSigmoid_MinMaxScaler_skf_75_25': 0.8268858800773694,\n",
       " 'SVMSigmoid_MinMaxScaler_skf_75_105': 0.8365570599613152,\n",
       " 'SVMSigmoid_MinMaxScaler_skf_75_94': 0.8239845261121856,\n",
       " 'SVMSigmoid_MinMaxScaler_skf_100_25': 0.8413926499032882,\n",
       " 'SVMSigmoid_MinMaxScaler_skf_100_105': 0.8404255319148937,\n",
       " 'SVMSigmoid_MinMaxScaler_skf_100_94': 0.8307543520309478,\n",
       " 'SVMSigmoid_MinMaxScaler_sss_25_25': 0.8676328502415459,\n",
       " 'SVMSigmoid_MinMaxScaler_sss_25_105': 0.8135265700483092,\n",
       " 'SVMSigmoid_MinMaxScaler_sss_25_94': 0.8115942028985508,\n",
       " 'SVMSigmoid_MinMaxScaler_sss_50_25': 0.8289855072463768,\n",
       " 'SVMSigmoid_MinMaxScaler_sss_50_105': 0.8270531400966183,\n",
       " 'SVMSigmoid_MinMaxScaler_sss_50_94': 0.8270531400966183,\n",
       " 'SVMSigmoid_MinMaxScaler_sss_75_25': 0.8724637681159421,\n",
       " 'SVMSigmoid_MinMaxScaler_sss_75_105': 0.8772946859903382,\n",
       " 'SVMSigmoid_MinMaxScaler_sss_75_94': 0.851207729468599,\n",
       " 'SVMSigmoid_MinMaxScaler_sss_100_25': 0.8338164251207729,\n",
       " 'SVMSigmoid_MinMaxScaler_sss_100_105': 0.8309178743961353,\n",
       " 'SVMSigmoid_MinMaxScaler_sss_100_94': 0.8318840579710145,\n",
       " 'KNN_5n_StandardScaler_tt_25_25': 0.9642512077294686,\n",
       " 'KNN_5n_StandardScaler_tt_25_105': 0.9555555555555556,\n",
       " 'KNN_5n_StandardScaler_tt_25_94': 0.9565217391304348,\n",
       " 'KNN_5n_StandardScaler_tt_50_25': 0.9565217391304348,\n",
       " 'KNN_5n_StandardScaler_tt_50_105': 0.957487922705314,\n",
       " 'KNN_5n_StandardScaler_tt_50_94': 0.9516908212560387,\n",
       " 'KNN_5n_StandardScaler_tt_75_25': 0.9594202898550724,\n",
       " 'KNN_5n_StandardScaler_tt_75_105': 0.9603864734299516,\n",
       " 'KNN_5n_StandardScaler_tt_75_94': 0.9516908212560387,\n",
       " 'KNN_5n_StandardScaler_tt_100_25': 0.9516908212560387,\n",
       " 'KNN_5n_StandardScaler_tt_100_105': 0.9603864734299516,\n",
       " 'KNN_5n_StandardScaler_tt_100_94': 0.9507246376811594,\n",
       " 'KNN_5n_StandardScaler_skf_25_25': 0.9564796905222437,\n",
       " 'KNN_5n_StandardScaler_skf_25_105': 0.965183752417795,\n",
       " 'KNN_5n_StandardScaler_skf_25_94': 0.9535783365570599,\n",
       " 'KNN_5n_StandardScaler_skf_50_25': 0.9564796905222437,\n",
       " 'KNN_5n_StandardScaler_skf_50_105': 0.9613152804642167,\n",
       " 'KNN_5n_StandardScaler_skf_50_94': 0.9468085106382979,\n",
       " 'KNN_5n_StandardScaler_skf_75_25': 0.9555125725338491,\n",
       " 'KNN_5n_StandardScaler_skf_75_105': 0.9564796905222437,\n",
       " 'KNN_5n_StandardScaler_skf_75_94': 0.9468085106382979,\n",
       " 'KNN_5n_StandardScaler_skf_100_25': 0.9439071566731141,\n",
       " 'KNN_5n_StandardScaler_skf_100_105': 0.9564796905222437,\n",
       " 'KNN_5n_StandardScaler_skf_100_94': 0.9410058027079303,\n",
       " 'KNN_5n_StandardScaler_sss_25_25': 0.9545893719806763,\n",
       " 'KNN_5n_StandardScaler_sss_25_105': 0.9603864734299516,\n",
       " 'KNN_5n_StandardScaler_sss_25_94': 0.9507246376811594,\n",
       " 'KNN_5n_StandardScaler_sss_50_25': 0.9545893719806763,\n",
       " 'KNN_5n_StandardScaler_sss_50_105': 0.9681159420289855,\n",
       " 'KNN_5n_StandardScaler_sss_50_94': 0.9497584541062802,\n",
       " 'KNN_5n_StandardScaler_sss_75_25': 0.9565217391304348,\n",
       " 'KNN_5n_StandardScaler_sss_75_105': 0.9681159420289855,\n",
       " 'KNN_5n_StandardScaler_sss_75_94': 0.9545893719806763,\n",
       " 'KNN_5n_StandardScaler_sss_100_25': 0.966183574879227,\n",
       " 'KNN_5n_StandardScaler_sss_100_105': 0.9594202898550724,\n",
       " 'KNN_5n_StandardScaler_sss_100_94': 0.9526570048309179,\n",
       " 'KNN_5n_MinMaxScaler_tt_25_25': 0.957487922705314,\n",
       " 'KNN_5n_MinMaxScaler_tt_25_105': 0.9584541062801932,\n",
       " 'KNN_5n_MinMaxScaler_tt_25_94': 0.957487922705314,\n",
       " 'KNN_5n_MinMaxScaler_tt_50_25': 0.957487922705314,\n",
       " 'KNN_5n_MinMaxScaler_tt_50_105': 0.957487922705314,\n",
       " 'KNN_5n_MinMaxScaler_tt_50_94': 0.9478260869565217,\n",
       " 'KNN_5n_MinMaxScaler_tt_75_25': 0.9478260869565217,\n",
       " 'KNN_5n_MinMaxScaler_tt_75_105': 0.9565217391304348,\n",
       " 'KNN_5n_MinMaxScaler_tt_75_94': 0.9439613526570049,\n",
       " 'KNN_5n_MinMaxScaler_tt_100_25': 0.9526570048309179,\n",
       " 'KNN_5n_MinMaxScaler_tt_100_105': 0.9458937198067633,\n",
       " 'KNN_5n_MinMaxScaler_tt_100_94': 0.9400966183574879,\n",
       " 'KNN_5n_MinMaxScaler_skf_25_25': 0.9574468085106383,\n",
       " 'KNN_5n_MinMaxScaler_skf_25_105': 0.9593810444874274,\n",
       " 'KNN_5n_MinMaxScaler_skf_25_94': 0.9448742746615088,\n",
       " 'KNN_5n_MinMaxScaler_skf_50_25': 0.9458413926499033,\n",
       " 'KNN_5n_MinMaxScaler_skf_50_105': 0.9526112185686654,\n",
       " 'KNN_5n_MinMaxScaler_skf_50_94': 0.9400386847195358,\n",
       " 'KNN_5n_MinMaxScaler_skf_75_25': 0.9400386847195358,\n",
       " 'KNN_5n_MinMaxScaler_skf_75_105': 0.9506769825918762,\n",
       " 'KNN_5n_MinMaxScaler_skf_75_94': 0.9323017408123792,\n",
       " 'KNN_5n_MinMaxScaler_skf_100_25': 0.9352030947775629,\n",
       " 'KNN_5n_MinMaxScaler_skf_100_105': 0.9410058027079303,\n",
       " 'KNN_5n_MinMaxScaler_skf_100_94': 0.9264990328820116,\n",
       " 'KNN_5n_MinMaxScaler_sss_25_25': 0.9671497584541063,\n",
       " 'KNN_5n_MinMaxScaler_sss_25_105': 0.9526570048309179,\n",
       " 'KNN_5n_MinMaxScaler_sss_25_94': 0.9536231884057971,\n",
       " 'KNN_5n_MinMaxScaler_sss_50_25': 0.9555555555555556,\n",
       " 'KNN_5n_MinMaxScaler_sss_50_105': 0.9478260869565217,\n",
       " 'KNN_5n_MinMaxScaler_sss_50_94': 0.9487922705314009,\n",
       " 'KNN_5n_MinMaxScaler_sss_75_25': 0.9555555555555556,\n",
       " 'KNN_5n_MinMaxScaler_sss_75_105': 0.9449275362318841,\n",
       " 'KNN_5n_MinMaxScaler_sss_75_94': 0.9420289855072463,\n",
       " 'KNN_5n_MinMaxScaler_sss_100_25': 0.9555555555555556,\n",
       " 'KNN_5n_MinMaxScaler_sss_100_105': 0.9352657004830918,\n",
       " 'KNN_5n_MinMaxScaler_sss_100_94': 0.9333333333333333,\n",
       " 'KNN_15n_StandardScaler_tt_25_25': 0.9545893719806763,\n",
       " 'KNN_15n_StandardScaler_tt_25_105': 0.9516908212560387,\n",
       " 'KNN_15n_StandardScaler_tt_25_94': 0.9526570048309179,\n",
       " 'KNN_15n_StandardScaler_tt_50_25': 0.9565217391304348,\n",
       " 'KNN_15n_StandardScaler_tt_50_105': 0.9449275362318841,\n",
       " 'KNN_15n_StandardScaler_tt_50_94': 0.9536231884057971,\n",
       " 'KNN_15n_StandardScaler_tt_75_25': 0.9526570048309179,\n",
       " 'KNN_15n_StandardScaler_tt_75_105': 0.9497584541062802,\n",
       " 'KNN_15n_StandardScaler_tt_75_94': 0.9449275362318841,\n",
       " 'KNN_15n_StandardScaler_tt_100_25': 0.9478260869565217,\n",
       " 'KNN_15n_StandardScaler_tt_100_105': 0.9420289855072463,\n",
       " 'KNN_15n_StandardScaler_tt_100_94': 0.9391304347826087,\n",
       " 'KNN_15n_StandardScaler_skf_25_25': 0.9555125725338491,\n",
       " 'KNN_15n_StandardScaler_skf_25_105': 0.9593810444874274,\n",
       " 'KNN_15n_StandardScaler_skf_25_94': 0.9448742746615088,\n",
       " 'KNN_15n_StandardScaler_skf_50_25': 0.9535783365570599,\n",
       " 'KNN_15n_StandardScaler_skf_50_105': 0.9516441005802708,\n",
       " 'KNN_15n_StandardScaler_skf_50_94': 0.9429400386847195,\n",
       " 'KNN_15n_StandardScaler_skf_75_25': 0.9448742746615088,\n",
       " 'KNN_15n_StandardScaler_skf_75_105': 0.9506769825918762,\n",
       " 'KNN_15n_StandardScaler_skf_75_94': 0.9342359767891683,\n",
       " 'KNN_15n_StandardScaler_skf_100_25': 0.9468085106382979,\n",
       " 'KNN_15n_StandardScaler_skf_100_105': 0.9439071566731141,\n",
       " 'KNN_15n_StandardScaler_skf_100_94': 0.9274661508704062,\n",
       " 'KNN_15n_StandardScaler_sss_25_25': 0.9623188405797102,\n",
       " 'KNN_15n_StandardScaler_sss_25_105': 0.9623188405797102,\n",
       " 'KNN_15n_StandardScaler_sss_25_94': 0.9584541062801932,\n",
       " 'KNN_15n_StandardScaler_sss_50_25': 0.9565217391304348,\n",
       " 'KNN_15n_StandardScaler_sss_50_105': 0.961352657004831,\n",
       " 'KNN_15n_StandardScaler_sss_50_94': 0.9516908212560387,\n",
       " 'KNN_15n_StandardScaler_sss_75_25': 0.9507246376811594,\n",
       " 'KNN_15n_StandardScaler_sss_75_105': 0.9526570048309179,\n",
       " 'KNN_15n_StandardScaler_sss_75_94': 0.9391304347826087,\n",
       " 'KNN_15n_StandardScaler_sss_100_25': 0.9449275362318841,\n",
       " 'KNN_15n_StandardScaler_sss_100_105': 0.9507246376811594,\n",
       " 'KNN_15n_StandardScaler_sss_100_94': 0.9420289855072463,\n",
       " 'KNN_15n_MinMaxScaler_tt_25_25': 0.9536231884057971,\n",
       " 'KNN_15n_MinMaxScaler_tt_25_105': 0.957487922705314,\n",
       " 'KNN_15n_MinMaxScaler_tt_25_94': 0.9497584541062802,\n",
       " 'KNN_15n_MinMaxScaler_tt_50_25': 0.9487922705314009,\n",
       " 'KNN_15n_MinMaxScaler_tt_50_105': 0.9458937198067633,\n",
       " 'KNN_15n_MinMaxScaler_tt_50_94': 0.9420289855072463,\n",
       " 'KNN_15n_MinMaxScaler_tt_75_25': 0.9381642512077295,\n",
       " 'KNN_15n_MinMaxScaler_tt_75_105': 0.9371980676328503,\n",
       " 'KNN_15n_MinMaxScaler_tt_75_94': 0.9323671497584541,\n",
       " 'KNN_15n_MinMaxScaler_tt_100_25': 0.9342995169082126,\n",
       " 'KNN_15n_MinMaxScaler_tt_100_105': 0.936231884057971,\n",
       " 'KNN_15n_MinMaxScaler_tt_100_94': 0.9304347826086956,\n",
       " 'KNN_15n_MinMaxScaler_skf_25_25': 0.9545454545454546,\n",
       " 'KNN_15n_MinMaxScaler_skf_25_105': 0.9613152804642167,\n",
       " 'KNN_15n_MinMaxScaler_skf_25_94': 0.9400386847195358,\n",
       " 'KNN_15n_MinMaxScaler_skf_50_25': 0.937137330754352,\n",
       " 'KNN_15n_MinMaxScaler_skf_50_105': 0.9545454545454546,\n",
       " 'KNN_15n_MinMaxScaler_skf_50_94': 0.9332688588007737,\n",
       " 'KNN_15n_MinMaxScaler_skf_75_25': 0.9332688588007737,\n",
       " 'KNN_15n_MinMaxScaler_skf_75_105': 0.937137330754352,\n",
       " 'KNN_15n_MinMaxScaler_skf_75_94': 0.9245647969052224,\n",
       " 'KNN_15n_MinMaxScaler_skf_100_25': 0.925531914893617,\n",
       " 'KNN_15n_MinMaxScaler_skf_100_105': 0.9294003868471954,\n",
       " 'KNN_15n_MinMaxScaler_skf_100_94': 0.9158607350096711,\n",
       " 'KNN_15n_MinMaxScaler_sss_25_25': 0.9594202898550724,\n",
       " 'KNN_15n_MinMaxScaler_sss_25_105': 0.9468599033816425,\n",
       " 'KNN_15n_MinMaxScaler_sss_25_94': 0.9478260869565217,\n",
       " 'KNN_15n_MinMaxScaler_sss_50_25': 0.9458937198067633,\n",
       " 'KNN_15n_MinMaxScaler_sss_50_105': 0.9391304347826087,\n",
       " 'KNN_15n_MinMaxScaler_sss_50_94': 0.9391304347826087,\n",
       " 'KNN_15n_MinMaxScaler_sss_75_25': 0.9391304347826087,\n",
       " 'KNN_15n_MinMaxScaler_sss_75_105': 0.927536231884058,\n",
       " 'KNN_15n_MinMaxScaler_sss_75_94': 0.9246376811594202,\n",
       " 'KNN_15n_MinMaxScaler_sss_100_25': 0.9410628019323671,\n",
       " 'KNN_15n_MinMaxScaler_sss_100_105': 0.9265700483091788,\n",
       " 'KNN_15n_MinMaxScaler_sss_100_94': 0.9207729468599034,\n",
       " 'KNN_25n_StandardScaler_tt_25_25': 0.9584541062801932,\n",
       " 'KNN_25n_StandardScaler_tt_25_105': 0.9497584541062802,\n",
       " 'KNN_25n_StandardScaler_tt_25_94': 0.9555555555555556,\n",
       " 'KNN_25n_StandardScaler_tt_50_25': 0.9478260869565217,\n",
       " 'KNN_25n_StandardScaler_tt_50_105': 0.9507246376811594,\n",
       " 'KNN_25n_StandardScaler_tt_50_94': 0.9487922705314009,\n",
       " 'KNN_25n_StandardScaler_tt_75_25': 0.9400966183574879,\n",
       " 'KNN_25n_StandardScaler_tt_75_105': 0.9449275362318841,\n",
       " 'KNN_25n_StandardScaler_tt_75_94': 0.936231884057971,\n",
       " 'KNN_25n_StandardScaler_tt_100_25': 0.9420289855072463,\n",
       " 'KNN_25n_StandardScaler_tt_100_105': 0.9333333333333333,\n",
       " 'KNN_25n_StandardScaler_tt_100_94': 0.927536231884058,\n",
       " 'KNN_25n_StandardScaler_skf_25_25': 0.9506769825918762,\n",
       " 'KNN_25n_StandardScaler_skf_25_105': 0.9613152804642167,\n",
       " 'KNN_25n_StandardScaler_skf_25_94': 0.9410058027079303,\n",
       " 'KNN_25n_StandardScaler_skf_50_25': 0.941972920696325,\n",
       " 'KNN_25n_StandardScaler_skf_50_105': 0.9516441005802708,\n",
       " 'KNN_25n_StandardScaler_skf_50_94': 0.9274661508704062,\n",
       " 'KNN_25n_StandardScaler_skf_75_25': 0.937137330754352,\n",
       " 'KNN_25n_StandardScaler_skf_75_105': 0.9390715667311412,\n",
       " 'KNN_25n_StandardScaler_skf_75_94': 0.925531914893617,\n",
       " 'KNN_25n_StandardScaler_skf_100_25': 0.9323017408123792,\n",
       " 'KNN_25n_StandardScaler_skf_100_105': 0.9342359767891683,\n",
       " 'KNN_25n_StandardScaler_skf_100_94': 0.9197292069632496,\n",
       " 'KNN_25n_StandardScaler_sss_25_25': 0.961352657004831,\n",
       " 'KNN_25n_StandardScaler_sss_25_105': 0.9584541062801932,\n",
       " 'KNN_25n_StandardScaler_sss_25_94': 0.9478260869565217,\n",
       " 'KNN_25n_StandardScaler_sss_50_25': 0.9478260869565217,\n",
       " 'KNN_25n_StandardScaler_sss_50_105': 0.9516908212560387,\n",
       " 'KNN_25n_StandardScaler_sss_50_94': 0.9429951690821256,\n",
       " 'KNN_25n_StandardScaler_sss_75_25': 0.9410628019323671,\n",
       " 'KNN_25n_StandardScaler_sss_75_105': 0.9468599033816425,\n",
       " 'KNN_25n_StandardScaler_sss_75_94': 0.9371980676328503,\n",
       " 'KNN_25n_StandardScaler_sss_100_25': 0.9381642512077295,\n",
       " 'KNN_25n_StandardScaler_sss_100_105': 0.936231884057971,\n",
       " 'KNN_25n_StandardScaler_sss_100_94': 0.9314009661835749,\n",
       " 'KNN_25n_MinMaxScaler_tt_25_25': 0.9468599033816425,\n",
       " 'KNN_25n_MinMaxScaler_tt_25_105': 0.9507246376811594,\n",
       " 'KNN_25n_MinMaxScaler_tt_25_94': 0.9439613526570049,\n",
       " 'KNN_25n_MinMaxScaler_tt_50_25': 0.9458937198067633,\n",
       " 'KNN_25n_MinMaxScaler_tt_50_105': 0.9468599033816425,\n",
       " 'KNN_25n_MinMaxScaler_tt_50_94': 0.9333333333333333,\n",
       " 'KNN_25n_MinMaxScaler_tt_75_25': 0.936231884057971,\n",
       " 'KNN_25n_MinMaxScaler_tt_75_105': 0.9285024154589372,\n",
       " 'KNN_25n_MinMaxScaler_tt_75_94': 0.927536231884058,\n",
       " 'KNN_25n_MinMaxScaler_tt_100_25': 0.927536231884058,\n",
       " 'KNN_25n_MinMaxScaler_tt_100_105': 0.927536231884058,\n",
       " 'KNN_25n_MinMaxScaler_tt_100_94': 0.9198067632850242,\n",
       " 'KNN_25n_MinMaxScaler_skf_25_25': 0.9458413926499033,\n",
       " 'KNN_25n_MinMaxScaler_skf_25_105': 0.9555125725338491,\n",
       " 'KNN_25n_MinMaxScaler_skf_25_94': 0.9332688588007737,\n",
       " 'KNN_25n_MinMaxScaler_skf_50_25': 0.937137330754352,\n",
       " 'KNN_25n_MinMaxScaler_skf_50_105': 0.9381044487427466,\n",
       " 'KNN_25n_MinMaxScaler_skf_50_94': 0.9235976789168279,\n",
       " 'KNN_25n_MinMaxScaler_skf_75_25': 0.9264990328820116,\n",
       " 'KNN_25n_MinMaxScaler_skf_75_105': 0.9284332688588007,\n",
       " 'KNN_25n_MinMaxScaler_skf_75_94': 0.9158607350096711,\n",
       " 'KNN_25n_MinMaxScaler_skf_100_25': 0.9284332688588007,\n",
       " 'KNN_25n_MinMaxScaler_skf_100_105': 0.925531914893617,\n",
       " 'KNN_25n_MinMaxScaler_skf_100_94': 0.9100580270793037,\n",
       " 'KNN_25n_MinMaxScaler_sss_25_25': 0.9565217391304348,\n",
       " 'KNN_25n_MinMaxScaler_sss_25_105': 0.9420289855072463,\n",
       " 'KNN_25n_MinMaxScaler_sss_25_94': 0.9410628019323671,\n",
       " 'KNN_25n_MinMaxScaler_sss_50_25': 0.9429951690821256,\n",
       " 'KNN_25n_MinMaxScaler_sss_50_105': 0.9294685990338164,\n",
       " 'KNN_25n_MinMaxScaler_sss_50_94': 0.9304347826086956,\n",
       " 'KNN_25n_MinMaxScaler_sss_75_25': 0.9333333333333333,\n",
       " 'KNN_25n_MinMaxScaler_sss_75_105': 0.9314009661835749,\n",
       " 'KNN_25n_MinMaxScaler_sss_75_94': 0.9246376811594202,\n",
       " 'KNN_25n_MinMaxScaler_sss_100_25': 0.9381642512077295,\n",
       " 'KNN_25n_MinMaxScaler_sss_100_105': 0.9198067632850242,\n",
       " 'KNN_25n_MinMaxScaler_sss_100_94': 0.9140096618357488,\n",
       " 'LGBM_StandardScaler_tt_25_25': 0.9671497584541063,\n",
       " 'LGBM_StandardScaler_tt_25_105': 0.966183574879227,\n",
       " 'LGBM_StandardScaler_tt_25_94': 0.9632850241545894,\n",
       " 'LGBM_StandardScaler_tt_50_25': 0.966183574879227,\n",
       " 'LGBM_StandardScaler_tt_50_105': 0.9690821256038648,\n",
       " 'LGBM_StandardScaler_tt_50_94': 0.961352657004831,\n",
       " 'LGBM_StandardScaler_tt_75_25': 0.966183574879227,\n",
       " 'LGBM_StandardScaler_tt_75_105': 0.9690821256038648,\n",
       " 'LGBM_StandardScaler_tt_75_94': 0.9603864734299516,\n",
       " 'LGBM_StandardScaler_tt_100_25': 0.9690821256038648,\n",
       " 'LGBM_StandardScaler_tt_100_105': 0.9690821256038648,\n",
       " 'LGBM_StandardScaler_tt_100_94': 0.9642512077294686,\n",
       " 'LGBM_StandardScaler_skf_25_25': 0.9709864603481625,\n",
       " 'LGBM_StandardScaler_skf_25_105': 0.9593810444874274,\n",
       " 'LGBM_StandardScaler_skf_25_94': 0.9593810444874274,\n",
       " 'LGBM_StandardScaler_skf_50_25': 0.9709864603481625,\n",
       " 'LGBM_StandardScaler_skf_50_105': 0.9622823984526112,\n",
       " 'LGBM_StandardScaler_skf_50_94': 0.9642166344294004,\n",
       " 'LGBM_StandardScaler_skf_75_25': 0.9709864603481625,\n",
       " 'LGBM_StandardScaler_skf_75_105': 0.9642166344294004,\n",
       " 'LGBM_StandardScaler_skf_75_94': 0.9593810444874274,\n",
       " 'LGBM_StandardScaler_skf_100_25': 0.9690522243713733,\n",
       " 'LGBM_StandardScaler_skf_100_105': 0.965183752417795,\n",
       " 'LGBM_StandardScaler_skf_100_94': 0.965183752417795,\n",
       " 'LGBM_StandardScaler_sss_25_25': 0.970048309178744,\n",
       " 'LGBM_StandardScaler_sss_25_105': 0.9671497584541063,\n",
       " 'LGBM_StandardScaler_sss_25_94': 0.9584541062801932,\n",
       " 'LGBM_StandardScaler_sss_50_25': 0.9748792270531401,\n",
       " 'LGBM_StandardScaler_sss_50_105': 0.9681159420289855,\n",
       " 'LGBM_StandardScaler_sss_50_94': 0.9584541062801932,\n",
       " 'LGBM_StandardScaler_sss_75_25': 0.9710144927536232,\n",
       " 'LGBM_StandardScaler_sss_75_105': 0.966183574879227,\n",
       " 'LGBM_StandardScaler_sss_75_94': 0.9671497584541063,\n",
       " 'LGBM_StandardScaler_sss_100_25': 0.9690821256038648,\n",
       " 'LGBM_StandardScaler_sss_100_105': 0.9642512077294686,\n",
       " 'LGBM_StandardScaler_sss_100_94': 0.9681159420289855,\n",
       " 'LGBM_MinMaxScaler_tt_25_25': 0.9652173913043478,\n",
       " 'LGBM_MinMaxScaler_tt_25_105': 0.9603864734299516,\n",
       " 'LGBM_MinMaxScaler_tt_25_94': 0.9594202898550724,\n",
       " 'LGBM_MinMaxScaler_tt_50_25': 0.9719806763285024,\n",
       " 'LGBM_MinMaxScaler_tt_50_105': 0.9719806763285024,\n",
       " 'LGBM_MinMaxScaler_tt_50_94': 0.966183574879227,\n",
       " 'LGBM_MinMaxScaler_tt_75_25': 0.970048309178744,\n",
       " 'LGBM_MinMaxScaler_tt_75_105': 0.966183574879227,\n",
       " 'LGBM_MinMaxScaler_tt_75_94': 0.9632850241545894,\n",
       " 'LGBM_MinMaxScaler_tt_100_25': 0.9758454106280193,\n",
       " 'LGBM_MinMaxScaler_tt_100_105': 0.970048309178744,\n",
       " 'LGBM_MinMaxScaler_tt_100_94': 0.9642512077294686,\n",
       " 'LGBM_MinMaxScaler_skf_25_25': 0.9661508704061895,\n",
       " 'LGBM_MinMaxScaler_skf_25_105': 0.965183752417795,\n",
       " 'LGBM_MinMaxScaler_skf_25_94': 0.9535783365570599,\n",
       " 'LGBM_MinMaxScaler_skf_50_25': 0.9671179883945842,\n",
       " 'LGBM_MinMaxScaler_skf_50_105': 0.965183752417795,\n",
       " 'LGBM_MinMaxScaler_skf_50_94': 0.9526112185686654,\n",
       " 'LGBM_MinMaxScaler_skf_75_25': 0.9680851063829787,\n",
       " 'LGBM_MinMaxScaler_skf_75_105': 0.9671179883945842,\n",
       " 'LGBM_MinMaxScaler_skf_75_94': 0.9545454545454546,\n",
       " 'LGBM_MinMaxScaler_skf_100_25': 0.971953578336557,\n",
       " 'LGBM_MinMaxScaler_skf_100_105': 0.9661508704061895,\n",
       " 'LGBM_MinMaxScaler_skf_100_94': 0.9526112185686654,\n",
       " 'LGBM_MinMaxScaler_sss_25_25': 0.9758454106280193,\n",
       " 'LGBM_MinMaxScaler_sss_25_105': 0.966183574879227,\n",
       " 'LGBM_MinMaxScaler_sss_25_94': 0.9719806763285024,\n",
       " 'LGBM_MinMaxScaler_sss_50_25': 0.9739130434782609,\n",
       " 'LGBM_MinMaxScaler_sss_50_105': 0.9623188405797102,\n",
       " 'LGBM_MinMaxScaler_sss_50_94': 0.970048309178744,\n",
       " 'LGBM_MinMaxScaler_sss_75_25': 0.9719806763285024,\n",
       " 'LGBM_MinMaxScaler_sss_75_105': 0.9719806763285024,\n",
       " 'LGBM_MinMaxScaler_sss_75_94': 0.966183574879227,\n",
       " 'LGBM_MinMaxScaler_sss_100_25': 0.9739130434782609,\n",
       " 'LGBM_MinMaxScaler_sss_100_105': 0.9681159420289855,\n",
       " 'LGBM_MinMaxScaler_sss_100_94': 0.9710144927536232,\n",
       " 'GrdBst_StandardScaler_tt_25_25': 0.9603864734299516,\n",
       " 'GrdBst_StandardScaler_tt_25_105': 0.961352657004831,\n",
       " 'GrdBst_StandardScaler_tt_25_94': 0.9632850241545894,\n",
       " 'GrdBst_StandardScaler_tt_50_25': 0.9681159420289855,\n",
       " 'GrdBst_StandardScaler_tt_50_105': 0.966183574879227,\n",
       " 'GrdBst_StandardScaler_tt_50_94': 0.966183574879227,\n",
       " 'GrdBst_StandardScaler_tt_75_25': 0.9729468599033816,\n",
       " 'GrdBst_StandardScaler_tt_75_105': 0.9652173913043478,\n",
       " 'GrdBst_StandardScaler_tt_75_94': 0.9642512077294686,\n",
       " 'GrdBst_StandardScaler_tt_100_25': 0.9719806763285024,\n",
       " 'GrdBst_StandardScaler_tt_100_105': 0.966183574879227,\n",
       " 'GrdBst_StandardScaler_tt_100_94': 0.9632850241545894,\n",
       " 'GrdBst_StandardScaler_skf_25_25': 0.9584139264990329,\n",
       " 'GrdBst_StandardScaler_skf_25_105': 0.9574468085106383,\n",
       " 'GrdBst_StandardScaler_skf_25_94': 0.9593810444874274,\n",
       " 'GrdBst_StandardScaler_skf_50_25': 0.9642166344294004,\n",
       " 'GrdBst_StandardScaler_skf_50_105': 0.9584139264990329,\n",
       " 'GrdBst_StandardScaler_skf_50_94': 0.9642166344294004,\n",
       " 'GrdBst_StandardScaler_skf_75_25': 0.9642166344294004,\n",
       " 'GrdBst_StandardScaler_skf_75_105': 0.9632495164410058,\n",
       " 'GrdBst_StandardScaler_skf_75_94': 0.960348162475822,\n",
       " 'GrdBst_StandardScaler_skf_100_25': 0.9671179883945842,\n",
       " 'GrdBst_StandardScaler_skf_100_105': 0.965183752417795,\n",
       " 'GrdBst_StandardScaler_skf_100_94': 0.9613152804642167,\n",
       " 'GrdBst_StandardScaler_sss_25_25': 0.961352657004831,\n",
       " 'GrdBst_StandardScaler_sss_25_105': 0.966183574879227,\n",
       " 'GrdBst_StandardScaler_sss_25_94': 0.9565217391304348,\n",
       " 'GrdBst_StandardScaler_sss_50_25': 0.9623188405797102,\n",
       " 'GrdBst_StandardScaler_sss_50_105': 0.9690821256038648,\n",
       " 'GrdBst_StandardScaler_sss_50_94': 0.9603864734299516,\n",
       " 'GrdBst_StandardScaler_sss_75_25': 0.966183574879227,\n",
       " 'GrdBst_StandardScaler_sss_75_105': 0.9671497584541063,\n",
       " 'GrdBst_StandardScaler_sss_75_94': 0.961352657004831,\n",
       " 'GrdBst_StandardScaler_sss_100_25': 0.9642512077294686,\n",
       " 'GrdBst_StandardScaler_sss_100_105': 0.966183574879227,\n",
       " 'GrdBst_StandardScaler_sss_100_94': 0.9623188405797102,\n",
       " 'GrdBst_MinMaxScaler_tt_25_25': 0.9603864734299516,\n",
       " 'GrdBst_MinMaxScaler_tt_25_105': 0.9603864734299516,\n",
       " 'GrdBst_MinMaxScaler_tt_25_94': 0.9594202898550724,\n",
       " 'GrdBst_MinMaxScaler_tt_50_25': 0.9642512077294686,\n",
       " 'GrdBst_MinMaxScaler_tt_50_105': 0.9642512077294686,\n",
       " 'GrdBst_MinMaxScaler_tt_50_94': 0.9603864734299516,\n",
       " 'GrdBst_MinMaxScaler_tt_75_25': 0.9623188405797102,\n",
       " 'GrdBst_MinMaxScaler_tt_75_105': 0.966183574879227,\n",
       " 'GrdBst_MinMaxScaler_tt_75_94': 0.9584541062801932,\n",
       " 'GrdBst_MinMaxScaler_tt_100_25': 0.9603864734299516,\n",
       " 'GrdBst_MinMaxScaler_tt_100_105': 0.9690821256038648,\n",
       " 'GrdBst_MinMaxScaler_tt_100_94': 0.9623188405797102,\n",
       " 'GrdBst_MinMaxScaler_skf_25_25': 0.9584139264990329,\n",
       " 'GrdBst_MinMaxScaler_skf_25_105': 0.9622823984526112,\n",
       " 'GrdBst_MinMaxScaler_skf_25_94': 0.941972920696325,\n",
       " 'GrdBst_MinMaxScaler_skf_50_25': 0.960348162475822,\n",
       " 'GrdBst_MinMaxScaler_skf_50_105': 0.9671179883945842,\n",
       " 'GrdBst_MinMaxScaler_skf_50_94': 0.9497098646034816,\n",
       " 'GrdBst_MinMaxScaler_skf_75_25': 0.9661508704061895,\n",
       " 'GrdBst_MinMaxScaler_skf_75_105': 0.965183752417795,\n",
       " 'GrdBst_MinMaxScaler_skf_75_94': 0.9458413926499033,\n",
       " 'GrdBst_MinMaxScaler_skf_100_25': 0.9661508704061895,\n",
       " 'GrdBst_MinMaxScaler_skf_100_105': 0.9593810444874274,\n",
       " 'GrdBst_MinMaxScaler_skf_100_94': 0.9487427466150871,\n",
       " 'GrdBst_MinMaxScaler_sss_25_25': 0.9642512077294686,\n",
       " 'GrdBst_MinMaxScaler_sss_25_105': 0.9565217391304348,\n",
       " 'GrdBst_MinMaxScaler_sss_25_94': 0.9603864734299516,\n",
       " 'GrdBst_MinMaxScaler_sss_50_25': 0.9681159420289855,\n",
       " 'GrdBst_MinMaxScaler_sss_50_105': 0.961352657004831,\n",
       " 'GrdBst_MinMaxScaler_sss_50_94': 0.9584541062801932,\n",
       " 'GrdBst_MinMaxScaler_sss_75_25': 0.966183574879227,\n",
       " 'GrdBst_MinMaxScaler_sss_75_105': 0.9632850241545894,\n",
       " 'GrdBst_MinMaxScaler_sss_75_94': 0.961352657004831,\n",
       " 'GrdBst_MinMaxScaler_sss_100_25': 0.9671497584541063,\n",
       " 'GrdBst_MinMaxScaler_sss_100_105': 0.9652173913043478,\n",
       " 'GrdBst_MinMaxScaler_sss_100_94': 0.9584541062801932,\n",
       " 'ADABoost_100_StandardScaler_tt_25_25': 0.957487922705314,\n",
       " 'ADABoost_100_StandardScaler_tt_25_105': 0.9603864734299516,\n",
       " 'ADABoost_100_StandardScaler_tt_25_94': 0.9526570048309179,\n",
       " 'ADABoost_100_StandardScaler_tt_50_25': 0.9594202898550724,\n",
       " 'ADABoost_100_StandardScaler_tt_50_105': 0.9642512077294686,\n",
       " 'ADABoost_100_StandardScaler_tt_50_94': 0.961352657004831,\n",
       " 'ADABoost_100_StandardScaler_tt_75_25': 0.9623188405797102,\n",
       " 'ADABoost_100_StandardScaler_tt_75_105': 0.9642512077294686,\n",
       " 'ADABoost_100_StandardScaler_tt_75_94': 0.9642512077294686,\n",
       " 'ADABoost_100_StandardScaler_tt_100_25': 0.9642512077294686,\n",
       " 'ADABoost_100_StandardScaler_tt_100_105': 0.9642512077294686,\n",
       " 'ADABoost_100_StandardScaler_tt_100_94': 0.961352657004831,\n",
       " 'ADABoost_100_StandardScaler_skf_25_25': 0.9545454545454546,\n",
       " 'ADABoost_100_StandardScaler_skf_25_105': 0.9487427466150871,\n",
       " 'ADABoost_100_StandardScaler_skf_25_94': 0.9439071566731141,\n",
       " 'ADABoost_100_StandardScaler_skf_50_25': 0.9555125725338491,\n",
       " 'ADABoost_100_StandardScaler_skf_50_105': 0.9632495164410058,\n",
       " 'ADABoost_100_StandardScaler_skf_50_94': 0.9535783365570599,\n",
       " 'ADABoost_100_StandardScaler_skf_75_25': 0.9613152804642167,\n",
       " 'ADABoost_100_StandardScaler_skf_75_105': 0.960348162475822,\n",
       " 'ADABoost_100_StandardScaler_skf_75_94': 0.960348162475822,\n",
       " 'ADABoost_100_StandardScaler_skf_100_25': 0.9642166344294004,\n",
       " 'ADABoost_100_StandardScaler_skf_100_105': 0.9661508704061895,\n",
       " 'ADABoost_100_StandardScaler_skf_100_94': 0.9506769825918762,\n",
       " 'ADABoost_100_StandardScaler_sss_25_25': 0.9603864734299516,\n",
       " 'ADABoost_100_StandardScaler_sss_25_105': 0.9594202898550724,\n",
       " 'ADABoost_100_StandardScaler_sss_25_94': 0.9507246376811594,\n",
       " 'ADABoost_100_StandardScaler_sss_50_25': 0.9584541062801932,\n",
       " 'ADABoost_100_StandardScaler_sss_50_105': 0.9632850241545894,\n",
       " 'ADABoost_100_StandardScaler_sss_50_94': 0.9565217391304348,\n",
       " 'ADABoost_100_StandardScaler_sss_75_25': 0.9594202898550724,\n",
       " 'ADABoost_100_StandardScaler_sss_75_105': 0.9594202898550724,\n",
       " 'ADABoost_100_StandardScaler_sss_75_94': 0.9555555555555556,\n",
       " 'ADABoost_100_StandardScaler_sss_100_25': 0.9623188405797102,\n",
       " 'ADABoost_100_StandardScaler_sss_100_105': 0.9594202898550724,\n",
       " 'ADABoost_100_StandardScaler_sss_100_94': 0.9555555555555556,\n",
       " 'ADABoost_100_MinMaxScaler_tt_25_25': 0.9391304347826087,\n",
       " 'ADABoost_100_MinMaxScaler_tt_25_105': 0.9565217391304348,\n",
       " 'ADABoost_100_MinMaxScaler_tt_25_94': 0.9439613526570049,\n",
       " 'ADABoost_100_MinMaxScaler_tt_50_25': 0.9565217391304348,\n",
       " 'ADABoost_100_MinMaxScaler_tt_50_105': 0.9623188405797102,\n",
       " 'ADABoost_100_MinMaxScaler_tt_50_94': 0.9400966183574879,\n",
       " 'ADABoost_100_MinMaxScaler_tt_75_25': 0.9536231884057971,\n",
       " 'ADABoost_100_MinMaxScaler_tt_75_105': 0.9594202898550724,\n",
       " 'ADABoost_100_MinMaxScaler_tt_75_94': 0.9487922705314009,\n",
       " 'ADABoost_100_MinMaxScaler_tt_100_25': 0.9507246376811594,\n",
       " 'ADABoost_100_MinMaxScaler_tt_100_105': 0.961352657004831,\n",
       " 'ADABoost_100_MinMaxScaler_tt_100_94': 0.9516908212560387,\n",
       " 'ADABoost_100_MinMaxScaler_skf_25_25': 0.9468085106382979,\n",
       " 'ADABoost_100_MinMaxScaler_skf_25_105': 0.9506769825918762,\n",
       " 'ADABoost_100_MinMaxScaler_skf_25_94': 0.9429400386847195,\n",
       " 'ADABoost_100_MinMaxScaler_skf_50_25': 0.9526112185686654,\n",
       " 'ADABoost_100_MinMaxScaler_skf_50_105': 0.9526112185686654,\n",
       " 'ADABoost_100_MinMaxScaler_skf_50_94': 0.9342359767891683,\n",
       " 'ADABoost_100_MinMaxScaler_skf_75_25': 0.9497098646034816,\n",
       " 'ADABoost_100_MinMaxScaler_skf_75_105': 0.9506769825918762,\n",
       " 'ADABoost_100_MinMaxScaler_skf_75_94': 0.9381044487427466,\n",
       " 'ADABoost_100_MinMaxScaler_skf_100_25': 0.965183752417795,\n",
       " 'ADABoost_100_MinMaxScaler_skf_100_105': 0.9584139264990329,\n",
       " 'ADABoost_100_MinMaxScaler_skf_100_94': 0.9410058027079303,\n",
       " 'ADABoost_100_MinMaxScaler_sss_25_25': 0.9487922705314009,\n",
       " 'ADABoost_100_MinMaxScaler_sss_25_105': 0.9449275362318841,\n",
       " 'ADABoost_100_MinMaxScaler_sss_25_94': 0.9478260869565217,\n",
       " 'ADABoost_100_MinMaxScaler_sss_50_25': 0.9487922705314009,\n",
       " 'ADABoost_100_MinMaxScaler_sss_50_105': 0.9497584541062802,\n",
       " 'ADABoost_100_MinMaxScaler_sss_50_94': 0.9468599033816425,\n",
       " 'ADABoost_100_MinMaxScaler_sss_75_25': 0.9507246376811594,\n",
       " 'ADABoost_100_MinMaxScaler_sss_75_105': 0.9507246376811594,\n",
       " 'ADABoost_100_MinMaxScaler_sss_75_94': 0.9497584541062802,\n",
       " 'ADABoost_100_MinMaxScaler_sss_100_25': 0.9545893719806763,\n",
       " 'ADABoost_100_MinMaxScaler_sss_100_105': 0.9545893719806763,\n",
       " 'ADABoost_100_MinMaxScaler_sss_100_94': 0.9468599033816425,\n",
       " 'ADABoost_200_StandardScaler_tt_25_25': 0.9652173913043478,\n",
       " 'ADABoost_200_StandardScaler_tt_25_105': 0.9526570048309179,\n",
       " 'ADABoost_200_StandardScaler_tt_25_94': 0.9497584541062802,\n",
       " 'ADABoost_200_StandardScaler_tt_50_25': 0.9652173913043478,\n",
       " 'ADABoost_200_StandardScaler_tt_50_105': 0.9594202898550724,\n",
       " 'ADABoost_200_StandardScaler_tt_50_94': 0.961352657004831,\n",
       " 'ADABoost_200_StandardScaler_tt_75_25': 0.9632850241545894,\n",
       " 'ADABoost_200_StandardScaler_tt_75_105': 0.970048309178744,\n",
       " 'ADABoost_200_StandardScaler_tt_75_94': 0.9603864734299516,\n",
       " 'ADABoost_200_StandardScaler_tt_100_25': 0.9584541062801932,\n",
       " 'ADABoost_200_StandardScaler_tt_100_105': 0.9642512077294686,\n",
       " 'ADABoost_200_StandardScaler_tt_100_94': 0.9584541062801932,\n",
       " 'ADABoost_200_StandardScaler_skf_25_25': 0.9564796905222437,\n",
       " 'ADABoost_200_StandardScaler_skf_25_105': 0.960348162475822,\n",
       " 'ADABoost_200_StandardScaler_skf_25_94': 0.9506769825918762,\n",
       " 'ADABoost_200_StandardScaler_skf_50_25': 0.9564796905222437,\n",
       " 'ADABoost_200_StandardScaler_skf_50_105': 0.960348162475822,\n",
       " 'ADABoost_200_StandardScaler_skf_50_94': 0.9535783365570599,\n",
       " 'ADABoost_200_StandardScaler_skf_75_25': 0.9584139264990329,\n",
       " 'ADABoost_200_StandardScaler_skf_75_105': 0.971953578336557,\n",
       " 'ADABoost_200_StandardScaler_skf_75_94': 0.9632495164410058,\n",
       " 'ADABoost_200_StandardScaler_skf_100_25': 0.9642166344294004,\n",
       " 'ADABoost_200_StandardScaler_skf_100_105': 0.9661508704061895,\n",
       " 'ADABoost_200_StandardScaler_skf_100_94': 0.9574468085106383,\n",
       " 'ADABoost_200_StandardScaler_sss_25_25': 0.961352657004831,\n",
       " 'ADABoost_200_StandardScaler_sss_25_105': 0.961352657004831,\n",
       " 'ADABoost_200_StandardScaler_sss_25_94': 0.9526570048309179,\n",
       " 'ADABoost_200_StandardScaler_sss_50_25': 0.9652173913043478,\n",
       " 'ADABoost_200_StandardScaler_sss_50_105': 0.9642512077294686,\n",
       " 'ADABoost_200_StandardScaler_sss_50_94': 0.9536231884057971,\n",
       " 'ADABoost_200_StandardScaler_sss_75_25': 0.9671497584541063,\n",
       " 'ADABoost_200_StandardScaler_sss_75_105': 0.9594202898550724,\n",
       " 'ADABoost_200_StandardScaler_sss_75_94': 0.9632850241545894,\n",
       " 'ADABoost_200_StandardScaler_sss_100_25': 0.966183574879227,\n",
       " 'ADABoost_200_StandardScaler_sss_100_105': 0.9681159420289855,\n",
       " 'ADABoost_200_StandardScaler_sss_100_94': 0.9594202898550724,\n",
       " 'ADABoost_200_MinMaxScaler_tt_25_25': 0.9449275362318841,\n",
       " 'ADABoost_200_MinMaxScaler_tt_25_105': 0.9555555555555556,\n",
       " 'ADABoost_200_MinMaxScaler_tt_25_94': 0.9478260869565217,\n",
       " 'ADABoost_200_MinMaxScaler_tt_50_25': 0.9623188405797102,\n",
       " 'ADABoost_200_MinMaxScaler_tt_50_105': 0.9623188405797102,\n",
       " 'ADABoost_200_MinMaxScaler_tt_50_94': 0.9458937198067633,\n",
       " 'ADABoost_200_MinMaxScaler_tt_75_25': 0.9584541062801932,\n",
       " 'ADABoost_200_MinMaxScaler_tt_75_105': 0.9603864734299516,\n",
       " 'ADABoost_200_MinMaxScaler_tt_75_94': 0.9536231884057971,\n",
       " 'ADABoost_200_MinMaxScaler_tt_100_25': 0.9565217391304348,\n",
       " 'ADABoost_200_MinMaxScaler_tt_100_105': 0.9681159420289855,\n",
       " 'ADABoost_200_MinMaxScaler_tt_100_94': 0.961352657004831,\n",
       " 'ADABoost_200_MinMaxScaler_skf_25_25': 0.9564796905222437,\n",
       " 'ADABoost_200_MinMaxScaler_skf_25_105': 0.9516441005802708,\n",
       " 'ADABoost_200_MinMaxScaler_skf_25_94': 0.9429400386847195,\n",
       " 'ADABoost_200_MinMaxScaler_skf_50_25': 0.9574468085106383,\n",
       " 'ADABoost_200_MinMaxScaler_skf_50_105': 0.960348162475822,\n",
       " 'ADABoost_200_MinMaxScaler_skf_50_94': 0.9439071566731141,\n",
       " 'ADABoost_200_MinMaxScaler_skf_75_25': 0.9535783365570599,\n",
       " 'ADABoost_200_MinMaxScaler_skf_75_105': 0.9497098646034816,\n",
       " 'ADABoost_200_MinMaxScaler_skf_75_94': 0.941972920696325,\n",
       " 'ADABoost_200_MinMaxScaler_skf_100_25': 0.9574468085106383,\n",
       " 'ADABoost_200_MinMaxScaler_skf_100_105': 0.960348162475822,\n",
       " 'ADABoost_200_MinMaxScaler_skf_100_94': 0.9535783365570599,\n",
       " 'ADABoost_200_MinMaxScaler_sss_25_25': 0.9497584541062802,\n",
       " 'ADABoost_200_MinMaxScaler_sss_25_105': 0.9545893719806763,\n",
       " 'ADABoost_200_MinMaxScaler_sss_25_94': 0.9497584541062802,\n",
       " 'ADABoost_200_MinMaxScaler_sss_50_25': 0.9555555555555556,\n",
       " 'ADABoost_200_MinMaxScaler_sss_50_105': 0.9497584541062802,\n",
       " 'ADABoost_200_MinMaxScaler_sss_50_94': 0.9468599033816425,\n",
       " 'ADABoost_200_MinMaxScaler_sss_75_25': 0.9526570048309179,\n",
       " 'ADABoost_200_MinMaxScaler_sss_75_105': 0.9565217391304348,\n",
       " 'ADABoost_200_MinMaxScaler_sss_75_94': 0.9478260869565217,\n",
       " 'ADABoost_200_MinMaxScaler_sss_100_25': 0.9526570048309179,\n",
       " 'ADABoost_200_MinMaxScaler_sss_100_105': 0.9545893719806763,\n",
       " 'ADABoost_200_MinMaxScaler_sss_100_94': 0.9449275362318841}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_results_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0790f9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_df = pd.DataFrame.from_dict(pca_results_acc, orient='index')\n",
    "acc_df.reset_index(inplace=True)\n",
    "acc_df.rename(columns={'index': 'model', 0 : 'accuracy'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8141b440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>underscore_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>RandomForest_200_MinMaxScaler_tt_100_105</td>\n",
       "      <td>0.978744</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>RandomForest_100_StandardScaler_sss_75_105</td>\n",
       "      <td>0.978744</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>RandomForest_200_MinMaxScaler_tt_75_105</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>RandomForest_100_MinMaxScaler_tt_100_105</td>\n",
       "      <td>0.976812</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>LGBM_MinMaxScaler_tt_100_25</td>\n",
       "      <td>0.975845</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>SVMSigmoid_StandardScaler_sss_25_105</td>\n",
       "      <td>0.813527</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>SVMSigmoid_MinMaxScaler_sss_25_105</td>\n",
       "      <td>0.813527</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>SVMSigmoid_MinMaxScaler_skf_25_94</td>\n",
       "      <td>0.813346</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>SVMSigmoid_MinMaxScaler_sss_25_94</td>\n",
       "      <td>0.811594</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>SVMSigmoid_MinMaxScaler_tt_25_105</td>\n",
       "      <td>0.802899</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>864 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          model  accuracy  underscore_count\n",
       "190    RandomForest_200_MinMaxScaler_tt_100_105  0.978744                 5\n",
       "103  RandomForest_100_StandardScaler_sss_75_105  0.978744                 5\n",
       "187     RandomForest_200_MinMaxScaler_tt_75_105  0.977778                 5\n",
       "118    RandomForest_100_MinMaxScaler_tt_100_105  0.976812                 5\n",
       "621                 LGBM_MinMaxScaler_tt_100_25  0.975845                 4\n",
       "..                                          ...       ...               ...\n",
       "313        SVMSigmoid_StandardScaler_sss_25_105  0.813527                 4\n",
       "349          SVMSigmoid_MinMaxScaler_sss_25_105  0.813527                 4\n",
       "338           SVMSigmoid_MinMaxScaler_skf_25_94  0.813346                 4\n",
       "350           SVMSigmoid_MinMaxScaler_sss_25_94  0.811594                 4\n",
       "325           SVMSigmoid_MinMaxScaler_tt_25_105  0.802899                 4\n",
       "\n",
       "[864 rows x 3 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_df.sort_values(by='accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a4db89",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_df.model.str.contains()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "51951c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of underscores in the 'model' column\n",
    "p_result_df['underscore_count'] = p_result_df['model'].str.count('_')\n",
    "\n",
    "# Find rows with exactly six underscores (i.e., seven parts)\n",
    "#acc_df = acc_df[acc_df['underscore_count'] == 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "7627a06c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "underscore_count\n",
       "5    504\n",
       "4    360\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_result_df.underscore_count.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c6f32285",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_5df = acc_df[acc_df['underscore_count'] == 5]\n",
    "acc_5df_2 = acc_5df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "47e35dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_5df_2['model'] = acc_5df_2['model'].str.replace('_', '',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "71255058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>underscore_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>RandomForest100_StandardScaler_tt_25_25</td>\n",
       "      <td>0.968116</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>RandomForest100_StandardScaler_tt_25_105</td>\n",
       "      <td>0.970048</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>RandomForest100_StandardScaler_tt_25_94</td>\n",
       "      <td>0.964251</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>RandomForest100_StandardScaler_tt_50_25</td>\n",
       "      <td>0.969082</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>RandomForest100_StandardScaler_tt_50_105</td>\n",
       "      <td>0.970048</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>ADABoost200_MinMaxScaler_sss_75_105</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>ADABoost200_MinMaxScaler_sss_75_94</td>\n",
       "      <td>0.947826</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>ADABoost200_MinMaxScaler_sss_100_25</td>\n",
       "      <td>0.952657</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>ADABoost200_MinMaxScaler_sss_100_105</td>\n",
       "      <td>0.954589</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>ADABoost200_MinMaxScaler_sss_100_94</td>\n",
       "      <td>0.944928</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>504 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        model  accuracy  underscore_count\n",
       "72    RandomForest100_StandardScaler_tt_25_25  0.968116                 5\n",
       "73   RandomForest100_StandardScaler_tt_25_105  0.970048                 5\n",
       "74    RandomForest100_StandardScaler_tt_25_94  0.964251                 5\n",
       "75    RandomForest100_StandardScaler_tt_50_25  0.969082                 5\n",
       "76   RandomForest100_StandardScaler_tt_50_105  0.970048                 5\n",
       "..                                        ...       ...               ...\n",
       "859       ADABoost200_MinMaxScaler_sss_75_105  0.956522                 5\n",
       "860        ADABoost200_MinMaxScaler_sss_75_94  0.947826                 5\n",
       "861       ADABoost200_MinMaxScaler_sss_100_25  0.952657                 5\n",
       "862      ADABoost200_MinMaxScaler_sss_100_105  0.954589                 5\n",
       "863       ADABoost200_MinMaxScaler_sss_100_94  0.944928                 5\n",
       "\n",
       "[504 rows x 3 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_5df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e47e4045",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_5df_2['model'] = acc_5df_2['model'].apply(lambda x: x.replace('_', '', 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "140ae17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_first_underscore(s):\n",
    "    # Find the position of the first underscore\n",
    "    pos = s.find('_')\n",
    "    # If an underscore is found, replace it with an empty string\n",
    "    if pos != -1:\n",
    "        return s[:pos] + s[pos + 1:]\n",
    "    return s\n",
    "\n",
    "# Apply the function to the 'model' column\n",
    "acc_5df_2['model'] = acc_5df_2['model'].apply(remove_first_underscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d60e02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "3eba9b79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72      RandomForest100StandardScalertt_25_25\n",
       "73     RandomForest100StandardScalertt_25_105\n",
       "74      RandomForest100StandardScalertt_25_94\n",
       "75      RandomForest100StandardScalertt_50_25\n",
       "76     RandomForest100StandardScalertt_50_105\n",
       "                        ...                  \n",
       "859         ADABoost200MinMaxScalersss_75_105\n",
       "860          ADABoost200MinMaxScalersss_75_94\n",
       "861         ADABoost200MinMaxScalersss_100_25\n",
       "862        ADABoost200MinMaxScalersss_100_105\n",
       "863         ADABoost200MinMaxScalersss_100_94\n",
       "Name: model, Length: 504, dtype: object"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_5df_2.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0193a466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "underscore_count\n",
       "4    504\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_5df_2['underscore_count'] = acc_5df_2['model'].str.count('_')\n",
    "acc_5df_2.underscore_count.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "06dbeb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_df2 = pd.concat([acc_df[acc_df['underscore_count'] == 4],acc_5df_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bddec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e72ec1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ed013142",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_models = acc_df[acc_df.accuracy > 0.97]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d6fc9077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression_StandardScaler_tt_100_105</td>\n",
       "      <td>0.971981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>LogisticRegression_StandardScaler_sss_75_25</td>\n",
       "      <td>0.971014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>LogisticRegression_StandardScaler_sss_100_25</td>\n",
       "      <td>0.970048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>RandomForest_100_StandardScaler_tt_25_105</td>\n",
       "      <td>0.970048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>RandomForest_100_StandardScaler_tt_50_105</td>\n",
       "      <td>0.970048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>LGBM_MinMaxScaler_sss_100_94</td>\n",
       "      <td>0.971014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>GrdBst_StandardScaler_tt_75_25</td>\n",
       "      <td>0.972947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>GrdBst_StandardScaler_tt_100_25</td>\n",
       "      <td>0.971981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>ADABoost_200_StandardScaler_tt_75_105</td>\n",
       "      <td>0.970048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>ADABoost_200_StandardScaler_skf_75_105</td>\n",
       "      <td>0.971954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            model  accuracy\n",
       "10   LogisticRegression_StandardScaler_tt_100_105  0.971981\n",
       "30    LogisticRegression_StandardScaler_sss_75_25  0.971014\n",
       "33   LogisticRegression_StandardScaler_sss_100_25  0.970048\n",
       "73      RandomForest_100_StandardScaler_tt_25_105  0.970048\n",
       "76      RandomForest_100_StandardScaler_tt_50_105  0.970048\n",
       "..                                            ...       ...\n",
       "647                  LGBM_MinMaxScaler_sss_100_94  0.971014\n",
       "654                GrdBst_StandardScaler_tt_75_25  0.972947\n",
       "657               GrdBst_StandardScaler_tt_100_25  0.971981\n",
       "799         ADABoost_200_StandardScaler_tt_75_105  0.970048\n",
       "811        ADABoost_200_StandardScaler_skf_75_105  0.971954\n",
       "\n",
       "[68 rows x 2 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "07e77601",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_columns = acc_df2['model'].str.split('_', expand=True)\n",
    "\n",
    "# Rename the new columns\n",
    "split_columns.columns = ['model_name', 'scaler', 'split_method', 'pca_components', 'random_state']\n",
    "\n",
    "# Join the new columns back to the original DataFrame\n",
    "acc_df3 = acc_df2.join(split_columns)\n",
    "\n",
    "# Optionally, drop the original 'model' column\n",
    "acc_df3.drop(columns=['model', 'underscore_count'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a27ca42b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>model_name</th>\n",
       "      <th>scaler</th>\n",
       "      <th>split_method</th>\n",
       "      <th>pca_components</th>\n",
       "      <th>random_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>0.978744</td>\n",
       "      <td>RandomForest200</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>tt</td>\n",
       "      <td>100</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.978744</td>\n",
       "      <td>RandomForest100</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>sss</td>\n",
       "      <td>75</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>0.977778</td>\n",
       "      <td>RandomForest200</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>tt</td>\n",
       "      <td>75</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0.976812</td>\n",
       "      <td>RandomForest100</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>tt</td>\n",
       "      <td>100</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>0.975845</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>sss</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>0.813527</td>\n",
       "      <td>SVMSigmoid</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>sss</td>\n",
       "      <td>25</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>0.813527</td>\n",
       "      <td>SVMSigmoid</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>sss</td>\n",
       "      <td>25</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>0.813346</td>\n",
       "      <td>SVMSigmoid</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>skf</td>\n",
       "      <td>25</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>0.811594</td>\n",
       "      <td>SVMSigmoid</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>sss</td>\n",
       "      <td>25</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>0.802899</td>\n",
       "      <td>SVMSigmoid</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>tt</td>\n",
       "      <td>25</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>864 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     accuracy       model_name          scaler split_method pca_components  \\\n",
       "190  0.978744  RandomForest200    MinMaxScaler           tt            100   \n",
       "103  0.978744  RandomForest100  StandardScaler          sss             75   \n",
       "187  0.977778  RandomForest200    MinMaxScaler           tt             75   \n",
       "118  0.976812  RandomForest100    MinMaxScaler           tt            100   \n",
       "636  0.975845             LGBM    MinMaxScaler          sss             25   \n",
       "..        ...              ...             ...          ...            ...   \n",
       "349  0.813527       SVMSigmoid    MinMaxScaler          sss             25   \n",
       "313  0.813527       SVMSigmoid  StandardScaler          sss             25   \n",
       "338  0.813346       SVMSigmoid    MinMaxScaler          skf             25   \n",
       "350  0.811594       SVMSigmoid    MinMaxScaler          sss             25   \n",
       "325  0.802899       SVMSigmoid    MinMaxScaler           tt             25   \n",
       "\n",
       "    random_state  \n",
       "190          105  \n",
       "103          105  \n",
       "187          105  \n",
       "118          105  \n",
       "636           25  \n",
       "..           ...  \n",
       "349          105  \n",
       "313          105  \n",
       "338           94  \n",
       "350           94  \n",
       "325          105  \n",
       "\n",
       "[864 rows x 6 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_df3.sort_values(by='accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "2576479d",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_df3 = acc_df3.sort_values(by='accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "509d91c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_models = acc_df3[acc_df3.accuracy > 0.97]\n",
    "len(top_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "a0dd707e",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_mods = acc_df3[acc_df3.model_name.isin(['RandomForest200', 'RandomForest100','LGBM','GrdBost','AdaBoost200','SVMLinear'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244ced4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "cce94d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest200: 0.9667\n",
      "RandomForest100: 0.9664\n",
      "LGBM: 0.9663\n",
      "SVMLinear: 0.9544\n",
      "\n",
      "\n",
      "MinMaxScaler: 0.9627\n",
      "StandardScaler: 0.9643\n",
      "\n",
      "\n",
      "tt: 0.9653\n",
      "sss: 0.9647\n",
      "skf: 0.9605\n",
      "\n",
      "\n",
      "100: 0.9652\n",
      "75: 0.9642\n",
      "25: 0.9604\n",
      "50: 0.9641\n"
     ]
    }
   ],
   "source": [
    "for mod in top_mods.model_name.unique():\n",
    "    print(mod + ': ' + str(round(top_mods[top_mods.model_name == mod]['accuracy'].mean(), 4)))\n",
    "\n",
    "print('\\n')\n",
    "for mod in top_mods.scaler.unique():\n",
    "    print(mod + ': ' + str(round(top_mods[top_mods.scaler == mod]['accuracy'].mean(), 4)))   \n",
    "    \n",
    "print('\\n')\n",
    "for mod in top_mods.split_method.unique():\n",
    "    print(mod + ': ' + str(round(top_mods[top_mods.split_method == mod]['accuracy'].mean(), 4))) \n",
    "    \n",
    "print('\\n')\n",
    "for mod in top_mods.pca_components.unique():\n",
    "    print(mod + ': ' + str(round(top_mods[top_mods.pca_components == mod]['accuracy'].mean(), 4)))     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cbca4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'tt', "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979f03a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "a3476d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest200: 0.972\n",
      "RandomForest100: 0.9718\n",
      "LGBM: 0.9721\n",
      "GrdBst: 0.9725\n",
      "LogisticRegression: 0.971\n",
      "ADABoost200: 0.971\n",
      "SVMLinear: 0.9705\n",
      "\n",
      "\n",
      "MinMaxScaler: 0.9723\n",
      "StandardScaler: 0.9715\n",
      "\n",
      "\n",
      "tt: 0.9724\n",
      "sss: 0.9718\n",
      "skf: 0.9707\n",
      "\n",
      "\n",
      "100: 0.9721\n",
      "75: 0.9723\n",
      "25: 0.9709\n",
      "50: 0.9717\n"
     ]
    }
   ],
   "source": [
    "for mod in top_models.model_name.unique():\n",
    "    print(mod + ': ' + str(round(top_models[top_models.model_name == mod]['accuracy'].mean(), 4)))\n",
    "\n",
    "print('\\n')\n",
    "for mod in top_models.scaler.unique():\n",
    "    print(mod + ': ' + str(round(top_models[top_models.scaler == mod]['accuracy'].mean(), 4)))   \n",
    "    \n",
    "print('\\n')\n",
    "for mod in top_models.split_method.unique():\n",
    "    print(mod + ': ' + str(round(top_models[top_models.split_method == mod]['accuracy'].mean(), 4))) \n",
    "    \n",
    "print('\\n')\n",
    "for mod in top_models.pca_components.unique():\n",
    "    print(mod + ': ' + str(round(top_models[top_models.pca_components == mod]['accuracy'].mean(), 4)))     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3823842",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb180c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f98e526",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1, c2 = sc_pca_class_test(X, y, mm_sc, 50, 0.2, LogisticRegression(), 'skf', 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "277245c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Random Forest\n",
      "SVM Linear\n",
      "SVM Sigmoid\n",
      "KNN\n",
      "LGBM\n",
      "GrdBst\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "results_acc = {}\n",
    "results_rep = {}\n",
    "\n",
    "for classifier, func in classifiers.items():\n",
    "    for sc_name, sc_func in sc_dc.items(): \n",
    "        results[classifier] = \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1d46c00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SV_log = SVC(kernel='sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "383f069c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1f94d5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_acc, svm_class = sc_pca_class(X, y, mm_sc, 50, 0.2, SV_log, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "baffe310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8521739130434782"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "23b526e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_acc_50, log_class = sc_pca_class(X, y, mm_sc, 50, 0.2, LogisticRegression(), 12)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ebec1234",
   "metadata": {},
   "source": [
    "rf_acc, rf_class = sc_pca_class(X, y, mm_sc, 50, 0.2, LogisticRegression(), 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ba1b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sc_pca_class(X, y, scaler, n_comp, ts, classifier, split_method)\n",
    "\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    if split_method == 'train_test':\n",
    "        # Split data using train_test_split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n",
    "        \n",
    "        # Train and evaluate the classifier\n",
    "        classifier.fit(X_train, y_train)\n",
    "        y_pred = classifier.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        report = classification_report(y_test, y_pred)\n",
    "        \n",
    "    elif split_method == 'stratified_kfold':\n",
    "        # Split data using StratifiedKFold\n",
    "        n_splits = kwargs.get('n_splits', 5)  # Default to 5 splits\n",
    "        skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "        \n",
    "        accuracies = []\n",
    "        reports = []\n",
    "\n",
    "        for train_index, test_index in skf.split(X_pca, y):\n",
    "            X_train, X_test = X_pca[train_index], X_pca[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            \n",
    "            classifier.fit(X_train, y_train)\n",
    "            y_pred = classifier.predict(X_test)\n",
    "            accuracies.append(accuracy_score(y_test, y_pred))\n",
    "            reports.append(classification_report(y_test, y_pred, output_dict=True))\n",
    "        \n",
    "        accuracy = np.mean(accuracies)\n",
    "        report = reports  # List of classification reports for each fold\n",
    "        \n",
    "    elif split_method == 'stratified_shuffle_split':\n",
    "        # Split data using StratifiedShuffleSplit\n",
    "        test_size = kwargs.get('test_size', 0.2)  # Default test size\n",
    "        sss = StratifiedShuffleSplit(n_splits=1, test_size=test_size, random_state=42)\n",
    "        \n",
    "        for train_index, test_index in sss.split(X_pca, y):\n",
    "            X_train, X_test = X_pca[train_index], X_pca[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            \n",
    "            classifier.fit(X_train, y_train)\n",
    "            y_pred = classifier.predict(X_test)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            report = classification_report(y_test, y_pred)\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(\"Unsupported split_method. Choose from 'train_test', 'stratified_kfold', or 'stratified_shuffle_split'.\")\n",
    "    \n",
    "    classifier.fit(X_train, y_train)    \n",
    "    \n",
    "    y_pred = classifier.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    return accuracy, classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c2961738",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sc_pca_class(X, y, scaler, components, ts, classifier, split_method):\n",
    "\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    pca = PCA(n_components=components)\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=ts, random_state=42)\n",
    "\n",
    "    classifier.fit(X_train, y_train)    \n",
    "    \n",
    "    y_pred = classifier.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    return accuracy, classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "93072177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9729468599033816\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       739\n",
      "           1       0.95      0.96      0.95       296\n",
      "\n",
      "    accuracy                           0.97      1035\n",
      "   macro avg       0.97      0.97      0.97      1035\n",
      "weighted avg       0.97      0.97      0.97      1035\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# pca = 25\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c40b46e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9429951690821256\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       739\n",
      "           1       0.89      0.91      0.90       296\n",
      "\n",
      "    accuracy                           0.94      1035\n",
      "   macro avg       0.93      0.93      0.93      1035\n",
      "weighted avg       0.94      0.94      0.94      1035\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# pca = 5\n",
    "\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "f3f4c9f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier()"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "LGBMClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "b4572097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1199, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000323 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3825\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289824 -> initscore=-0.896241\n",
      "[LightGBM] [Info] Start training from score -0.896241\n",
      "[LightGBM] [Info] Number of positive: 1187, number of negative: 2950\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000314 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3825\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.286923 -> initscore=-0.910376\n",
      "[LightGBM] [Info] Start training from score -0.910376\n",
      "[LightGBM] [Info] Number of positive: 1207, number of negative: 2930\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000820 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3825\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.291757 -> initscore=-0.886864\n",
      "[LightGBM] [Info] Start training from score -0.886864\n",
      "[LightGBM] [Info] Number of positive: 1199, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000555 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6375\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289824 -> initscore=-0.896241\n",
      "[LightGBM] [Info] Start training from score -0.896241\n",
      "[LightGBM] [Info] Number of positive: 1187, number of negative: 2950\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000543 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6375\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.286923 -> initscore=-0.910376\n",
      "[LightGBM] [Info] Start training from score -0.910376\n",
      "[LightGBM] [Info] Number of positive: 1207, number of negative: 2930\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000515 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6375\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.291757 -> initscore=-0.886864\n",
      "[LightGBM] [Info] Start training from score -0.886864\n",
      "[LightGBM] [Info] Number of positive: 1199, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001003 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289824 -> initscore=-0.896241\n",
      "[LightGBM] [Info] Start training from score -0.896241\n",
      "[LightGBM] [Info] Number of positive: 1187, number of negative: 2950\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001087 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.286923 -> initscore=-0.910376\n",
      "[LightGBM] [Info] Start training from score -0.910376\n",
      "[LightGBM] [Info] Number of positive: 1207, number of negative: 2930\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001142 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.291757 -> initscore=-0.886864\n",
      "[LightGBM] [Info] Start training from score -0.886864\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000411 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3825\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000307 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3825\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000324 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3825\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000483 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6375\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000526 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6375\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000515 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6375\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000919 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001406 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000860 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1199, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000257 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3825\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289824 -> initscore=-0.896241\n",
      "[LightGBM] [Info] Start training from score -0.896241\n",
      "[LightGBM] [Info] Number of positive: 1187, number of negative: 2950\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000307 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3825\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.286923 -> initscore=-0.910376\n",
      "[LightGBM] [Info] Start training from score -0.910376\n",
      "[LightGBM] [Info] Number of positive: 1207, number of negative: 2930\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000247 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3825\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.291757 -> initscore=-0.886864\n",
      "[LightGBM] [Info] Start training from score -0.886864\n",
      "[LightGBM] [Info] Number of positive: 1199, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000423 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6375\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289824 -> initscore=-0.896241\n",
      "[LightGBM] [Info] Start training from score -0.896241\n",
      "[LightGBM] [Info] Number of positive: 1187, number of negative: 2950\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000494 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6375\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.286923 -> initscore=-0.910376\n",
      "[LightGBM] [Info] Start training from score -0.910376\n",
      "[LightGBM] [Info] Number of positive: 1207, number of negative: 2930\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000447 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6375\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.291757 -> initscore=-0.886864\n",
      "[LightGBM] [Info] Start training from score -0.886864\n",
      "[LightGBM] [Info] Number of positive: 1199, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000885 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289824 -> initscore=-0.896241\n",
      "[LightGBM] [Info] Start training from score -0.896241\n",
      "[LightGBM] [Info] Number of positive: 1187, number of negative: 2950\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000907 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.286923 -> initscore=-0.910376\n",
      "[LightGBM] [Info] Start training from score -0.910376\n",
      "[LightGBM] [Info] Number of positive: 1207, number of negative: 2930\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000912 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.291757 -> initscore=-0.886864\n",
      "[LightGBM] [Info] Start training from score -0.886864\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000292 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3825\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000258 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3825\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000304 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3825\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000480 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6375\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000639 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6375\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000470 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6375\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000877 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000930 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000875 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8925\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 35\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1199, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025931 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23603\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2571\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289824 -> initscore=-0.896241\n",
      "[LightGBM] [Info] Start training from score -0.896241\n",
      "[LightGBM] [Info] Number of positive: 1187, number of negative: 2950\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024239 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23788\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2584\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.286923 -> initscore=-0.910376\n",
      "[LightGBM] [Info] Start training from score -0.910376\n",
      "[LightGBM] [Info] Number of positive: 1207, number of negative: 2930\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022966 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23741\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2593\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.291757 -> initscore=-0.886864\n",
      "[LightGBM] [Info] Start training from score -0.886864\n",
      "[LightGBM] [Info] Number of positive: 1199, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023080 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23603\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2571\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289824 -> initscore=-0.896241\n",
      "[LightGBM] [Info] Start training from score -0.896241\n",
      "[LightGBM] [Info] Number of positive: 1187, number of negative: 2950\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023931 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23788\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2584\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.286923 -> initscore=-0.910376\n",
      "[LightGBM] [Info] Start training from score -0.910376\n",
      "[LightGBM] [Info] Number of positive: 1207, number of negative: 2930\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024137 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23741\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2593\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.291757 -> initscore=-0.886864\n",
      "[LightGBM] [Info] Start training from score -0.886864\n",
      "[LightGBM] [Info] Number of positive: 1199, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031546 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23603\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2571\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289824 -> initscore=-0.896241\n",
      "[LightGBM] [Info] Start training from score -0.896241\n",
      "[LightGBM] [Info] Number of positive: 1187, number of negative: 2950\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028483 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23788\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2584\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.286923 -> initscore=-0.910376\n",
      "[LightGBM] [Info] Start training from score -0.910376\n",
      "[LightGBM] [Info] Number of positive: 1207, number of negative: 2930\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026439 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23741\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2593\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.291757 -> initscore=-0.886864\n",
      "[LightGBM] [Info] Start training from score -0.886864\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023537 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23574\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2584\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029453 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23603\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2577\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026920 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23723\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2593\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023695 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23574\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2584\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022972 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23603\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2577\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025289 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23723\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2593\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027409 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23574\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2584\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031232 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23603\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2577\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n",
      "[LightGBM] [Info] Number of positive: 1200, number of negative: 2937\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031493 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23723\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2593\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290065 -> initscore=-0.895067\n",
      "[LightGBM] [Info] Start training from score -0.895067\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>model_name</th>\n",
       "      <th>split_method</th>\n",
       "      <th>pca</th>\n",
       "      <th>n_components</th>\n",
       "      <th>random_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.983575</td>\n",
       "      <td>RandomForest100</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>15</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0.983575</td>\n",
       "      <td>RandomForest200</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>35</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>0.982609</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>0.982609</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>0.982609</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>35</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.940097</td>\n",
       "      <td>RandomForest100</td>\n",
       "      <td>sss</td>\n",
       "      <td>svd</td>\n",
       "      <td>15</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>0.940097</td>\n",
       "      <td>RandomForest200</td>\n",
       "      <td>sss</td>\n",
       "      <td>pca</td>\n",
       "      <td>15</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.939130</td>\n",
       "      <td>RandomForest150</td>\n",
       "      <td>sss</td>\n",
       "      <td>pca</td>\n",
       "      <td>15</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0.939130</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>sss</td>\n",
       "      <td>svd</td>\n",
       "      <td>15</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.936232</td>\n",
       "      <td>RandomForest100</td>\n",
       "      <td>sss</td>\n",
       "      <td>pca</td>\n",
       "      <td>15</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>216 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     accuracy       model_name split_method   pca n_components random_state\n",
       "36   0.983575  RandomForest100           tt  None           15           25\n",
       "150  0.983575  RandomForest200           tt  None           35           25\n",
       "202  0.982609             LGBM           tt  None           25            9\n",
       "201  0.982609             LGBM           tt  None           25           25\n",
       "206  0.982609             LGBM           tt  None           35          210\n",
       "..        ...              ...          ...   ...          ...          ...\n",
       "29   0.940097  RandomForest100          sss   svd           15          210\n",
       "119  0.940097  RandomForest200          sss   pca           15          210\n",
       "65   0.939130  RandomForest150          sss   pca           15          210\n",
       "191  0.939130             LGBM          sss   svd           15          210\n",
       "11   0.936232  RandomForest100          sss   pca           15          210\n",
       "\n",
       "[216 rows x 6 columns]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = {'RandomForest100': RandomForestClassifier(n_estimators=100),\n",
    "'RandomForest150': RandomForestClassifier(n_estimators=150),         \n",
    " 'RandomForest200': RandomForestClassifier(n_estimators=200),\n",
    " 'LGBM': LGBMClassifier()}\n",
    "\n",
    "test_df_1 = create_acc_df(classes, ['tt', 'sss'], ['pca', 'svd', 'None'], [15, 25, 35])\n",
    "test_df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "2dcf620a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None: 0.9750939345142243\n",
      "pca: 0.9630703166935051\n",
      "svd: 0.9629495437466452\n",
      "\n",
      "\n",
      "RandomForest100: 0.9661120057255322\n",
      "RandomForest200: 0.9673286813383434\n",
      "LGBM: 0.968795848989086\n",
      "RandomForest150: 0.9659151905528719\n"
     ]
    }
   ],
   "source": [
    "for c in test_df_1.pca.unique():\n",
    "    print(str(c) + ': ' + str(test_df_1[test_df_1.pca == c]['accuracy'].mean()))\n",
    "\n",
    "print('\\n')\n",
    "    \n",
    "for c in test_df_1.model_name.unique():\n",
    "    print(str(c) + ': ' + str(test_df_1[test_df_1.model_name == c]['accuracy'].mean()))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "a89d6ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1199, number of negative: 2938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019966 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23327\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2558\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.289824 -> initscore=-0.896241\n",
      "[LightGBM] [Info] Start training from score -0.896241\n",
      "[LightGBM] [Info] Number of positive: 1185, number of negative: 2952\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019430 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23207\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2540\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.286439 -> initscore=-0.912740\n",
      "[LightGBM] [Info] Start training from score -0.912740\n",
      "[LightGBM] [Info] Number of positive: 1179, number of negative: 2958\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019835 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23602\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2568\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.284989 -> initscore=-0.919847\n",
      "[LightGBM] [Info] Start training from score -0.919847\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>model_name</th>\n",
       "      <th>split_method</th>\n",
       "      <th>pca</th>\n",
       "      <th>n_components</th>\n",
       "      <th>random_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.982609</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.979710</td>\n",
       "      <td>RandomForest300</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.979710</td>\n",
       "      <td>RandomForest300</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.978744</td>\n",
       "      <td>RandomForest200</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.977778</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.976812</td>\n",
       "      <td>RandomForest200</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.976812</td>\n",
       "      <td>RandomForest300</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.975845</td>\n",
       "      <td>RandomForest250</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.974879</td>\n",
       "      <td>RandomForest250</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.974879</td>\n",
       "      <td>RandomForest250</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.973913</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.971981</td>\n",
       "      <td>RandomForest200</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    accuracy       model_name split_method   pca n_components random_state\n",
       "11  0.982609             LGBM           tt  None            0           35\n",
       "6   0.979710  RandomForest300           tt  None            0           94\n",
       "8   0.979710  RandomForest300           tt  None            0           35\n",
       "0   0.978744  RandomForest200           tt  None            0           94\n",
       "9   0.977778             LGBM           tt  None            0           94\n",
       "2   0.976812  RandomForest200           tt  None            0           35\n",
       "7   0.976812  RandomForest300           tt  None            0           73\n",
       "3   0.975845  RandomForest250           tt  None            0           94\n",
       "4   0.974879  RandomForest250           tt  None            0           73\n",
       "5   0.974879  RandomForest250           tt  None            0           35\n",
       "10  0.973913             LGBM           tt  None            0           73\n",
       "1   0.971981  RandomForest200           tt  None            0           73"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes_2 = {'RandomForest200': RandomForestClassifier(n_estimators=200),\n",
    "'RandomForest250': RandomForestClassifier(n_estimators=250),         \n",
    " 'RandomForest300': RandomForestClassifier(n_estimators=300),\n",
    " 'LGBM': LGBMClassifier()}\n",
    "\n",
    "test_df_2 = create_acc_df(classes_2, ['tt'], [None], [0], [94, 73, 35])\n",
    "test_df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "069b8b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM: 0.9780998389694041\n",
      "RandomForest300: 0.9787439613526571\n",
      "RandomForest200: 0.9758454106280192\n",
      "RandomForest250: 0.9752012882447666\n"
     ]
    }
   ],
   "source": [
    "for c in test_df_2.model_name.unique():\n",
    "    print(str(c) + ': ' + str(test_df_2[test_df_2.model_name == c]['accuracy'].mean()))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "a4c6b82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1190, number of negative: 2947\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020166 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23419\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2559\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.287648 -> initscore=-0.906834\n",
      "[LightGBM] [Info] Start training from score -0.906834\n",
      "[LightGBM] [Info] Number of positive: 1201, number of negative: 2936\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023706 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23742\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2584\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290307 -> initscore=-0.893894\n",
      "[LightGBM] [Info] Start training from score -0.893894\n",
      "[LightGBM] [Info] Number of positive: 1218, number of negative: 2919\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022749 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23550\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2572\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.294416 -> initscore=-0.874031\n",
      "[LightGBM] [Info] Start training from score -0.874031\n",
      "[LightGBM] [Info] Number of positive: 1214, number of negative: 2923\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022779 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23472\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2564\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.293449 -> initscore=-0.878690\n",
      "[LightGBM] [Info] Start training from score -0.878690\n",
      "[LightGBM] [Info] Number of positive: 1205, number of negative: 2932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024742 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23809\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2610\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.291274 -> initscore=-0.889205\n",
      "[LightGBM] [Info] Start training from score -0.889205\n",
      "[LightGBM] [Info] Number of positive: 1203, number of negative: 2934\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023602 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23436\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2569\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290790 -> initscore=-0.891548\n",
      "[LightGBM] [Info] Start training from score -0.891548\n",
      "[LightGBM] [Info] Number of positive: 1201, number of negative: 2936\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021951 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23911\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2602\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.290307 -> initscore=-0.893894\n",
      "[LightGBM] [Info] Start training from score -0.893894\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>model_name</th>\n",
       "      <th>split_method</th>\n",
       "      <th>pca</th>\n",
       "      <th>n_components</th>\n",
       "      <th>random_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.984541</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.984541</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.984541</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.983575</td>\n",
       "      <td>RandomForest350</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.983575</td>\n",
       "      <td>RandomForest300</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.982609</td>\n",
       "      <td>RandomForest350</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.982609</td>\n",
       "      <td>RandomForest400</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.981643</td>\n",
       "      <td>RandomForest350</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.981643</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.981643</td>\n",
       "      <td>RandomForest300</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.980676</td>\n",
       "      <td>RandomForest400</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.978744</td>\n",
       "      <td>RandomForest400</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.978744</td>\n",
       "      <td>RandomForest300</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.978744</td>\n",
       "      <td>RandomForest350</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.978744</td>\n",
       "      <td>RandomForest300</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.976812</td>\n",
       "      <td>RandomForest350</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.976812</td>\n",
       "      <td>RandomForest300</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.976812</td>\n",
       "      <td>RandomForest400</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.974879</td>\n",
       "      <td>RandomForest400</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.971981</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.971981</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.969082</td>\n",
       "      <td>RandomForest400</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.967150</td>\n",
       "      <td>RandomForest300</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.967150</td>\n",
       "      <td>LGBM</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.966184</td>\n",
       "      <td>RandomForest400</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.965217</td>\n",
       "      <td>RandomForest350</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.964251</td>\n",
       "      <td>RandomForest300</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.963285</td>\n",
       "      <td>RandomForest350</td>\n",
       "      <td>tt</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    accuracy       model_name split_method   pca n_components random_state\n",
       "27  0.984541             LGBM           tt  None            0           21\n",
       "22  0.984541             LGBM           tt  None            0          290\n",
       "21  0.984541             LGBM           tt  None            0          194\n",
       "8   0.983575  RandomForest350           tt  None            0          290\n",
       "1   0.983575  RandomForest300           tt  None            0          290\n",
       "7   0.982609  RandomForest350           tt  None            0          194\n",
       "15  0.982609  RandomForest400           tt  None            0          290\n",
       "13  0.981643  RandomForest350           tt  None            0           21\n",
       "23  0.981643             LGBM           tt  None            0           20\n",
       "6   0.981643  RandomForest300           tt  None            0           21\n",
       "20  0.980676  RandomForest400           tt  None            0           21\n",
       "18  0.978744  RandomForest400           tt  None            0            2\n",
       "0   0.978744  RandomForest300           tt  None            0          194\n",
       "11  0.978744  RandomForest350           tt  None            0            2\n",
       "2   0.978744  RandomForest300           tt  None            0           20\n",
       "9   0.976812  RandomForest350           tt  None            0           20\n",
       "4   0.976812  RandomForest300           tt  None            0            2\n",
       "14  0.976812  RandomForest400           tt  None            0          194\n",
       "16  0.974879  RandomForest400           tt  None            0           20\n",
       "25  0.971981             LGBM           tt  None            0            2\n",
       "26  0.971981             LGBM           tt  None            0           53\n",
       "17  0.969082  RandomForest400           tt  None            0          100\n",
       "3   0.967150  RandomForest300           tt  None            0          100\n",
       "24  0.967150             LGBM           tt  None            0          100\n",
       "19  0.966184  RandomForest400           tt  None            0           53\n",
       "10  0.965217  RandomForest350           tt  None            0          100\n",
       "5   0.964251  RandomForest300           tt  None            0           53\n",
       "12  0.963285  RandomForest350           tt  None            0           53"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes_3 = {'RandomForest300': RandomForestClassifier(n_estimators=300),\n",
    "'RandomForest350': RandomForestClassifier(n_estimators=350),         \n",
    " 'RandomForest400': RandomForestClassifier(n_estimators=400),\n",
    " 'LGBM': LGBMClassifier()}\n",
    "\n",
    "test_df_3 = create_acc_df(classes_3, ['tt'], [None], [0], [194, 290, 20, 100, 2, 53, 21])\n",
    "test_df_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "c30e6b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "def lgbm_rand_seach(X, y, params):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    lgbm = lgb.LGBMClassifier()\n",
    "    \n",
    "    param_dist = params\n",
    "    \n",
    "    random_search = RandomizedSearchCV(\n",
    "    estimator=lgbm,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=10,\n",
    "    scoring='accuracy',\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # Fit RandomizedSearchCV\n",
    "    random_search.fit(X_train, y_train)\n",
    "\n",
    "    # Best parameters and score\n",
    "    print(\"Best parameters found: \", random_search.best_params_)\n",
    "    print(\"Best score: \", random_search.best_score_)\n",
    "\n",
    "    # Predict and evaluate on the test set\n",
    "    best_model = random_search.best_estimator_\n",
    "    test_score = best_model.score(X_test, y_test)\n",
    "    print(\"Test set score: \", test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "f4d9c6a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[LightGBM] [Info] Number of positive: 1204, number of negative: 2933\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043176 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21031\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2582\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.291032 -> initscore=-0.890376\n",
      "[LightGBM] [Info] Start training from score -0.890376\n",
      "Best parameters found:  {'num_leaves': 70, 'n_estimators': 60, 'min_child_samples': 20, 'max_depth': 20, 'learning_rate': 0.2}\n",
      "Best score:  0.9758299306614328\n",
      "Test set score:  0.978743961352657\n"
     ]
    }
   ],
   "source": [
    "'''    param_dist = {\n",
    "        'num_leaves': [31, 50, 70],\n",
    "        'max_depth': [-1, 10, 20, 30],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'n_estimators': [20, 40, 60, 100],\n",
    "        'min_child_samples': [5, 10, 20]\n",
    "    }    \n",
    "'''\n",
    "lgbm_rand_seach(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "217cbcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_1 = {\n",
    "    'num_leaves': [50, 70, 90],\n",
    "    'max_depth': [15, 20, 25, 35],\n",
    "    'learning_rate': [0.225, 0.15, 0.175],\n",
    "    'n_estimators': [80, 60, 100, 120],\n",
    "    'min_child_samples': [10, 20, 30, 25]\n",
    "}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "4fe1cf6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[LightGBM] [Info] Number of positive: 1204, number of negative: 2933\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.037450 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21031\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2582\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.291032 -> initscore=-0.890376\n",
      "[LightGBM] [Info] Start training from score -0.890376\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Best parameters found:  {'num_leaves': 70, 'n_estimators': 120, 'min_child_samples': 20, 'max_depth': 25, 'learning_rate': 0.225}\n",
      "Best score:  0.9767946538621057\n",
      "Test set score:  0.978743961352657\n"
     ]
    }
   ],
   "source": [
    "lgbm_rand_seach(X,y,param_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "e7da3f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_2 = {\n",
    "    'num_leaves': [110, 70, 90],\n",
    "    'max_depth': [30, 22, 25, 35],\n",
    "    'learning_rate': [0.225, 0.25, 0.2],\n",
    "    'n_estimators': [80, 150, 110, 120],\n",
    "    'min_child_samples': [35, 20, 30, 25]\n",
    "}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "c19b05da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[LightGBM] [Info] Number of positive: 1204, number of negative: 2933\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.048650 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21031\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2582\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.291032 -> initscore=-0.890376\n",
      "[LightGBM] [Info] Start training from score -0.890376\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Best parameters found:  {'num_leaves': 70, 'n_estimators': 120, 'min_child_samples': 20, 'max_depth': 25, 'learning_rate': 0.225}\n",
      "Best score:  0.9767946538621057\n",
      "Test set score:  0.978743961352657\n"
     ]
    }
   ],
   "source": [
    "lgbm_rand_seach(X,y,param_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "689721ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_3 = {\n",
    "    'num_leaves': [80, 70, 90],\n",
    "    'max_depth': [22, 25, 28],\n",
    "    'learning_rate': [0.225, 0.25, 0.2],\n",
    "    'n_estimators': [100, 130, 110, 120],\n",
    "    'min_child_samples': [15, 20, 25]\n",
    "}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "451d94f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[LightGBM] [Info] Number of positive: 1204, number of negative: 2933\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030461 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21820\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2808\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.291032 -> initscore=-0.890376\n",
      "[LightGBM] [Info] Start training from score -0.890376\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Best parameters found:  {'num_leaves': 80, 'n_estimators': 130, 'min_child_samples': 15, 'max_depth': 22, 'learning_rate': 0.2}\n",
      "Best score:  0.976553400043227\n",
      "Test set score:  0.9826086956521739\n"
     ]
    }
   ],
   "source": [
    "lgbm_rand_seach(X,y,param_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20014158",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "f69f4602",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_4 = {\n",
    "    'num_leaves': [80, 85, 90],\n",
    "    'max_depth': [22, 25, 20],\n",
    "    'learning_rate': [0.21, 0.19, 0.2],\n",
    "    'n_estimators': [135, 130, 125],\n",
    "    'min_child_samples': [15, 18, 12]\n",
    "}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "6b7e9170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[LightGBM] [Info] Number of positive: 1204, number of negative: 2933\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024100 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21356\n",
      "[LightGBM] [Info] Number of data points in the train set: 4137, number of used features: 2679\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.291032 -> initscore=-0.890376\n",
      "[LightGBM] [Info] Start training from score -0.890376\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Best parameters found:  {'num_leaves': 80, 'n_estimators': 125, 'min_child_samples': 18, 'max_depth': 20, 'learning_rate': 0.19}\n",
      "Best score:  0.977036783905508\n",
      "Test set score:  0.9826086956521739\n"
     ]
    }
   ],
   "source": [
    "lgbm_rand_seach(X,y,param_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "7fe1ed66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM: 0.9780538302277434\n",
      "RandomForest350: 0.975983436853002\n",
      "RandomForest300: 0.9758454106280192\n",
      "RandomForest400: 0.9755693581780537\n"
     ]
    }
   ],
   "source": [
    "for c in test_df_3.model_name.unique():\n",
    "    print(str(c) + ': ' + str(test_df_3[test_df_3.model_name == c]['accuracy'].mean()))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d531b5c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
